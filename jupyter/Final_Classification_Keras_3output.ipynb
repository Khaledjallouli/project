{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Sequantial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 999)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow_core.estimator import inputs\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "\n",
    "from  IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_try1(dataframe):\n",
    "    highestValue = 0;\n",
    "    \n",
    "    for i in range(0,3):\n",
    "        for j in range(0,dataframe.shape[0]):\n",
    "            if highestValue < dataframe[j][i]:\n",
    "                highestValue = dataframe[j][i]\n",
    "                \n",
    "    for i in range(0,3):\n",
    "        for j in range(0,dataframe.shape[0]):\n",
    "                dataframe[j][i] = (dataframe[j][i]/highestValue)\n",
    "    \n",
    "    print(highestValue)\n",
    "    highestValue = 0;\n",
    "    for i in range(3,6):\n",
    "        for j in range(0,dataframe.shape[0]):\n",
    "            if highestValue < dataframe[j][i]:\n",
    "                highestValue = dataframe[j][i]\n",
    "    \n",
    "    for i in range(3,6):\n",
    "        for j in range(0,dataframe.shape[0]):\n",
    "                dataframe[j][i] = (dataframe[j][i]/highestValue)\n",
    "    \n",
    "    print(highestValue)\n",
    "    highestValue = 0;\n",
    "    for i in range(6,12):\n",
    "        for j in range(0,dataframe.shape[0]):\n",
    "            if highestValue < dataframe[j][i]:\n",
    "                highestValue = dataframe[j][i]\n",
    "    \n",
    "    for i in range(6,12):\n",
    "        for j in range(0,dataframe.shape[0]):\n",
    "                dataframe[j][i] = (dataframe[j][i]/highestValue)\n",
    "    \n",
    "    print(highestValue)\n",
    "    highestValue = 0;\n",
    "    for i in range(12,16):\n",
    "        for j in range(0,dataframe.shape[0]):\n",
    "            if highestValue < dataframe[j][i]:\n",
    "                highestValue = dataframe[j][i]\n",
    "    \n",
    "    for i in range(12,16):\n",
    "        for j in range(0,dataframe.shape[0]):\n",
    "                dataframe[j][i] = (dataframe[j][i]/highestValue)\n",
    "    \n",
    "    print(highestValue)\n",
    "    highestValue = 0;\n",
    "    for i in range(16,21):\n",
    "        for j in range(0,dataframe.shape[0]):\n",
    "            if highestValue < dataframe[j][i]:\n",
    "                highestValue = dataframe[j][i]\n",
    "    \n",
    "    for i in range(16,21):\n",
    "        for j in range(0,dataframe.shape[0]):\n",
    "                dataframe[j][i] = (dataframe[j][i]/highestValue)\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def normalize_try(dataframe):\n",
    "    \n",
    "    highestValue = 0;\n",
    "    \n",
    "    for i in range(0,4):\n",
    "        for j in range(0,dataframe.shape[0]):\n",
    "            if highestValue < dataframe[j][i]:\n",
    "                highestValue = dataframe[j][i]\n",
    "                \n",
    "    for i in range(0,4):\n",
    "        for j in range(0,dataframe.shape[0]):\n",
    "                dataframe[j][i] = (dataframe[j][i]/highestValue)\n",
    "    \n",
    "    \n",
    "    \n",
    "    highestValue = 0;\n",
    "    \n",
    "    for i in range(4,7):\n",
    "        for j in range(0,dataframe.shape[0]):\n",
    "            if highestValue < dataframe[j][i]:\n",
    "                highestValue = dataframe[j][i]\n",
    "        print(i)\n",
    "    for i in range(12,15):\n",
    "        for j in range(0,dataframe.shape[0]):\n",
    "            if highestValue < dataframe[j][i]:\n",
    "                highestValue = dataframe[j][i]\n",
    "    for i in range(4,7):\n",
    "        for j in range(0,dataframe.shape[0]):\n",
    "                dataframe[j][i] = (dataframe[j][i]/highestValue)\n",
    "    for i in range(12,15):\n",
    "        for j in range(0,dataframe.shape[0]):\n",
    "                dataframe[j][i] = (dataframe[j][i]/highestValue)\n",
    "    \n",
    "    highestValue = 0;\n",
    "    \n",
    "    for i in range(7,9):\n",
    "        for j in range(0,dataframe.shape[0]):\n",
    "            if highestValue < dataframe[j][i]:\n",
    "                highestValue = dataframe[j][i]\n",
    "    for i in range(15,19):\n",
    "        for j in range(0,dataframe.shape[0]):\n",
    "            if highestValue < dataframe[j][i]:\n",
    "                highestValue = dataframe[j][i]\n",
    "    for i in range(7,9):\n",
    "        for j in range(0,dataframe.shape[0]):\n",
    "                dataframe[j][i] = (dataframe[j][i]/highestValue)\n",
    "    for i in range(15,19):\n",
    "        for j in range(0,dataframe.shape[0]):\n",
    "                dataframe[j][i] = (dataframe[j][i]/highestValue)\n",
    "                \n",
    "    \n",
    "    \n",
    "    highestValue = 0;\n",
    "    \n",
    "    for i in range(9,12):\n",
    "        for j in range(0,dataframe.shape[0]):\n",
    "            if highestValue < dataframe[j][i]:\n",
    "                highestValue = dataframe[j][i]\n",
    "    for i in range(19,21):\n",
    "        for j in range(0,dataframe.shape[0]):\n",
    "            if highestValue < dataframe[j][i]:\n",
    "                highestValue = dataframe[j][i]\n",
    "    for i in range(9,12):\n",
    "        for j in range(0,dataframe.shape[0]):\n",
    "                dataframe[j][i] = (dataframe[j][i]/highestValue)\n",
    "    for i in range(19,21):\n",
    "        for j in range(0,dataframe.shape[0]):\n",
    "                dataframe[j][i] = (dataframe[j][i]/highestValue)\n",
    "                \n",
    "    \n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "\n",
    "\n",
    "def encode(i):\n",
    "    switcher = {\n",
    "        \"H\": 2,\n",
    "        \"D\": 1,\n",
    "        \"A\": 0,\n",
    "        }\n",
    "    # 1 be assigned as default value of passed argument (if goals > 5)\n",
    "    return switcher.get(i, 1)\n",
    "\n",
    "def normalize_and_encode(dataframe):\n",
    "    column_names_to_not_normalize = ['result']\n",
    "    column_names_to_normalize = [x for x in list(dataframe) if x not in column_names_to_not_normalize ]\n",
    "    x = dataframe[column_names_to_normalize].values\n",
    "    x_scaled = preprocessing.normalize(x) #vom alten\n",
    "    std_scale = preprocessing.MinMaxScaler().fit(x)\n",
    "    #x_train_norm = std_scale.transform(x)\n",
    "    x_train_norm = normalize_try(x)\n",
    "    df_temp = pd.DataFrame(x_train_norm, columns=column_names_to_normalize, index = dataframe.index)\n",
    "    dataframe[column_names_to_normalize] = df_temp\n",
    "\n",
    "    #dataframe['result'] = dataframe.apply(lambda row: encode(row['result']), axis=1)\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit([ \"H\", \"D\", \"A\"])\n",
    "    dataframe.loc[:,['result']]=le.transform(dataframe['result'])\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "def get_X_and_y(dataframe):\n",
    "    X = dataframe.drop(columns=['result']).values\n",
    "    y = dataframe[['result']].values\n",
    "    return X,y\n",
    "\n",
    "\n",
    "#def get_lr_schedule(train, batch_size):\n",
    "    #lr_schedule = tf.keras.optimizers.SGD(lr=0.001, clipvalue=0.5)\n",
    "    #tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "    #0.0001, # lr??\n",
    "    #decay_steps=(len(train)//batch_size)*1000,\n",
    "    #decay_rate=1,\n",
    "    #staircase=False)\n",
    "    #return lr_schedule\n",
    "\n",
    "def get_optimizer(train, batch_size):\n",
    "    return tf.keras.optimizers.SGD(lr=0.01, momentum=0.9) \n",
    "            #tf.keras.optimizers.Adam(get_lr_schedule(train, batch_size))\n",
    "\n",
    "\n",
    "def get_callbacks(name):\n",
    "    return [\n",
    "        tfdocs.modeling.EpochDots(),\n",
    "        #tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200),\n",
    "        #tf.keras.callbacks.TensorBoard(logdir/name), # Jupyter Notebook\n",
    "        #tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1) # Google Colab\n",
    "      ]\n",
    "\n",
    "def compile_and_fit(model, name, X, y, validation_split, batch_size, optimizer=None, max_epochs=1000):\n",
    "    if optimizer is None:\n",
    "        optimizer = get_optimizer(X, batch_size)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "     \n",
    "    history = model.fit(\n",
    "        X,\n",
    "        y,\n",
    "        validation_split=validation_split,\n",
    "        batch_size=batch_size,\n",
    "        epochs=max_epochs,\n",
    "        callbacks=get_callbacks(name),\n",
    "        verbose=0)\n",
    "    \n",
    "    model.save(\"../model/%s.h5\" %name) \n",
    "    \n",
    "    return history\n",
    "\n",
    "def plot_history(model_history):\n",
    "\tplt.plot(model_history.history['accuracy'])\n",
    "\tplt.plot(model_history.history['val_accuracy'])\n",
    "\tplt.title(\"%s accuracy\" %model_history)\n",
    "\tplt.ylabel('accuracy')\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.legend(['train', 'val'], loc='upper left')\n",
    "\tplt.show()\n",
    "\t\n",
    "\tplt.plot(model_history.history['loss'])\n",
    "\tplt.plot(model_history.history['val_loss'])\n",
    "\tplt.title(\"%s loss\" %model_history)\n",
    "\tplt.ylabel('loss')\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.legend(['train', 'val'], loc='upper left')\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the sliding window + Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>137</td>\n",
       "      <td>67</td>\n",
       "      <td>117</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>161</td>\n",
       "      <td>78</td>\n",
       "      <td>72</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>134</td>\n",
       "      <td>64</td>\n",
       "      <td>151</td>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>104</td>\n",
       "      <td>44</td>\n",
       "      <td>87</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>120</td>\n",
       "      <td>58</td>\n",
       "      <td>124</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>134</td>\n",
       "      <td>59</td>\n",
       "      <td>100</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.30</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>177</td>\n",
       "      <td>82</td>\n",
       "      <td>74</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>169</td>\n",
       "      <td>95</td>\n",
       "      <td>113</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H</td>\n",
       "      <td>1.20</td>\n",
       "      <td>6.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>161</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>143</td>\n",
       "      <td>69</td>\n",
       "      <td>134</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7028</th>\n",
       "      <td>H</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.70</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>80</td>\n",
       "      <td>43</td>\n",
       "      <td>117</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>119</td>\n",
       "      <td>58</td>\n",
       "      <td>112</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>H</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>89</td>\n",
       "      <td>47</td>\n",
       "      <td>92</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>104</td>\n",
       "      <td>55</td>\n",
       "      <td>63</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7030</th>\n",
       "      <td>H</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.50</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>122</td>\n",
       "      <td>59</td>\n",
       "      <td>92</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>84</td>\n",
       "      <td>43</td>\n",
       "      <td>118</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031</th>\n",
       "      <td>H</td>\n",
       "      <td>1.33</td>\n",
       "      <td>5.25</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>124</td>\n",
       "      <td>62</td>\n",
       "      <td>99</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>103</td>\n",
       "      <td>53</td>\n",
       "      <td>122</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>H</td>\n",
       "      <td>1.67</td>\n",
       "      <td>4.20</td>\n",
       "      <td>5.25</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>105</td>\n",
       "      <td>65</td>\n",
       "      <td>126</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>114</td>\n",
       "      <td>63</td>\n",
       "      <td>106</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7033 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     result  odds-home  odds-draw  odds-away  home-wins  home-draws  \\\n",
       "0         H       3.50       3.30       2.10          1           3   \n",
       "1         D       2.50       3.30       2.88          3           1   \n",
       "2         A       1.91       3.40       4.20          4           2   \n",
       "3         H       3.25       3.25       2.30          5           2   \n",
       "4         H       1.20       6.00      19.00          7           2   \n",
       "...     ...        ...        ...        ...        ...         ...   \n",
       "7028      H       5.00       3.80       1.70          4           2   \n",
       "7029      H       2.00       3.60       3.70          3           2   \n",
       "7030      H       1.80       3.75       4.50          3           3   \n",
       "7031      H       1.33       5.25       9.00          2           3   \n",
       "7032      H       1.67       4.20       5.25          6           1   \n",
       "\n",
       "      home-losses  home-goals  home-opposition-goals  home-shots  \\\n",
       "0               6          11                     16         137   \n",
       "1               6           8                     16         134   \n",
       "2               4          10                     15         120   \n",
       "3               3          22                     12         177   \n",
       "4               1          15                      8         161   \n",
       "...           ...         ...                    ...         ...   \n",
       "7028            4          10                     12          80   \n",
       "7029            5           9                     21          89   \n",
       "7030            4           8                      8         122   \n",
       "7031            5          12                     14         124   \n",
       "7032            3          10                      8         105   \n",
       "\n",
       "      home-shots_on_target  home-opposition_shots  \\\n",
       "0                       67                    117   \n",
       "1                       64                    151   \n",
       "2                       58                    124   \n",
       "3                       82                     74   \n",
       "4                       72                     74   \n",
       "...                    ...                    ...   \n",
       "7028                    43                    117   \n",
       "7029                    47                     92   \n",
       "7030                    59                     92   \n",
       "7031                    62                     99   \n",
       "7032                    65                    126   \n",
       "\n",
       "      home-opposition_shots_on_target  away-wins  away-draws  away-losses  \\\n",
       "0                                  53          8           2            0   \n",
       "1                                  77          3           3            4   \n",
       "2                                  56          2           2            6   \n",
       "3                                  37          6           3            1   \n",
       "4                                  31          3           2            5   \n",
       "...                               ...        ...         ...          ...   \n",
       "7028                               60          2           4            4   \n",
       "7029                               46          1           4            5   \n",
       "7030                               50          5           2            3   \n",
       "7031                               50          3           3            4   \n",
       "7032                               54          3           2            5   \n",
       "\n",
       "      away-goals  away-opposition-goals  away-shots  away-shots_on_target  \\\n",
       "0             15                      6         161                    78   \n",
       "1             11                     18         104                    44   \n",
       "2             11                     15         134                    59   \n",
       "3             19                      8         169                    95   \n",
       "4             10                     17         143                    69   \n",
       "...          ...                    ...         ...                   ...   \n",
       "7028          10                     21         119                    58   \n",
       "7029           7                     21         104                    55   \n",
       "7030          15                      9          84                    43   \n",
       "7031          11                     17         103                    53   \n",
       "7032          13                     19         114                    63   \n",
       "\n",
       "      away-opposition_shots  away-opposition_shots_on_target  \n",
       "0                        72                               30  \n",
       "1                        87                               36  \n",
       "2                       100                               46  \n",
       "3                       113                               58  \n",
       "4                       134                               69  \n",
       "...                     ...                              ...  \n",
       "7028                    112                               65  \n",
       "7029                     63                               26  \n",
       "7030                    118                               56  \n",
       "7031                    122                               54  \n",
       "7032                    106                               46  \n",
       "\n",
       "[7033 rows x 22 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df02 = pd.read_csv('../data/data_classification_results/sliding02_shots.csv', sep=',', index_col=0)\n",
    "df02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "6\n",
      "6329 train examples\n",
      "704 test examples\n"
     ]
    }
   ],
   "source": [
    "n02 = normalize_and_encode(df02)\n",
    "\n",
    "\n",
    "train02, test02 = train_test_split(n02, test_size=0.1, shuffle=False)\n",
    "print(len(train02), 'train examples')\n",
    "print(len(test02), 'test examples')\n",
    "\n",
    "\n",
    "train_X02,train_y02 = get_X_and_y(train02)\n",
    "\n",
    "test_X02,test_y02 = get_X_and_y(test02)\n",
    "\n",
    "train_y02 = to_categorical(train_y02)\n",
    "test_y02 = to_categorical(test_y02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.085366</td>\n",
       "      <td>0.080488</td>\n",
       "      <td>0.051220</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.658654</td>\n",
       "      <td>0.303167</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.239819</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072115</td>\n",
       "      <td>0.028846</td>\n",
       "      <td>0.774038</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.325792</td>\n",
       "      <td>0.135747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.060976</td>\n",
       "      <td>0.080488</td>\n",
       "      <td>0.070244</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.644231</td>\n",
       "      <td>0.289593</td>\n",
       "      <td>0.683258</td>\n",
       "      <td>0.348416</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.052885</td>\n",
       "      <td>0.086538</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.393665</td>\n",
       "      <td>0.162896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.046585</td>\n",
       "      <td>0.082927</td>\n",
       "      <td>0.102439</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.072115</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.262443</td>\n",
       "      <td>0.561086</td>\n",
       "      <td>0.253394</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.052885</td>\n",
       "      <td>0.072115</td>\n",
       "      <td>0.644231</td>\n",
       "      <td>0.283654</td>\n",
       "      <td>0.452489</td>\n",
       "      <td>0.208145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.079268</td>\n",
       "      <td>0.079268</td>\n",
       "      <td>0.056098</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.850962</td>\n",
       "      <td>0.371041</td>\n",
       "      <td>0.334842</td>\n",
       "      <td>0.167421</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.091346</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.456731</td>\n",
       "      <td>0.511312</td>\n",
       "      <td>0.262443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.029268</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.774038</td>\n",
       "      <td>0.325792</td>\n",
       "      <td>0.334842</td>\n",
       "      <td>0.140271</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.048077</td>\n",
       "      <td>0.081731</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.331731</td>\n",
       "      <td>0.606335</td>\n",
       "      <td>0.312217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7028</th>\n",
       "      <td>2</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.092683</td>\n",
       "      <td>0.041463</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.194570</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.271493</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.048077</td>\n",
       "      <td>0.100962</td>\n",
       "      <td>0.572115</td>\n",
       "      <td>0.278846</td>\n",
       "      <td>0.506787</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>2</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.087805</td>\n",
       "      <td>0.090244</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100962</td>\n",
       "      <td>0.427885</td>\n",
       "      <td>0.212670</td>\n",
       "      <td>0.416290</td>\n",
       "      <td>0.208145</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.033654</td>\n",
       "      <td>0.100962</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.264423</td>\n",
       "      <td>0.285068</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7030</th>\n",
       "      <td>2</td>\n",
       "      <td>0.043902</td>\n",
       "      <td>0.091463</td>\n",
       "      <td>0.109756</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.586538</td>\n",
       "      <td>0.266968</td>\n",
       "      <td>0.416290</td>\n",
       "      <td>0.226244</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.072115</td>\n",
       "      <td>0.043269</td>\n",
       "      <td>0.403846</td>\n",
       "      <td>0.206731</td>\n",
       "      <td>0.533937</td>\n",
       "      <td>0.253394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031</th>\n",
       "      <td>2</td>\n",
       "      <td>0.032439</td>\n",
       "      <td>0.128049</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.067308</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.280543</td>\n",
       "      <td>0.447964</td>\n",
       "      <td>0.226244</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.052885</td>\n",
       "      <td>0.081731</td>\n",
       "      <td>0.495192</td>\n",
       "      <td>0.254808</td>\n",
       "      <td>0.552036</td>\n",
       "      <td>0.244344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>2</td>\n",
       "      <td>0.040732</td>\n",
       "      <td>0.102439</td>\n",
       "      <td>0.128049</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.504808</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.570136</td>\n",
       "      <td>0.244344</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.091346</td>\n",
       "      <td>0.548077</td>\n",
       "      <td>0.302885</td>\n",
       "      <td>0.479638</td>\n",
       "      <td>0.208145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7033 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result  odds-home  odds-draw  odds-away  home-wins  home-draws  \\\n",
       "0          2   0.085366   0.080488   0.051220   0.024390    0.066667   \n",
       "1          1   0.060976   0.080488   0.070244   0.073171    0.022222   \n",
       "2          0   0.046585   0.082927   0.102439   0.097561    0.044444   \n",
       "3          2   0.079268   0.079268   0.056098   0.121951    0.044444   \n",
       "4          2   0.029268   0.146341   0.463415   0.170732    0.044444   \n",
       "...      ...        ...        ...        ...        ...         ...   \n",
       "7028       2   0.121951   0.092683   0.041463   0.097561    0.044444   \n",
       "7029       2   0.048780   0.087805   0.090244   0.073171    0.044444   \n",
       "7030       2   0.043902   0.091463   0.109756   0.073171    0.066667   \n",
       "7031       2   0.032439   0.128049   0.219512   0.048780    0.066667   \n",
       "7032       2   0.040732   0.102439   0.128049   0.146341    0.022222   \n",
       "\n",
       "      home-losses  home-goals  home-opposition-goals  home-shots  \\\n",
       "0        0.133333    0.244444               0.076923    0.658654   \n",
       "1        0.133333    0.177778               0.076923    0.644231   \n",
       "2        0.088889    0.222222               0.072115    0.576923   \n",
       "3        0.066667    0.488889               0.057692    0.850962   \n",
       "4        0.022222    0.333333               0.038462    0.774038   \n",
       "...           ...         ...                    ...         ...   \n",
       "7028     0.088889    0.222222               0.057692    0.384615   \n",
       "7029     0.111111    0.200000               0.100962    0.427885   \n",
       "7030     0.088889    0.177778               0.038462    0.586538   \n",
       "7031     0.111111    0.266667               0.067308    0.596154   \n",
       "7032     0.066667    0.222222               0.038462    0.504808   \n",
       "\n",
       "      home-shots_on_target  home-opposition_shots  \\\n",
       "0                 0.303167               0.529412   \n",
       "1                 0.289593               0.683258   \n",
       "2                 0.262443               0.561086   \n",
       "3                 0.371041               0.334842   \n",
       "4                 0.325792               0.334842   \n",
       "...                    ...                    ...   \n",
       "7028              0.194570               0.529412   \n",
       "7029              0.212670               0.416290   \n",
       "7030              0.266968               0.416290   \n",
       "7031              0.280543               0.447964   \n",
       "7032              0.294118               0.570136   \n",
       "\n",
       "      home-opposition_shots_on_target  away-wins  away-draws  away-losses  \\\n",
       "0                            0.239819   0.177778    0.044444     0.000000   \n",
       "1                            0.348416   0.066667    0.066667     0.088889   \n",
       "2                            0.253394   0.044444    0.044444     0.133333   \n",
       "3                            0.167421   0.133333    0.066667     0.022222   \n",
       "4                            0.140271   0.066667    0.044444     0.111111   \n",
       "...                               ...        ...         ...          ...   \n",
       "7028                         0.271493   0.044444    0.088889     0.088889   \n",
       "7029                         0.208145   0.022222    0.088889     0.111111   \n",
       "7030                         0.226244   0.111111    0.044444     0.066667   \n",
       "7031                         0.226244   0.066667    0.066667     0.088889   \n",
       "7032                         0.244344   0.066667    0.044444     0.111111   \n",
       "\n",
       "      away-goals  away-opposition-goals  away-shots  away-shots_on_target  \\\n",
       "0       0.072115               0.028846    0.774038              0.375000   \n",
       "1       0.052885               0.086538    0.500000              0.211538   \n",
       "2       0.052885               0.072115    0.644231              0.283654   \n",
       "3       0.091346               0.038462    0.812500              0.456731   \n",
       "4       0.048077               0.081731    0.687500              0.331731   \n",
       "...          ...                    ...         ...                   ...   \n",
       "7028    0.048077               0.100962    0.572115              0.278846   \n",
       "7029    0.033654               0.100962    0.500000              0.264423   \n",
       "7030    0.072115               0.043269    0.403846              0.206731   \n",
       "7031    0.052885               0.081731    0.495192              0.254808   \n",
       "7032    0.062500               0.091346    0.548077              0.302885   \n",
       "\n",
       "      away-opposition_shots  away-opposition_shots_on_target  \n",
       "0                  0.325792                         0.135747  \n",
       "1                  0.393665                         0.162896  \n",
       "2                  0.452489                         0.208145  \n",
       "3                  0.511312                         0.262443  \n",
       "4                  0.606335                         0.312217  \n",
       "...                     ...                              ...  \n",
       "7028               0.506787                         0.294118  \n",
       "7029               0.285068                         0.117647  \n",
       "7030               0.533937                         0.253394  \n",
       "7031               0.552036                         0.244344  \n",
       "7032               0.479638                         0.208145  \n",
       "\n",
       "[7033 rows x 22 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.085366</td>\n",
       "      <td>0.080488</td>\n",
       "      <td>0.051220</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.658654</td>\n",
       "      <td>0.303167</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.239819</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072115</td>\n",
       "      <td>0.028846</td>\n",
       "      <td>0.774038</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.325792</td>\n",
       "      <td>0.135747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.060976</td>\n",
       "      <td>0.080488</td>\n",
       "      <td>0.070244</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.644231</td>\n",
       "      <td>0.289593</td>\n",
       "      <td>0.683258</td>\n",
       "      <td>0.348416</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.052885</td>\n",
       "      <td>0.086538</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.393665</td>\n",
       "      <td>0.162896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.046585</td>\n",
       "      <td>0.082927</td>\n",
       "      <td>0.102439</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.072115</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.262443</td>\n",
       "      <td>0.561086</td>\n",
       "      <td>0.253394</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.052885</td>\n",
       "      <td>0.072115</td>\n",
       "      <td>0.644231</td>\n",
       "      <td>0.283654</td>\n",
       "      <td>0.452489</td>\n",
       "      <td>0.208145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.079268</td>\n",
       "      <td>0.079268</td>\n",
       "      <td>0.056098</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.850962</td>\n",
       "      <td>0.371041</td>\n",
       "      <td>0.334842</td>\n",
       "      <td>0.167421</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.091346</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.456731</td>\n",
       "      <td>0.511312</td>\n",
       "      <td>0.262443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.029268</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.774038</td>\n",
       "      <td>0.325792</td>\n",
       "      <td>0.334842</td>\n",
       "      <td>0.140271</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.048077</td>\n",
       "      <td>0.081731</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.331731</td>\n",
       "      <td>0.606335</td>\n",
       "      <td>0.312217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7028</th>\n",
       "      <td>2</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.092683</td>\n",
       "      <td>0.041463</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.194570</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.271493</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.048077</td>\n",
       "      <td>0.100962</td>\n",
       "      <td>0.572115</td>\n",
       "      <td>0.278846</td>\n",
       "      <td>0.506787</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>2</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.087805</td>\n",
       "      <td>0.090244</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100962</td>\n",
       "      <td>0.427885</td>\n",
       "      <td>0.212670</td>\n",
       "      <td>0.416290</td>\n",
       "      <td>0.208145</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.033654</td>\n",
       "      <td>0.100962</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.264423</td>\n",
       "      <td>0.285068</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7030</th>\n",
       "      <td>2</td>\n",
       "      <td>0.043902</td>\n",
       "      <td>0.091463</td>\n",
       "      <td>0.109756</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.586538</td>\n",
       "      <td>0.266968</td>\n",
       "      <td>0.416290</td>\n",
       "      <td>0.226244</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.072115</td>\n",
       "      <td>0.043269</td>\n",
       "      <td>0.403846</td>\n",
       "      <td>0.206731</td>\n",
       "      <td>0.533937</td>\n",
       "      <td>0.253394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031</th>\n",
       "      <td>2</td>\n",
       "      <td>0.032439</td>\n",
       "      <td>0.128049</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.067308</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.280543</td>\n",
       "      <td>0.447964</td>\n",
       "      <td>0.226244</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.052885</td>\n",
       "      <td>0.081731</td>\n",
       "      <td>0.495192</td>\n",
       "      <td>0.254808</td>\n",
       "      <td>0.552036</td>\n",
       "      <td>0.244344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>2</td>\n",
       "      <td>0.040732</td>\n",
       "      <td>0.102439</td>\n",
       "      <td>0.128049</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.504808</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.570136</td>\n",
       "      <td>0.244344</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.091346</td>\n",
       "      <td>0.548077</td>\n",
       "      <td>0.302885</td>\n",
       "      <td>0.479638</td>\n",
       "      <td>0.208145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7033 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result  odds-home  odds-draw  odds-away  home-wins  home-draws  \\\n",
       "0          2   0.085366   0.080488   0.051220   0.024390    0.066667   \n",
       "1          1   0.060976   0.080488   0.070244   0.073171    0.022222   \n",
       "2          0   0.046585   0.082927   0.102439   0.097561    0.044444   \n",
       "3          2   0.079268   0.079268   0.056098   0.121951    0.044444   \n",
       "4          2   0.029268   0.146341   0.463415   0.170732    0.044444   \n",
       "...      ...        ...        ...        ...        ...         ...   \n",
       "7028       2   0.121951   0.092683   0.041463   0.097561    0.044444   \n",
       "7029       2   0.048780   0.087805   0.090244   0.073171    0.044444   \n",
       "7030       2   0.043902   0.091463   0.109756   0.073171    0.066667   \n",
       "7031       2   0.032439   0.128049   0.219512   0.048780    0.066667   \n",
       "7032       2   0.040732   0.102439   0.128049   0.146341    0.022222   \n",
       "\n",
       "      home-losses  home-goals  home-opposition-goals  home-shots  \\\n",
       "0        0.133333    0.244444               0.076923    0.658654   \n",
       "1        0.133333    0.177778               0.076923    0.644231   \n",
       "2        0.088889    0.222222               0.072115    0.576923   \n",
       "3        0.066667    0.488889               0.057692    0.850962   \n",
       "4        0.022222    0.333333               0.038462    0.774038   \n",
       "...           ...         ...                    ...         ...   \n",
       "7028     0.088889    0.222222               0.057692    0.384615   \n",
       "7029     0.111111    0.200000               0.100962    0.427885   \n",
       "7030     0.088889    0.177778               0.038462    0.586538   \n",
       "7031     0.111111    0.266667               0.067308    0.596154   \n",
       "7032     0.066667    0.222222               0.038462    0.504808   \n",
       "\n",
       "      home-shots_on_target  home-opposition_shots  \\\n",
       "0                 0.303167               0.529412   \n",
       "1                 0.289593               0.683258   \n",
       "2                 0.262443               0.561086   \n",
       "3                 0.371041               0.334842   \n",
       "4                 0.325792               0.334842   \n",
       "...                    ...                    ...   \n",
       "7028              0.194570               0.529412   \n",
       "7029              0.212670               0.416290   \n",
       "7030              0.266968               0.416290   \n",
       "7031              0.280543               0.447964   \n",
       "7032              0.294118               0.570136   \n",
       "\n",
       "      home-opposition_shots_on_target  away-wins  away-draws  away-losses  \\\n",
       "0                            0.239819   0.177778    0.044444     0.000000   \n",
       "1                            0.348416   0.066667    0.066667     0.088889   \n",
       "2                            0.253394   0.044444    0.044444     0.133333   \n",
       "3                            0.167421   0.133333    0.066667     0.022222   \n",
       "4                            0.140271   0.066667    0.044444     0.111111   \n",
       "...                               ...        ...         ...          ...   \n",
       "7028                         0.271493   0.044444    0.088889     0.088889   \n",
       "7029                         0.208145   0.022222    0.088889     0.111111   \n",
       "7030                         0.226244   0.111111    0.044444     0.066667   \n",
       "7031                         0.226244   0.066667    0.066667     0.088889   \n",
       "7032                         0.244344   0.066667    0.044444     0.111111   \n",
       "\n",
       "      away-goals  away-opposition-goals  away-shots  away-shots_on_target  \\\n",
       "0       0.072115               0.028846    0.774038              0.375000   \n",
       "1       0.052885               0.086538    0.500000              0.211538   \n",
       "2       0.052885               0.072115    0.644231              0.283654   \n",
       "3       0.091346               0.038462    0.812500              0.456731   \n",
       "4       0.048077               0.081731    0.687500              0.331731   \n",
       "...          ...                    ...         ...                   ...   \n",
       "7028    0.048077               0.100962    0.572115              0.278846   \n",
       "7029    0.033654               0.100962    0.500000              0.264423   \n",
       "7030    0.072115               0.043269    0.403846              0.206731   \n",
       "7031    0.052885               0.081731    0.495192              0.254808   \n",
       "7032    0.062500               0.091346    0.548077              0.302885   \n",
       "\n",
       "      away-opposition_shots  away-opposition_shots_on_target  \n",
       "0                  0.325792                         0.135747  \n",
       "1                  0.393665                         0.162896  \n",
       "2                  0.452489                         0.208145  \n",
       "3                  0.511312                         0.262443  \n",
       "4                  0.606335                         0.312217  \n",
       "...                     ...                              ...  \n",
       "7028               0.506787                         0.294118  \n",
       "7029               0.285068                         0.117647  \n",
       "7030               0.533937                         0.253394  \n",
       "7031               0.552036                         0.244344  \n",
       "7032               0.479638                         0.208145  \n",
       "\n",
       "[7033 rows x 22 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "result\n",
       "2    3238\n",
       "0    2035\n",
       "1    1760\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byhomegoal = df02.groupby('result')\n",
    "byhomegoal.size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.046585</td>\n",
       "      <td>0.082927</td>\n",
       "      <td>0.102439</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.072115</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.262443</td>\n",
       "      <td>0.561086</td>\n",
       "      <td>0.253394</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.052885</td>\n",
       "      <td>0.072115</td>\n",
       "      <td>0.644231</td>\n",
       "      <td>0.283654</td>\n",
       "      <td>0.452489</td>\n",
       "      <td>0.208145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.058049</td>\n",
       "      <td>0.080488</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.052885</td>\n",
       "      <td>0.490385</td>\n",
       "      <td>0.212670</td>\n",
       "      <td>0.601810</td>\n",
       "      <td>0.348416</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.052885</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.605769</td>\n",
       "      <td>0.283654</td>\n",
       "      <td>0.552036</td>\n",
       "      <td>0.266968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.063415</td>\n",
       "      <td>0.079268</td>\n",
       "      <td>0.068293</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.600962</td>\n",
       "      <td>0.285068</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.330317</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.495192</td>\n",
       "      <td>0.245192</td>\n",
       "      <td>0.624434</td>\n",
       "      <td>0.343891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.054878</td>\n",
       "      <td>0.079268</td>\n",
       "      <td>0.082927</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.081731</td>\n",
       "      <td>0.427885</td>\n",
       "      <td>0.167421</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.330317</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.033654</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.669683</td>\n",
       "      <td>0.334842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.041463</td>\n",
       "      <td>0.092683</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.052885</td>\n",
       "      <td>0.456731</td>\n",
       "      <td>0.190045</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.330317</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.043269</td>\n",
       "      <td>0.072115</td>\n",
       "      <td>0.504808</td>\n",
       "      <td>0.245192</td>\n",
       "      <td>0.723982</td>\n",
       "      <td>0.357466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3747</th>\n",
       "      <td>2</td>\n",
       "      <td>0.041463</td>\n",
       "      <td>0.092683</td>\n",
       "      <td>0.115854</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.581731</td>\n",
       "      <td>0.289593</td>\n",
       "      <td>0.443439</td>\n",
       "      <td>0.276018</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.048077</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.475962</td>\n",
       "      <td>0.201923</td>\n",
       "      <td>0.506787</td>\n",
       "      <td>0.285068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749</th>\n",
       "      <td>2</td>\n",
       "      <td>0.058049</td>\n",
       "      <td>0.080488</td>\n",
       "      <td>0.070732</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.052885</td>\n",
       "      <td>0.620192</td>\n",
       "      <td>0.303167</td>\n",
       "      <td>0.565611</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.081731</td>\n",
       "      <td>0.591346</td>\n",
       "      <td>0.264423</td>\n",
       "      <td>0.583710</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3750</th>\n",
       "      <td>2</td>\n",
       "      <td>0.043902</td>\n",
       "      <td>0.085366</td>\n",
       "      <td>0.109756</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.004808</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.375566</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.144796</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.067308</td>\n",
       "      <td>0.052885</td>\n",
       "      <td>0.629808</td>\n",
       "      <td>0.264423</td>\n",
       "      <td>0.452489</td>\n",
       "      <td>0.217195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>2</td>\n",
       "      <td>0.036585</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.043269</td>\n",
       "      <td>0.682692</td>\n",
       "      <td>0.343891</td>\n",
       "      <td>0.393665</td>\n",
       "      <td>0.194570</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.033654</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.259615</td>\n",
       "      <td>0.524887</td>\n",
       "      <td>0.244344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3753</th>\n",
       "      <td>2</td>\n",
       "      <td>0.044634</td>\n",
       "      <td>0.082927</td>\n",
       "      <td>0.109756</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.072115</td>\n",
       "      <td>0.466346</td>\n",
       "      <td>0.199095</td>\n",
       "      <td>0.407240</td>\n",
       "      <td>0.144796</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.024038</td>\n",
       "      <td>0.052885</td>\n",
       "      <td>0.528846</td>\n",
       "      <td>0.245192</td>\n",
       "      <td>0.642534</td>\n",
       "      <td>0.312217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5280 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result  odds-home  odds-draw  odds-away  home-wins  home-draws  \\\n",
       "2          0   0.046585   0.082927   0.102439   0.097561    0.044444   \n",
       "5          0   0.058049   0.080488   0.073171   0.073171    0.066667   \n",
       "6          0   0.063415   0.079268   0.068293   0.097561    0.022222   \n",
       "7          0   0.054878   0.079268   0.082927   0.121951    0.044444   \n",
       "9          0   0.041463   0.092683   0.121951   0.146341    0.044444   \n",
       "...      ...        ...        ...        ...        ...         ...   \n",
       "3747       2   0.041463   0.092683   0.115854   0.073171    0.066667   \n",
       "3749       2   0.058049   0.080488   0.070732   0.097561    0.066667   \n",
       "3750       2   0.043902   0.085366   0.109756   0.243902    0.000000   \n",
       "3751       2   0.036585   0.097561   0.170732   0.146341    0.044444   \n",
       "3753       2   0.044634   0.082927   0.109756   0.073171    0.066667   \n",
       "\n",
       "      home-losses  home-goals  home-opposition-goals  home-shots  \\\n",
       "2        0.088889    0.222222               0.072115    0.576923   \n",
       "5        0.088889    0.200000               0.052885    0.490385   \n",
       "6        0.111111    0.333333               0.076923    0.600962   \n",
       "7        0.066667    0.333333               0.081731    0.427885   \n",
       "9        0.044444    0.377778               0.052885    0.456731   \n",
       "...           ...         ...                    ...         ...   \n",
       "3747     0.088889    0.333333               0.076923    0.581731   \n",
       "3749     0.066667    0.155556               0.052885    0.620192   \n",
       "3750     0.000000    0.511111               0.004808    0.875000   \n",
       "3751     0.044444    0.355556               0.043269    0.682692   \n",
       "3753     0.088889    0.266667               0.072115    0.466346   \n",
       "\n",
       "      home-shots_on_target  home-opposition_shots  \\\n",
       "2                 0.262443               0.561086   \n",
       "5                 0.212670               0.601810   \n",
       "6                 0.285068               0.692308   \n",
       "7                 0.167421               0.782805   \n",
       "9                 0.190045               0.647059   \n",
       "...                    ...                    ...   \n",
       "3747              0.289593               0.443439   \n",
       "3749              0.303167               0.565611   \n",
       "3750              0.375566               0.307692   \n",
       "3751              0.343891               0.393665   \n",
       "3753              0.199095               0.407240   \n",
       "\n",
       "      home-opposition_shots_on_target  away-wins  away-draws  away-losses  \\\n",
       "2                            0.253394   0.044444    0.044444     0.133333   \n",
       "5                            0.348416   0.088889    0.044444     0.088889   \n",
       "6                            0.330317   0.088889    0.066667     0.066667   \n",
       "7                            0.330317   0.044444    0.044444     0.133333   \n",
       "9                            0.330317   0.066667    0.044444     0.111111   \n",
       "...                               ...        ...         ...          ...   \n",
       "3747                         0.276018   0.066667    0.066667     0.088889   \n",
       "3749                         0.235294   0.111111    0.044444     0.066667   \n",
       "3750                         0.144796   0.111111    0.066667     0.044444   \n",
       "3751                         0.194570   0.022222    0.066667     0.133333   \n",
       "3753                         0.144796   0.066667    0.044444     0.111111   \n",
       "\n",
       "      away-goals  away-opposition-goals  away-shots  away-shots_on_target  \\\n",
       "2       0.052885               0.072115    0.644231              0.283654   \n",
       "5       0.052885               0.062500    0.605769              0.283654   \n",
       "6       0.062500               0.076923    0.495192              0.245192   \n",
       "7       0.033654               0.057692    0.615385              0.307692   \n",
       "9       0.043269               0.072115    0.504808              0.245192   \n",
       "...          ...                    ...         ...                   ...   \n",
       "3747    0.048077               0.057692    0.475962              0.201923   \n",
       "3749    0.115385               0.081731    0.591346              0.264423   \n",
       "3750    0.067308               0.052885    0.629808              0.264423   \n",
       "3751    0.033654               0.076923    0.538462              0.259615   \n",
       "3753    0.024038               0.052885    0.528846              0.245192   \n",
       "\n",
       "      away-opposition_shots  away-opposition_shots_on_target  \n",
       "2                  0.452489                         0.208145  \n",
       "5                  0.552036                         0.266968  \n",
       "6                  0.624434                         0.343891  \n",
       "7                  0.669683                         0.334842  \n",
       "9                  0.723982                         0.357466  \n",
       "...                     ...                              ...  \n",
       "3747               0.506787                         0.285068  \n",
       "3749               0.583710                         0.294118  \n",
       "3750               0.452489                         0.217195  \n",
       "3751               0.524887                         0.244344  \n",
       "3753               0.642534                         0.312217  \n",
       "\n",
       "[5280 rows x 22 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdA = df02[df02.result == 0].head(1760)\n",
    "fdD = df02[df02.result == 1].head(1760)\n",
    "fdH = df02[df02.result == 2].head(1760)\n",
    "df02 = pd.concat([fdA, fdD])\n",
    "df02 = pd.concat([df02, fdH])\n",
    "\n",
    "df02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "result\n",
       "2    1760\n",
       "1    1760\n",
       "0    1760\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byhomegoal = df02.groupby('result')\n",
    "byhomegoal.size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train02, test02 = train_test_split(df02, test_size=0.1, shuffle=False)\n",
    "print(len(train02), 'train examples')\n",
    "print(len(test02), 'test examples')\n",
    "\n",
    "\n",
    "train_X02,train_y02 = get_X_and_y(train02)\n",
    "\n",
    "test_X02,test_y02 = get_X_and_y(test02)\n",
    "\n",
    "train_y02 = to_categorical(train_y02)\n",
    "test_y02 = to_categorical(test_y02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "shutil.rmtree(logdir, ignore_errors=True)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 20\n",
    "EPOCHS=10000\n",
    "validation_split = 0.2\n",
    "size_histories = {}\n",
    "\n",
    "model02_H3_M = tf.keras.Sequential([\n",
    "  layers.Dense(35, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(20, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(10, activation='relu'),\n",
    "  #layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax'),\n",
    "  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "shutil.rmtree(logdir, ignore_errors=True)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 20\n",
    "EPOCHS=10000\n",
    "validation_split = 0.2\n",
    "size_histories = {}\n",
    "\n",
    "model02_H3_M = tf.keras.Sequential([\n",
    "  layers.Dense(35, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(20, activation='relu',kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "  bias_initializer=initializers.Zeros()),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(10, activation='relu',kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "  bias_initializer=initializers.Zeros()),\n",
    "  #layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax', kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "  bias_initializer=initializers.Zeros()),\n",
    "  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model02_H3_M.compile(optimizer=\"Adam\", loss='categorical_crossentropy', metrics=[ \"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33333305, 0.33333358, 0.33333346],\n",
       "       [0.3333331 , 0.33333352, 0.33333328],\n",
       "       [0.3333334 , 0.3333334 , 0.3333331 ],\n",
       "       ...,\n",
       "       [0.3333334 , 0.33333358, 0.33333305],\n",
       "       [0.33333337, 0.33333352, 0.33333305],\n",
       "       [0.33333334, 0.33333364, 0.33333305]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedResult = model02_H3_M.predict(test_X02, batch_size=BATCH_SIZE)\n",
    "predictedResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynew = model02_H3_M.predict_classes(test_X02)\n",
    "ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 35)                770       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 35)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                720       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 1,733\n",
      "Trainable params: 1,733\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.4640,  loss:1.0648,  val_accuracy:0.4408,  val_loss:1.0736,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.4653,  loss:1.0612,  val_accuracy:0.4408,  val_loss:1.0720,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5418,  loss:0.9650,  val_accuracy:0.5000,  val_loss:0.9961,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5471,  loss:0.9618,  val_accuracy:0.4937,  val_loss:1.0055,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5457,  loss:0.9594,  val_accuracy:0.5016,  val_loss:0.9985,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5426,  loss:0.9614,  val_accuracy:0.5024,  val_loss:0.9988,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5467,  loss:0.9554,  val_accuracy:0.4984,  val_loss:1.0110,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5483,  loss:0.9556,  val_accuracy:0.4976,  val_loss:0.9988,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5487,  loss:0.9571,  val_accuracy:0.4937,  val_loss:1.0075,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5489,  loss:0.9570,  val_accuracy:0.5071,  val_loss:1.0006,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5516,  loss:0.9514,  val_accuracy:0.4984,  val_loss:1.0037,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5524,  loss:0.9527,  val_accuracy:0.4889,  val_loss:1.0083,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5489,  loss:0.9523,  val_accuracy:0.4976,  val_loss:1.0141,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5532,  loss:0.9498,  val_accuracy:0.4897,  val_loss:1.0079,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5485,  loss:0.9520,  val_accuracy:0.4937,  val_loss:1.0073,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5530,  loss:0.9481,  val_accuracy:0.4953,  val_loss:1.0023,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5558,  loss:0.9472,  val_accuracy:0.4976,  val_loss:1.0069,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5629,  loss:0.9468,  val_accuracy:0.4858,  val_loss:1.0086,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5574,  loss:0.9443,  val_accuracy:0.4984,  val_loss:1.0133,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5617,  loss:0.9420,  val_accuracy:0.4921,  val_loss:1.0087,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5615,  loss:0.9428,  val_accuracy:0.4874,  val_loss:1.0124,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5603,  loss:0.9447,  val_accuracy:0.5016,  val_loss:1.0270,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5619,  loss:0.9417,  val_accuracy:0.4889,  val_loss:1.0165,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, accuracy:0.5599,  loss:0.9375,  val_accuracy:0.4921,  val_loss:1.0167,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, accuracy:0.5601,  loss:0.9432,  val_accuracy:0.4984,  val_loss:1.0054,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, accuracy:0.5631,  loss:0.9381,  val_accuracy:0.4921,  val_loss:1.0163,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, accuracy:0.5582,  loss:0.9422,  val_accuracy:0.4929,  val_loss:1.0165,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, accuracy:0.5686,  loss:0.9353,  val_accuracy:0.4826,  val_loss:1.0088,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, accuracy:0.5678,  loss:0.9365,  val_accuracy:0.4810,  val_loss:1.0175,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, accuracy:0.5661,  loss:0.9334,  val_accuracy:0.4826,  val_loss:1.0188,  \n",
      "....................................................................................................\n",
      "Epoch: 3000, accuracy:0.5680,  loss:0.9366,  val_accuracy:0.4842,  val_loss:1.0173,  \n",
      "....................................................................................................\n",
      "Epoch: 3100, accuracy:0.5649,  loss:0.9322,  val_accuracy:0.4937,  val_loss:1.0117,  \n",
      "....................................................................................................\n",
      "Epoch: 3200, accuracy:0.5722,  loss:0.9297,  val_accuracy:0.4826,  val_loss:1.0228,  \n",
      "....................................................................................................\n",
      "Epoch: 3300, accuracy:0.5740,  loss:0.9314,  val_accuracy:0.4810,  val_loss:1.0330,  \n",
      "....................................................................................................\n",
      "Epoch: 3400, accuracy:0.5692,  loss:0.9309,  val_accuracy:0.4897,  val_loss:1.0168,  \n",
      "....................................................................................................\n",
      "Epoch: 3500, accuracy:0.5726,  loss:0.9257,  val_accuracy:0.4961,  val_loss:1.0238,  \n",
      "....................................................................................................\n",
      "Epoch: 3600, accuracy:0.5663,  loss:0.9342,  val_accuracy:0.4897,  val_loss:1.0240,  \n",
      "....................................................................................................\n",
      "Epoch: 3700, accuracy:0.5771,  loss:0.9262,  val_accuracy:0.4803,  val_loss:1.0280,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 3800, accuracy:0.5682,  loss:0.9310,  val_accuracy:0.4882,  val_loss:1.0217,  \n",
      "....................................................................................................\n",
      "Epoch: 3900, accuracy:0.5746,  loss:0.9307,  val_accuracy:0.4897,  val_loss:1.0209,  \n",
      "....................................................................................................\n",
      "Epoch: 4000, accuracy:0.5688,  loss:0.9271,  val_accuracy:0.4803,  val_loss:1.0189,  \n",
      "....................................................................................................\n",
      "Epoch: 4100, accuracy:0.5783,  loss:0.9239,  val_accuracy:0.4834,  val_loss:1.0203,  \n",
      "....................................................................................................\n",
      "Epoch: 4200, accuracy:0.5700,  loss:0.9288,  val_accuracy:0.4913,  val_loss:1.0206,  \n",
      "....................................................................................................\n",
      "Epoch: 4300, accuracy:0.5742,  loss:0.9260,  val_accuracy:0.4810,  val_loss:1.0226,  \n",
      "....................................................................................................\n",
      "Epoch: 4400, accuracy:0.5779,  loss:0.9257,  val_accuracy:0.4992,  val_loss:1.0326,  \n",
      "....................................................................................................\n",
      "Epoch: 4500, accuracy:0.5740,  loss:0.9209,  val_accuracy:0.4826,  val_loss:1.0327,  \n",
      "....................................................................................................\n",
      "Epoch: 4600, accuracy:0.5684,  loss:0.9237,  val_accuracy:0.4921,  val_loss:1.0505,  \n",
      "....................................................................................................\n",
      "Epoch: 4700, accuracy:0.5720,  loss:0.9232,  val_accuracy:0.4842,  val_loss:1.0247,  \n",
      "....................................................................................................\n",
      "Epoch: 4800, accuracy:0.5673,  loss:0.9259,  val_accuracy:0.4803,  val_loss:1.0311,  \n",
      "....................................................................................................\n",
      "Epoch: 4900, accuracy:0.5767,  loss:0.9222,  val_accuracy:0.4858,  val_loss:1.0322,  \n",
      "....................................................................................................\n",
      "Epoch: 5000, accuracy:0.5771,  loss:0.9237,  val_accuracy:0.4929,  val_loss:1.0277,  \n",
      "....................................................................................................\n",
      "Epoch: 5100, accuracy:0.5846,  loss:0.9220,  val_accuracy:0.4889,  val_loss:1.0189,  \n",
      "....................................................................................................\n",
      "Epoch: 5200, accuracy:0.5698,  loss:0.9261,  val_accuracy:0.4874,  val_loss:1.0312,  \n",
      "....................................................................................................\n",
      "Epoch: 5300, accuracy:0.5779,  loss:0.9164,  val_accuracy:0.4834,  val_loss:1.0299,  \n",
      "....................................................................................................\n",
      "Epoch: 5400, accuracy:0.5779,  loss:0.9175,  val_accuracy:0.4866,  val_loss:1.0298,  \n",
      "....................................................................................................\n",
      "Epoch: 5500, accuracy:0.5799,  loss:0.9178,  val_accuracy:0.4810,  val_loss:1.0367,  \n",
      "....................................................................................................\n",
      "Epoch: 5600, accuracy:0.5840,  loss:0.9192,  val_accuracy:0.4889,  val_loss:1.0301,  \n",
      "....................................................................................................\n",
      "Epoch: 5700, accuracy:0.5783,  loss:0.9182,  val_accuracy:0.4771,  val_loss:1.0363,  \n",
      "....................................................................................................\n",
      "Epoch: 5800, accuracy:0.5700,  loss:0.9196,  val_accuracy:0.4795,  val_loss:1.0363,  \n",
      "....................................................................................................\n",
      "Epoch: 5900, accuracy:0.5769,  loss:0.9246,  val_accuracy:0.4826,  val_loss:1.0248,  \n",
      "....................................................................................................\n",
      "Epoch: 6000, accuracy:0.5702,  loss:0.9229,  val_accuracy:0.4795,  val_loss:1.0297,  \n",
      "....................................................................................................\n",
      "Epoch: 6100, accuracy:0.5750,  loss:0.9199,  val_accuracy:0.4818,  val_loss:1.0334,  \n",
      "....................................................................................................\n",
      "Epoch: 6200, accuracy:0.5748,  loss:0.9208,  val_accuracy:0.4755,  val_loss:1.0341,  \n",
      "....................................................................................................\n",
      "Epoch: 6300, accuracy:0.5686,  loss:0.9209,  val_accuracy:0.4826,  val_loss:1.0319,  \n",
      "....................................................................................................\n",
      "Epoch: 6400, accuracy:0.5734,  loss:0.9156,  val_accuracy:0.4779,  val_loss:1.0400,  \n",
      "....................................................................................................\n",
      "Epoch: 6500, accuracy:0.5777,  loss:0.9176,  val_accuracy:0.4724,  val_loss:1.0396,  \n",
      "....................................................................................................\n",
      "Epoch: 6600, accuracy:0.5682,  loss:0.9273,  val_accuracy:0.4795,  val_loss:1.0316,  \n",
      "....................................................................................................\n",
      "Epoch: 6700, accuracy:0.5755,  loss:0.9239,  val_accuracy:0.4937,  val_loss:1.0358,  \n",
      "....................................................................................................\n",
      "Epoch: 6800, accuracy:0.5752,  loss:0.9259,  val_accuracy:0.4795,  val_loss:1.0396,  \n",
      "....................................................................................................\n",
      "Epoch: 6900, accuracy:0.5821,  loss:0.9201,  val_accuracy:0.4818,  val_loss:1.0372,  \n",
      "....................................................................................................\n",
      "Epoch: 7000, accuracy:0.5813,  loss:0.9161,  val_accuracy:0.4755,  val_loss:1.0345,  \n",
      "....................................................................................................\n",
      "Epoch: 7100, accuracy:0.5803,  loss:0.9183,  val_accuracy:0.4976,  val_loss:1.0241,  \n",
      "....................................................................................................\n",
      "Epoch: 7200, accuracy:0.5759,  loss:0.9202,  val_accuracy:0.4897,  val_loss:1.0294,  \n",
      "....................................................................................................\n",
      "Epoch: 7300, accuracy:0.5801,  loss:0.9198,  val_accuracy:0.4945,  val_loss:1.0279,  \n",
      "....................................................................................................\n",
      "Epoch: 7400, accuracy:0.5856,  loss:0.9135,  val_accuracy:0.4882,  val_loss:1.0385,  \n",
      "....................................................................................................\n",
      "Epoch: 7500, accuracy:0.5763,  loss:0.9134,  val_accuracy:0.4889,  val_loss:1.0349,  \n",
      "....................................................................................................\n",
      "Epoch: 7600, accuracy:0.5848,  loss:0.9038,  val_accuracy:0.4905,  val_loss:1.0482,  \n",
      "....................................................................................................\n",
      "Epoch: 7700, accuracy:0.5775,  loss:0.9198,  val_accuracy:0.4842,  val_loss:1.0390,  \n",
      "....................................................................................................\n",
      "Epoch: 7800, accuracy:0.5817,  loss:0.9105,  val_accuracy:0.4795,  val_loss:1.0457,  \n",
      "....................................................................................................\n",
      "Epoch: 7900, accuracy:0.5791,  loss:0.9204,  val_accuracy:0.4755,  val_loss:1.0467,  \n",
      "....................................................................................................\n",
      "Epoch: 8000, accuracy:0.5773,  loss:0.9229,  val_accuracy:0.4826,  val_loss:1.0354,  \n",
      "....................................................................................................\n",
      "Epoch: 8100, accuracy:0.5823,  loss:0.9168,  val_accuracy:0.4905,  val_loss:1.0278,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 8200, accuracy:0.5872,  loss:0.9120,  val_accuracy:0.4795,  val_loss:1.0478,  \n",
      "....................................................................................................\n",
      "Epoch: 8300, accuracy:0.5795,  loss:0.9193,  val_accuracy:0.4818,  val_loss:1.0372,  \n",
      "....................................................................................................\n",
      "Epoch: 8400, accuracy:0.5815,  loss:0.9161,  val_accuracy:0.4818,  val_loss:1.0389,  \n",
      "....................................................................................................\n",
      "Epoch: 8500, accuracy:0.5724,  loss:0.9230,  val_accuracy:0.4779,  val_loss:1.0370,  \n",
      "....................................................................................................\n",
      "Epoch: 8600, accuracy:0.5785,  loss:0.9162,  val_accuracy:0.4945,  val_loss:1.0294,  \n",
      "....................................................................................................\n",
      "Epoch: 8700, accuracy:0.5773,  loss:0.9182,  val_accuracy:0.4976,  val_loss:1.0311,  \n",
      "....................................................................................................\n",
      "Epoch: 8800, accuracy:0.5844,  loss:0.9174,  val_accuracy:0.4882,  val_loss:1.0335,  \n",
      "....................................................................................................\n",
      "Epoch: 8900, accuracy:0.5807,  loss:0.9184,  val_accuracy:0.4779,  val_loss:1.0381,  \n",
      "....................................................................................................\n",
      "Epoch: 9000, accuracy:0.5807,  loss:0.9171,  val_accuracy:0.4882,  val_loss:1.0319,  \n",
      "....................................................................................................\n",
      "Epoch: 9100, accuracy:0.5842,  loss:0.9120,  val_accuracy:0.4795,  val_loss:1.0393,  \n",
      "....................................................................................................\n",
      "Epoch: 9200, accuracy:0.5777,  loss:0.9160,  val_accuracy:0.4810,  val_loss:1.0424,  \n",
      "....................................................................................................\n",
      "Epoch: 9300, accuracy:0.5862,  loss:0.9148,  val_accuracy:0.4882,  val_loss:1.0344,  \n",
      "....................................................................................................\n",
      "Epoch: 9400, accuracy:0.5842,  loss:0.9123,  val_accuracy:0.4905,  val_loss:1.0379,  \n",
      "....................................................................................................\n",
      "Epoch: 9500, accuracy:0.5823,  loss:0.9206,  val_accuracy:0.4850,  val_loss:1.0382,  \n",
      "....................................................................................................\n",
      "Epoch: 9600, accuracy:0.5807,  loss:0.9114,  val_accuracy:0.4803,  val_loss:1.0391,  \n",
      "....................................................................................................\n",
      "Epoch: 9700, accuracy:0.5805,  loss:0.9191,  val_accuracy:0.4834,  val_loss:1.0346,  \n",
      "....................................................................................................\n",
      "Epoch: 9800, accuracy:0.5819,  loss:0.9136,  val_accuracy:0.4795,  val_loss:1.0454,  \n",
      "....................................................................................................\n",
      "Epoch: 9900, accuracy:0.5876,  loss:0.9030,  val_accuracy:0.4882,  val_loss:1.0301,  \n",
      "...................................................................................................."
     ]
    }
   ],
   "source": [
    "size_histories['model02_H3_M'] = compile_and_fit(model02_H3_M, 'model02_H3_M', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE, max_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model02_H3_M\n",
      "Loss: 1.0017564703117718\n",
      "Test Accuracy: 0.5113636\n"
     ]
    }
   ],
   "source": [
    "model = load_model('../model/model02_H3_M.h5')\n",
    "score = model.evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02_H3_M\")\n",
    "print(\"Loss:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'loss', smoothing_std=10)\n",
    "plotter.plot(size_histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedResult = model.predict(test_X02, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0046908 , 0.04058318, 0.9547261 ],\n",
       "       [0.1502635 , 0.250177  , 0.5995595 ],\n",
       "       [0.5794233 , 0.27182478, 0.14875193],\n",
       "       ...,\n",
       "       [0.17626457, 0.27602327, 0.54771215],\n",
       "       [0.09578377, 0.22974223, 0.67447394],\n",
       "       [0.16703495, 0.25382823, 0.5791368 ]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, ..., 1, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynewtrin = model.predict_classes(train_X02)\n",
    "ynewtrin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prob: Predicting only two classes instead of 3!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 2, 0, 2, 2, 0, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 0, 2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 2, 0, 0, 2, 2, 2, 2, 2,\n",
       "       0, 0, 2, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 0, 2, 2, 0, 0, 2,\n",
       "       2, 0, 2, 2, 0, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 0, 2, 1, 1, 0, 2,\n",
       "       2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 2, 0, 0, 1, 1, 0, 2, 2, 2,\n",
       "       2, 0, 1, 2, 2, 2, 2, 2, 2, 1, 1, 0, 2, 2, 0, 2, 2, 0, 2, 1, 2, 2,\n",
       "       2, 2, 2, 0, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 0, 2, 2, 2, 2, 2, 1, 2,\n",
       "       2, 2, 0, 1, 1, 2, 2, 0, 1, 2, 2, 2, 2, 1, 2, 2, 0, 0, 1, 2, 2, 2,\n",
       "       2, 0, 0, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2, 0,\n",
       "       2, 0, 2, 2, 1, 0, 1, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0,\n",
       "       2, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0, 1, 2, 1, 2, 2, 2, 1, 2,\n",
       "       2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 0, 2, 2, 2, 2, 1, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 0, 2, 2, 0,\n",
       "       1, 1, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 0, 0, 2, 2,\n",
       "       2, 2, 2, 1, 1, 1, 0, 2, 1, 1, 1, 0, 2, 2, 0, 2, 2, 2, 1, 2, 0, 2,\n",
       "       2, 2, 2, 0, 0, 1, 0, 2, 2, 0, 2, 1, 2, 1, 2, 2, 2, 2, 2, 0, 2, 2,\n",
       "       0, 2, 2, 2, 1, 0, 0, 2, 2, 0, 2, 2, 2, 0, 1, 0, 2, 2, 0, 1, 2, 0,\n",
       "       0, 1, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0, 0, 2, 0, 2, 1, 2, 0,\n",
       "       2, 2, 0, 2, 1, 0, 2, 2, 2, 0, 2, 0, 2, 2, 2, 1, 2, 2, 1, 0, 2, 2,\n",
       "       1, 2, 0, 2, 2, 2, 2, 2, 0, 0, 1, 2, 2, 2, 2, 0, 0, 1, 2, 2, 2, 1,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 0, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 0,\n",
       "       0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2,\n",
       "       1, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 0,\n",
       "       2, 0, 2, 2, 0, 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 1, 1,\n",
       "       2, 2, 0, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 2, 2,\n",
       "       0, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 2, 0, 2,\n",
       "       1, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 1, 2, 2, 0, 2, 2, 2, 1, 2, 2,\n",
       "       0, 2, 2, 2, 1, 0, 1, 2, 2, 2, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 1, 0, 0, 0, 1, 2, 2, 2, 0,\n",
       "       0, 0, 2, 2, 2, 0, 2, 0, 2, 1, 2, 2, 0, 2, 0, 0, 2, 2, 2, 0, 2, 2,\n",
       "       0, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 0, 2, 2, 2, 2, 0, 0,\n",
       "       2, 2, 2, 1, 2, 0, 2, 0, 0, 2, 0, 2, 2, 2, 2, 1, 2, 0, 2, 2, 2, 2],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynew = model.predict_classes(test_X02)\n",
    "ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y02 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
