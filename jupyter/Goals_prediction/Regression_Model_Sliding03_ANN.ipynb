{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Regression_Model_Sliding03_ANN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMQmP-Bknt5P",
        "colab_type": "text"
      },
      "source": [
        "# Regression\n",
        "Predict the final goals scored per each team."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FtJth4hT577a",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', 999)\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.estimator import inputs\n",
        "from tensorflow import feature_column\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.modeling\n",
        "import tensorflow_docs.plots\n",
        "\n",
        "from  IPython import display\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import pathlib\n",
        "import shutil\n",
        "import tempfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVI7Xp89n15I",
        "colab_type": "code",
        "outputId": "980c23d0-e0de-4351-bdbb-1d98c088d547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "pip install git+https://github.com/tensorflow/docs"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/tensorflow/docs\n",
            "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-d0afoiat\n",
            "  Running command git clone -q https://github.com/tensorflow/docs /tmp/pip-req-build-d0afoiat\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.6/dist-packages (from tensorflow-docs===0.0.08f33bfd07a3990ed05925c186c765baf687d1bd0-) (0.8.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow-docs===0.0.08f33bfd07a3990ed05925c186c765baf687d1bd0-) (0.9.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from tensorflow-docs===0.0.08f33bfd07a3990ed05925c186c765baf687d1bd0-) (3.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from tensorflow-docs===0.0.08f33bfd07a3990ed05925c186c765baf687d1bd0-) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py->tensorflow-docs===0.0.08f33bfd07a3990ed05925c186c765baf687d1bd0-) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->tensorflow-docs===0.0.08f33bfd07a3990ed05925c186c765baf687d1bd0-) (47.1.1)\n",
            "Building wheels for collected packages: tensorflow-docs\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-docs: filename=tensorflow_docs-0.0.08f33bfd07a3990ed05925c186c765baf687d1bd0_-cp36-none-any.whl size=114636 sha256=b335e0ca6bc3b28d2903afd5b22065fdbd5dd22a9758cc31134a570aab8b6a4a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tkbonxsk/wheels/eb/1b/35/fce87697be00d2fc63e0b4b395b0d9c7e391a10e98d9a0d97f\n",
            "Successfully built tensorflow-docs\n",
            "Installing collected packages: tensorflow-docs\n",
            "Successfully installed tensorflow-docs-0.0.08f33bfd07a3990ed05925c186c765baf687d1bd0-\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmP557n8nt5X",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing\n",
        "    1. Normalization\n",
        "    2. Data encoding: The goals [0,10] => [-1,1]. If Goal > 10 => 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_NuYqrJnt5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df03 = pd.read_csv('https://raw.githubusercontent.com/Khaledjallouli/project/master/data/data_regression_goals/sliding03_goals.csv', sep=',', index_col=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFm2Qfk2nt5c",
        "colab_type": "code",
        "outputId": "e7d003b0-17ab-4d05-f62f-5e9abe0cdece",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        }
      },
      "source": [
        "df03"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>home_team_goal</th>\n",
              "      <th>away_team_goal</th>\n",
              "      <th>odds-home</th>\n",
              "      <th>odds-draw</th>\n",
              "      <th>odds-away</th>\n",
              "      <th>home-wins</th>\n",
              "      <th>home-draws</th>\n",
              "      <th>home-losses</th>\n",
              "      <th>home-goals</th>\n",
              "      <th>home-opposition-goals</th>\n",
              "      <th>home-shots</th>\n",
              "      <th>home-shots_on_target</th>\n",
              "      <th>home-opposition_shots</th>\n",
              "      <th>home-opposition_shots_on_target</th>\n",
              "      <th>away-wins</th>\n",
              "      <th>away-draws</th>\n",
              "      <th>away-losses</th>\n",
              "      <th>away-goals</th>\n",
              "      <th>away-opposition-goals</th>\n",
              "      <th>away-shots</th>\n",
              "      <th>away-shots_on_target</th>\n",
              "      <th>away-opposition_shots</th>\n",
              "      <th>away-opposition_shots_on_target</th>\n",
              "      <th>home_shot_accuracy</th>\n",
              "      <th>home_shot_efficiency</th>\n",
              "      <th>home_opposition_shot_accuracy</th>\n",
              "      <th>home_opposition_shot_efficiency</th>\n",
              "      <th>away_shot_accuracy</th>\n",
              "      <th>away_shot_efficiency</th>\n",
              "      <th>away_opposition_shot_accuracy</th>\n",
              "      <th>away_opposition_shot_efficiency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.30</td>\n",
              "      <td>2.10</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>16</td>\n",
              "      <td>137</td>\n",
              "      <td>67</td>\n",
              "      <td>117</td>\n",
              "      <td>53</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>6</td>\n",
              "      <td>161</td>\n",
              "      <td>78</td>\n",
              "      <td>72</td>\n",
              "      <td>30</td>\n",
              "      <td>0.489051</td>\n",
              "      <td>0.164179</td>\n",
              "      <td>0.452991</td>\n",
              "      <td>0.301887</td>\n",
              "      <td>0.484472</td>\n",
              "      <td>0.192308</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2.50</td>\n",
              "      <td>3.30</td>\n",
              "      <td>2.88</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>16</td>\n",
              "      <td>134</td>\n",
              "      <td>64</td>\n",
              "      <td>151</td>\n",
              "      <td>77</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>18</td>\n",
              "      <td>104</td>\n",
              "      <td>44</td>\n",
              "      <td>87</td>\n",
              "      <td>36</td>\n",
              "      <td>0.477612</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.509934</td>\n",
              "      <td>0.207792</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.413793</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1.91</td>\n",
              "      <td>3.40</td>\n",
              "      <td>4.20</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>15</td>\n",
              "      <td>120</td>\n",
              "      <td>58</td>\n",
              "      <td>124</td>\n",
              "      <td>56</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>15</td>\n",
              "      <td>134</td>\n",
              "      <td>59</td>\n",
              "      <td>100</td>\n",
              "      <td>46</td>\n",
              "      <td>0.483333</td>\n",
              "      <td>0.172414</td>\n",
              "      <td>0.451613</td>\n",
              "      <td>0.267857</td>\n",
              "      <td>0.440299</td>\n",
              "      <td>0.186441</td>\n",
              "      <td>0.460000</td>\n",
              "      <td>0.326087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.25</td>\n",
              "      <td>2.30</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>22</td>\n",
              "      <td>12</td>\n",
              "      <td>177</td>\n",
              "      <td>82</td>\n",
              "      <td>74</td>\n",
              "      <td>37</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>8</td>\n",
              "      <td>169</td>\n",
              "      <td>95</td>\n",
              "      <td>113</td>\n",
              "      <td>58</td>\n",
              "      <td>0.463277</td>\n",
              "      <td>0.268293</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.324324</td>\n",
              "      <td>0.562130</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.513274</td>\n",
              "      <td>0.137931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1.20</td>\n",
              "      <td>6.00</td>\n",
              "      <td>19.00</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>8</td>\n",
              "      <td>161</td>\n",
              "      <td>72</td>\n",
              "      <td>74</td>\n",
              "      <td>31</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>17</td>\n",
              "      <td>143</td>\n",
              "      <td>69</td>\n",
              "      <td>134</td>\n",
              "      <td>69</td>\n",
              "      <td>0.447205</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.418919</td>\n",
              "      <td>0.258065</td>\n",
              "      <td>0.482517</td>\n",
              "      <td>0.144928</td>\n",
              "      <td>0.514925</td>\n",
              "      <td>0.246377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7028</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.80</td>\n",
              "      <td>1.70</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>80</td>\n",
              "      <td>43</td>\n",
              "      <td>117</td>\n",
              "      <td>60</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>21</td>\n",
              "      <td>119</td>\n",
              "      <td>58</td>\n",
              "      <td>112</td>\n",
              "      <td>65</td>\n",
              "      <td>0.537500</td>\n",
              "      <td>0.232558</td>\n",
              "      <td>0.512821</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.487395</td>\n",
              "      <td>0.172414</td>\n",
              "      <td>0.580357</td>\n",
              "      <td>0.323077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7029</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2.00</td>\n",
              "      <td>3.60</td>\n",
              "      <td>3.70</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>21</td>\n",
              "      <td>89</td>\n",
              "      <td>47</td>\n",
              "      <td>92</td>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>21</td>\n",
              "      <td>104</td>\n",
              "      <td>55</td>\n",
              "      <td>63</td>\n",
              "      <td>26</td>\n",
              "      <td>0.528090</td>\n",
              "      <td>0.191489</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.456522</td>\n",
              "      <td>0.528846</td>\n",
              "      <td>0.127273</td>\n",
              "      <td>0.412698</td>\n",
              "      <td>0.807692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7030</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1.80</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.50</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>122</td>\n",
              "      <td>59</td>\n",
              "      <td>92</td>\n",
              "      <td>50</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "      <td>9</td>\n",
              "      <td>84</td>\n",
              "      <td>43</td>\n",
              "      <td>118</td>\n",
              "      <td>56</td>\n",
              "      <td>0.483607</td>\n",
              "      <td>0.135593</td>\n",
              "      <td>0.543478</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>0.511905</td>\n",
              "      <td>0.348837</td>\n",
              "      <td>0.474576</td>\n",
              "      <td>0.160714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7031</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1.33</td>\n",
              "      <td>5.25</td>\n",
              "      <td>9.00</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>14</td>\n",
              "      <td>124</td>\n",
              "      <td>62</td>\n",
              "      <td>99</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>17</td>\n",
              "      <td>103</td>\n",
              "      <td>53</td>\n",
              "      <td>122</td>\n",
              "      <td>54</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.193548</td>\n",
              "      <td>0.505051</td>\n",
              "      <td>0.280000</td>\n",
              "      <td>0.514563</td>\n",
              "      <td>0.207547</td>\n",
              "      <td>0.442623</td>\n",
              "      <td>0.314815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7032</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1.67</td>\n",
              "      <td>4.20</td>\n",
              "      <td>5.25</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>105</td>\n",
              "      <td>65</td>\n",
              "      <td>126</td>\n",
              "      <td>54</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>19</td>\n",
              "      <td>114</td>\n",
              "      <td>63</td>\n",
              "      <td>106</td>\n",
              "      <td>46</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.148148</td>\n",
              "      <td>0.552632</td>\n",
              "      <td>0.206349</td>\n",
              "      <td>0.433962</td>\n",
              "      <td>0.413043</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7033 rows Ã— 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      home_team_goal  away_team_goal  odds-home  odds-draw  odds-away  \\\n",
              "0                  2               1       3.50       3.30       2.10   \n",
              "1                  2               2       2.50       3.30       2.88   \n",
              "2                  1               2       1.91       3.40       4.20   \n",
              "3                  2               1       3.25       3.25       2.30   \n",
              "4                  3               0       1.20       6.00      19.00   \n",
              "...              ...             ...        ...        ...        ...   \n",
              "7028               2               1       5.00       3.80       1.70   \n",
              "7029               4               2       2.00       3.60       3.70   \n",
              "7030               4               1       1.80       3.75       4.50   \n",
              "7031               3               1       1.33       5.25       9.00   \n",
              "7032               3               1       1.67       4.20       5.25   \n",
              "\n",
              "      home-wins  home-draws  home-losses  home-goals  home-opposition-goals  \\\n",
              "0             1           3            6          11                     16   \n",
              "1             3           1            6           8                     16   \n",
              "2             4           2            4          10                     15   \n",
              "3             5           2            3          22                     12   \n",
              "4             7           2            1          15                      8   \n",
              "...         ...         ...          ...         ...                    ...   \n",
              "7028          4           2            4          10                     12   \n",
              "7029          3           2            5           9                     21   \n",
              "7030          3           3            4           8                      8   \n",
              "7031          2           3            5          12                     14   \n",
              "7032          6           1            3          10                      8   \n",
              "\n",
              "      home-shots  home-shots_on_target  home-opposition_shots  \\\n",
              "0            137                    67                    117   \n",
              "1            134                    64                    151   \n",
              "2            120                    58                    124   \n",
              "3            177                    82                     74   \n",
              "4            161                    72                     74   \n",
              "...          ...                   ...                    ...   \n",
              "7028          80                    43                    117   \n",
              "7029          89                    47                     92   \n",
              "7030         122                    59                     92   \n",
              "7031         124                    62                     99   \n",
              "7032         105                    65                    126   \n",
              "\n",
              "      home-opposition_shots_on_target  away-wins  away-draws  away-losses  \\\n",
              "0                                  53          8           2            0   \n",
              "1                                  77          3           3            4   \n",
              "2                                  56          2           2            6   \n",
              "3                                  37          6           3            1   \n",
              "4                                  31          3           2            5   \n",
              "...                               ...        ...         ...          ...   \n",
              "7028                               60          2           4            4   \n",
              "7029                               46          1           4            5   \n",
              "7030                               50          5           2            3   \n",
              "7031                               50          3           3            4   \n",
              "7032                               54          3           2            5   \n",
              "\n",
              "      away-goals  away-opposition-goals  away-shots  away-shots_on_target  \\\n",
              "0             15                      6         161                    78   \n",
              "1             11                     18         104                    44   \n",
              "2             11                     15         134                    59   \n",
              "3             19                      8         169                    95   \n",
              "4             10                     17         143                    69   \n",
              "...          ...                    ...         ...                   ...   \n",
              "7028          10                     21         119                    58   \n",
              "7029           7                     21         104                    55   \n",
              "7030          15                      9          84                    43   \n",
              "7031          11                     17         103                    53   \n",
              "7032          13                     19         114                    63   \n",
              "\n",
              "      away-opposition_shots  away-opposition_shots_on_target  \\\n",
              "0                        72                               30   \n",
              "1                        87                               36   \n",
              "2                       100                               46   \n",
              "3                       113                               58   \n",
              "4                       134                               69   \n",
              "...                     ...                              ...   \n",
              "7028                    112                               65   \n",
              "7029                     63                               26   \n",
              "7030                    118                               56   \n",
              "7031                    122                               54   \n",
              "7032                    106                               46   \n",
              "\n",
              "      home_shot_accuracy  home_shot_efficiency  home_opposition_shot_accuracy  \\\n",
              "0               0.489051              0.164179                       0.452991   \n",
              "1               0.477612              0.125000                       0.509934   \n",
              "2               0.483333              0.172414                       0.451613   \n",
              "3               0.463277              0.268293                       0.500000   \n",
              "4               0.447205              0.208333                       0.418919   \n",
              "...                  ...                   ...                            ...   \n",
              "7028            0.537500              0.232558                       0.512821   \n",
              "7029            0.528090              0.191489                       0.500000   \n",
              "7030            0.483607              0.135593                       0.543478   \n",
              "7031            0.500000              0.193548                       0.505051   \n",
              "7032            0.619048              0.153846                       0.428571   \n",
              "\n",
              "      home_opposition_shot_efficiency  away_shot_accuracy  \\\n",
              "0                            0.301887            0.484472   \n",
              "1                            0.207792            0.423077   \n",
              "2                            0.267857            0.440299   \n",
              "3                            0.324324            0.562130   \n",
              "4                            0.258065            0.482517   \n",
              "...                               ...                 ...   \n",
              "7028                         0.200000            0.487395   \n",
              "7029                         0.456522            0.528846   \n",
              "7030                         0.160000            0.511905   \n",
              "7031                         0.280000            0.514563   \n",
              "7032                         0.148148            0.552632   \n",
              "\n",
              "      away_shot_efficiency  away_opposition_shot_accuracy  \\\n",
              "0                 0.192308                       0.416667   \n",
              "1                 0.250000                       0.413793   \n",
              "2                 0.186441                       0.460000   \n",
              "3                 0.200000                       0.513274   \n",
              "4                 0.144928                       0.514925   \n",
              "...                    ...                            ...   \n",
              "7028              0.172414                       0.580357   \n",
              "7029              0.127273                       0.412698   \n",
              "7030              0.348837                       0.474576   \n",
              "7031              0.207547                       0.442623   \n",
              "7032              0.206349                       0.433962   \n",
              "\n",
              "      away_opposition_shot_efficiency  \n",
              "0                            0.200000  \n",
              "1                            0.500000  \n",
              "2                            0.326087  \n",
              "3                            0.137931  \n",
              "4                            0.246377  \n",
              "...                               ...  \n",
              "7028                         0.323077  \n",
              "7029                         0.807692  \n",
              "7030                         0.160714  \n",
              "7031                         0.314815  \n",
              "7032                         0.413043  \n",
              "\n",
              "[7033 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzti9zrknt5h",
        "colab_type": "code",
        "outputId": "3dc55a6f-0bb6-4d87-a30f-aa670fff6bb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "byhomegoal = df03.groupby('home_team_goal')\n",
        "byhomegoal.size().sort_values(ascending=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "home_team_goal\n",
              "1     2251\n",
              "2     1732\n",
              "0     1589\n",
              "3      885\n",
              "4      378\n",
              "5      132\n",
              "6       43\n",
              "7       13\n",
              "8        7\n",
              "9        2\n",
              "10       1\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V2WCPxmnt5m",
        "colab_type": "code",
        "outputId": "e2bc8cb4-d80c-4b1e-c0ae-d04963702c76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "byawaygoal = df03.groupby('away_team_goal')\n",
        "byawaygoal.size().sort_values(ascending=False)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "away_team_goal\n",
              "1    2381\n",
              "0    2362\n",
              "2    1401\n",
              "3     613\n",
              "4     193\n",
              "5      52\n",
              "6      23\n",
              "8       5\n",
              "7       2\n",
              "9       1\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6MockV_nt5p",
        "colab_type": "text"
      },
      "source": [
        "### =>The two previous cells show that we can keep 6 classes: [0.5].\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwHnhYEynt5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_X_and_y(dataframe):\n",
        "    X = dataframe.drop(columns=['home_team_goal','away_team_goal']).values\n",
        "    y = dataframe[['home_team_goal','away_team_goal']].values\n",
        "    return X,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyNjI6jPnt5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode(i):\n",
        "    switcher = {\n",
        "        0: -1,\n",
        "        1: -0.6,\n",
        "        2: -0.2,\n",
        "        3: 0.2,\n",
        "        4: 0.6,\n",
        "        5: 1,\n",
        "    }\n",
        "    # 1 be assigned as default value of passed argument (if goals > 5)\n",
        "    return switcher.get(i, 1)\n",
        "\n",
        "def decode(i):\n",
        "    switcher = {\n",
        "          -1: 0,\n",
        "        -0.6: 1,\n",
        "        -0.2: 2,\n",
        "         0.2: 3,\n",
        "         0.6: 4,\n",
        "           1: 5,\n",
        "    }\n",
        "    return switcher.get(i, \"ERROR! Use Encode Before!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOw4-355nt5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(dataframe):\n",
        "    column_names_to_not_normalize = ['home_team_goal','away_team_goal']\n",
        "    column_names_to_normalize = [x for x in list(dataframe) if x not in column_names_to_not_normalize ]\n",
        "    x = dataframe[column_names_to_normalize].values\n",
        "    x_scaled = preprocessing.normalize(x)\n",
        "    df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = dataframe.index)\n",
        "    dataframe[column_names_to_normalize] = df_temp\n",
        "    \n",
        "    dataframe['home_team_goal'] = dataframe.apply(lambda row: encode(row['home_team_goal']), axis=1)\n",
        "    dataframe['away_team_goal'] = dataframe.apply(lambda row: encode(row['away_team_goal']), axis=1)\n",
        "    \n",
        "    return dataframe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PmG9M4ent52",
        "colab_type": "code",
        "outputId": "967797bc-3484-4042-9ae9-c70b29b3cd4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "n03 = normalize(df03)\n",
        "\n",
        "train02, test02 = train_test_split(n03, test_size=0.1, shuffle=False)\n",
        "print(len(train02), 'train examples')\n",
        "print(len(test02), 'test examples')\n",
        "\n",
        "\n",
        "train_X02,train_y02 = get_X_and_y(train02)\n",
        "\n",
        "test_X02,test_y02 = get_X_and_y(test02)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6329 train examples\n",
            "704 test examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTAm_MXlnt54",
        "colab_type": "code",
        "outputId": "02f45fdd-19d4-4d9d-b7e2-6e2478829b2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        }
      },
      "source": [
        "n03"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>home_team_goal</th>\n",
              "      <th>away_team_goal</th>\n",
              "      <th>odds-home</th>\n",
              "      <th>odds-draw</th>\n",
              "      <th>odds-away</th>\n",
              "      <th>home-wins</th>\n",
              "      <th>home-draws</th>\n",
              "      <th>home-losses</th>\n",
              "      <th>home-goals</th>\n",
              "      <th>home-opposition-goals</th>\n",
              "      <th>home-shots</th>\n",
              "      <th>home-shots_on_target</th>\n",
              "      <th>home-opposition_shots</th>\n",
              "      <th>home-opposition_shots_on_target</th>\n",
              "      <th>away-wins</th>\n",
              "      <th>away-draws</th>\n",
              "      <th>away-losses</th>\n",
              "      <th>away-goals</th>\n",
              "      <th>away-opposition-goals</th>\n",
              "      <th>away-shots</th>\n",
              "      <th>away-shots_on_target</th>\n",
              "      <th>away-opposition_shots</th>\n",
              "      <th>away-opposition_shots_on_target</th>\n",
              "      <th>home_shot_accuracy</th>\n",
              "      <th>home_shot_efficiency</th>\n",
              "      <th>home_opposition_shot_accuracy</th>\n",
              "      <th>home_opposition_shot_efficiency</th>\n",
              "      <th>away_shot_accuracy</th>\n",
              "      <th>away_shot_efficiency</th>\n",
              "      <th>away_opposition_shot_accuracy</th>\n",
              "      <th>away_opposition_shot_efficiency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.012482</td>\n",
              "      <td>0.011769</td>\n",
              "      <td>0.007489</td>\n",
              "      <td>0.003566</td>\n",
              "      <td>0.010699</td>\n",
              "      <td>0.021398</td>\n",
              "      <td>0.039229</td>\n",
              "      <td>0.057061</td>\n",
              "      <td>0.488583</td>\n",
              "      <td>0.238942</td>\n",
              "      <td>0.417257</td>\n",
              "      <td>0.189014</td>\n",
              "      <td>0.028530</td>\n",
              "      <td>0.007133</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.053495</td>\n",
              "      <td>0.021398</td>\n",
              "      <td>0.574174</td>\n",
              "      <td>0.278171</td>\n",
              "      <td>0.256774</td>\n",
              "      <td>0.106989</td>\n",
              "      <td>0.001744</td>\n",
              "      <td>0.000586</td>\n",
              "      <td>0.001616</td>\n",
              "      <td>0.001077</td>\n",
              "      <td>0.001728</td>\n",
              "      <td>0.000686</td>\n",
              "      <td>0.001486</td>\n",
              "      <td>0.000713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.009236</td>\n",
              "      <td>0.012191</td>\n",
              "      <td>0.010640</td>\n",
              "      <td>0.011083</td>\n",
              "      <td>0.003694</td>\n",
              "      <td>0.022166</td>\n",
              "      <td>0.029555</td>\n",
              "      <td>0.059109</td>\n",
              "      <td>0.495039</td>\n",
              "      <td>0.236437</td>\n",
              "      <td>0.557843</td>\n",
              "      <td>0.284463</td>\n",
              "      <td>0.011083</td>\n",
              "      <td>0.011083</td>\n",
              "      <td>0.014777</td>\n",
              "      <td>0.040638</td>\n",
              "      <td>0.066498</td>\n",
              "      <td>0.384210</td>\n",
              "      <td>0.162550</td>\n",
              "      <td>0.321406</td>\n",
              "      <td>0.132996</td>\n",
              "      <td>0.001764</td>\n",
              "      <td>0.000462</td>\n",
              "      <td>0.001884</td>\n",
              "      <td>0.000768</td>\n",
              "      <td>0.001563</td>\n",
              "      <td>0.000924</td>\n",
              "      <td>0.001529</td>\n",
              "      <td>0.001847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.007188</td>\n",
              "      <td>0.012795</td>\n",
              "      <td>0.015805</td>\n",
              "      <td>0.015053</td>\n",
              "      <td>0.007526</td>\n",
              "      <td>0.015053</td>\n",
              "      <td>0.037632</td>\n",
              "      <td>0.056448</td>\n",
              "      <td>0.451581</td>\n",
              "      <td>0.218264</td>\n",
              "      <td>0.466634</td>\n",
              "      <td>0.210738</td>\n",
              "      <td>0.007526</td>\n",
              "      <td>0.007526</td>\n",
              "      <td>0.022579</td>\n",
              "      <td>0.041395</td>\n",
              "      <td>0.056448</td>\n",
              "      <td>0.504266</td>\n",
              "      <td>0.222028</td>\n",
              "      <td>0.376318</td>\n",
              "      <td>0.173106</td>\n",
              "      <td>0.001819</td>\n",
              "      <td>0.000649</td>\n",
              "      <td>0.001699</td>\n",
              "      <td>0.001008</td>\n",
              "      <td>0.001657</td>\n",
              "      <td>0.000702</td>\n",
              "      <td>0.001731</td>\n",
              "      <td>0.001227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.010289</td>\n",
              "      <td>0.010289</td>\n",
              "      <td>0.007281</td>\n",
              "      <td>0.015829</td>\n",
              "      <td>0.006331</td>\n",
              "      <td>0.009497</td>\n",
              "      <td>0.069646</td>\n",
              "      <td>0.037989</td>\n",
              "      <td>0.560335</td>\n",
              "      <td>0.259590</td>\n",
              "      <td>0.234264</td>\n",
              "      <td>0.117132</td>\n",
              "      <td>0.018994</td>\n",
              "      <td>0.009497</td>\n",
              "      <td>0.003166</td>\n",
              "      <td>0.060149</td>\n",
              "      <td>0.025326</td>\n",
              "      <td>0.535009</td>\n",
              "      <td>0.300745</td>\n",
              "      <td>0.357728</td>\n",
              "      <td>0.183613</td>\n",
              "      <td>0.001467</td>\n",
              "      <td>0.000849</td>\n",
              "      <td>0.001583</td>\n",
              "      <td>0.001027</td>\n",
              "      <td>0.001780</td>\n",
              "      <td>0.000633</td>\n",
              "      <td>0.001625</td>\n",
              "      <td>0.000437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.004077</td>\n",
              "      <td>0.020384</td>\n",
              "      <td>0.064550</td>\n",
              "      <td>0.023782</td>\n",
              "      <td>0.006795</td>\n",
              "      <td>0.003397</td>\n",
              "      <td>0.050961</td>\n",
              "      <td>0.027179</td>\n",
              "      <td>0.546979</td>\n",
              "      <td>0.244612</td>\n",
              "      <td>0.251406</td>\n",
              "      <td>0.105319</td>\n",
              "      <td>0.010192</td>\n",
              "      <td>0.006795</td>\n",
              "      <td>0.016987</td>\n",
              "      <td>0.033974</td>\n",
              "      <td>0.057756</td>\n",
              "      <td>0.485826</td>\n",
              "      <td>0.234419</td>\n",
              "      <td>0.455249</td>\n",
              "      <td>0.234419</td>\n",
              "      <td>0.001519</td>\n",
              "      <td>0.000708</td>\n",
              "      <td>0.001423</td>\n",
              "      <td>0.000877</td>\n",
              "      <td>0.001639</td>\n",
              "      <td>0.000492</td>\n",
              "      <td>0.001749</td>\n",
              "      <td>0.000837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7028</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.020289</td>\n",
              "      <td>0.015420</td>\n",
              "      <td>0.006898</td>\n",
              "      <td>0.016231</td>\n",
              "      <td>0.008116</td>\n",
              "      <td>0.016231</td>\n",
              "      <td>0.040578</td>\n",
              "      <td>0.048693</td>\n",
              "      <td>0.324623</td>\n",
              "      <td>0.174485</td>\n",
              "      <td>0.474761</td>\n",
              "      <td>0.243467</td>\n",
              "      <td>0.008116</td>\n",
              "      <td>0.016231</td>\n",
              "      <td>0.016231</td>\n",
              "      <td>0.040578</td>\n",
              "      <td>0.085213</td>\n",
              "      <td>0.482876</td>\n",
              "      <td>0.235351</td>\n",
              "      <td>0.454472</td>\n",
              "      <td>0.263756</td>\n",
              "      <td>0.002181</td>\n",
              "      <td>0.000944</td>\n",
              "      <td>0.002081</td>\n",
              "      <td>0.000812</td>\n",
              "      <td>0.001978</td>\n",
              "      <td>0.000700</td>\n",
              "      <td>0.002355</td>\n",
              "      <td>0.001311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7029</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.009960</td>\n",
              "      <td>0.017928</td>\n",
              "      <td>0.018426</td>\n",
              "      <td>0.014940</td>\n",
              "      <td>0.009960</td>\n",
              "      <td>0.024900</td>\n",
              "      <td>0.044821</td>\n",
              "      <td>0.104582</td>\n",
              "      <td>0.443228</td>\n",
              "      <td>0.234064</td>\n",
              "      <td>0.458168</td>\n",
              "      <td>0.229084</td>\n",
              "      <td>0.004980</td>\n",
              "      <td>0.019920</td>\n",
              "      <td>0.024900</td>\n",
              "      <td>0.034861</td>\n",
              "      <td>0.104582</td>\n",
              "      <td>0.517929</td>\n",
              "      <td>0.273905</td>\n",
              "      <td>0.313745</td>\n",
              "      <td>0.129482</td>\n",
              "      <td>0.002630</td>\n",
              "      <td>0.000954</td>\n",
              "      <td>0.002490</td>\n",
              "      <td>0.002274</td>\n",
              "      <td>0.002634</td>\n",
              "      <td>0.000634</td>\n",
              "      <td>0.002055</td>\n",
              "      <td>0.004022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7030</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.007617</td>\n",
              "      <td>0.015870</td>\n",
              "      <td>0.019043</td>\n",
              "      <td>0.012696</td>\n",
              "      <td>0.012696</td>\n",
              "      <td>0.016927</td>\n",
              "      <td>0.033855</td>\n",
              "      <td>0.033855</td>\n",
              "      <td>0.516288</td>\n",
              "      <td>0.249680</td>\n",
              "      <td>0.389332</td>\n",
              "      <td>0.211593</td>\n",
              "      <td>0.021159</td>\n",
              "      <td>0.008464</td>\n",
              "      <td>0.012696</td>\n",
              "      <td>0.063478</td>\n",
              "      <td>0.038087</td>\n",
              "      <td>0.355477</td>\n",
              "      <td>0.181970</td>\n",
              "      <td>0.499360</td>\n",
              "      <td>0.236985</td>\n",
              "      <td>0.002047</td>\n",
              "      <td>0.000574</td>\n",
              "      <td>0.002300</td>\n",
              "      <td>0.000677</td>\n",
              "      <td>0.002166</td>\n",
              "      <td>0.001476</td>\n",
              "      <td>0.002008</td>\n",
              "      <td>0.000680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7031</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.005271</td>\n",
              "      <td>0.020806</td>\n",
              "      <td>0.035667</td>\n",
              "      <td>0.007926</td>\n",
              "      <td>0.011889</td>\n",
              "      <td>0.019815</td>\n",
              "      <td>0.047556</td>\n",
              "      <td>0.055482</td>\n",
              "      <td>0.491412</td>\n",
              "      <td>0.245706</td>\n",
              "      <td>0.392337</td>\n",
              "      <td>0.198150</td>\n",
              "      <td>0.011889</td>\n",
              "      <td>0.011889</td>\n",
              "      <td>0.015852</td>\n",
              "      <td>0.043593</td>\n",
              "      <td>0.067371</td>\n",
              "      <td>0.408189</td>\n",
              "      <td>0.210039</td>\n",
              "      <td>0.483486</td>\n",
              "      <td>0.214002</td>\n",
              "      <td>0.001981</td>\n",
              "      <td>0.000767</td>\n",
              "      <td>0.002002</td>\n",
              "      <td>0.001110</td>\n",
              "      <td>0.002039</td>\n",
              "      <td>0.000823</td>\n",
              "      <td>0.001754</td>\n",
              "      <td>0.001248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7032</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.006541</td>\n",
              "      <td>0.016450</td>\n",
              "      <td>0.020563</td>\n",
              "      <td>0.023500</td>\n",
              "      <td>0.003917</td>\n",
              "      <td>0.011750</td>\n",
              "      <td>0.039167</td>\n",
              "      <td>0.031334</td>\n",
              "      <td>0.411255</td>\n",
              "      <td>0.254586</td>\n",
              "      <td>0.493506</td>\n",
              "      <td>0.211503</td>\n",
              "      <td>0.011750</td>\n",
              "      <td>0.007833</td>\n",
              "      <td>0.019584</td>\n",
              "      <td>0.050917</td>\n",
              "      <td>0.074418</td>\n",
              "      <td>0.446505</td>\n",
              "      <td>0.246753</td>\n",
              "      <td>0.415172</td>\n",
              "      <td>0.180169</td>\n",
              "      <td>0.002425</td>\n",
              "      <td>0.000603</td>\n",
              "      <td>0.001679</td>\n",
              "      <td>0.000580</td>\n",
              "      <td>0.002164</td>\n",
              "      <td>0.000808</td>\n",
              "      <td>0.001700</td>\n",
              "      <td>0.001618</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7033 rows Ã— 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      home_team_goal  away_team_goal  odds-home  odds-draw  odds-away  \\\n",
              "0                1.0             1.0   0.012482   0.011769   0.007489   \n",
              "1                1.0             1.0   0.009236   0.012191   0.010640   \n",
              "2                1.0             1.0   0.007188   0.012795   0.015805   \n",
              "3                1.0             1.0   0.010289   0.010289   0.007281   \n",
              "4                1.0             1.0   0.004077   0.020384   0.064550   \n",
              "...              ...             ...        ...        ...        ...   \n",
              "7028             1.0             1.0   0.020289   0.015420   0.006898   \n",
              "7029             1.0             1.0   0.009960   0.017928   0.018426   \n",
              "7030             1.0             1.0   0.007617   0.015870   0.019043   \n",
              "7031             1.0             1.0   0.005271   0.020806   0.035667   \n",
              "7032             1.0             1.0   0.006541   0.016450   0.020563   \n",
              "\n",
              "      home-wins  home-draws  home-losses  home-goals  home-opposition-goals  \\\n",
              "0      0.003566    0.010699     0.021398    0.039229               0.057061   \n",
              "1      0.011083    0.003694     0.022166    0.029555               0.059109   \n",
              "2      0.015053    0.007526     0.015053    0.037632               0.056448   \n",
              "3      0.015829    0.006331     0.009497    0.069646               0.037989   \n",
              "4      0.023782    0.006795     0.003397    0.050961               0.027179   \n",
              "...         ...         ...          ...         ...                    ...   \n",
              "7028   0.016231    0.008116     0.016231    0.040578               0.048693   \n",
              "7029   0.014940    0.009960     0.024900    0.044821               0.104582   \n",
              "7030   0.012696    0.012696     0.016927    0.033855               0.033855   \n",
              "7031   0.007926    0.011889     0.019815    0.047556               0.055482   \n",
              "7032   0.023500    0.003917     0.011750    0.039167               0.031334   \n",
              "\n",
              "      home-shots  home-shots_on_target  home-opposition_shots  \\\n",
              "0       0.488583              0.238942               0.417257   \n",
              "1       0.495039              0.236437               0.557843   \n",
              "2       0.451581              0.218264               0.466634   \n",
              "3       0.560335              0.259590               0.234264   \n",
              "4       0.546979              0.244612               0.251406   \n",
              "...          ...                   ...                    ...   \n",
              "7028    0.324623              0.174485               0.474761   \n",
              "7029    0.443228              0.234064               0.458168   \n",
              "7030    0.516288              0.249680               0.389332   \n",
              "7031    0.491412              0.245706               0.392337   \n",
              "7032    0.411255              0.254586               0.493506   \n",
              "\n",
              "      home-opposition_shots_on_target  away-wins  away-draws  away-losses  \\\n",
              "0                            0.189014   0.028530    0.007133     0.000000   \n",
              "1                            0.284463   0.011083    0.011083     0.014777   \n",
              "2                            0.210738   0.007526    0.007526     0.022579   \n",
              "3                            0.117132   0.018994    0.009497     0.003166   \n",
              "4                            0.105319   0.010192    0.006795     0.016987   \n",
              "...                               ...        ...         ...          ...   \n",
              "7028                         0.243467   0.008116    0.016231     0.016231   \n",
              "7029                         0.229084   0.004980    0.019920     0.024900   \n",
              "7030                         0.211593   0.021159    0.008464     0.012696   \n",
              "7031                         0.198150   0.011889    0.011889     0.015852   \n",
              "7032                         0.211503   0.011750    0.007833     0.019584   \n",
              "\n",
              "      away-goals  away-opposition-goals  away-shots  away-shots_on_target  \\\n",
              "0       0.053495               0.021398    0.574174              0.278171   \n",
              "1       0.040638               0.066498    0.384210              0.162550   \n",
              "2       0.041395               0.056448    0.504266              0.222028   \n",
              "3       0.060149               0.025326    0.535009              0.300745   \n",
              "4       0.033974               0.057756    0.485826              0.234419   \n",
              "...          ...                    ...         ...                   ...   \n",
              "7028    0.040578               0.085213    0.482876              0.235351   \n",
              "7029    0.034861               0.104582    0.517929              0.273905   \n",
              "7030    0.063478               0.038087    0.355477              0.181970   \n",
              "7031    0.043593               0.067371    0.408189              0.210039   \n",
              "7032    0.050917               0.074418    0.446505              0.246753   \n",
              "\n",
              "      away-opposition_shots  away-opposition_shots_on_target  \\\n",
              "0                  0.256774                         0.106989   \n",
              "1                  0.321406                         0.132996   \n",
              "2                  0.376318                         0.173106   \n",
              "3                  0.357728                         0.183613   \n",
              "4                  0.455249                         0.234419   \n",
              "...                     ...                              ...   \n",
              "7028               0.454472                         0.263756   \n",
              "7029               0.313745                         0.129482   \n",
              "7030               0.499360                         0.236985   \n",
              "7031               0.483486                         0.214002   \n",
              "7032               0.415172                         0.180169   \n",
              "\n",
              "      home_shot_accuracy  home_shot_efficiency  home_opposition_shot_accuracy  \\\n",
              "0               0.001744              0.000586                       0.001616   \n",
              "1               0.001764              0.000462                       0.001884   \n",
              "2               0.001819              0.000649                       0.001699   \n",
              "3               0.001467              0.000849                       0.001583   \n",
              "4               0.001519              0.000708                       0.001423   \n",
              "...                  ...                   ...                            ...   \n",
              "7028            0.002181              0.000944                       0.002081   \n",
              "7029            0.002630              0.000954                       0.002490   \n",
              "7030            0.002047              0.000574                       0.002300   \n",
              "7031            0.001981              0.000767                       0.002002   \n",
              "7032            0.002425              0.000603                       0.001679   \n",
              "\n",
              "      home_opposition_shot_efficiency  away_shot_accuracy  \\\n",
              "0                            0.001077            0.001728   \n",
              "1                            0.000768            0.001563   \n",
              "2                            0.001008            0.001657   \n",
              "3                            0.001027            0.001780   \n",
              "4                            0.000877            0.001639   \n",
              "...                               ...                 ...   \n",
              "7028                         0.000812            0.001978   \n",
              "7029                         0.002274            0.002634   \n",
              "7030                         0.000677            0.002166   \n",
              "7031                         0.001110            0.002039   \n",
              "7032                         0.000580            0.002164   \n",
              "\n",
              "      away_shot_efficiency  away_opposition_shot_accuracy  \\\n",
              "0                 0.000686                       0.001486   \n",
              "1                 0.000924                       0.001529   \n",
              "2                 0.000702                       0.001731   \n",
              "3                 0.000633                       0.001625   \n",
              "4                 0.000492                       0.001749   \n",
              "...                    ...                            ...   \n",
              "7028              0.000700                       0.002355   \n",
              "7029              0.000634                       0.002055   \n",
              "7030              0.001476                       0.002008   \n",
              "7031              0.000823                       0.001754   \n",
              "7032              0.000808                       0.001700   \n",
              "\n",
              "      away_opposition_shot_efficiency  \n",
              "0                            0.000713  \n",
              "1                            0.001847  \n",
              "2                            0.001227  \n",
              "3                            0.000437  \n",
              "4                            0.000837  \n",
              "...                               ...  \n",
              "7028                         0.001311  \n",
              "7029                         0.004022  \n",
              "7030                         0.000680  \n",
              "7031                         0.001248  \n",
              "7032                         0.001618  \n",
              "\n",
              "[7033 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44kHTmIWnt57",
        "colab_type": "code",
        "outputId": "49f7df1f-3a7d-46a2-a93c-325b77c1f0db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# verif the classes\n",
        "byhomegoal = df03.groupby('home_team_goal')\n",
        "byhomegoal.size().sort_values(ascending=False)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "home_team_goal\n",
              " 1.0    6835\n",
              "-0.6     198\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrUTbaq5nt5-",
        "colab_type": "code",
        "outputId": "adf3c5d2-8f18-4ac4-a364-ee794b7f96e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "byawaygoal = df03.groupby('away_team_goal')\n",
        "byawaygoal.size().sort_values(ascending=False)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "away_team_goal\n",
              " 1.0    6950\n",
              "-0.6      83\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-12xzP9nt6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def round_pred(val):\n",
        "    if val <=1 and val > 0.67:\n",
        "        return 1\n",
        "    elif val <=0.67 and val >0.33:\n",
        "        return 0.60\n",
        "    elif val <= 0.33 and val > 0:\n",
        "        return 0.20\n",
        "    elif val <= 0 and val > -0.33:\n",
        "        return -0.20\n",
        "    elif val<=-0.33 and val> -0.67:\n",
        "        return -0.60\n",
        "    else:\n",
        "        return -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIwYgXYent6L",
        "colab_type": "text"
      },
      "source": [
        "### Build the model\n",
        "\n",
        "https://www.tensorflow.org/tutorials/keras/regression\n",
        "The mean_squared_error (mse) and mean_absolute_error (mae) are our loss functions â€“ i.e. an estimate of how accurate the neural network is in predicting the test data. We can see that with the validation_split set to 0.2, 80% of the training data is used to test the model, while the remaining 20% is used for testing purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN2xrrDOnt6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "  model= tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(units=30, activation='relu', input_shape=(train_X02.shape[1],)))\n",
        "  model.add(tf.keras.layers.Dense(units=20, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(units=10, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(units=2))\n",
        "  \n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse','accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY5_C13Knt6O",
        "colab_type": "code",
        "outputId": "1aa03117-498a-4a51-fc65-aaf1056928fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model = build_model()\n",
        "\n",
        "EPOCHS = 1000\n",
        "\n",
        "history = model.fit(\n",
        "  train_X02, train_y02,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=0, batch_size=32,\n",
        "  callbacks=[tfdocs.modeling.EpochDots()])\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0, accuracy:0.6147,  loss:0.2985,  mae:0.3838,  mse:0.2985,  val_accuracy:0.8649,  val_loss:0.0519,  val_mae:0.0620,  val_mse:0.0519,  \n",
            "....................................................................................................\n",
            "Epoch: 100, accuracy:0.4531,  loss:0.0466,  mae:0.0681,  mse:0.0466,  val_accuracy:0.0577,  val_loss:0.0506,  val_mae:0.0976,  val_mse:0.0506,  \n",
            "....................................................................................................\n",
            "Epoch: 200, accuracy:0.4051,  loss:0.0457,  mae:0.0656,  mse:0.0457,  val_accuracy:0.3823,  val_loss:0.0495,  val_mae:0.0608,  val_mse:0.0495,  \n",
            "....................................................................................................\n",
            "Epoch: 300, accuracy:0.3932,  loss:0.0456,  mae:0.0626,  mse:0.0456,  val_accuracy:0.3152,  val_loss:0.0492,  val_mae:0.0575,  val_mse:0.0492,  \n",
            "....................................................................................................\n",
            "Epoch: 400, accuracy:0.3668,  loss:0.0449,  mae:0.0614,  mse:0.0449,  val_accuracy:0.1288,  val_loss:0.0503,  val_mae:0.0670,  val_mse:0.0503,  \n",
            "....................................................................................................\n",
            "Epoch: 500, accuracy:0.3745,  loss:0.0438,  mae:0.0619,  mse:0.0438,  val_accuracy:0.3081,  val_loss:0.0514,  val_mae:0.0536,  val_mse:0.0514,  \n",
            "....................................................................................................\n",
            "Epoch: 600, accuracy:0.3960,  loss:0.0429,  mae:0.0590,  mse:0.0429,  val_accuracy:0.1367,  val_loss:0.0514,  val_mae:0.0643,  val_mse:0.0514,  \n",
            "....................................................................................................\n",
            "Epoch: 700, accuracy:0.4173,  loss:0.0419,  mae:0.0584,  mse:0.0419,  val_accuracy:0.0837,  val_loss:0.0528,  val_mae:0.0717,  val_mse:0.0528,  \n",
            "....................................................................................................\n",
            "Epoch: 800, accuracy:0.4057,  loss:0.0421,  mae:0.0587,  mse:0.0421,  val_accuracy:0.1295,  val_loss:0.0540,  val_mae:0.0595,  val_mse:0.0540,  \n",
            "....................................................................................................\n",
            "Epoch: 900, accuracy:0.3749,  loss:0.0415,  mae:0.0577,  mse:0.0415,  val_accuracy:0.9471,  val_loss:0.0524,  val_mae:0.0811,  val_mse:0.0524,  \n",
            "...................................................................................................."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83LeFNq3t5Sc",
        "colab_type": "text"
      },
      "source": [
        "From the output, we can see that the more epochs are run, the lower our MSE and MAE become, indicating improvement in accuracy across each iteration of our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJgyJ8M_un_V",
        "colab_type": "text"
      },
      "source": [
        "**keras is calculating both the training loss and validation loss, i.e. the deviation between the predicted y and actual y as measured by the mean squared error**\n",
        "Letâ€™s see our respective losses plot on using graph\n",
        "**Testing loss is decreasing, however Validation loss is still high**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiGi9AjHuh9b",
        "colab_type": "code",
        "outputId": "d7bebb2e-8a06-4429-f186-e4b5b17e6a59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "print(history.history.keys())\n",
        "# \"Loss\"\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'mae', 'mse', 'accuracy', 'val_loss', 'val_mae', 'val_mse', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kvq1gkdF8Zah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_pred = model.predict(train_X02)\n",
        "y_test_pred = model.predict(test_X02)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-XjI_-G9Uup",
        "colab_type": "code",
        "outputId": "0a5b5fee-5980-48f8-9e57-b9cfc32dc663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "y_train_pred"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0080671 , 0.9033072 ],\n",
              "       [0.9877805 , 1.0001502 ],\n",
              "       [0.98517185, 0.98225355],\n",
              "       ...,\n",
              "       [0.9989299 , 0.9814245 ],\n",
              "       [1.0104723 , 0.8529871 ],\n",
              "       [1.0114493 , 0.98103946]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72PZFQdi9fEe",
        "colab_type": "code",
        "outputId": "fb624a67-bfb8-4584-d2d6-27a1243d1d97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "train_y02"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       ...,\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1h3696e8Kdy",
        "colab_type": "text"
      },
      "source": [
        "--------------------------------------------------------------\n",
        "**SECOND MODEL**\n",
        "------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9q__74KzaYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "  model= tf.keras.models.Sequential()\n",
        "  #Input Layers\n",
        "  model.add(tf.keras.layers.Dense(units=30, activation='relu', kernel_initializer='normal', input_shape=(train_X02.shape[1],)))\n",
        "  #Hidden Layers\n",
        "  model.add(tf.keras.layers.Dense(units=20, activation='relu', kernel_initializer='normal'))\n",
        "  model.add(tf.keras.layers.Dense(units=10, activation='relu', kernel_initializer='normal'))\n",
        "  #model.add(tf.keras.layers.Dense(units=5, activation='relu', kernel_initializer='normal'))\n",
        "  model.add(tf.keras.layers.Dense(units=2, activation='linear'))\n",
        "  \n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mae', 'mse','accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBfUGefSzpAK",
        "colab_type": "code",
        "outputId": "7bf0b3b9-d3f1-4a54-e13f-57317bd5bb1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model = build_model()\n",
        "\n",
        "EPOCHS = 1000\n",
        "\n",
        "history = model.fit(\n",
        "  train_X02, train_y02,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=0, batch_size=32,\n",
        "  callbacks=[tfdocs.modeling.EpochDots()])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0, accuracy:0.1503,  loss:0.3815,  mae:0.3815,  mse:0.3013,  val_accuracy:0.9684,  val_loss:0.0423,  val_mae:0.0423,  val_mse:0.0523,  \n",
            "....................................................................................................\n",
            "Epoch: 100, accuracy:0.4843,  loss:0.0335,  mae:0.0335,  mse:0.0505,  val_accuracy:0.9684,  val_loss:0.0341,  val_mae:0.0341,  val_mse:0.0514,  \n",
            "....................................................................................................\n",
            "Epoch: 200, accuracy:0.4944,  loss:0.0337,  mae:0.0337,  mse:0.0506,  val_accuracy:0.0316,  val_loss:0.0325,  val_mae:0.0325,  val_mse:0.0515,  \n",
            "....................................................................................................\n",
            "Epoch: 300, accuracy:0.4896,  loss:0.0327,  mae:0.0327,  mse:0.0506,  val_accuracy:0.0316,  val_loss:0.0328,  val_mae:0.0328,  val_mse:0.0515,  \n",
            "....................................................................................................\n",
            "Epoch: 400, accuracy:0.5451,  loss:0.0327,  mae:0.0327,  mse:0.0506,  val_accuracy:0.9684,  val_loss:0.0334,  val_mae:0.0334,  val_mse:0.0515,  \n",
            "....................................................................................................\n",
            "Epoch: 500, accuracy:0.4888,  loss:0.0326,  mae:0.0326,  mse:0.0506,  val_accuracy:0.9684,  val_loss:0.0325,  val_mae:0.0325,  val_mse:0.0516,  \n",
            "....................................................................................................\n",
            "Epoch: 600, accuracy:0.5437,  loss:0.0326,  mae:0.0326,  mse:0.0506,  val_accuracy:0.9684,  val_loss:0.0325,  val_mae:0.0325,  val_mse:0.0516,  \n",
            "....................................................................................................\n",
            "Epoch: 700, accuracy:0.4782,  loss:0.0326,  mae:0.0326,  mse:0.0506,  val_accuracy:0.9684,  val_loss:0.0326,  val_mae:0.0326,  val_mse:0.0516,  \n",
            "....................................................................................................\n",
            "Epoch: 800, accuracy:0.5430,  loss:0.0325,  mae:0.0325,  mse:0.0506,  val_accuracy:0.0316,  val_loss:0.0335,  val_mae:0.0335,  val_mse:0.0515,  \n",
            "....................................................................................................\n",
            "Epoch: 900, accuracy:0.4689,  loss:0.0325,  mae:0.0325,  mse:0.0506,  val_accuracy:0.0316,  val_loss:0.0329,  val_mae:0.0329,  val_mse:0.0516,  \n",
            "...................................................................................................."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8hQiGZk6n7c",
        "colab_type": "text"
      },
      "source": [
        "**Using this model, we can see both Validation Loss and Training loss have reduced exponentially**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN8EeFJs1Nfv",
        "colab_type": "code",
        "outputId": "9faa386a-f436-45b0-9e02-53b354e99c54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "print(history.history.keys())\n",
        "# \"Loss\"\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'mae', 'mse', 'accuracy', 'val_loss', 'val_mae', 'val_mse', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfxJO7idvOZv",
        "colab_type": "text"
      },
      "source": [
        "**PREDICTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5SQrswant6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_pred = model.predict(train_X02)\n",
        "y_test_pred = model.predict(test_X02)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5EFi3vgnt6S",
        "colab_type": "code",
        "outputId": "1eb3792c-7348-49a6-f1b0-0b0ea39d6977",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "y_train_pred"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0001278, 1.0000823],\n",
              "       [1.0001278, 1.0000823],\n",
              "       [1.0001278, 1.0000823],\n",
              "       ...,\n",
              "       [1.0001278, 1.0000823],\n",
              "       [1.0001278, 1.0000823],\n",
              "       [1.0001278, 1.0000823]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMkrw0csnt6V",
        "colab_type": "code",
        "outputId": "aaa6095a-7cb5-44b0-c0db-3e0f6cdb9c4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "train_y02"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       ...,\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSbwBNq3nt6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train: Round and decode predicted value\n",
        "ypredhome_train = np.array([round_pred(val) for val in y_train_pred[:,0]])\n",
        "ypredhome_train = np.array([decode(val) for val in ypredhome_train])\n",
        "\n",
        "ypredaway_train = np.array([round_pred(val) for val in y_train_pred[:,1]])\n",
        "ypredaway_train = np.array([decode(val) for val in ypredaway_train])\n",
        "\n",
        "#decode the goals\n",
        "yorighome_train = np.array([decode(val) for val in train_y02[:,0]])\n",
        "yorigaway_train = np.array([decode(val) for val in train_y02[:,1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVw4jylYnt6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test: Round and decode predicted value\n",
        "ypredhome_test = np.array([round_pred(val) for val in y_test_pred[:,0]])\n",
        "ypredhome_test = np.array([decode(val) for val in ypredhome_test])\n",
        "\n",
        "ypredaway_test = np.array([round_pred(val) for val in y_test_pred[:,1]])\n",
        "ypredaway_test = np.array([decode(val) for val in ypredaway_test])\n",
        "\n",
        "#decode the goals\n",
        "yorighome_test = np.array([decode(val) for val in test_y02[:,0]])\n",
        "yorigaway_test = np.array([decode(val) for val in test_y02[:,1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3g8v3Zh_VSB",
        "colab_type": "text"
      },
      "source": [
        "**QUALITY MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yCvA3Rpnt6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def degree_diff(yoriginal,ypred):\n",
        "    val = abs(yoriginal - ypred)\n",
        "    switcher = {\n",
        "        0: 1, # yoriginal = ypred\n",
        "        1: 0.8, # diff of 1. Exple original 1 predicted 2 => 0.75\n",
        "        2: 0.6,\n",
        "        3: 0.4,\n",
        "        4: 0.2, # diff of 4. Exple original 0 predicted 4\n",
        "        5: 0\n",
        "    }\n",
        "    return switcher.get(val, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj9AbU8Cnt6g",
        "colab_type": "code",
        "outputId": "b62dac93-3ed0-46a7-b77e-03327d31ce9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "quality_model_home_goals=0\n",
        "\n",
        "for valorg,valpred in zip(yorighome_train,ypredhome_train):\n",
        "    quality_model_home_goals += degree_diff(valorg,valpred)\n",
        "    \n",
        "quality_model_home_goals = quality_model_home_goals / len(yorighome_train)\n",
        "print (\"Quality model home goals TRAIN\", quality_model_home_goals)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quality model home goals TRAIN 0.02212039816716698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvwDg6D6nt6j",
        "colab_type": "code",
        "outputId": "4e12d81e-2460-4de2-f114-e9ee215153f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "quality_model_away_goals=0\n",
        "\n",
        "for valorg,valpred in zip(yorigaway_train,ypredaway_train):\n",
        "    quality_model_away_goals += degree_diff(valorg,valpred)\n",
        "    \n",
        "quality_model_away_goals = quality_model_away_goals / len(yorigaway_train)\n",
        "print (\"Quality model away goals TRAIN\", quality_model_away_goals)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quality model away goals TRAIN 0.009606572918312515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6hm7M-Znt6l",
        "colab_type": "code",
        "outputId": "26838838-67b4-4f5a-f7d2-bb3e8bc1f613",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#TO DO : Improve the final quality\n",
        "\n",
        "#final_quality = (quality_model_home_goals**2 + quality_model_away_goals**2)/4\n",
        "final_quality = (quality_model_home_goals + quality_model_away_goals)/2\n",
        "final_quality"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01586348554273975"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK3kS3fbnt6p",
        "colab_type": "code",
        "outputId": "164f9e90-6c6f-49c9-8f67-6fe7b42333ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "quality_model_home_goals_test=0\n",
        "\n",
        "for valorg,valpred in zip(yorighome_test,ypredhome_test):\n",
        "    quality_model_home_goals_test += degree_diff(valorg,valpred)\n",
        "    \n",
        "quality_model_home_goals_test = quality_model_home_goals_test / len(yorighome_test)\n",
        "print (\"Quality model home goals TEST\", quality_model_home_goals_test)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quality model home goals TEST 0.026136363636363645\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgeEMNJQnt6t",
        "colab_type": "code",
        "outputId": "0fbb7c2b-ab00-4670-be7f-c62162bb71f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "quality_model_away_goals_test=0\n",
        "\n",
        "for valorg,valpred in zip(yorigaway_test,ypredaway_test):\n",
        "    quality_model_away_goals_test += degree_diff(valorg,valpred)\n",
        "    \n",
        "quality_model_away_goals_test = quality_model_away_goals_test / len(yorigaway_test)\n",
        "print (\"Quality model away goals TEST\", quality_model_away_goals_test)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quality model away goals TEST 0.007954545454545454\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXokS5Ntnt6v",
        "colab_type": "code",
        "outputId": "87e974c3-00a5-4cf4-aeb9-1fc63fc70771",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#TO DO : Improve the final quality\n",
        "\n",
        "#final_quality = (quality_model_home_goals**2 + quality_model_away_goals**2)/4\n",
        "final_quality_test = (quality_model_home_goals_test + quality_model_away_goals_test)/2\n",
        "final_quality_test"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01704545454545455"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aof63nTgnt6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}