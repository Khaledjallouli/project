{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EMQmP-Bknt5P"
   },
   "source": [
    "# Regression\n",
    "Predict the final goals scored per each team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FtJth4hT577a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 999)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.estimator import inputs\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "\n",
    "from  IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "nVI7Xp89n15I",
    "outputId": "a6867d27-3e4c-4d1d-fd55-89e3dfe9d2eb"
   },
   "outputs": [],
   "source": [
    "#pip install git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pmP557n8nt5X"
   },
   "source": [
    "## Data Preprocessing\n",
    "    1. Normalization\n",
    "    2. Data encoding: The goals [0,10] => [-1,1]. If Goal > 10 => 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u_NuYqrJnt5Y"
   },
   "outputs": [],
   "source": [
    "df02 = pd.read_csv('https://raw.githubusercontent.com/Khaledjallouli/project/master/data/data_regression_goals/sliding02_goals.csv', sep=',', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "colab_type": "code",
    "id": "MFm2Qfk2nt5c",
    "outputId": "87ae932c-32f0-4105-85a5-7f11f80d595a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_team_goal</th>\n",
       "      <th>away_team_goal</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>137</td>\n",
       "      <td>67</td>\n",
       "      <td>117</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>161</td>\n",
       "      <td>78</td>\n",
       "      <td>72</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>134</td>\n",
       "      <td>64</td>\n",
       "      <td>151</td>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>104</td>\n",
       "      <td>44</td>\n",
       "      <td>87</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>120</td>\n",
       "      <td>58</td>\n",
       "      <td>124</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>134</td>\n",
       "      <td>59</td>\n",
       "      <td>100</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.30</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>177</td>\n",
       "      <td>82</td>\n",
       "      <td>74</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>169</td>\n",
       "      <td>95</td>\n",
       "      <td>113</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>6.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>161</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>143</td>\n",
       "      <td>69</td>\n",
       "      <td>134</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7028</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.70</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>80</td>\n",
       "      <td>43</td>\n",
       "      <td>117</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>119</td>\n",
       "      <td>58</td>\n",
       "      <td>112</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>89</td>\n",
       "      <td>47</td>\n",
       "      <td>92</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>104</td>\n",
       "      <td>55</td>\n",
       "      <td>63</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7030</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.50</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>122</td>\n",
       "      <td>59</td>\n",
       "      <td>92</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>84</td>\n",
       "      <td>43</td>\n",
       "      <td>118</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.33</td>\n",
       "      <td>5.25</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>124</td>\n",
       "      <td>62</td>\n",
       "      <td>99</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>103</td>\n",
       "      <td>53</td>\n",
       "      <td>122</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.67</td>\n",
       "      <td>4.20</td>\n",
       "      <td>5.25</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>105</td>\n",
       "      <td>65</td>\n",
       "      <td>126</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>114</td>\n",
       "      <td>63</td>\n",
       "      <td>106</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7033 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      home_team_goal  away_team_goal  odds-home  odds-draw  odds-away  \\\n",
       "0                  2               1       3.50       3.30       2.10   \n",
       "1                  2               2       2.50       3.30       2.88   \n",
       "2                  1               2       1.91       3.40       4.20   \n",
       "3                  2               1       3.25       3.25       2.30   \n",
       "4                  3               0       1.20       6.00      19.00   \n",
       "...              ...             ...        ...        ...        ...   \n",
       "7028               2               1       5.00       3.80       1.70   \n",
       "7029               4               2       2.00       3.60       3.70   \n",
       "7030               4               1       1.80       3.75       4.50   \n",
       "7031               3               1       1.33       5.25       9.00   \n",
       "7032               3               1       1.67       4.20       5.25   \n",
       "\n",
       "      home-wins  home-draws  home-losses  home-goals  home-opposition-goals  \\\n",
       "0             1           3            6          11                     16   \n",
       "1             3           1            6           8                     16   \n",
       "2             4           2            4          10                     15   \n",
       "3             5           2            3          22                     12   \n",
       "4             7           2            1          15                      8   \n",
       "...         ...         ...          ...         ...                    ...   \n",
       "7028          4           2            4          10                     12   \n",
       "7029          3           2            5           9                     21   \n",
       "7030          3           3            4           8                      8   \n",
       "7031          2           3            5          12                     14   \n",
       "7032          6           1            3          10                      8   \n",
       "\n",
       "      home-shots  home-shots_on_target  home-opposition_shots  \\\n",
       "0            137                    67                    117   \n",
       "1            134                    64                    151   \n",
       "2            120                    58                    124   \n",
       "3            177                    82                     74   \n",
       "4            161                    72                     74   \n",
       "...          ...                   ...                    ...   \n",
       "7028          80                    43                    117   \n",
       "7029          89                    47                     92   \n",
       "7030         122                    59                     92   \n",
       "7031         124                    62                     99   \n",
       "7032         105                    65                    126   \n",
       "\n",
       "      home-opposition_shots_on_target  away-wins  away-draws  away-losses  \\\n",
       "0                                  53          8           2            0   \n",
       "1                                  77          3           3            4   \n",
       "2                                  56          2           2            6   \n",
       "3                                  37          6           3            1   \n",
       "4                                  31          3           2            5   \n",
       "...                               ...        ...         ...          ...   \n",
       "7028                               60          2           4            4   \n",
       "7029                               46          1           4            5   \n",
       "7030                               50          5           2            3   \n",
       "7031                               50          3           3            4   \n",
       "7032                               54          3           2            5   \n",
       "\n",
       "      away-goals  away-opposition-goals  away-shots  away-shots_on_target  \\\n",
       "0             15                      6         161                    78   \n",
       "1             11                     18         104                    44   \n",
       "2             11                     15         134                    59   \n",
       "3             19                      8         169                    95   \n",
       "4             10                     17         143                    69   \n",
       "...          ...                    ...         ...                   ...   \n",
       "7028          10                     21         119                    58   \n",
       "7029           7                     21         104                    55   \n",
       "7030          15                      9          84                    43   \n",
       "7031          11                     17         103                    53   \n",
       "7032          13                     19         114                    63   \n",
       "\n",
       "      away-opposition_shots  away-opposition_shots_on_target  \n",
       "0                        72                               30  \n",
       "1                        87                               36  \n",
       "2                       100                               46  \n",
       "3                       113                               58  \n",
       "4                       134                               69  \n",
       "...                     ...                              ...  \n",
       "7028                    112                               65  \n",
       "7029                     63                               26  \n",
       "7030                    118                               56  \n",
       "7031                    122                               54  \n",
       "7032                    106                               46  \n",
       "\n",
       "[7033 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "tzti9zrknt5h",
    "outputId": "0a707ad9-790e-4e25-b52d-9f1c216a360e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "home_team_goal\n",
       "1     2251\n",
       "2     1732\n",
       "0     1589\n",
       "3      885\n",
       "4      378\n",
       "5      132\n",
       "6       43\n",
       "7       13\n",
       "8        7\n",
       "9        2\n",
       "10       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byhomegoal = df02.groupby('home_team_goal')\n",
    "byhomegoal.size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "1V2WCPxmnt5m",
    "outputId": "1fdfd4ba-6e53-4d89-b19f-ebdbe379edaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "away_team_goal\n",
       "1    2381\n",
       "0    2362\n",
       "2    1401\n",
       "3     613\n",
       "4     193\n",
       "5      52\n",
       "6      23\n",
       "8       5\n",
       "7       2\n",
       "9       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byawaygoal = df02.groupby('away_team_goal')\n",
    "byawaygoal.size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O6MockV_nt5p"
   },
   "source": [
    "### =>The two previous cells show that we can keep 6 classes: [0.5].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uwHnhYEynt5t"
   },
   "outputs": [],
   "source": [
    "def get_X_and_y(dataframe):\n",
    "    X = dataframe.drop(columns=['home_team_goal','away_team_goal']).values\n",
    "    y = dataframe[['home_team_goal','away_team_goal']].values\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EyNjI6jPnt5w"
   },
   "outputs": [],
   "source": [
    "def encode(i):\n",
    "    switcher = {\n",
    "        0: 0,\n",
    "        1: 1,\n",
    "        2: 2,\n",
    "        3: 3,\n",
    "        4: 4,\n",
    "        5: 5,\n",
    "    }\n",
    "    # 1 be assigned as default value of passed argument (if goals > 5)\n",
    "    #return switcher.get(i, 1)\n",
    "    return switcher.get(i, 1)\n",
    "\n",
    "def decode(i):\n",
    "    switcher = {\n",
    "        0: 0,\n",
    "        1: 1,\n",
    "        2: 2,\n",
    "        3: 3,\n",
    "        4: 4,\n",
    "        5: 5,\n",
    "    }\n",
    "    #return switcher.get(i, \"ERROR! Use Encode Before!\")\n",
    "    return switcher.get(i, \"ERROR! Use Encode Before!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yOw4-355nt5y"
   },
   "outputs": [],
   "source": [
    "def normalize(dataframe):\n",
    "    column_names_to_not_normalize = ['home_team_goal','away_team_goal']\n",
    "    column_names_to_normalize = [x for x in list(dataframe) if x not in column_names_to_not_normalize ]\n",
    "    x = dataframe[column_names_to_normalize].values\n",
    "    x_scaled = preprocessing.normalize(x)\n",
    "    df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = dataframe.index)\n",
    "    dataframe[column_names_to_normalize] = df_temp\n",
    "    \n",
    "    dataframe['home_team_goal'] = dataframe.apply(lambda row: encode(row['home_team_goal']), axis=1)\n",
    "    dataframe['away_team_goal'] = dataframe.apply(lambda row: encode(row['away_team_goal']), axis=1)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "3PmG9M4ent52",
    "outputId": "d8463e61-9811-45b1-b260-8a02202d9105"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329 train examples\n",
      "704 test examples\n"
     ]
    }
   ],
   "source": [
    "n02 = normalize(df02)\n",
    "\n",
    "train02, test02 = train_test_split(n02, test_size=0.1, shuffle=False)\n",
    "print(len(train02), 'train examples')\n",
    "print(len(test02), 'test examples')\n",
    "\n",
    "labels = n02.iloc[:,0:2]\n",
    "train = n02.iloc[:,2:]\n",
    "\n",
    "\n",
    "train_X02,train_y02 = get_X_and_y(train02)\n",
    "labels_train = n02.iloc[:,0:2]\n",
    "\n",
    "test_X02,test_y02 = get_X_and_y(test02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012482</td>\n",
       "      <td>0.011769</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.010699</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.039230</td>\n",
       "      <td>0.057061</td>\n",
       "      <td>0.488587</td>\n",
       "      <td>0.238944</td>\n",
       "      <td>0.417260</td>\n",
       "      <td>0.189015</td>\n",
       "      <td>0.028531</td>\n",
       "      <td>0.007133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053495</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.574178</td>\n",
       "      <td>0.278173</td>\n",
       "      <td>0.256775</td>\n",
       "      <td>0.106990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009236</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.010640</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.022166</td>\n",
       "      <td>0.029555</td>\n",
       "      <td>0.059110</td>\n",
       "      <td>0.495044</td>\n",
       "      <td>0.236439</td>\n",
       "      <td>0.557848</td>\n",
       "      <td>0.284465</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.014777</td>\n",
       "      <td>0.040638</td>\n",
       "      <td>0.066498</td>\n",
       "      <td>0.384213</td>\n",
       "      <td>0.162552</td>\n",
       "      <td>0.321409</td>\n",
       "      <td>0.132997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007188</td>\n",
       "      <td>0.012795</td>\n",
       "      <td>0.015805</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.037632</td>\n",
       "      <td>0.056448</td>\n",
       "      <td>0.451585</td>\n",
       "      <td>0.218266</td>\n",
       "      <td>0.466638</td>\n",
       "      <td>0.210740</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.022579</td>\n",
       "      <td>0.041395</td>\n",
       "      <td>0.056448</td>\n",
       "      <td>0.504270</td>\n",
       "      <td>0.222029</td>\n",
       "      <td>0.376321</td>\n",
       "      <td>0.173108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010289</td>\n",
       "      <td>0.010289</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.015829</td>\n",
       "      <td>0.006332</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.069647</td>\n",
       "      <td>0.037989</td>\n",
       "      <td>0.560339</td>\n",
       "      <td>0.259592</td>\n",
       "      <td>0.234266</td>\n",
       "      <td>0.117133</td>\n",
       "      <td>0.018995</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.060149</td>\n",
       "      <td>0.025326</td>\n",
       "      <td>0.535013</td>\n",
       "      <td>0.300747</td>\n",
       "      <td>0.357730</td>\n",
       "      <td>0.183614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004077</td>\n",
       "      <td>0.020384</td>\n",
       "      <td>0.064551</td>\n",
       "      <td>0.023782</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.050961</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.546982</td>\n",
       "      <td>0.244613</td>\n",
       "      <td>0.251408</td>\n",
       "      <td>0.105320</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.016987</td>\n",
       "      <td>0.033974</td>\n",
       "      <td>0.057756</td>\n",
       "      <td>0.485829</td>\n",
       "      <td>0.234421</td>\n",
       "      <td>0.455252</td>\n",
       "      <td>0.234421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7028</th>\n",
       "      <td>0.020289</td>\n",
       "      <td>0.015420</td>\n",
       "      <td>0.006898</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.040578</td>\n",
       "      <td>0.048694</td>\n",
       "      <td>0.324626</td>\n",
       "      <td>0.174487</td>\n",
       "      <td>0.474766</td>\n",
       "      <td>0.243470</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.040578</td>\n",
       "      <td>0.085214</td>\n",
       "      <td>0.482881</td>\n",
       "      <td>0.235354</td>\n",
       "      <td>0.454477</td>\n",
       "      <td>0.263759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.017929</td>\n",
       "      <td>0.018427</td>\n",
       "      <td>0.014941</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.024901</td>\n",
       "      <td>0.044822</td>\n",
       "      <td>0.104584</td>\n",
       "      <td>0.443238</td>\n",
       "      <td>0.234070</td>\n",
       "      <td>0.458179</td>\n",
       "      <td>0.229089</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.019921</td>\n",
       "      <td>0.024901</td>\n",
       "      <td>0.034861</td>\n",
       "      <td>0.104584</td>\n",
       "      <td>0.517941</td>\n",
       "      <td>0.273911</td>\n",
       "      <td>0.313753</td>\n",
       "      <td>0.129485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7030</th>\n",
       "      <td>0.007617</td>\n",
       "      <td>0.015870</td>\n",
       "      <td>0.019044</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.016928</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.516293</td>\n",
       "      <td>0.249683</td>\n",
       "      <td>0.389336</td>\n",
       "      <td>0.211596</td>\n",
       "      <td>0.021160</td>\n",
       "      <td>0.008464</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.063479</td>\n",
       "      <td>0.038087</td>\n",
       "      <td>0.355481</td>\n",
       "      <td>0.181972</td>\n",
       "      <td>0.499366</td>\n",
       "      <td>0.236987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031</th>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.020806</td>\n",
       "      <td>0.035667</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.019815</td>\n",
       "      <td>0.047556</td>\n",
       "      <td>0.055483</td>\n",
       "      <td>0.491416</td>\n",
       "      <td>0.245708</td>\n",
       "      <td>0.392341</td>\n",
       "      <td>0.198152</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.015852</td>\n",
       "      <td>0.043593</td>\n",
       "      <td>0.067372</td>\n",
       "      <td>0.408193</td>\n",
       "      <td>0.210041</td>\n",
       "      <td>0.483490</td>\n",
       "      <td>0.214004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>0.006541</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.020563</td>\n",
       "      <td>0.023501</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.039168</td>\n",
       "      <td>0.031334</td>\n",
       "      <td>0.411259</td>\n",
       "      <td>0.254589</td>\n",
       "      <td>0.493511</td>\n",
       "      <td>0.211505</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.007834</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.050918</td>\n",
       "      <td>0.074418</td>\n",
       "      <td>0.446510</td>\n",
       "      <td>0.246755</td>\n",
       "      <td>0.415176</td>\n",
       "      <td>0.180171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7033 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      odds-home  odds-draw  odds-away  home-wins  home-draws  home-losses  \\\n",
       "0      0.012482   0.011769   0.007489   0.003566    0.010699     0.021398   \n",
       "1      0.009236   0.012191   0.010640   0.011083    0.003694     0.022166   \n",
       "2      0.007188   0.012795   0.015805   0.015053    0.007526     0.015053   \n",
       "3      0.010289   0.010289   0.007281   0.015829    0.006332     0.009497   \n",
       "4      0.004077   0.020384   0.064551   0.023782    0.006795     0.003397   \n",
       "...         ...        ...        ...        ...         ...          ...   \n",
       "7028   0.020289   0.015420   0.006898   0.016231    0.008116     0.016231   \n",
       "7029   0.009960   0.017929   0.018427   0.014941    0.009960     0.024901   \n",
       "7030   0.007617   0.015870   0.019044   0.012696    0.012696     0.016928   \n",
       "7031   0.005271   0.020806   0.035667   0.007926    0.011889     0.019815   \n",
       "7032   0.006541   0.016450   0.020563   0.023501    0.003917     0.011750   \n",
       "\n",
       "      home-goals  home-opposition-goals  home-shots  home-shots_on_target  \\\n",
       "0       0.039230               0.057061    0.488587              0.238944   \n",
       "1       0.029555               0.059110    0.495044              0.236439   \n",
       "2       0.037632               0.056448    0.451585              0.218266   \n",
       "3       0.069647               0.037989    0.560339              0.259592   \n",
       "4       0.050961               0.027179    0.546982              0.244613   \n",
       "...          ...                    ...         ...                   ...   \n",
       "7028    0.040578               0.048694    0.324626              0.174487   \n",
       "7029    0.044822               0.104584    0.443238              0.234070   \n",
       "7030    0.033855               0.033855    0.516293              0.249683   \n",
       "7031    0.047556               0.055483    0.491416              0.245708   \n",
       "7032    0.039168               0.031334    0.411259              0.254589   \n",
       "\n",
       "      home-opposition_shots  home-opposition_shots_on_target  away-wins  \\\n",
       "0                  0.417260                         0.189015   0.028531   \n",
       "1                  0.557848                         0.284465   0.011083   \n",
       "2                  0.466638                         0.210740   0.007526   \n",
       "3                  0.234266                         0.117133   0.018995   \n",
       "4                  0.251408                         0.105320   0.010192   \n",
       "...                     ...                              ...        ...   \n",
       "7028               0.474766                         0.243470   0.008116   \n",
       "7029               0.458179                         0.229089   0.004980   \n",
       "7030               0.389336                         0.211596   0.021160   \n",
       "7031               0.392341                         0.198152   0.011889   \n",
       "7032               0.493511                         0.211505   0.011750   \n",
       "\n",
       "      away-draws  away-losses  away-goals  away-opposition-goals  away-shots  \\\n",
       "0       0.007133     0.000000    0.053495               0.021398    0.574178   \n",
       "1       0.011083     0.014777    0.040638               0.066498    0.384213   \n",
       "2       0.007526     0.022579    0.041395               0.056448    0.504270   \n",
       "3       0.009497     0.003166    0.060149               0.025326    0.535013   \n",
       "4       0.006795     0.016987    0.033974               0.057756    0.485829   \n",
       "...          ...          ...         ...                    ...         ...   \n",
       "7028    0.016231     0.016231    0.040578               0.085214    0.482881   \n",
       "7029    0.019921     0.024901    0.034861               0.104584    0.517941   \n",
       "7030    0.008464     0.012696    0.063479               0.038087    0.355481   \n",
       "7031    0.011889     0.015852    0.043593               0.067372    0.408193   \n",
       "7032    0.007834     0.019584    0.050918               0.074418    0.446510   \n",
       "\n",
       "      away-shots_on_target  away-opposition_shots  \\\n",
       "0                 0.278173               0.256775   \n",
       "1                 0.162552               0.321409   \n",
       "2                 0.222029               0.376321   \n",
       "3                 0.300747               0.357730   \n",
       "4                 0.234421               0.455252   \n",
       "...                    ...                    ...   \n",
       "7028              0.235354               0.454477   \n",
       "7029              0.273911               0.313753   \n",
       "7030              0.181972               0.499366   \n",
       "7031              0.210041               0.483490   \n",
       "7032              0.246755               0.415176   \n",
       "\n",
       "      away-opposition_shots_on_target  \n",
       "0                            0.106990  \n",
       "1                            0.132997  \n",
       "2                            0.173108  \n",
       "3                            0.183614  \n",
       "4                            0.234421  \n",
       "...                               ...  \n",
       "7028                         0.263759  \n",
       "7029                         0.129485  \n",
       "7030                         0.236987  \n",
       "7031                         0.214004  \n",
       "7032                         0.180171  \n",
       "\n",
       "[7033 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "colab_type": "code",
    "id": "tTAm_MXlnt54",
    "outputId": "a344201f-a5aa-4c17-a193-4c257e25f624"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_team_goal</th>\n",
       "      <th>away_team_goal</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012482</td>\n",
       "      <td>0.011769</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.010699</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.039230</td>\n",
       "      <td>0.057061</td>\n",
       "      <td>0.488587</td>\n",
       "      <td>0.238944</td>\n",
       "      <td>0.417260</td>\n",
       "      <td>0.189015</td>\n",
       "      <td>0.028531</td>\n",
       "      <td>0.007133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053495</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.574178</td>\n",
       "      <td>0.278173</td>\n",
       "      <td>0.256775</td>\n",
       "      <td>0.106990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.010640</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.022166</td>\n",
       "      <td>0.029555</td>\n",
       "      <td>0.059110</td>\n",
       "      <td>0.495044</td>\n",
       "      <td>0.236439</td>\n",
       "      <td>0.557848</td>\n",
       "      <td>0.284465</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.014777</td>\n",
       "      <td>0.040638</td>\n",
       "      <td>0.066498</td>\n",
       "      <td>0.384213</td>\n",
       "      <td>0.162552</td>\n",
       "      <td>0.321409</td>\n",
       "      <td>0.132997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007188</td>\n",
       "      <td>0.012795</td>\n",
       "      <td>0.015805</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.037632</td>\n",
       "      <td>0.056448</td>\n",
       "      <td>0.451585</td>\n",
       "      <td>0.218266</td>\n",
       "      <td>0.466638</td>\n",
       "      <td>0.210740</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.022579</td>\n",
       "      <td>0.041395</td>\n",
       "      <td>0.056448</td>\n",
       "      <td>0.504270</td>\n",
       "      <td>0.222029</td>\n",
       "      <td>0.376321</td>\n",
       "      <td>0.173108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010289</td>\n",
       "      <td>0.010289</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.015829</td>\n",
       "      <td>0.006332</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.069647</td>\n",
       "      <td>0.037989</td>\n",
       "      <td>0.560339</td>\n",
       "      <td>0.259592</td>\n",
       "      <td>0.234266</td>\n",
       "      <td>0.117133</td>\n",
       "      <td>0.018995</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.060149</td>\n",
       "      <td>0.025326</td>\n",
       "      <td>0.535013</td>\n",
       "      <td>0.300747</td>\n",
       "      <td>0.357730</td>\n",
       "      <td>0.183614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>0.020384</td>\n",
       "      <td>0.064551</td>\n",
       "      <td>0.023782</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.050961</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.546982</td>\n",
       "      <td>0.244613</td>\n",
       "      <td>0.251408</td>\n",
       "      <td>0.105320</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.016987</td>\n",
       "      <td>0.033974</td>\n",
       "      <td>0.057756</td>\n",
       "      <td>0.485829</td>\n",
       "      <td>0.234421</td>\n",
       "      <td>0.455252</td>\n",
       "      <td>0.234421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7028</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020289</td>\n",
       "      <td>0.015420</td>\n",
       "      <td>0.006898</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.040578</td>\n",
       "      <td>0.048694</td>\n",
       "      <td>0.324626</td>\n",
       "      <td>0.174487</td>\n",
       "      <td>0.474766</td>\n",
       "      <td>0.243470</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.040578</td>\n",
       "      <td>0.085214</td>\n",
       "      <td>0.482881</td>\n",
       "      <td>0.235354</td>\n",
       "      <td>0.454477</td>\n",
       "      <td>0.263759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.017929</td>\n",
       "      <td>0.018427</td>\n",
       "      <td>0.014941</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.024901</td>\n",
       "      <td>0.044822</td>\n",
       "      <td>0.104584</td>\n",
       "      <td>0.443238</td>\n",
       "      <td>0.234070</td>\n",
       "      <td>0.458179</td>\n",
       "      <td>0.229089</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.019921</td>\n",
       "      <td>0.024901</td>\n",
       "      <td>0.034861</td>\n",
       "      <td>0.104584</td>\n",
       "      <td>0.517941</td>\n",
       "      <td>0.273911</td>\n",
       "      <td>0.313753</td>\n",
       "      <td>0.129485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7030</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007617</td>\n",
       "      <td>0.015870</td>\n",
       "      <td>0.019044</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.016928</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.516293</td>\n",
       "      <td>0.249683</td>\n",
       "      <td>0.389336</td>\n",
       "      <td>0.211596</td>\n",
       "      <td>0.021160</td>\n",
       "      <td>0.008464</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.063479</td>\n",
       "      <td>0.038087</td>\n",
       "      <td>0.355481</td>\n",
       "      <td>0.181972</td>\n",
       "      <td>0.499366</td>\n",
       "      <td>0.236987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.020806</td>\n",
       "      <td>0.035667</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.019815</td>\n",
       "      <td>0.047556</td>\n",
       "      <td>0.055483</td>\n",
       "      <td>0.491416</td>\n",
       "      <td>0.245708</td>\n",
       "      <td>0.392341</td>\n",
       "      <td>0.198152</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.015852</td>\n",
       "      <td>0.043593</td>\n",
       "      <td>0.067372</td>\n",
       "      <td>0.408193</td>\n",
       "      <td>0.210041</td>\n",
       "      <td>0.483490</td>\n",
       "      <td>0.214004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006541</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.020563</td>\n",
       "      <td>0.023501</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.039168</td>\n",
       "      <td>0.031334</td>\n",
       "      <td>0.411259</td>\n",
       "      <td>0.254589</td>\n",
       "      <td>0.493511</td>\n",
       "      <td>0.211505</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.007834</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.050918</td>\n",
       "      <td>0.074418</td>\n",
       "      <td>0.446510</td>\n",
       "      <td>0.246755</td>\n",
       "      <td>0.415176</td>\n",
       "      <td>0.180171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7033 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      home_team_goal  away_team_goal  odds-home  odds-draw  odds-away  \\\n",
       "0                  2               1   0.012482   0.011769   0.007489   \n",
       "1                  2               2   0.009236   0.012191   0.010640   \n",
       "2                  1               2   0.007188   0.012795   0.015805   \n",
       "3                  2               1   0.010289   0.010289   0.007281   \n",
       "4                  3               0   0.004077   0.020384   0.064551   \n",
       "...              ...             ...        ...        ...        ...   \n",
       "7028               2               1   0.020289   0.015420   0.006898   \n",
       "7029               4               2   0.009960   0.017929   0.018427   \n",
       "7030               4               1   0.007617   0.015870   0.019044   \n",
       "7031               3               1   0.005271   0.020806   0.035667   \n",
       "7032               3               1   0.006541   0.016450   0.020563   \n",
       "\n",
       "      home-wins  home-draws  home-losses  home-goals  home-opposition-goals  \\\n",
       "0      0.003566    0.010699     0.021398    0.039230               0.057061   \n",
       "1      0.011083    0.003694     0.022166    0.029555               0.059110   \n",
       "2      0.015053    0.007526     0.015053    0.037632               0.056448   \n",
       "3      0.015829    0.006332     0.009497    0.069647               0.037989   \n",
       "4      0.023782    0.006795     0.003397    0.050961               0.027179   \n",
       "...         ...         ...          ...         ...                    ...   \n",
       "7028   0.016231    0.008116     0.016231    0.040578               0.048694   \n",
       "7029   0.014941    0.009960     0.024901    0.044822               0.104584   \n",
       "7030   0.012696    0.012696     0.016928    0.033855               0.033855   \n",
       "7031   0.007926    0.011889     0.019815    0.047556               0.055483   \n",
       "7032   0.023501    0.003917     0.011750    0.039168               0.031334   \n",
       "\n",
       "      home-shots  home-shots_on_target  home-opposition_shots  \\\n",
       "0       0.488587              0.238944               0.417260   \n",
       "1       0.495044              0.236439               0.557848   \n",
       "2       0.451585              0.218266               0.466638   \n",
       "3       0.560339              0.259592               0.234266   \n",
       "4       0.546982              0.244613               0.251408   \n",
       "...          ...                   ...                    ...   \n",
       "7028    0.324626              0.174487               0.474766   \n",
       "7029    0.443238              0.234070               0.458179   \n",
       "7030    0.516293              0.249683               0.389336   \n",
       "7031    0.491416              0.245708               0.392341   \n",
       "7032    0.411259              0.254589               0.493511   \n",
       "\n",
       "      home-opposition_shots_on_target  away-wins  away-draws  away-losses  \\\n",
       "0                            0.189015   0.028531    0.007133     0.000000   \n",
       "1                            0.284465   0.011083    0.011083     0.014777   \n",
       "2                            0.210740   0.007526    0.007526     0.022579   \n",
       "3                            0.117133   0.018995    0.009497     0.003166   \n",
       "4                            0.105320   0.010192    0.006795     0.016987   \n",
       "...                               ...        ...         ...          ...   \n",
       "7028                         0.243470   0.008116    0.016231     0.016231   \n",
       "7029                         0.229089   0.004980    0.019921     0.024901   \n",
       "7030                         0.211596   0.021160    0.008464     0.012696   \n",
       "7031                         0.198152   0.011889    0.011889     0.015852   \n",
       "7032                         0.211505   0.011750    0.007834     0.019584   \n",
       "\n",
       "      away-goals  away-opposition-goals  away-shots  away-shots_on_target  \\\n",
       "0       0.053495               0.021398    0.574178              0.278173   \n",
       "1       0.040638               0.066498    0.384213              0.162552   \n",
       "2       0.041395               0.056448    0.504270              0.222029   \n",
       "3       0.060149               0.025326    0.535013              0.300747   \n",
       "4       0.033974               0.057756    0.485829              0.234421   \n",
       "...          ...                    ...         ...                   ...   \n",
       "7028    0.040578               0.085214    0.482881              0.235354   \n",
       "7029    0.034861               0.104584    0.517941              0.273911   \n",
       "7030    0.063479               0.038087    0.355481              0.181972   \n",
       "7031    0.043593               0.067372    0.408193              0.210041   \n",
       "7032    0.050918               0.074418    0.446510              0.246755   \n",
       "\n",
       "      away-opposition_shots  away-opposition_shots_on_target  \n",
       "0                  0.256775                         0.106990  \n",
       "1                  0.321409                         0.132997  \n",
       "2                  0.376321                         0.173108  \n",
       "3                  0.357730                         0.183614  \n",
       "4                  0.455252                         0.234421  \n",
       "...                     ...                              ...  \n",
       "7028               0.454477                         0.263759  \n",
       "7029               0.313753                         0.129485  \n",
       "7030               0.499366                         0.236987  \n",
       "7031               0.483490                         0.214004  \n",
       "7032               0.415176                         0.180171  \n",
       "\n",
       "[7033 rows x 23 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "44kHTmIWnt57",
    "outputId": "85c08ed4-f34f-4606-83e9-0c126016e171"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "home_team_goal\n",
       "1    2317\n",
       "2    1732\n",
       "0    1589\n",
       "3     885\n",
       "4     378\n",
       "5     132\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verif the classes\n",
    "byhomegoal = df02.groupby('home_team_goal')\n",
    "byhomegoal.size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "LrUTbaq5nt5-",
    "outputId": "f937345d-0acc-42d0-91b3-921c76c8cf40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "away_team_goal\n",
       "1    2412\n",
       "0    2362\n",
       "2    1401\n",
       "3     613\n",
       "4     193\n",
       "5      52\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byawaygoal = df02.groupby('away_team_goal')\n",
    "byawaygoal.size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x-12xzP9nt6F"
   },
   "outputs": [],
   "source": [
    "def round_pred(val):\n",
    "    if val <=1 and val > 0.67:\n",
    "        return 1\n",
    "    elif val <=0.67 and val >0.33:\n",
    "        return 0.60\n",
    "    elif val <= 0.33 and val > 0:\n",
    "        return 0.20\n",
    "    elif val <= 0 and val > -0.33:\n",
    "        return -0.20\n",
    "    elif val<=-0.33 and val> -0.67:\n",
    "        return -0.60\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mIwYgXYent6L"
   },
   "source": [
    "### Build the model\n",
    "\n",
    "https://www.tensorflow.org/tutorials/keras/regression\n",
    "The mean_squared_error (mse) and mean_absolute_error (mae) are our loss functions – i.e. an estimate of how accurate the neural network is in predicting the test data. We can see that with the validation_split set to 0.2, 80% of the training data is used to test the model, while the remaining 20% is used for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "train02, test02 = train_test_split(train, test_size=0.1, shuffle=False)\n",
    "trainlabels02, testlabels02 = train_test_split(labels, test_size=0.1, shuffle=False)\n",
    "\n",
    "yout1 = testlabels02.iloc[:,0]\n",
    "yout2 = testlabels02.iloc[:,1]\n",
    "\n",
    "x = train02\n",
    "y = testlabels02\n",
    "y1 = trainlabels02.iloc[:,0]\n",
    "y2 = trainlabels02.iloc[:,1]\n",
    "\n",
    "y = y.astype(int)\n",
    "y1 = y1.astype(int)\n",
    "y2 = y2.astype(int)\n",
    "yout1 = yout1.astype(int)\n",
    "yout2 = yout2.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "train02, test02 = train_test_split(train, test_size=0.1, shuffle=False)\n",
    "trainlabels02, testlabels02 = train_test_split(labels, test_size=0.1, shuffle=False)\n",
    "\n",
    "yout1 = testlabels02.iloc[:,0]\n",
    "yout2 = testlabels02.iloc[:,1]\n",
    "\n",
    "x = train02\n",
    "y = testlabels02\n",
    "y1 = trainlabels02.iloc[:,0]\n",
    "y2 = trainlabels02.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(int)\n",
    "y1 = y1.astype(int)\n",
    "y2 = y2.astype(int)\n",
    "yout1 = yout1.astype(int)\n",
    "yout2 = yout2.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_team_goal</th>\n",
       "      <th>away_team_goal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7028</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7030</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>704 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      home_team_goal  away_team_goal\n",
       "6329               1               1\n",
       "6330               2               0\n",
       "6331               0               1\n",
       "6332               3               0\n",
       "6333               1               3\n",
       "...              ...             ...\n",
       "7028               2               1\n",
       "7029               4               2\n",
       "7030               4               1\n",
       "7031               3               1\n",
       "7032               3               1\n",
       "\n",
       "[704 rows x 2 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aof63nTgnt6x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6329 samples\n",
      "Epoch 1/500\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 3.0391 - layer3_loss: 1.5802 - layer3_1_loss: 1.4584 - layer3_acc: 0.3228 - layer3_1_acc: 0.3334\n",
      "Epoch 2/500\n",
      "6329/6329 [==============================] - 0s 52us/sample - loss: 2.9646 - layer3_loss: 1.5479 - layer3_1_loss: 1.4165 - layer3_acc: 0.3286 - layer3_1_acc: 0.3421\n",
      "Epoch 3/500\n",
      "6329/6329 [==============================] - 0s 52us/sample - loss: 2.9632 - layer3_loss: 1.5443 - layer3_1_loss: 1.4190 - layer3_acc: 0.3272 - layer3_1_acc: 0.3429\n",
      "Epoch 4/500\n",
      "6329/6329 [==============================] - 0s 50us/sample - loss: 2.9605 - layer3_loss: 1.5423 - layer3_1_loss: 1.4182 - layer3_acc: 0.3288 - layer3_1_acc: 0.3418\n",
      "Epoch 5/500\n",
      "6329/6329 [==============================] - 0s 61us/sample - loss: 2.9598 - layer3_loss: 1.5407 - layer3_1_loss: 1.4191 - layer3_acc: 0.3288 - layer3_1_acc: 0.3408\n",
      "Epoch 6/500\n",
      "6329/6329 [==============================] - 0s 58us/sample - loss: 2.9589 - layer3_loss: 1.5388 - layer3_1_loss: 1.4200 - layer3_acc: 0.3286 - layer3_1_acc: 0.3443\n",
      "Epoch 7/500\n",
      "6329/6329 [==============================] - 0s 53us/sample - loss: 2.9589 - layer3_loss: 1.5375 - layer3_1_loss: 1.4214 - layer3_acc: 0.3285 - layer3_1_acc: 0.3421\n",
      "Epoch 8/500\n",
      "6329/6329 [==============================] - 0s 45us/sample - loss: 2.9567 - layer3_loss: 1.5347 - layer3_1_loss: 1.4219 - layer3_acc: 0.3231 - layer3_1_acc: 0.3432\n",
      "Epoch 9/500\n",
      "6329/6329 [==============================] - 0s 46us/sample - loss: 2.9589 - layer3_loss: 1.5360 - layer3_1_loss: 1.4229 - layer3_acc: 0.3252 - layer3_1_acc: 0.3446\n",
      "Epoch 10/500\n",
      "6329/6329 [==============================] - 0s 49us/sample - loss: 2.9560 - layer3_loss: 1.5348 - layer3_1_loss: 1.4210 - layer3_acc: 0.3285 - layer3_1_acc: 0.3427\n",
      "Epoch 11/500\n",
      "6329/6329 [==============================] - 0s 48us/sample - loss: 2.9568 - layer3_loss: 1.5341 - layer3_1_loss: 1.4228 - layer3_acc: 0.3260 - layer3_1_acc: 0.3441\n",
      "Epoch 12/500\n",
      "6329/6329 [==============================] - 0s 47us/sample - loss: 2.9567 - layer3_loss: 1.5340 - layer3_1_loss: 1.4230 - layer3_acc: 0.3252 - layer3_1_acc: 0.3459\n",
      "Epoch 13/500\n",
      "6329/6329 [==============================] - 0s 49us/sample - loss: 2.9539 - layer3_loss: 1.5333 - layer3_1_loss: 1.4202 - layer3_acc: 0.3219 - layer3_1_acc: 0.3492\n",
      "Epoch 14/500\n",
      "6329/6329 [==============================] - 0s 49us/sample - loss: 2.9546 - layer3_loss: 1.5334 - layer3_1_loss: 1.4210 - layer3_acc: 0.3225 - layer3_1_acc: 0.3471\n",
      "Epoch 15/500\n",
      "6329/6329 [==============================] - 0s 49us/sample - loss: 2.9548 - layer3_loss: 1.5337 - layer3_1_loss: 1.4214 - layer3_acc: 0.3203 - layer3_1_acc: 0.3470\n",
      "Epoch 16/500\n",
      "6329/6329 [==============================] - 0s 48us/sample - loss: 2.9544 - layer3_loss: 1.5324 - layer3_1_loss: 1.4219 - layer3_acc: 0.3220 - layer3_1_acc: 0.3473\n",
      "Epoch 17/500\n",
      "6329/6329 [==============================] - 0s 47us/sample - loss: 2.9521 - layer3_loss: 1.5320 - layer3_1_loss: 1.4198 - layer3_acc: 0.3228 - layer3_1_acc: 0.3497\n",
      "Epoch 18/500\n",
      "6329/6329 [==============================] - 0s 49us/sample - loss: 2.9536 - layer3_loss: 1.5315 - layer3_1_loss: 1.4220 - layer3_acc: 0.3228 - layer3_1_acc: 0.3489\n",
      "Epoch 19/500\n",
      "6329/6329 [==============================] - 0s 51us/sample - loss: 2.9531 - layer3_loss: 1.5336 - layer3_1_loss: 1.4199 - layer3_acc: 0.3185 - layer3_1_acc: 0.3533\n",
      "Epoch 20/500\n",
      "6329/6329 [==============================] - 0s 47us/sample - loss: 2.9531 - layer3_loss: 1.5335 - layer3_1_loss: 1.4196 - layer3_acc: 0.3220 - layer3_1_acc: 0.3506\n",
      "Epoch 21/500\n",
      "6329/6329 [==============================] - 0s 48us/sample - loss: 2.9522 - layer3_loss: 1.5316 - layer3_1_loss: 1.4207 - layer3_acc: 0.3217 - layer3_1_acc: 0.3514\n",
      "Epoch 22/500\n",
      "6329/6329 [==============================] - 0s 48us/sample - loss: 2.9529 - layer3_loss: 1.5335 - layer3_1_loss: 1.4193 - layer3_acc: 0.3190 - layer3_1_acc: 0.3517\n",
      "Epoch 23/500\n",
      "6329/6329 [==============================] - 0s 48us/sample - loss: 2.9531 - layer3_loss: 1.5322 - layer3_1_loss: 1.4211 - layer3_acc: 0.3215 - layer3_1_acc: 0.3517\n",
      "Epoch 24/500\n",
      "6329/6329 [==============================] - 0s 56us/sample - loss: 2.9521 - layer3_loss: 1.5320 - layer3_1_loss: 1.4203 - layer3_acc: 0.3219 - layer3_1_acc: 0.3550\n",
      "Epoch 25/500\n",
      "6329/6329 [==============================] - 0s 57us/sample - loss: 2.9520 - layer3_loss: 1.5321 - layer3_1_loss: 1.4200 - layer3_acc: 0.3214 - layer3_1_acc: 0.3542\n",
      "Epoch 26/500\n",
      "6329/6329 [==============================] - 0s 54us/sample - loss: 2.9520 - layer3_loss: 1.5336 - layer3_1_loss: 1.4186 - layer3_acc: 0.3151 - layer3_1_acc: 0.3555\n",
      "Epoch 27/500\n",
      "6329/6329 [==============================] - 0s 53us/sample - loss: 2.9512 - layer3_loss: 1.5312 - layer3_1_loss: 1.4203 - layer3_acc: 0.3239 - layer3_1_acc: 0.3528\n",
      "Epoch 28/500\n",
      "6329/6329 [==============================] - 0s 57us/sample - loss: 2.9516 - layer3_loss: 1.5312 - layer3_1_loss: 1.4204 - layer3_acc: 0.3162 - layer3_1_acc: 0.3527\n",
      "Epoch 29/500\n",
      "6329/6329 [==============================] - 0s 55us/sample - loss: 2.9511 - layer3_loss: 1.5320 - layer3_1_loss: 1.4190 - layer3_acc: 0.3188 - layer3_1_acc: 0.3547\n",
      "Epoch 30/500\n",
      "6329/6329 [==============================] - 0s 55us/sample - loss: 2.9524 - layer3_loss: 1.5335 - layer3_1_loss: 1.4188 - layer3_acc: 0.3176 - layer3_1_acc: 0.3536\n",
      "Epoch 31/500\n",
      "6329/6329 [==============================] - 0s 50us/sample - loss: 2.9506 - layer3_loss: 1.5297 - layer3_1_loss: 1.4209 - layer3_acc: 0.3219 - layer3_1_acc: 0.3516\n",
      "Epoch 32/500\n",
      "6329/6329 [==============================] - 0s 49us/sample - loss: 2.9508 - layer3_loss: 1.5316 - layer3_1_loss: 1.4191 - layer3_acc: 0.3214 - layer3_1_acc: 0.3535\n",
      "Epoch 33/500\n",
      "6329/6329 [==============================] - 0s 49us/sample - loss: 2.9505 - layer3_loss: 1.5317 - layer3_1_loss: 1.4188 - layer3_acc: 0.3176 - layer3_1_acc: 0.3555\n",
      "Epoch 34/500\n",
      "6329/6329 [==============================] - 0s 54us/sample - loss: 2.9502 - layer3_loss: 1.5320 - layer3_1_loss: 1.4180 - layer3_acc: 0.3201 - layer3_1_acc: 0.3553\n",
      "Epoch 35/500\n",
      "6329/6329 [==============================] - 0s 51us/sample - loss: 2.9500 - layer3_loss: 1.5323 - layer3_1_loss: 1.4174 - layer3_acc: 0.3184 - layer3_1_acc: 0.3571\n",
      "Epoch 36/500\n",
      "6329/6329 [==============================] - 0s 52us/sample - loss: 2.9501 - layer3_loss: 1.5316 - layer3_1_loss: 1.4182 - layer3_acc: 0.3188 - layer3_1_acc: 0.3563\n",
      "Epoch 37/500\n",
      "6329/6329 [==============================] - 0s 50us/sample - loss: 2.9497 - layer3_loss: 1.5307 - layer3_1_loss: 1.4190 - layer3_acc: 0.3196 - layer3_1_acc: 0.3563\n",
      "Epoch 38/500\n",
      "6329/6329 [==============================] - 0s 50us/sample - loss: 2.9497 - layer3_loss: 1.5317 - layer3_1_loss: 1.4182 - layer3_acc: 0.3176 - layer3_1_acc: 0.3569\n",
      "Epoch 39/500\n",
      "6329/6329 [==============================] - 0s 48us/sample - loss: 2.9510 - layer3_loss: 1.5313 - layer3_1_loss: 1.4201 - layer3_acc: 0.3193 - layer3_1_acc: 0.3569\n",
      "Epoch 40/500\n",
      "6329/6329 [==============================] - 0s 51us/sample - loss: 2.9499 - layer3_loss: 1.5321 - layer3_1_loss: 1.4176 - layer3_acc: 0.3219 - layer3_1_acc: 0.3561\n",
      "Epoch 41/500\n",
      "6329/6329 [==============================] - 0s 51us/sample - loss: 2.9498 - layer3_loss: 1.5321 - layer3_1_loss: 1.4178 - layer3_acc: 0.3209 - layer3_1_acc: 0.3588\n",
      "Epoch 42/500\n",
      "6329/6329 [==============================] - 0s 50us/sample - loss: 2.9496 - layer3_loss: 1.5301 - layer3_1_loss: 1.4197 - layer3_acc: 0.3168 - layer3_1_acc: 0.3536\n",
      "Epoch 43/500\n",
      "6329/6329 [==============================] - 0s 50us/sample - loss: 2.9511 - layer3_loss: 1.5327 - layer3_1_loss: 1.4181 - layer3_acc: 0.3217 - layer3_1_acc: 0.3574\n",
      "Epoch 44/500\n",
      "6329/6329 [==============================] - 0s 49us/sample - loss: 2.9478 - layer3_loss: 1.5310 - layer3_1_loss: 1.4164 - layer3_acc: 0.3204 - layer3_1_acc: 0.3557\n",
      "Epoch 45/500\n",
      "6329/6329 [==============================] - 0s 47us/sample - loss: 2.9490 - layer3_loss: 1.5322 - layer3_1_loss: 1.4171 - layer3_acc: 0.3215 - layer3_1_acc: 0.3566\n",
      "Epoch 46/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329/6329 [==============================] - 0s 50us/sample - loss: 2.9487 - layer3_loss: 1.5313 - layer3_1_loss: 1.4177 - layer3_acc: 0.3190 - layer3_1_acc: 0.3547\n",
      "Epoch 47/500\n",
      "6329/6329 [==============================] - 0s 51us/sample - loss: 2.9474 - layer3_loss: 1.5307 - layer3_1_loss: 1.4168 - layer3_acc: 0.3198 - layer3_1_acc: 0.3571\n",
      "Epoch 48/500\n",
      "6329/6329 [==============================] - 0s 47us/sample - loss: 2.9482 - layer3_loss: 1.5306 - layer3_1_loss: 1.4175 - layer3_acc: 0.3214 - layer3_1_acc: 0.3576\n",
      "Epoch 49/500\n",
      "6329/6329 [==============================] - 0s 50us/sample - loss: 2.9496 - layer3_loss: 1.5296 - layer3_1_loss: 1.4199 - layer3_acc: 0.3179 - layer3_1_acc: 0.3588\n",
      "Epoch 50/500\n",
      "6329/6329 [==============================] - 0s 46us/sample - loss: 2.9477 - layer3_loss: 1.5314 - layer3_1_loss: 1.4164 - layer3_acc: 0.3200 - layer3_1_acc: 0.3568\n",
      "Epoch 51/500\n",
      "6329/6329 [==============================] - 0s 50us/sample - loss: 2.9482 - layer3_loss: 1.5304 - layer3_1_loss: 1.4181 - layer3_acc: 0.3206 - layer3_1_acc: 0.3549\n",
      "Epoch 52/500\n",
      "6329/6329 [==============================] - 0s 50us/sample - loss: 2.9484 - layer3_loss: 1.5310 - layer3_1_loss: 1.4176 - layer3_acc: 0.3201 - layer3_1_acc: 0.3579\n",
      "Epoch 53/500\n",
      "6329/6329 [==============================] - 0s 50us/sample - loss: 2.9483 - layer3_loss: 1.5310 - layer3_1_loss: 1.4173 - layer3_acc: 0.3198 - layer3_1_acc: 0.3547\n",
      "Epoch 54/500\n",
      "6329/6329 [==============================] - 0s 55us/sample - loss: 2.9474 - layer3_loss: 1.5295 - layer3_1_loss: 1.4178 - layer3_acc: 0.3207 - layer3_1_acc: 0.3558\n",
      "Epoch 55/500\n",
      "6329/6329 [==============================] - 0s 61us/sample - loss: 2.9474 - layer3_loss: 1.5304 - layer3_1_loss: 1.4170 - layer3_acc: 0.3198 - layer3_1_acc: 0.3590\n",
      "Epoch 56/500\n",
      "6329/6329 [==============================] - 0s 54us/sample - loss: 2.9469 - layer3_loss: 1.5301 - layer3_1_loss: 1.4171 - layer3_acc: 0.3184 - layer3_1_acc: 0.3558\n",
      "Epoch 57/500\n",
      "6329/6329 [==============================] - 0s 44us/sample - loss: 2.9486 - layer3_loss: 1.5301 - layer3_1_loss: 1.4185 - layer3_acc: 0.3204 - layer3_1_acc: 0.3541\n",
      "Epoch 58/500\n",
      "6329/6329 [==============================] - 0s 50us/sample - loss: 2.9471 - layer3_loss: 1.5300 - layer3_1_loss: 1.4168 - layer3_acc: 0.3171 - layer3_1_acc: 0.3568\n",
      "Epoch 59/500\n",
      "6329/6329 [==============================] - 0s 50us/sample - loss: 2.9483 - layer3_loss: 1.5314 - layer3_1_loss: 1.4173 - layer3_acc: 0.3188 - layer3_1_acc: 0.3550\n",
      "Epoch 60/500\n",
      "6329/6329 [==============================] - 0s 50us/sample - loss: 2.9470 - layer3_loss: 1.5284 - layer3_1_loss: 1.4187 - layer3_acc: 0.3171 - layer3_1_acc: 0.3591\n",
      "Epoch 61/500\n",
      "6329/6329 [==============================] - 0s 58us/sample - loss: 2.9466 - layer3_loss: 1.5291 - layer3_1_loss: 1.4177 - layer3_acc: 0.3239 - layer3_1_acc: 0.3577\n",
      "Epoch 62/500\n",
      "6329/6329 [==============================] - 0s 53us/sample - loss: 2.9461 - layer3_loss: 1.5288 - layer3_1_loss: 1.4173 - layer3_acc: 0.3219 - layer3_1_acc: 0.3580\n",
      "Epoch 63/500\n",
      "6329/6329 [==============================] - 0s 51us/sample - loss: 2.9455 - layer3_loss: 1.5283 - layer3_1_loss: 1.4173 - layer3_acc: 0.3222 - layer3_1_acc: 0.3577\n",
      "Epoch 64/500\n",
      "6329/6329 [==============================] - 0s 49us/sample - loss: 2.9469 - layer3_loss: 1.5309 - layer3_1_loss: 1.4158 - layer3_acc: 0.3222 - layer3_1_acc: 0.3602\n",
      "Epoch 65/500\n",
      "6329/6329 [==============================] - 0s 50us/sample - loss: 2.9457 - layer3_loss: 1.5293 - layer3_1_loss: 1.4161 - layer3_acc: 0.3196 - layer3_1_acc: 0.3576\n",
      "Epoch 66/500\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9460 - layer3_loss: 1.5302 - layer3_1_loss: 1.4160 - layer3_acc: 0.3225 - layer3_1_acc: 0.3574\n",
      "Epoch 67/500\n",
      "6329/6329 [==============================] - 0s 55us/sample - loss: 2.9460 - layer3_loss: 1.5294 - layer3_1_loss: 1.4165 - layer3_acc: 0.3198 - layer3_1_acc: 0.3584\n",
      "Epoch 68/500\n",
      "6329/6329 [==============================] - 0s 55us/sample - loss: 2.9454 - layer3_loss: 1.5290 - layer3_1_loss: 1.4162 - layer3_acc: 0.3198 - layer3_1_acc: 0.3588\n",
      "Epoch 69/500\n",
      "6329/6329 [==============================] - 0s 54us/sample - loss: 2.9461 - layer3_loss: 1.5282 - layer3_1_loss: 1.4176 - layer3_acc: 0.3223 - layer3_1_acc: 0.3560\n",
      "Epoch 70/500\n",
      "6329/6329 [==============================] - 0s 49us/sample - loss: 2.9461 - layer3_loss: 1.5291 - layer3_1_loss: 1.4172 - layer3_acc: 0.3214 - layer3_1_acc: 0.3542\n",
      "Epoch 71/500\n",
      "6329/6329 [==============================] - 0s 55us/sample - loss: 2.9450 - layer3_loss: 1.5282 - layer3_1_loss: 1.4168 - layer3_acc: 0.3215 - layer3_1_acc: 0.3580\n",
      "Epoch 72/500\n",
      "6329/6329 [==============================] - 0s 57us/sample - loss: 2.9454 - layer3_loss: 1.5303 - layer3_1_loss: 1.4156 - layer3_acc: 0.3144 - layer3_1_acc: 0.3591\n",
      "Epoch 73/500\n",
      "6329/6329 [==============================] - 0s 49us/sample - loss: 2.9444 - layer3_loss: 1.5285 - layer3_1_loss: 1.4159 - layer3_acc: 0.3203 - layer3_1_acc: 0.3579\n",
      "Epoch 74/500\n",
      "6329/6329 [==============================] - 0s 49us/sample - loss: 2.9446 - layer3_loss: 1.5304 - layer3_1_loss: 1.4144 - layer3_acc: 0.3195 - layer3_1_acc: 0.3576\n",
      "Epoch 75/500\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9442 - layer3_loss: 1.5283 - layer3_1_loss: 1.4164 - layer3_acc: 0.3225 - layer3_1_acc: 0.3601\n",
      "Epoch 76/500\n",
      "6329/6329 [==============================] - 0s 57us/sample - loss: 2.9442 - layer3_loss: 1.5275 - layer3_1_loss: 1.4168 - layer3_acc: 0.3193 - layer3_1_acc: 0.3609\n",
      "Epoch 77/500\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9442 - layer3_loss: 1.5290 - layer3_1_loss: 1.4153 - layer3_acc: 0.3176 - layer3_1_acc: 0.3596\n",
      "Epoch 78/500\n",
      "6329/6329 [==============================] - 0s 60us/sample - loss: 2.9432 - layer3_loss: 1.5272 - layer3_1_loss: 1.4162 - layer3_acc: 0.3192 - layer3_1_acc: 0.3576\n",
      "Epoch 79/500\n",
      "6329/6329 [==============================] - 0s 53us/sample - loss: 2.9430 - layer3_loss: 1.5279 - layer3_1_loss: 1.4150 - layer3_acc: 0.3214 - layer3_1_acc: 0.3599\n",
      "Epoch 80/500\n",
      "6329/6329 [==============================] - 0s 56us/sample - loss: 2.9436 - layer3_loss: 1.5287 - layer3_1_loss: 1.4148 - layer3_acc: 0.3162 - layer3_1_acc: 0.3631\n",
      "Epoch 81/500\n",
      "6329/6329 [==============================] - 0s 56us/sample - loss: 2.9438 - layer3_loss: 1.5285 - layer3_1_loss: 1.4153 - layer3_acc: 0.3230 - layer3_1_acc: 0.3585\n",
      "Epoch 82/500\n",
      "6329/6329 [==============================] - 0s 58us/sample - loss: 2.9433 - layer3_loss: 1.5271 - layer3_1_loss: 1.4161 - layer3_acc: 0.3234 - layer3_1_acc: 0.3656\n",
      "Epoch 83/500\n",
      "6329/6329 [==============================] - 0s 57us/sample - loss: 2.9429 - layer3_loss: 1.5284 - layer3_1_loss: 1.4142 - layer3_acc: 0.3226 - layer3_1_acc: 0.3602\n",
      "Epoch 84/500\n",
      "6329/6329 [==============================] - 0s 58us/sample - loss: 2.9425 - layer3_loss: 1.5275 - layer3_1_loss: 1.4151 - layer3_acc: 0.3177 - layer3_1_acc: 0.3609\n",
      "Epoch 85/500\n",
      "6329/6329 [==============================] - 0s 57us/sample - loss: 2.9424 - layer3_loss: 1.5279 - layer3_1_loss: 1.4146 - layer3_acc: 0.3203 - layer3_1_acc: 0.3640\n",
      "Epoch 86/500\n",
      "6329/6329 [==============================] - 0s 50us/sample - loss: 2.9435 - layer3_loss: 1.5280 - layer3_1_loss: 1.4153 - layer3_acc: 0.3200 - layer3_1_acc: 0.3612\n",
      "Epoch 87/500\n",
      "6329/6329 [==============================] - 0s 53us/sample - loss: 2.9426 - layer3_loss: 1.5277 - layer3_1_loss: 1.4151 - layer3_acc: 0.3166 - layer3_1_acc: 0.3584\n",
      "Epoch 88/500\n",
      "6329/6329 [==============================] - 0s 53us/sample - loss: 2.9426 - layer3_loss: 1.5261 - layer3_1_loss: 1.4163 - layer3_acc: 0.3174 - layer3_1_acc: 0.3593\n",
      "Epoch 89/500\n",
      "6329/6329 [==============================] - 0s 52us/sample - loss: 2.9416 - layer3_loss: 1.5287 - layer3_1_loss: 1.4127 - layer3_acc: 0.3196 - layer3_1_acc: 0.3598\n",
      "Epoch 90/500\n",
      "6329/6329 [==============================] - 0s 52us/sample - loss: 2.9410 - layer3_loss: 1.5269 - layer3_1_loss: 1.4143 - layer3_acc: 0.3222 - layer3_1_acc: 0.3620\n",
      "Epoch 91/500\n",
      "6329/6329 [==============================] - 0s 52us/sample - loss: 2.9412 - layer3_loss: 1.5265 - layer3_1_loss: 1.4150 - layer3_acc: 0.3179 - layer3_1_acc: 0.3626\n",
      "Epoch 92/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329/6329 [==============================] - 0s 53us/sample - loss: 2.9421 - layer3_loss: 1.5283 - layer3_1_loss: 1.4137 - layer3_acc: 0.3230 - layer3_1_acc: 0.3606\n",
      "Epoch 93/500\n",
      "6329/6329 [==============================] - 0s 51us/sample - loss: 2.9411 - layer3_loss: 1.5247 - layer3_1_loss: 1.4160 - layer3_acc: 0.3225 - layer3_1_acc: 0.3628\n",
      "Epoch 94/500\n",
      "6329/6329 [==============================] - 0s 51us/sample - loss: 2.9412 - layer3_loss: 1.5267 - layer3_1_loss: 1.4144 - layer3_acc: 0.3160 - layer3_1_acc: 0.3617\n",
      "Epoch 95/500\n",
      "6329/6329 [==============================] - 0s 50us/sample - loss: 2.9425 - layer3_loss: 1.5274 - layer3_1_loss: 1.4149 - layer3_acc: 0.3160 - layer3_1_acc: 0.3587\n",
      "Epoch 96/500\n",
      "6329/6329 [==============================] - 0s 51us/sample - loss: 2.9416 - layer3_loss: 1.5272 - layer3_1_loss: 1.4144 - layer3_acc: 0.3188 - layer3_1_acc: 0.3621\n",
      "Epoch 97/500\n",
      "6329/6329 [==============================] - 0s 50us/sample - loss: 2.9407 - layer3_loss: 1.5255 - layer3_1_loss: 1.4155 - layer3_acc: 0.3233 - layer3_1_acc: 0.3590\n",
      "Epoch 98/500\n",
      "6329/6329 [==============================] - 0s 50us/sample - loss: 2.9409 - layer3_loss: 1.5266 - layer3_1_loss: 1.4144 - layer3_acc: 0.3187 - layer3_1_acc: 0.3576\n",
      "Epoch 99/500\n",
      "6329/6329 [==============================] - 0s 49us/sample - loss: 2.9390 - layer3_loss: 1.5256 - layer3_1_loss: 1.4133 - layer3_acc: 0.3236 - layer3_1_acc: 0.3584\n",
      "Epoch 100/500\n",
      "6329/6329 [==============================] - 0s 54us/sample - loss: 2.9406 - layer3_loss: 1.5254 - layer3_1_loss: 1.4152 - layer3_acc: 0.3203 - layer3_1_acc: 0.3612\n",
      "Epoch 101/500\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9403 - layer3_loss: 1.5274 - layer3_1_loss: 1.4127 - layer3_acc: 0.3209 - layer3_1_acc: 0.3572\n",
      "Epoch 102/500\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9396 - layer3_loss: 1.5256 - layer3_1_loss: 1.4141 - layer3_acc: 0.3226 - layer3_1_acc: 0.3587\n",
      "Epoch 103/500\n",
      "6329/6329 [==============================] - 0s 58us/sample - loss: 2.9390 - layer3_loss: 1.5250 - layer3_1_loss: 1.4143 - layer3_acc: 0.3206 - layer3_1_acc: 0.3666\n",
      "Epoch 104/500\n",
      "6329/6329 [==============================] - 0s 50us/sample - loss: 2.9393 - layer3_loss: 1.5255 - layer3_1_loss: 1.4140 - layer3_acc: 0.3201 - layer3_1_acc: 0.3632\n",
      "Epoch 105/500\n",
      "6329/6329 [==============================] - 0s 50us/sample - loss: 2.9385 - layer3_loss: 1.5244 - layer3_1_loss: 1.4140 - layer3_acc: 0.3223 - layer3_1_acc: 0.3623\n",
      "Epoch 106/500\n",
      "6329/6329 [==============================] - 0s 48us/sample - loss: 2.9381 - layer3_loss: 1.5252 - layer3_1_loss: 1.4128 - layer3_acc: 0.3215 - layer3_1_acc: 0.3658\n",
      "Epoch 107/500\n",
      "6329/6329 [==============================] - 0s 47us/sample - loss: 2.9401 - layer3_loss: 1.5253 - layer3_1_loss: 1.4150 - layer3_acc: 0.3204 - layer3_1_acc: 0.3615\n",
      "Epoch 108/500\n",
      "6329/6329 [==============================] - 0s 47us/sample - loss: 2.9391 - layer3_loss: 1.5268 - layer3_1_loss: 1.4122 - layer3_acc: 0.3245 - layer3_1_acc: 0.3587\n",
      "Epoch 109/500\n",
      "6329/6329 [==============================] - 0s 49us/sample - loss: 2.9392 - layer3_loss: 1.5243 - layer3_1_loss: 1.4153 - layer3_acc: 0.3260 - layer3_1_acc: 0.3626\n",
      "Epoch 110/500\n",
      "6329/6329 [==============================] - 0s 46us/sample - loss: 2.9395 - layer3_loss: 1.5268 - layer3_1_loss: 1.4125 - layer3_acc: 0.3220 - layer3_1_acc: 0.3621\n",
      "Epoch 111/500\n",
      "6329/6329 [==============================] - 0s 45us/sample - loss: 2.9397 - layer3_loss: 1.5256 - layer3_1_loss: 1.4142 - layer3_acc: 0.3187 - layer3_1_acc: 0.3617\n",
      "Epoch 112/500\n",
      "6329/6329 [==============================] - 0s 49us/sample - loss: 2.9373 - layer3_loss: 1.5242 - layer3_1_loss: 1.4132 - layer3_acc: 0.3242 - layer3_1_acc: 0.3625\n",
      "Epoch 113/500\n",
      "6329/6329 [==============================] - 0s 47us/sample - loss: 2.9379 - layer3_loss: 1.5250 - layer3_1_loss: 1.4126 - layer3_acc: 0.3236 - layer3_1_acc: 0.3626\n",
      "Epoch 114/500\n",
      "6329/6329 [==============================] - 0s 45us/sample - loss: 2.9379 - layer3_loss: 1.5239 - layer3_1_loss: 1.4139 - layer3_acc: 0.3203 - layer3_1_acc: 0.3598\n",
      "Epoch 115/500\n",
      "6329/6329 [==============================] - 0s 47us/sample - loss: 2.9377 - layer3_loss: 1.5248 - layer3_1_loss: 1.4129 - layer3_acc: 0.3195 - layer3_1_acc: 0.3650\n",
      "Epoch 116/500\n",
      "6329/6329 [==============================] - 0s 48us/sample - loss: 2.9373 - layer3_loss: 1.5248 - layer3_1_loss: 1.4124 - layer3_acc: 0.3219 - layer3_1_acc: 0.3609\n",
      "Epoch 117/500\n",
      "6329/6329 [==============================] - 0s 49us/sample - loss: 2.9369 - layer3_loss: 1.5236 - layer3_1_loss: 1.4132 - layer3_acc: 0.3275 - layer3_1_acc: 0.3610\n",
      "Epoch 118/500\n",
      "6329/6329 [==============================] - 0s 48us/sample - loss: 2.9381 - layer3_loss: 1.5249 - layer3_1_loss: 1.4131 - layer3_acc: 0.3252 - layer3_1_acc: 0.3618\n",
      "Epoch 119/500\n",
      "6329/6329 [==============================] - 0s 48us/sample - loss: 2.9362 - layer3_loss: 1.5237 - layer3_1_loss: 1.4125 - layer3_acc: 0.3242 - layer3_1_acc: 0.3618\n",
      "Epoch 120/500\n",
      "6329/6329 [==============================] - 0s 55us/sample - loss: 2.9362 - layer3_loss: 1.5238 - layer3_1_loss: 1.4126 - layer3_acc: 0.3219 - layer3_1_acc: 0.3599\n",
      "Epoch 121/500\n",
      "6329/6329 [==============================] - 0s 50us/sample - loss: 2.9364 - layer3_loss: 1.5234 - layer3_1_loss: 1.4129 - layer3_acc: 0.3220 - layer3_1_acc: 0.3618\n",
      "Epoch 122/500\n",
      "6329/6329 [==============================] - 0s 49us/sample - loss: 2.9349 - layer3_loss: 1.5236 - layer3_1_loss: 1.4117 - layer3_acc: 0.3195 - layer3_1_acc: 0.3663\n",
      "Epoch 123/500\n",
      "6329/6329 [==============================] - 0s 48us/sample - loss: 2.9355 - layer3_loss: 1.5231 - layer3_1_loss: 1.4126 - layer3_acc: 0.3249 - layer3_1_acc: 0.3610\n",
      "Epoch 124/500\n",
      "6329/6329 [==============================] - 0s 48us/sample - loss: 2.9356 - layer3_loss: 1.5233 - layer3_1_loss: 1.4125 - layer3_acc: 0.3260 - layer3_1_acc: 0.3644\n",
      "Epoch 125/500\n",
      "6329/6329 [==============================] - 0s 49us/sample - loss: 2.9357 - layer3_loss: 1.5222 - layer3_1_loss: 1.4136 - layer3_acc: 0.3223 - layer3_1_acc: 0.3577\n",
      "Epoch 126/500\n",
      "6329/6329 [==============================] - 0s 50us/sample - loss: 2.9361 - layer3_loss: 1.5238 - layer3_1_loss: 1.4119 - layer3_acc: 0.3237 - layer3_1_acc: 0.3607\n",
      "Epoch 127/500\n",
      "6329/6329 [==============================] - 0s 46us/sample - loss: 2.9375 - layer3_loss: 1.5241 - layer3_1_loss: 1.4131 - layer3_acc: 0.3196 - layer3_1_acc: 0.3632\n",
      "Epoch 128/500\n",
      "6329/6329 [==============================] - 0s 48us/sample - loss: 2.9356 - layer3_loss: 1.5241 - layer3_1_loss: 1.4114 - layer3_acc: 0.3234 - layer3_1_acc: 0.3585\n",
      "Epoch 129/500\n",
      "6329/6329 [==============================] - 0s 50us/sample - loss: 2.9343 - layer3_loss: 1.5221 - layer3_1_loss: 1.4122 - layer3_acc: 0.3231 - layer3_1_acc: 0.3614\n",
      "Epoch 130/500\n",
      "6329/6329 [==============================] - 0s 52us/sample - loss: 2.9346 - layer3_loss: 1.5238 - layer3_1_loss: 1.4110 - layer3_acc: 0.3247 - layer3_1_acc: 0.3617\n",
      "Epoch 131/500\n",
      "6329/6329 [==============================] - 0s 51us/sample - loss: 2.9345 - layer3_loss: 1.5223 - layer3_1_loss: 1.4119 - layer3_acc: 0.3255 - layer3_1_acc: 0.3612\n",
      "Epoch 132/500\n",
      "6329/6329 [==============================] - 0s 48us/sample - loss: 2.9339 - layer3_loss: 1.5225 - layer3_1_loss: 1.4114 - layer3_acc: 0.3279 - layer3_1_acc: 0.3606\n",
      "Epoch 133/500\n",
      "6329/6329 [==============================] - 0s 47us/sample - loss: 2.9339 - layer3_loss: 1.5250 - layer3_1_loss: 1.4085 - layer3_acc: 0.3241 - layer3_1_acc: 0.3647\n",
      "Epoch 134/500\n",
      "6329/6329 [==============================] - 0s 47us/sample - loss: 2.9332 - layer3_loss: 1.5218 - layer3_1_loss: 1.4118 - layer3_acc: 0.3247 - layer3_1_acc: 0.3625\n",
      "Epoch 135/500\n",
      "6329/6329 [==============================] - 0s 50us/sample - loss: 2.9336 - layer3_loss: 1.5224 - layer3_1_loss: 1.4113 - layer3_acc: 0.3242 - layer3_1_acc: 0.3598\n",
      "Epoch 136/500\n",
      "6329/6329 [==============================] - 0s 48us/sample - loss: 2.9333 - layer3_loss: 1.5227 - layer3_1_loss: 1.4105 - layer3_acc: 0.3237 - layer3_1_acc: 0.3650\n",
      "Epoch 137/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329/6329 [==============================] - 0s 47us/sample - loss: 2.9329 - layer3_loss: 1.5214 - layer3_1_loss: 1.4119 - layer3_acc: 0.3234 - layer3_1_acc: 0.3677\n",
      "Epoch 138/500\n",
      "6329/6329 [==============================] - 0s 45us/sample - loss: 2.9328 - layer3_loss: 1.5211 - layer3_1_loss: 1.4116 - layer3_acc: 0.3264 - layer3_1_acc: 0.3591\n",
      "Epoch 139/500\n",
      "6329/6329 [==============================] - 0s 46us/sample - loss: 2.9316 - layer3_loss: 1.5200 - layer3_1_loss: 1.4114 - layer3_acc: 0.3279 - layer3_1_acc: 0.3617\n",
      "Epoch 140/500\n",
      "6329/6329 [==============================] - 0s 47us/sample - loss: 2.9322 - layer3_loss: 1.5230 - layer3_1_loss: 1.4094 - layer3_acc: 0.3255 - layer3_1_acc: 0.3647\n",
      "Epoch 141/500\n",
      "6329/6329 [==============================] - 0s 46us/sample - loss: 2.9311 - layer3_loss: 1.5194 - layer3_1_loss: 1.4116 - layer3_acc: 0.3223 - layer3_1_acc: 0.3674\n",
      "Epoch 142/500\n",
      "6329/6329 [==============================] - 0s 49us/sample - loss: 2.9319 - layer3_loss: 1.5218 - layer3_1_loss: 1.4102 - layer3_acc: 0.3266 - layer3_1_acc: 0.3599\n",
      "Epoch 143/500\n",
      "6329/6329 [==============================] - 0s 44us/sample - loss: 2.9316 - layer3_loss: 1.5217 - layer3_1_loss: 1.4101 - layer3_acc: 0.3209 - layer3_1_acc: 0.3664\n",
      "Epoch 144/500\n",
      "6329/6329 [==============================] - 0s 43us/sample - loss: 2.9307 - layer3_loss: 1.5195 - layer3_1_loss: 1.4108 - layer3_acc: 0.3223 - layer3_1_acc: 0.3642\n",
      "Epoch 145/500\n",
      "6329/6329 [==============================] - 0s 45us/sample - loss: 2.9305 - layer3_loss: 1.5211 - layer3_1_loss: 1.4095 - layer3_acc: 0.3263 - layer3_1_acc: 0.3666\n",
      "Epoch 146/500\n",
      "6329/6329 [==============================] - 0s 46us/sample - loss: 2.9307 - layer3_loss: 1.5211 - layer3_1_loss: 1.4098 - layer3_acc: 0.3264 - layer3_1_acc: 0.3637\n",
      "Epoch 147/500\n",
      "6329/6329 [==============================] - 0s 47us/sample - loss: 2.9312 - layer3_loss: 1.5200 - layer3_1_loss: 1.4110 - layer3_acc: 0.3283 - layer3_1_acc: 0.3602\n",
      "Epoch 148/500\n",
      "6329/6329 [==============================] - 0s 44us/sample - loss: 2.9314 - layer3_loss: 1.5200 - layer3_1_loss: 1.4110 - layer3_acc: 0.3247 - layer3_1_acc: 0.3628\n",
      "Epoch 149/500\n",
      "6329/6329 [==============================] - 0s 51us/sample - loss: 2.9301 - layer3_loss: 1.5218 - layer3_1_loss: 1.4082 - layer3_acc: 0.3225 - layer3_1_acc: 0.3653\n",
      "Epoch 150/500\n",
      "6329/6329 [==============================] - 0s 52us/sample - loss: 2.9301 - layer3_loss: 1.5198 - layer3_1_loss: 1.4104 - layer3_acc: 0.3230 - layer3_1_acc: 0.3674\n",
      "Epoch 151/500\n",
      "6329/6329 [==============================] - 0s 59us/sample - loss: 2.9307 - layer3_loss: 1.5208 - layer3_1_loss: 1.4098 - layer3_acc: 0.3260 - layer3_1_acc: 0.3634\n",
      "Epoch 152/500\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9304 - layer3_loss: 1.5203 - layer3_1_loss: 1.4102 - layer3_acc: 0.3226 - layer3_1_acc: 0.3647\n",
      "Epoch 153/500\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9288 - layer3_loss: 1.5197 - layer3_1_loss: 1.4089 - layer3_acc: 0.3277 - layer3_1_acc: 0.3625\n",
      "Epoch 154/500\n",
      "6329/6329 [==============================] - 0s 49us/sample - loss: 2.9296 - layer3_loss: 1.5198 - layer3_1_loss: 1.4094 - layer3_acc: 0.3275 - layer3_1_acc: 0.3683\n",
      "Epoch 155/500\n",
      "6329/6329 [==============================] - 0s 47us/sample - loss: 2.9308 - layer3_loss: 1.5198 - layer3_1_loss: 1.4111 - layer3_acc: 0.3269 - layer3_1_acc: 0.3617\n",
      "Epoch 156/500\n",
      "6329/6329 [==============================] - 0s 50us/sample - loss: 2.9291 - layer3_loss: 1.5196 - layer3_1_loss: 1.4094 - layer3_acc: 0.3223 - layer3_1_acc: 0.3626\n",
      "Epoch 157/500\n",
      "6329/6329 [==============================] - 0s 51us/sample - loss: 2.9288 - layer3_loss: 1.5202 - layer3_1_loss: 1.4086 - layer3_acc: 0.3244 - layer3_1_acc: 0.3636\n",
      "Epoch 158/500\n",
      "6329/6329 [==============================] - 0s 46us/sample - loss: 2.9292 - layer3_loss: 1.5181 - layer3_1_loss: 1.4110 - layer3_acc: 0.3260 - layer3_1_acc: 0.3625\n",
      "Epoch 159/500\n",
      "6329/6329 [==============================] - 0s 53us/sample - loss: 2.9281 - layer3_loss: 1.5187 - layer3_1_loss: 1.4092 - layer3_acc: 0.3258 - layer3_1_acc: 0.3637\n",
      "Epoch 160/500\n",
      "6329/6329 [==============================] - 0s 46us/sample - loss: 2.9279 - layer3_loss: 1.5188 - layer3_1_loss: 1.4092 - layer3_acc: 0.3261 - layer3_1_acc: 0.3626\n",
      "Epoch 161/500\n",
      "6329/6329 [==============================] - 0s 45us/sample - loss: 2.9275 - layer3_loss: 1.5188 - layer3_1_loss: 1.4087 - layer3_acc: 0.3279 - layer3_1_acc: 0.3623\n",
      "Epoch 162/500\n",
      "6329/6329 [==============================] - 0s 46us/sample - loss: 2.9275 - layer3_loss: 1.5184 - layer3_1_loss: 1.4091 - layer3_acc: 0.3228 - layer3_1_acc: 0.3655\n",
      "Epoch 163/500\n",
      "6329/6329 [==============================] - 0s 45us/sample - loss: 2.9275 - layer3_loss: 1.5191 - layer3_1_loss: 1.4086 - layer3_acc: 0.3253 - layer3_1_acc: 0.3659\n",
      "Epoch 164/500\n",
      "6329/6329 [==============================] - 0s 43us/sample - loss: 2.9278 - layer3_loss: 1.5194 - layer3_1_loss: 1.4085 - layer3_acc: 0.3258 - layer3_1_acc: 0.3647\n",
      "Epoch 165/500\n",
      "6329/6329 [==============================] - 0s 43us/sample - loss: 2.9275 - layer3_loss: 1.5180 - layer3_1_loss: 1.4095 - layer3_acc: 0.3267 - layer3_1_acc: 0.3618\n",
      "Epoch 166/500\n",
      "6329/6329 [==============================] - 0s 46us/sample - loss: 2.9253 - layer3_loss: 1.5167 - layer3_1_loss: 1.4087 - layer3_acc: 0.3233 - layer3_1_acc: 0.3647\n",
      "Epoch 167/500\n",
      "6329/6329 [==============================] - 0s 46us/sample - loss: 2.9284 - layer3_loss: 1.5192 - layer3_1_loss: 1.4090 - layer3_acc: 0.3244 - layer3_1_acc: 0.3612\n",
      "Epoch 168/500\n",
      "6329/6329 [==============================] - 0s 53us/sample - loss: 2.9264 - layer3_loss: 1.5187 - layer3_1_loss: 1.4078 - layer3_acc: 0.3258 - layer3_1_acc: 0.3601\n",
      "Epoch 169/500\n",
      "6329/6329 [==============================] - 0s 51us/sample - loss: 2.9272 - layer3_loss: 1.5182 - layer3_1_loss: 1.4089 - layer3_acc: 0.3263 - layer3_1_acc: 0.3621\n",
      "Epoch 170/500\n",
      "6329/6329 [==============================] - 0s 47us/sample - loss: 2.9268 - layer3_loss: 1.5184 - layer3_1_loss: 1.4084 - layer3_acc: 0.3237 - layer3_1_acc: 0.3628\n",
      "Epoch 171/500\n",
      "6329/6329 [==============================] - 0s 46us/sample - loss: 2.9273 - layer3_loss: 1.5177 - layer3_1_loss: 1.4094 - layer3_acc: 0.3264 - layer3_1_acc: 0.3634\n",
      "Epoch 172/500\n",
      "6329/6329 [==============================] - 0s 50us/sample - loss: 2.9256 - layer3_loss: 1.5183 - layer3_1_loss: 1.4072 - layer3_acc: 0.3291 - layer3_1_acc: 0.3658\n",
      "Epoch 173/500\n",
      "6329/6329 [==============================] - 0s 47us/sample - loss: 2.9261 - layer3_loss: 1.5177 - layer3_1_loss: 1.4082 - layer3_acc: 0.3282 - layer3_1_acc: 0.3626\n",
      "Epoch 174/500\n",
      "6329/6329 [==============================] - 0s 51us/sample - loss: 2.9263 - layer3_loss: 1.5180 - layer3_1_loss: 1.4084 - layer3_acc: 0.3274 - layer3_1_acc: 0.3647\n",
      "Epoch 175/500\n",
      "6329/6329 [==============================] - 0s 52us/sample - loss: 2.9240 - layer3_loss: 1.5166 - layer3_1_loss: 1.4077 - layer3_acc: 0.3266 - layer3_1_acc: 0.3661\n",
      "Epoch 176/500\n",
      "6329/6329 [==============================] - 0s 46us/sample - loss: 2.9254 - layer3_loss: 1.5169 - layer3_1_loss: 1.4086 - layer3_acc: 0.3249 - layer3_1_acc: 0.3639\n",
      "Epoch 177/500\n",
      "6329/6329 [==============================] - 0s 46us/sample - loss: 2.9242 - layer3_loss: 1.5170 - layer3_1_loss: 1.4072 - layer3_acc: 0.3282 - layer3_1_acc: 0.3667\n",
      "Epoch 178/500\n",
      "6329/6329 [==============================] - 0s 45us/sample - loss: 2.9255 - layer3_loss: 1.5180 - layer3_1_loss: 1.4075 - layer3_acc: 0.3274 - layer3_1_acc: 0.3632\n",
      "Epoch 179/500\n",
      "6329/6329 [==============================] - 0s 47us/sample - loss: 2.9258 - layer3_loss: 1.5184 - layer3_1_loss: 1.4079 - layer3_acc: 0.3215 - layer3_1_acc: 0.3634\n",
      "Epoch 180/500\n",
      "6329/6329 [==============================] - 0s 43us/sample - loss: 2.9255 - layer3_loss: 1.5161 - layer3_1_loss: 1.4093 - layer3_acc: 0.3271 - layer3_1_acc: 0.3621\n",
      "Epoch 181/500\n",
      "6329/6329 [==============================] - 0s 45us/sample - loss: 2.9224 - layer3_loss: 1.5158 - layer3_1_loss: 1.4065 - layer3_acc: 0.3299 - layer3_1_acc: 0.3631\n",
      "Epoch 182/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329/6329 [==============================] - 0s 45us/sample - loss: 2.9239 - layer3_loss: 1.5173 - layer3_1_loss: 1.4066 - layer3_acc: 0.3260 - layer3_1_acc: 0.3626\n",
      "Epoch 183/500\n",
      "6329/6329 [==============================] - 0s 54us/sample - loss: 2.9228 - layer3_loss: 1.5152 - layer3_1_loss: 1.4076 - layer3_acc: 0.3290 - layer3_1_acc: 0.3642\n",
      "Epoch 184/500\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9241 - layer3_loss: 1.5165 - layer3_1_loss: 1.4075 - layer3_acc: 0.3252 - layer3_1_acc: 0.3669\n",
      "Epoch 185/500\n",
      "6329/6329 [==============================] - 1s 90us/sample - loss: 2.9241 - layer3_loss: 1.5171 - layer3_1_loss: 1.4067 - layer3_acc: 0.3272 - layer3_1_acc: 0.3670\n",
      "Epoch 186/500\n",
      "6329/6329 [==============================] - 1s 83us/sample - loss: 2.9235 - layer3_loss: 1.5148 - layer3_1_loss: 1.4088 - layer3_acc: 0.3214 - layer3_1_acc: 0.3664\n",
      "Epoch 187/500\n",
      "6329/6329 [==============================] - 0s 61us/sample - loss: 2.9227 - layer3_loss: 1.5161 - layer3_1_loss: 1.4067 - layer3_acc: 0.3271 - layer3_1_acc: 0.3629\n",
      "Epoch 188/500\n",
      "6329/6329 [==============================] - 0s 57us/sample - loss: 2.9228 - layer3_loss: 1.5171 - layer3_1_loss: 1.4056 - layer3_acc: 0.3249 - layer3_1_acc: 0.3681\n",
      "Epoch 189/500\n",
      "6329/6329 [==============================] - 0s 55us/sample - loss: 2.9218 - layer3_loss: 1.5153 - layer3_1_loss: 1.4067 - layer3_acc: 0.3280 - layer3_1_acc: 0.3653\n",
      "Epoch 190/500\n",
      "6329/6329 [==============================] - 0s 53us/sample - loss: 2.9229 - layer3_loss: 1.5162 - layer3_1_loss: 1.4071 - layer3_acc: 0.3264 - layer3_1_acc: 0.3669\n",
      "Epoch 191/500\n",
      "6329/6329 [==============================] - 0s 52us/sample - loss: 2.9214 - layer3_loss: 1.5157 - layer3_1_loss: 1.4057 - layer3_acc: 0.3285 - layer3_1_acc: 0.3715\n",
      "Epoch 192/500\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9222 - layer3_loss: 1.5163 - layer3_1_loss: 1.4060 - layer3_acc: 0.3263 - layer3_1_acc: 0.3648\n",
      "Epoch 193/500\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9213 - layer3_loss: 1.5154 - layer3_1_loss: 1.4060 - layer3_acc: 0.3280 - layer3_1_acc: 0.3620\n",
      "Epoch 194/500\n",
      "3520/6329 [===============>..............] - ETA: 0s - loss: 2.9323 - layer3_loss: 1.5192 - layer3_1_loss: 1.4132 - layer3_acc: 0.3259 - layer3_1_acc: 0.3582"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(21,))\n",
    "d = tf.keras.layers.Dense(6, activation='softmax', name='out')\n",
    "\n",
    "layer1 = layers.Dense(42, activation=\"relu\", name=\"layer1\")\n",
    "layer2 = layers.Dense(84, activation=\"relu\", name=\"layer2\")\n",
    "layer3 = layers.Dense(6, activation=\"softmax\", name=\"layer3\")\n",
    "b = layer3(layer2(layer1(inputs)))\n",
    "\n",
    "output_1 = b\n",
    "output_2 = b\n",
    "model = tf.keras.models.Model(\n",
    "   inputs=inputs, outputs=[output_1, output_2])\n",
    "model.compile(optimizer=\"Adam\", loss='sparse_categorical_crossentropy', metrics=[ \"acc\"])\n",
    "history = model.fit(x, (y1, y2), epochs=500)\n",
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test02,( yout1, yout2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['layer3_loss'])\n",
    "plt.plot(history.history['layer3_1_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['home', 'away'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['layer3_acc'])\n",
    "plt.plot(history.history['layer3_1_acc'])\n",
    "plt.title('model acc')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['home', 'away'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(train_X02)\n",
    "y_test_pred = model.predict(test_X02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_goal(arr, team):\n",
    "    a=0\n",
    "    retVal=np.empty((arr[0].size+1))\n",
    "    games = int(arr[team].size / arr[team][1].size)\n",
    "    for i in range(0, games):\n",
    "        for j in range(0, (arr[team][i].size)):\n",
    "            if a < arr[team][i][j]:\n",
    "                a = arr[team][i][j]\n",
    "                retVal[i] = j\n",
    "    return retVal\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predHome = pred_goal(y_test_pred, 0)\n",
    "predAway = pred_goal(y_test_pred, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree_diff(yoriginal,ypred):\n",
    "    val = abs(yoriginal - ypred)\n",
    "    switcher = {\n",
    "        0: 1, # yoriginal = ypred\n",
    "        1: 0.8, # diff of 1. Exple original 1 predicted 2 => 0.75\n",
    "        2: 0.6,\n",
    "        3: 0.4,\n",
    "        4: 0.2, # diff of 4. Exple original 0 predicted 4\n",
    "        5: 0\n",
    "    }\n",
    "    return switcher.get(val, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_model_home_goals=0\n",
    "\n",
    "for valorg,valpred in zip(yout1,predHome):\n",
    "    quality_model_home_goals += degree_diff(valorg,valpred)\n",
    "    \n",
    "quality_model_home_goals = quality_model_home_goals / len(yout1)\n",
    "print (\"Quality model home goals TRAIN\", quality_model_home_goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_model_away_goals=0\n",
    "\n",
    "for valorg,valpred in zip(yout2,predAway):\n",
    "    quality_model_away_goals += degree_diff(valorg,valpred)\n",
    "    \n",
    "quality_model_away_goals = quality_model_away_goals / len(yout2)\n",
    "print (\"Quality model away goals TRAIN\", quality_model_away_goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_quality = (quality_model_home_goals + quality_model_away_goals)/2\n",
    "final_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Updated_Regression_Model_ANN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
