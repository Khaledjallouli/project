{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EMQmP-Bknt5P"
   },
   "source": [
    "# Regression\n",
    "Predict the final goals scored per each team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FtJth4hT577a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 999)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.estimator import inputs\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "\n",
    "from  IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "nVI7Xp89n15I",
    "outputId": "a6867d27-3e4c-4d1d-fd55-89e3dfe9d2eb"
   },
   "outputs": [],
   "source": [
    "#pip install git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pmP557n8nt5X"
   },
   "source": [
    "## Data Preprocessing\n",
    "    1. Normalization\n",
    "    2. Data encoding: The goals [0,10] => [-1,1]. If Goal > 10 => 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u_NuYqrJnt5Y"
   },
   "outputs": [],
   "source": [
    "df02 = pd.read_csv('https://raw.githubusercontent.com/Khaledjallouli/project/master/data/data_regression_goals/sliding02_goals.csv', sep=',', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "colab_type": "code",
    "id": "MFm2Qfk2nt5c",
    "outputId": "87ae932c-32f0-4105-85a5-7f11f80d595a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_team_goal</th>\n",
       "      <th>away_team_goal</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>137</td>\n",
       "      <td>67</td>\n",
       "      <td>117</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>161</td>\n",
       "      <td>78</td>\n",
       "      <td>72</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>134</td>\n",
       "      <td>64</td>\n",
       "      <td>151</td>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>104</td>\n",
       "      <td>44</td>\n",
       "      <td>87</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>120</td>\n",
       "      <td>58</td>\n",
       "      <td>124</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>134</td>\n",
       "      <td>59</td>\n",
       "      <td>100</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.30</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>177</td>\n",
       "      <td>82</td>\n",
       "      <td>74</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>169</td>\n",
       "      <td>95</td>\n",
       "      <td>113</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>6.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>161</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>143</td>\n",
       "      <td>69</td>\n",
       "      <td>134</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7028</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.70</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>80</td>\n",
       "      <td>43</td>\n",
       "      <td>117</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>119</td>\n",
       "      <td>58</td>\n",
       "      <td>112</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>89</td>\n",
       "      <td>47</td>\n",
       "      <td>92</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>104</td>\n",
       "      <td>55</td>\n",
       "      <td>63</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7030</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.50</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>122</td>\n",
       "      <td>59</td>\n",
       "      <td>92</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>84</td>\n",
       "      <td>43</td>\n",
       "      <td>118</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.33</td>\n",
       "      <td>5.25</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>124</td>\n",
       "      <td>62</td>\n",
       "      <td>99</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>103</td>\n",
       "      <td>53</td>\n",
       "      <td>122</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.67</td>\n",
       "      <td>4.20</td>\n",
       "      <td>5.25</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>105</td>\n",
       "      <td>65</td>\n",
       "      <td>126</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>114</td>\n",
       "      <td>63</td>\n",
       "      <td>106</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7033 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      home_team_goal  away_team_goal  odds-home  odds-draw  odds-away  \\\n",
       "0                  2               1       3.50       3.30       2.10   \n",
       "1                  2               2       2.50       3.30       2.88   \n",
       "2                  1               2       1.91       3.40       4.20   \n",
       "3                  2               1       3.25       3.25       2.30   \n",
       "4                  3               0       1.20       6.00      19.00   \n",
       "...              ...             ...        ...        ...        ...   \n",
       "7028               2               1       5.00       3.80       1.70   \n",
       "7029               4               2       2.00       3.60       3.70   \n",
       "7030               4               1       1.80       3.75       4.50   \n",
       "7031               3               1       1.33       5.25       9.00   \n",
       "7032               3               1       1.67       4.20       5.25   \n",
       "\n",
       "      home-wins  home-draws  home-losses  home-goals  home-opposition-goals  \\\n",
       "0             1           3            6          11                     16   \n",
       "1             3           1            6           8                     16   \n",
       "2             4           2            4          10                     15   \n",
       "3             5           2            3          22                     12   \n",
       "4             7           2            1          15                      8   \n",
       "...         ...         ...          ...         ...                    ...   \n",
       "7028          4           2            4          10                     12   \n",
       "7029          3           2            5           9                     21   \n",
       "7030          3           3            4           8                      8   \n",
       "7031          2           3            5          12                     14   \n",
       "7032          6           1            3          10                      8   \n",
       "\n",
       "      home-shots  home-shots_on_target  home-opposition_shots  \\\n",
       "0            137                    67                    117   \n",
       "1            134                    64                    151   \n",
       "2            120                    58                    124   \n",
       "3            177                    82                     74   \n",
       "4            161                    72                     74   \n",
       "...          ...                   ...                    ...   \n",
       "7028          80                    43                    117   \n",
       "7029          89                    47                     92   \n",
       "7030         122                    59                     92   \n",
       "7031         124                    62                     99   \n",
       "7032         105                    65                    126   \n",
       "\n",
       "      home-opposition_shots_on_target  away-wins  away-draws  away-losses  \\\n",
       "0                                  53          8           2            0   \n",
       "1                                  77          3           3            4   \n",
       "2                                  56          2           2            6   \n",
       "3                                  37          6           3            1   \n",
       "4                                  31          3           2            5   \n",
       "...                               ...        ...         ...          ...   \n",
       "7028                               60          2           4            4   \n",
       "7029                               46          1           4            5   \n",
       "7030                               50          5           2            3   \n",
       "7031                               50          3           3            4   \n",
       "7032                               54          3           2            5   \n",
       "\n",
       "      away-goals  away-opposition-goals  away-shots  away-shots_on_target  \\\n",
       "0             15                      6         161                    78   \n",
       "1             11                     18         104                    44   \n",
       "2             11                     15         134                    59   \n",
       "3             19                      8         169                    95   \n",
       "4             10                     17         143                    69   \n",
       "...          ...                    ...         ...                   ...   \n",
       "7028          10                     21         119                    58   \n",
       "7029           7                     21         104                    55   \n",
       "7030          15                      9          84                    43   \n",
       "7031          11                     17         103                    53   \n",
       "7032          13                     19         114                    63   \n",
       "\n",
       "      away-opposition_shots  away-opposition_shots_on_target  \n",
       "0                        72                               30  \n",
       "1                        87                               36  \n",
       "2                       100                               46  \n",
       "3                       113                               58  \n",
       "4                       134                               69  \n",
       "...                     ...                              ...  \n",
       "7028                    112                               65  \n",
       "7029                     63                               26  \n",
       "7030                    118                               56  \n",
       "7031                    122                               54  \n",
       "7032                    106                               46  \n",
       "\n",
       "[7033 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "tzti9zrknt5h",
    "outputId": "0a707ad9-790e-4e25-b52d-9f1c216a360e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "home_team_goal\n",
       "1     2251\n",
       "2     1732\n",
       "0     1589\n",
       "3      885\n",
       "4      378\n",
       "5      132\n",
       "6       43\n",
       "7       13\n",
       "8        7\n",
       "9        2\n",
       "10       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byhomegoal = df02.groupby('home_team_goal')\n",
    "byhomegoal.size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "1V2WCPxmnt5m",
    "outputId": "1fdfd4ba-6e53-4d89-b19f-ebdbe379edaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "away_team_goal\n",
       "1    2381\n",
       "0    2362\n",
       "2    1401\n",
       "3     613\n",
       "4     193\n",
       "5      52\n",
       "6      23\n",
       "8       5\n",
       "7       2\n",
       "9       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byawaygoal = df02.groupby('away_team_goal')\n",
    "byawaygoal.size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O6MockV_nt5p"
   },
   "source": [
    "### =>The two previous cells show that we can keep 6 classes: [0.5].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uwHnhYEynt5t"
   },
   "outputs": [],
   "source": [
    "def get_X_and_y(dataframe):\n",
    "    X = dataframe.drop(columns=['home_team_goal','away_team_goal']).values\n",
    "    y = dataframe[['home_team_goal','away_team_goal']].values\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EyNjI6jPnt5w"
   },
   "outputs": [],
   "source": [
    "def encode(i):\n",
    "    switcher = {\n",
    "        0: 0,\n",
    "        1: 1,\n",
    "        2: 2,\n",
    "        3: 3,\n",
    "        4: 4,\n",
    "        5: 5,\n",
    "    }\n",
    "    # 1 be assigned as default value of passed argument (if goals > 5)\n",
    "    #return switcher.get(i, 1)\n",
    "    return switcher.get(i, 5)\n",
    "\n",
    "def decode(i):\n",
    "    switcher = {\n",
    "        0: 0,\n",
    "        1: 1,\n",
    "        2: 2,\n",
    "        3: 3,\n",
    "        4: 4,\n",
    "        5: 5,\n",
    "    }\n",
    "    #return switcher.get(i, \"ERROR! Use Encode Before!\")\n",
    "    return switcher.get(i, \"ERROR! Use Encode Before!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yOw4-355nt5y"
   },
   "outputs": [],
   "source": [
    "def normalize_try(dataframe):\n",
    "    highestValue = 0;\n",
    "    ds = np.full((dataframe.shape[0], dataframe.shape[1]), 0)\n",
    "    for i in range(dataframe.shape[0]):\n",
    "        for j in range(dataframe.shape[1]):\n",
    "            if highestValue < dataframe[i][j]:\n",
    "                highestValue = dataframe[i][j]\n",
    "    \n",
    "    for i in range(dataframe.shape[0]):\n",
    "        for j in range(dataframe.shape[1]):\n",
    "                dataframe[i][j] = (dataframe[i][j]/highestValue)\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "def normalize(dataframe):\n",
    "    column_names_to_not_normalize = ['home_team_goal','away_team_goal']\n",
    "    column_names_to_normalize = [x for x in list(dataframe) if x not in column_names_to_not_normalize ]\n",
    "    x = dataframe[column_names_to_normalize].values\n",
    "    #x_scaled = preprocessing.normalize(x)\n",
    "    x_scaled = normalize_try(x)\n",
    "    df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = dataframe.index)\n",
    "    dataframe[column_names_to_normalize] = df_temp\n",
    "    \n",
    "    dataframe['home_team_goal'] = dataframe.apply(lambda row: encode(row['home_team_goal']), axis=1)\n",
    "    dataframe['away_team_goal'] = dataframe.apply(lambda row: encode(row['away_team_goal']), axis=1)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "3PmG9M4ent52",
    "outputId": "d8463e61-9811-45b1-b260-8a02202d9105"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329 train examples\n",
      "704 test examples\n"
     ]
    }
   ],
   "source": [
    "n02 = normalize(df02)\n",
    "\n",
    "train02, test02 = train_test_split(n02, test_size=0.1, shuffle=False)\n",
    "print(len(train02), 'train examples')\n",
    "print(len(test02), 'test examples')\n",
    "\n",
    "labels = n02.iloc[:,0:2]\n",
    "train = n02.iloc[:,2:]\n",
    "\n",
    "\n",
    "train_X02,train_y02 = get_X_and_y(train02)\n",
    "labels_train = n02.iloc[:,0:2]\n",
    "\n",
    "test_X02,test_y02 = get_X_and_y(test02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015837</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>0.009502</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.072398</td>\n",
       "      <td>0.619910</td>\n",
       "      <td>0.303167</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.239819</td>\n",
       "      <td>0.036199</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067873</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.728507</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.325792</td>\n",
       "      <td>0.135747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011312</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>0.013032</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.036199</td>\n",
       "      <td>0.072398</td>\n",
       "      <td>0.606335</td>\n",
       "      <td>0.289593</td>\n",
       "      <td>0.683258</td>\n",
       "      <td>0.348416</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.081448</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.199095</td>\n",
       "      <td>0.393665</td>\n",
       "      <td>0.162896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008643</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.019005</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.045249</td>\n",
       "      <td>0.067873</td>\n",
       "      <td>0.542986</td>\n",
       "      <td>0.262443</td>\n",
       "      <td>0.561086</td>\n",
       "      <td>0.253394</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.067873</td>\n",
       "      <td>0.606335</td>\n",
       "      <td>0.266968</td>\n",
       "      <td>0.452489</td>\n",
       "      <td>0.208145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.010407</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.054299</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.371041</td>\n",
       "      <td>0.334842</td>\n",
       "      <td>0.167421</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.085973</td>\n",
       "      <td>0.036199</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.429864</td>\n",
       "      <td>0.511312</td>\n",
       "      <td>0.262443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005430</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.085973</td>\n",
       "      <td>0.031674</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.067873</td>\n",
       "      <td>0.036199</td>\n",
       "      <td>0.728507</td>\n",
       "      <td>0.325792</td>\n",
       "      <td>0.334842</td>\n",
       "      <td>0.140271</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.045249</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.312217</td>\n",
       "      <td>0.606335</td>\n",
       "      <td>0.312217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7028</th>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.017195</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.045249</td>\n",
       "      <td>0.054299</td>\n",
       "      <td>0.361991</td>\n",
       "      <td>0.194570</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.271493</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.045249</td>\n",
       "      <td>0.095023</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.262443</td>\n",
       "      <td>0.506787</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.016290</td>\n",
       "      <td>0.016742</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.040724</td>\n",
       "      <td>0.095023</td>\n",
       "      <td>0.402715</td>\n",
       "      <td>0.212670</td>\n",
       "      <td>0.416290</td>\n",
       "      <td>0.208145</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.031674</td>\n",
       "      <td>0.095023</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.248869</td>\n",
       "      <td>0.285068</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7030</th>\n",
       "      <td>0.008145</td>\n",
       "      <td>0.016968</td>\n",
       "      <td>0.020362</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.036199</td>\n",
       "      <td>0.036199</td>\n",
       "      <td>0.552036</td>\n",
       "      <td>0.266968</td>\n",
       "      <td>0.416290</td>\n",
       "      <td>0.226244</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.067873</td>\n",
       "      <td>0.040724</td>\n",
       "      <td>0.380090</td>\n",
       "      <td>0.194570</td>\n",
       "      <td>0.533937</td>\n",
       "      <td>0.253394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031</th>\n",
       "      <td>0.006018</td>\n",
       "      <td>0.023756</td>\n",
       "      <td>0.040724</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.054299</td>\n",
       "      <td>0.063348</td>\n",
       "      <td>0.561086</td>\n",
       "      <td>0.280543</td>\n",
       "      <td>0.447964</td>\n",
       "      <td>0.226244</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.466063</td>\n",
       "      <td>0.239819</td>\n",
       "      <td>0.552036</td>\n",
       "      <td>0.244344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>0.007557</td>\n",
       "      <td>0.019005</td>\n",
       "      <td>0.023756</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.045249</td>\n",
       "      <td>0.036199</td>\n",
       "      <td>0.475113</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.570136</td>\n",
       "      <td>0.244344</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.085973</td>\n",
       "      <td>0.515837</td>\n",
       "      <td>0.285068</td>\n",
       "      <td>0.479638</td>\n",
       "      <td>0.208145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7033 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      odds-home  odds-draw  odds-away  home-wins  home-draws  home-losses  \\\n",
       "0      0.015837   0.014932   0.009502   0.004525    0.013575     0.027149   \n",
       "1      0.011312   0.014932   0.013032   0.013575    0.004525     0.027149   \n",
       "2      0.008643   0.015385   0.019005   0.018100    0.009050     0.018100   \n",
       "3      0.014706   0.014706   0.010407   0.022624    0.009050     0.013575   \n",
       "4      0.005430   0.027149   0.085973   0.031674    0.009050     0.004525   \n",
       "...         ...        ...        ...        ...         ...          ...   \n",
       "7028   0.022624   0.017195   0.007692   0.018100    0.009050     0.018100   \n",
       "7029   0.009050   0.016290   0.016742   0.013575    0.009050     0.022624   \n",
       "7030   0.008145   0.016968   0.020362   0.013575    0.013575     0.018100   \n",
       "7031   0.006018   0.023756   0.040724   0.009050    0.013575     0.022624   \n",
       "7032   0.007557   0.019005   0.023756   0.027149    0.004525     0.013575   \n",
       "\n",
       "      home-goals  home-opposition-goals  home-shots  home-shots_on_target  \\\n",
       "0       0.049774               0.072398    0.619910              0.303167   \n",
       "1       0.036199               0.072398    0.606335              0.289593   \n",
       "2       0.045249               0.067873    0.542986              0.262443   \n",
       "3       0.099548               0.054299    0.800905              0.371041   \n",
       "4       0.067873               0.036199    0.728507              0.325792   \n",
       "...          ...                    ...         ...                   ...   \n",
       "7028    0.045249               0.054299    0.361991              0.194570   \n",
       "7029    0.040724               0.095023    0.402715              0.212670   \n",
       "7030    0.036199               0.036199    0.552036              0.266968   \n",
       "7031    0.054299               0.063348    0.561086              0.280543   \n",
       "7032    0.045249               0.036199    0.475113              0.294118   \n",
       "\n",
       "      home-opposition_shots  home-opposition_shots_on_target  away-wins  \\\n",
       "0                  0.529412                         0.239819   0.036199   \n",
       "1                  0.683258                         0.348416   0.013575   \n",
       "2                  0.561086                         0.253394   0.009050   \n",
       "3                  0.334842                         0.167421   0.027149   \n",
       "4                  0.334842                         0.140271   0.013575   \n",
       "...                     ...                              ...        ...   \n",
       "7028               0.529412                         0.271493   0.009050   \n",
       "7029               0.416290                         0.208145   0.004525   \n",
       "7030               0.416290                         0.226244   0.022624   \n",
       "7031               0.447964                         0.226244   0.013575   \n",
       "7032               0.570136                         0.244344   0.013575   \n",
       "\n",
       "      away-draws  away-losses  away-goals  away-opposition-goals  away-shots  \\\n",
       "0       0.009050     0.000000    0.067873               0.027149    0.728507   \n",
       "1       0.013575     0.018100    0.049774               0.081448    0.470588   \n",
       "2       0.009050     0.027149    0.049774               0.067873    0.606335   \n",
       "3       0.013575     0.004525    0.085973               0.036199    0.764706   \n",
       "4       0.009050     0.022624    0.045249               0.076923    0.647059   \n",
       "...          ...          ...         ...                    ...         ...   \n",
       "7028    0.018100     0.018100    0.045249               0.095023    0.538462   \n",
       "7029    0.018100     0.022624    0.031674               0.095023    0.470588   \n",
       "7030    0.009050     0.013575    0.067873               0.040724    0.380090   \n",
       "7031    0.013575     0.018100    0.049774               0.076923    0.466063   \n",
       "7032    0.009050     0.022624    0.058824               0.085973    0.515837   \n",
       "\n",
       "      away-shots_on_target  away-opposition_shots  \\\n",
       "0                 0.352941               0.325792   \n",
       "1                 0.199095               0.393665   \n",
       "2                 0.266968               0.452489   \n",
       "3                 0.429864               0.511312   \n",
       "4                 0.312217               0.606335   \n",
       "...                    ...                    ...   \n",
       "7028              0.262443               0.506787   \n",
       "7029              0.248869               0.285068   \n",
       "7030              0.194570               0.533937   \n",
       "7031              0.239819               0.552036   \n",
       "7032              0.285068               0.479638   \n",
       "\n",
       "      away-opposition_shots_on_target  \n",
       "0                            0.135747  \n",
       "1                            0.162896  \n",
       "2                            0.208145  \n",
       "3                            0.262443  \n",
       "4                            0.312217  \n",
       "...                               ...  \n",
       "7028                         0.294118  \n",
       "7029                         0.117647  \n",
       "7030                         0.253394  \n",
       "7031                         0.244344  \n",
       "7032                         0.208145  \n",
       "\n",
       "[7033 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "colab_type": "code",
    "id": "tTAm_MXlnt54",
    "outputId": "a344201f-a5aa-4c17-a193-4c257e25f624"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_team_goal</th>\n",
       "      <th>away_team_goal</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015837</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>0.009502</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.072398</td>\n",
       "      <td>0.619910</td>\n",
       "      <td>0.303167</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.239819</td>\n",
       "      <td>0.036199</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067873</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.728507</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.325792</td>\n",
       "      <td>0.135747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.011312</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>0.013032</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.036199</td>\n",
       "      <td>0.072398</td>\n",
       "      <td>0.606335</td>\n",
       "      <td>0.289593</td>\n",
       "      <td>0.683258</td>\n",
       "      <td>0.348416</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.081448</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.199095</td>\n",
       "      <td>0.393665</td>\n",
       "      <td>0.162896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.008643</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.019005</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.045249</td>\n",
       "      <td>0.067873</td>\n",
       "      <td>0.542986</td>\n",
       "      <td>0.262443</td>\n",
       "      <td>0.561086</td>\n",
       "      <td>0.253394</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.067873</td>\n",
       "      <td>0.606335</td>\n",
       "      <td>0.266968</td>\n",
       "      <td>0.452489</td>\n",
       "      <td>0.208145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.010407</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.054299</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.371041</td>\n",
       "      <td>0.334842</td>\n",
       "      <td>0.167421</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.085973</td>\n",
       "      <td>0.036199</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.429864</td>\n",
       "      <td>0.511312</td>\n",
       "      <td>0.262443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005430</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.085973</td>\n",
       "      <td>0.031674</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.067873</td>\n",
       "      <td>0.036199</td>\n",
       "      <td>0.728507</td>\n",
       "      <td>0.325792</td>\n",
       "      <td>0.334842</td>\n",
       "      <td>0.140271</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.045249</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.312217</td>\n",
       "      <td>0.606335</td>\n",
       "      <td>0.312217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7028</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.017195</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.045249</td>\n",
       "      <td>0.054299</td>\n",
       "      <td>0.361991</td>\n",
       "      <td>0.194570</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.271493</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.045249</td>\n",
       "      <td>0.095023</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.262443</td>\n",
       "      <td>0.506787</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.016290</td>\n",
       "      <td>0.016742</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.040724</td>\n",
       "      <td>0.095023</td>\n",
       "      <td>0.402715</td>\n",
       "      <td>0.212670</td>\n",
       "      <td>0.416290</td>\n",
       "      <td>0.208145</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.031674</td>\n",
       "      <td>0.095023</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.248869</td>\n",
       "      <td>0.285068</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7030</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008145</td>\n",
       "      <td>0.016968</td>\n",
       "      <td>0.020362</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.036199</td>\n",
       "      <td>0.036199</td>\n",
       "      <td>0.552036</td>\n",
       "      <td>0.266968</td>\n",
       "      <td>0.416290</td>\n",
       "      <td>0.226244</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.067873</td>\n",
       "      <td>0.040724</td>\n",
       "      <td>0.380090</td>\n",
       "      <td>0.194570</td>\n",
       "      <td>0.533937</td>\n",
       "      <td>0.253394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006018</td>\n",
       "      <td>0.023756</td>\n",
       "      <td>0.040724</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.054299</td>\n",
       "      <td>0.063348</td>\n",
       "      <td>0.561086</td>\n",
       "      <td>0.280543</td>\n",
       "      <td>0.447964</td>\n",
       "      <td>0.226244</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.466063</td>\n",
       "      <td>0.239819</td>\n",
       "      <td>0.552036</td>\n",
       "      <td>0.244344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007557</td>\n",
       "      <td>0.019005</td>\n",
       "      <td>0.023756</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.045249</td>\n",
       "      <td>0.036199</td>\n",
       "      <td>0.475113</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.570136</td>\n",
       "      <td>0.244344</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.085973</td>\n",
       "      <td>0.515837</td>\n",
       "      <td>0.285068</td>\n",
       "      <td>0.479638</td>\n",
       "      <td>0.208145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7033 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      home_team_goal  away_team_goal  odds-home  odds-draw  odds-away  \\\n",
       "0                  2               1   0.015837   0.014932   0.009502   \n",
       "1                  2               2   0.011312   0.014932   0.013032   \n",
       "2                  1               2   0.008643   0.015385   0.019005   \n",
       "3                  2               1   0.014706   0.014706   0.010407   \n",
       "4                  3               0   0.005430   0.027149   0.085973   \n",
       "...              ...             ...        ...        ...        ...   \n",
       "7028               2               1   0.022624   0.017195   0.007692   \n",
       "7029               4               2   0.009050   0.016290   0.016742   \n",
       "7030               4               1   0.008145   0.016968   0.020362   \n",
       "7031               3               1   0.006018   0.023756   0.040724   \n",
       "7032               3               1   0.007557   0.019005   0.023756   \n",
       "\n",
       "      home-wins  home-draws  home-losses  home-goals  home-opposition-goals  \\\n",
       "0      0.004525    0.013575     0.027149    0.049774               0.072398   \n",
       "1      0.013575    0.004525     0.027149    0.036199               0.072398   \n",
       "2      0.018100    0.009050     0.018100    0.045249               0.067873   \n",
       "3      0.022624    0.009050     0.013575    0.099548               0.054299   \n",
       "4      0.031674    0.009050     0.004525    0.067873               0.036199   \n",
       "...         ...         ...          ...         ...                    ...   \n",
       "7028   0.018100    0.009050     0.018100    0.045249               0.054299   \n",
       "7029   0.013575    0.009050     0.022624    0.040724               0.095023   \n",
       "7030   0.013575    0.013575     0.018100    0.036199               0.036199   \n",
       "7031   0.009050    0.013575     0.022624    0.054299               0.063348   \n",
       "7032   0.027149    0.004525     0.013575    0.045249               0.036199   \n",
       "\n",
       "      home-shots  home-shots_on_target  home-opposition_shots  \\\n",
       "0       0.619910              0.303167               0.529412   \n",
       "1       0.606335              0.289593               0.683258   \n",
       "2       0.542986              0.262443               0.561086   \n",
       "3       0.800905              0.371041               0.334842   \n",
       "4       0.728507              0.325792               0.334842   \n",
       "...          ...                   ...                    ...   \n",
       "7028    0.361991              0.194570               0.529412   \n",
       "7029    0.402715              0.212670               0.416290   \n",
       "7030    0.552036              0.266968               0.416290   \n",
       "7031    0.561086              0.280543               0.447964   \n",
       "7032    0.475113              0.294118               0.570136   \n",
       "\n",
       "      home-opposition_shots_on_target  away-wins  away-draws  away-losses  \\\n",
       "0                            0.239819   0.036199    0.009050     0.000000   \n",
       "1                            0.348416   0.013575    0.013575     0.018100   \n",
       "2                            0.253394   0.009050    0.009050     0.027149   \n",
       "3                            0.167421   0.027149    0.013575     0.004525   \n",
       "4                            0.140271   0.013575    0.009050     0.022624   \n",
       "...                               ...        ...         ...          ...   \n",
       "7028                         0.271493   0.009050    0.018100     0.018100   \n",
       "7029                         0.208145   0.004525    0.018100     0.022624   \n",
       "7030                         0.226244   0.022624    0.009050     0.013575   \n",
       "7031                         0.226244   0.013575    0.013575     0.018100   \n",
       "7032                         0.244344   0.013575    0.009050     0.022624   \n",
       "\n",
       "      away-goals  away-opposition-goals  away-shots  away-shots_on_target  \\\n",
       "0       0.067873               0.027149    0.728507              0.352941   \n",
       "1       0.049774               0.081448    0.470588              0.199095   \n",
       "2       0.049774               0.067873    0.606335              0.266968   \n",
       "3       0.085973               0.036199    0.764706              0.429864   \n",
       "4       0.045249               0.076923    0.647059              0.312217   \n",
       "...          ...                    ...         ...                   ...   \n",
       "7028    0.045249               0.095023    0.538462              0.262443   \n",
       "7029    0.031674               0.095023    0.470588              0.248869   \n",
       "7030    0.067873               0.040724    0.380090              0.194570   \n",
       "7031    0.049774               0.076923    0.466063              0.239819   \n",
       "7032    0.058824               0.085973    0.515837              0.285068   \n",
       "\n",
       "      away-opposition_shots  away-opposition_shots_on_target  \n",
       "0                  0.325792                         0.135747  \n",
       "1                  0.393665                         0.162896  \n",
       "2                  0.452489                         0.208145  \n",
       "3                  0.511312                         0.262443  \n",
       "4                  0.606335                         0.312217  \n",
       "...                     ...                              ...  \n",
       "7028               0.506787                         0.294118  \n",
       "7029               0.285068                         0.117647  \n",
       "7030               0.533937                         0.253394  \n",
       "7031               0.552036                         0.244344  \n",
       "7032               0.479638                         0.208145  \n",
       "\n",
       "[7033 rows x 23 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "44kHTmIWnt57",
    "outputId": "85c08ed4-f34f-4606-83e9-0c126016e171"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "home_team_goal\n",
       "1    2251\n",
       "2    1732\n",
       "0    1589\n",
       "3     885\n",
       "4     378\n",
       "5     198\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verif the classes\n",
    "byhomegoal = df02.groupby('home_team_goal')\n",
    "byhomegoal.size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "LrUTbaq5nt5-",
    "outputId": "f937345d-0acc-42d0-91b3-921c76c8cf40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "away_team_goal\n",
       "1    2381\n",
       "0    2362\n",
       "2    1401\n",
       "3     613\n",
       "4     193\n",
       "5      83\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byawaygoal = df02.groupby('away_team_goal')\n",
    "byawaygoal.size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x-12xzP9nt6F"
   },
   "outputs": [],
   "source": [
    "def round_pred(val):\n",
    "    if val <=1 and val > 0.67:\n",
    "        return 1\n",
    "    elif val <=0.67 and val >0.33:\n",
    "        return 0.60\n",
    "    elif val <= 0.33 and val > 0:\n",
    "        return 0.20\n",
    "    elif val <= 0 and val > -0.33:\n",
    "        return -0.20\n",
    "    elif val<=-0.33 and val> -0.67:\n",
    "        return -0.60\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mIwYgXYent6L"
   },
   "source": [
    "### Build the model\n",
    "\n",
    "https://www.tensorflow.org/tutorials/keras/regression\n",
    "The mean_squared_error (mse) and mean_absolute_error (mae) are our loss functions – i.e. an estimate of how accurate the neural network is in predicting the test data. We can see that with the validation_split set to 0.2, 80% of the training data is used to test the model, while the remaining 20% is used for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train02, test02 = train_test_split(train, test_size=0.1, shuffle=False)\n",
    "trainlabels02, testlabels02 = train_test_split(labels, test_size=0.1, shuffle=False)\n",
    "\n",
    "yout1 = testlabels02.iloc[:,0]\n",
    "yout2 = testlabels02.iloc[:,1]\n",
    "\n",
    "x = train02\n",
    "y = testlabels02\n",
    "y1 = trainlabels02.iloc[:,0]\n",
    "y2 = trainlabels02.iloc[:,1]\n",
    "\n",
    "y = y.astype(int)\n",
    "y1 = y1.astype(int)\n",
    "y2 = y2.astype(int)\n",
    "yout1 = yout1.astype(int)\n",
    "yout2 = yout2.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train02, test02 = train_test_split(train, test_size=0.1, shuffle=False)\n",
    "trainlabels02, testlabels02 = train_test_split(labels, test_size=0.1, shuffle=False)\n",
    "\n",
    "yout1 = testlabels02.iloc[:,0]\n",
    "yout2 = testlabels02.iloc[:,1]\n",
    "\n",
    "x = train02\n",
    "y = testlabels02\n",
    "y1 = trainlabels02.iloc[:,0]\n",
    "y2 = trainlabels02.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(int)\n",
    "y1 = y1.astype(int)\n",
    "y2 = y2.astype(int)\n",
    "yout1 = yout1.astype(int)\n",
    "yout2 = yout2.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_team_goal</th>\n",
       "      <th>away_team_goal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7028</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7030</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>704 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      home_team_goal  away_team_goal\n",
       "6329               5               1\n",
       "6330               2               0\n",
       "6331               0               1\n",
       "6332               3               0\n",
       "6333               1               3\n",
       "...              ...             ...\n",
       "7028               2               1\n",
       "7029               4               2\n",
       "7030               4               1\n",
       "7031               3               1\n",
       "7032               3               1\n",
       "\n",
       "[704 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aof63nTgnt6x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lisa\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Train on 6329 samples\n",
      "Epoch 1/1000\n",
      "6329/6329 [==============================] - 1s 96us/sample - loss: 3.1397 - layer3_loss: 1.6221 - layer3_1_loss: 1.5167 - layer3_acc: 0.3095 - layer3_1_acc: 0.3286\n",
      "Epoch 2/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 3.0072 - layer3_loss: 1.5696 - layer3_1_loss: 1.4371 - layer3_acc: 0.3163 - layer3_1_acc: 0.3384\n",
      "Epoch 3/1000\n",
      "6329/6329 [==============================] - 0s 69us/sample - loss: 3.0052 - layer3_loss: 1.5681 - layer3_1_loss: 1.4380 - layer3_acc: 0.3163 - layer3_1_acc: 0.3403\n",
      "Epoch 4/1000\n",
      "6329/6329 [==============================] - 0s 69us/sample - loss: 3.0033 - layer3_loss: 1.5661 - layer3_1_loss: 1.4380 - layer3_acc: 0.3176 - layer3_1_acc: 0.3405\n",
      "Epoch 5/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 3.0010 - layer3_loss: 1.5632 - layer3_1_loss: 1.4374 - layer3_acc: 0.3135 - layer3_1_acc: 0.3427\n",
      "Epoch 6/1000\n",
      "6329/6329 [==============================] - 0s 69us/sample - loss: 3.0003 - layer3_loss: 1.5629 - layer3_1_loss: 1.4384 - layer3_acc: 0.3133 - layer3_1_acc: 0.3413\n",
      "Epoch 7/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9993 - layer3_loss: 1.5596 - layer3_1_loss: 1.4392 - layer3_acc: 0.3130 - layer3_1_acc: 0.3433\n",
      "Epoch 8/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9976 - layer3_loss: 1.5585 - layer3_1_loss: 1.4387 - layer3_acc: 0.3141 - layer3_1_acc: 0.3451\n",
      "Epoch 9/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9960 - layer3_loss: 1.5556 - layer3_1_loss: 1.4395 - layer3_acc: 0.3121 - layer3_1_acc: 0.3470\n",
      "Epoch 10/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9946 - layer3_loss: 1.5542 - layer3_1_loss: 1.4400 - layer3_acc: 0.3124 - layer3_1_acc: 0.3486\n",
      "Epoch 11/1000\n",
      "6329/6329 [==============================] - 0s 69us/sample - loss: 2.9939 - layer3_loss: 1.5546 - layer3_1_loss: 1.4390 - layer3_acc: 0.3122 - layer3_1_acc: 0.3421\n",
      "Epoch 12/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9920 - layer3_loss: 1.5531 - layer3_1_loss: 1.4392 - layer3_acc: 0.3130 - layer3_1_acc: 0.3495\n",
      "Epoch 13/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9911 - layer3_loss: 1.5512 - layer3_1_loss: 1.4396 - layer3_acc: 0.3108 - layer3_1_acc: 0.3478\n",
      "Epoch 14/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9909 - layer3_loss: 1.5508 - layer3_1_loss: 1.4397 - layer3_acc: 0.3141 - layer3_1_acc: 0.3473\n",
      "Epoch 15/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9909 - layer3_loss: 1.5515 - layer3_1_loss: 1.4394 - layer3_acc: 0.3108 - layer3_1_acc: 0.3525\n",
      "Epoch 16/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9894 - layer3_loss: 1.5513 - layer3_1_loss: 1.4380 - layer3_acc: 0.3113 - layer3_1_acc: 0.3509\n",
      "Epoch 17/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9893 - layer3_loss: 1.5508 - layer3_1_loss: 1.4386 - layer3_acc: 0.3094 - layer3_1_acc: 0.3523\n",
      "Epoch 18/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9880 - layer3_loss: 1.5499 - layer3_1_loss: 1.4373 - layer3_acc: 0.3097 - layer3_1_acc: 0.3517\n",
      "Epoch 19/1000\n",
      "6329/6329 [==============================] - 0s 69us/sample - loss: 2.9884 - layer3_loss: 1.5486 - layer3_1_loss: 1.4394 - layer3_acc: 0.3113 - layer3_1_acc: 0.3501\n",
      "Epoch 20/1000\n",
      "6329/6329 [==============================] - 1s 85us/sample - loss: 2.9875 - layer3_loss: 1.5493 - layer3_1_loss: 1.4381 - layer3_acc: 0.3127 - layer3_1_acc: 0.3512\n",
      "Epoch 21/1000\n",
      "6329/6329 [==============================] - 1s 82us/sample - loss: 2.9872 - layer3_loss: 1.5494 - layer3_1_loss: 1.4384 - layer3_acc: 0.3087 - layer3_1_acc: 0.3493\n",
      "Epoch 22/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9876 - layer3_loss: 1.5488 - layer3_1_loss: 1.4384 - layer3_acc: 0.3130 - layer3_1_acc: 0.3487\n",
      "Epoch 23/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9869 - layer3_loss: 1.5499 - layer3_1_loss: 1.4372 - layer3_acc: 0.3135 - layer3_1_acc: 0.3511\n",
      "Epoch 24/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9865 - layer3_loss: 1.5495 - layer3_1_loss: 1.4369 - layer3_acc: 0.3103 - layer3_1_acc: 0.3547\n",
      "Epoch 25/1000\n",
      "6329/6329 [==============================] - 0s 69us/sample - loss: 2.9859 - layer3_loss: 1.5483 - layer3_1_loss: 1.4377 - layer3_acc: 0.3119 - layer3_1_acc: 0.3487\n",
      "Epoch 26/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9849 - layer3_loss: 1.5486 - layer3_1_loss: 1.4360 - layer3_acc: 0.3114 - layer3_1_acc: 0.3528\n",
      "Epoch 27/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9843 - layer3_loss: 1.5499 - layer3_1_loss: 1.4347 - layer3_acc: 0.3108 - layer3_1_acc: 0.3528\n",
      "Epoch 28/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9850 - layer3_loss: 1.5491 - layer3_1_loss: 1.4374 - layer3_acc: 0.3091 - layer3_1_acc: 0.3511\n",
      "Epoch 29/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9844 - layer3_loss: 1.5480 - layer3_1_loss: 1.4362 - layer3_acc: 0.3124 - layer3_1_acc: 0.3511\n",
      "Epoch 30/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9840 - layer3_loss: 1.5483 - layer3_1_loss: 1.4359 - layer3_acc: 0.3108 - layer3_1_acc: 0.3549\n",
      "Epoch 31/1000\n",
      "6329/6329 [==============================] - 1s 88us/sample - loss: 2.9836 - layer3_loss: 1.5486 - layer3_1_loss: 1.4349 - layer3_acc: 0.3136 - layer3_1_acc: 0.3522\n",
      "Epoch 32/1000\n",
      "6329/6329 [==============================] - 1s 87us/sample - loss: 2.9831 - layer3_loss: 1.5482 - layer3_1_loss: 1.4345 - layer3_acc: 0.3128 - layer3_1_acc: 0.3522\n",
      "Epoch 33/1000\n",
      "6329/6329 [==============================] - 0s 79us/sample - loss: 2.9829 - layer3_loss: 1.5474 - layer3_1_loss: 1.4363 - layer3_acc: 0.3146 - layer3_1_acc: 0.3530\n",
      "Epoch 34/1000\n",
      "6329/6329 [==============================] - 0s 73us/sample - loss: 2.9835 - layer3_loss: 1.5499 - layer3_1_loss: 1.4333 - layer3_acc: 0.3114 - layer3_1_acc: 0.3516\n",
      "Epoch 35/1000\n",
      "6329/6329 [==============================] - 0s 69us/sample - loss: 2.9821 - layer3_loss: 1.5468 - layer3_1_loss: 1.4351 - layer3_acc: 0.3113 - layer3_1_acc: 0.3522\n",
      "Epoch 36/1000\n",
      "6329/6329 [==============================] - 1s 84us/sample - loss: 2.9822 - layer3_loss: 1.5489 - layer3_1_loss: 1.4340 - layer3_acc: 0.3114 - layer3_1_acc: 0.3538\n",
      "Epoch 37/1000\n",
      "6329/6329 [==============================] - 1s 85us/sample - loss: 2.9824 - layer3_loss: 1.5488 - layer3_1_loss: 1.4338 - layer3_acc: 0.3136 - layer3_1_acc: 0.3512\n",
      "Epoch 38/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9820 - layer3_loss: 1.5497 - layer3_1_loss: 1.4330 - layer3_acc: 0.3130 - layer3_1_acc: 0.3520\n",
      "Epoch 39/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9813 - layer3_loss: 1.5490 - layer3_1_loss: 1.4339 - layer3_acc: 0.3132 - layer3_1_acc: 0.3544\n",
      "Epoch 40/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9807 - layer3_loss: 1.5476 - layer3_1_loss: 1.4330 - layer3_acc: 0.3130 - layer3_1_acc: 0.3514\n",
      "Epoch 41/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9820 - layer3_loss: 1.5486 - layer3_1_loss: 1.4333 - layer3_acc: 0.3152 - layer3_1_acc: 0.3503\n",
      "Epoch 42/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9815 - layer3_loss: 1.5480 - layer3_1_loss: 1.4335 - layer3_acc: 0.3132 - layer3_1_acc: 0.3479\n",
      "Epoch 43/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9812 - layer3_loss: 1.5477 - layer3_1_loss: 1.4335 - layer3_acc: 0.3109 - layer3_1_acc: 0.3541\n",
      "Epoch 44/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9808 - layer3_loss: 1.5476 - layer3_1_loss: 1.4331 - layer3_acc: 0.3128 - layer3_1_acc: 0.3528\n",
      "Epoch 45/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9807 - layer3_loss: 1.5474 - layer3_1_loss: 1.4329 - layer3_acc: 0.3143 - layer3_1_acc: 0.3528\n",
      "Epoch 46/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9801 - layer3_loss: 1.5480 - layer3_1_loss: 1.4322 - layer3_acc: 0.3128 - layer3_1_acc: 0.3471\n",
      "Epoch 47/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9812 - layer3_loss: 1.5483 - layer3_1_loss: 1.4339 - layer3_acc: 0.3124 - layer3_1_acc: 0.3511\n",
      "Epoch 48/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9801 - layer3_loss: 1.5488 - layer3_1_loss: 1.4316 - layer3_acc: 0.3154 - layer3_1_acc: 0.3572\n",
      "Epoch 49/1000\n",
      "6329/6329 [==============================] - 0s 69us/sample - loss: 2.9798 - layer3_loss: 1.5467 - layer3_1_loss: 1.4327 - layer3_acc: 0.3105 - layer3_1_acc: 0.3508\n",
      "Epoch 50/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9801 - layer3_loss: 1.5470 - layer3_1_loss: 1.4329 - layer3_acc: 0.3136 - layer3_1_acc: 0.3500\n",
      "Epoch 51/1000\n",
      "6329/6329 [==============================] - 0s 69us/sample - loss: 2.9800 - layer3_loss: 1.5470 - layer3_1_loss: 1.4326 - layer3_acc: 0.3160 - layer3_1_acc: 0.3542\n",
      "Epoch 52/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9797 - layer3_loss: 1.5468 - layer3_1_loss: 1.4325 - layer3_acc: 0.3113 - layer3_1_acc: 0.3549\n",
      "Epoch 53/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9797 - layer3_loss: 1.5480 - layer3_1_loss: 1.4315 - layer3_acc: 0.3130 - layer3_1_acc: 0.3516\n",
      "Epoch 54/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9786 - layer3_loss: 1.5480 - layer3_1_loss: 1.4310 - layer3_acc: 0.3140 - layer3_1_acc: 0.3558\n",
      "Epoch 55/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9790 - layer3_loss: 1.5458 - layer3_1_loss: 1.4329 - layer3_acc: 0.3135 - layer3_1_acc: 0.3508\n",
      "Epoch 56/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9794 - layer3_loss: 1.5471 - layer3_1_loss: 1.4326 - layer3_acc: 0.3141 - layer3_1_acc: 0.3569\n",
      "Epoch 57/1000\n",
      "6329/6329 [==============================] - 0s 73us/sample - loss: 2.9783 - layer3_loss: 1.5460 - layer3_1_loss: 1.4329 - layer3_acc: 0.3100 - layer3_1_acc: 0.3546\n",
      "Epoch 58/1000\n",
      "6329/6329 [==============================] - 0s 76us/sample - loss: 2.9790 - layer3_loss: 1.5476 - layer3_1_loss: 1.4316 - layer3_acc: 0.3109 - layer3_1_acc: 0.3538\n",
      "Epoch 59/1000\n",
      "6329/6329 [==============================] - 0s 76us/sample - loss: 2.9790 - layer3_loss: 1.5468 - layer3_1_loss: 1.4324 - layer3_acc: 0.3138 - layer3_1_acc: 0.3497\n",
      "Epoch 60/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9782 - layer3_loss: 1.5471 - layer3_1_loss: 1.4318 - layer3_acc: 0.3171 - layer3_1_acc: 0.3517\n",
      "Epoch 61/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9790 - layer3_loss: 1.5464 - layer3_1_loss: 1.4320 - layer3_acc: 0.3122 - layer3_1_acc: 0.3512\n",
      "Epoch 62/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9789 - layer3_loss: 1.5477 - layer3_1_loss: 1.4307 - layer3_acc: 0.3105 - layer3_1_acc: 0.3547\n",
      "Epoch 63/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9782 - layer3_loss: 1.5472 - layer3_1_loss: 1.4311 - layer3_acc: 0.3141 - layer3_1_acc: 0.3514\n",
      "Epoch 64/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9775 - layer3_loss: 1.5473 - layer3_1_loss: 1.4298 - layer3_acc: 0.3111 - layer3_1_acc: 0.3482\n",
      "Epoch 65/1000\n",
      "6329/6329 [==============================] - 1s 85us/sample - loss: 2.9785 - layer3_loss: 1.5468 - layer3_1_loss: 1.4321 - layer3_acc: 0.3146 - layer3_1_acc: 0.3525\n",
      "Epoch 66/1000\n",
      "6329/6329 [==============================] - 1s 90us/sample - loss: 2.9777 - layer3_loss: 1.5473 - layer3_1_loss: 1.4302 - layer3_acc: 0.3149 - layer3_1_acc: 0.3535\n",
      "Epoch 67/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9775 - layer3_loss: 1.5460 - layer3_1_loss: 1.4313 - layer3_acc: 0.3160 - layer3_1_acc: 0.3527\n",
      "Epoch 68/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9776 - layer3_loss: 1.5474 - layer3_1_loss: 1.4301 - layer3_acc: 0.3109 - layer3_1_acc: 0.3563\n",
      "Epoch 69/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9766 - layer3_loss: 1.5450 - layer3_1_loss: 1.4317 - layer3_acc: 0.3143 - layer3_1_acc: 0.3584\n",
      "Epoch 70/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9769 - layer3_loss: 1.5454 - layer3_1_loss: 1.4313 - layer3_acc: 0.3155 - layer3_1_acc: 0.3546\n",
      "Epoch 71/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9773 - layer3_loss: 1.5484 - layer3_1_loss: 1.4291 - layer3_acc: 0.3143 - layer3_1_acc: 0.3549\n",
      "Epoch 72/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9773 - layer3_loss: 1.5461 - layer3_1_loss: 1.4307 - layer3_acc: 0.3111 - layer3_1_acc: 0.3527\n",
      "Epoch 73/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9772 - layer3_loss: 1.5459 - layer3_1_loss: 1.4313 - layer3_acc: 0.3106 - layer3_1_acc: 0.3555\n",
      "Epoch 74/1000\n",
      "6329/6329 [==============================] - 1s 79us/sample - loss: 2.9770 - layer3_loss: 1.5472 - layer3_1_loss: 1.4292 - layer3_acc: 0.3133 - layer3_1_acc: 0.3546\n",
      "Epoch 75/1000\n",
      "6329/6329 [==============================] - 1s 87us/sample - loss: 2.9770 - layer3_loss: 1.5496 - layer3_1_loss: 1.4280 - layer3_acc: 0.3103 - layer3_1_acc: 0.3574\n",
      "Epoch 76/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9766 - layer3_loss: 1.5455 - layer3_1_loss: 1.4308 - layer3_acc: 0.3176 - layer3_1_acc: 0.3512\n",
      "Epoch 77/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9765 - layer3_loss: 1.5475 - layer3_1_loss: 1.4289 - layer3_acc: 0.3084 - layer3_1_acc: 0.3566\n",
      "Epoch 78/1000\n",
      "6329/6329 [==============================] - 0s 73us/sample - loss: 2.9766 - layer3_loss: 1.5473 - layer3_1_loss: 1.4296 - layer3_acc: 0.3105 - layer3_1_acc: 0.3535\n",
      "Epoch 79/1000\n",
      "6329/6329 [==============================] - 0s 69us/sample - loss: 2.9766 - layer3_loss: 1.5456 - layer3_1_loss: 1.4304 - layer3_acc: 0.3168 - layer3_1_acc: 0.3517\n",
      "Epoch 80/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9759 - layer3_loss: 1.5463 - layer3_1_loss: 1.4288 - layer3_acc: 0.3079 - layer3_1_acc: 0.3555\n",
      "Epoch 81/1000\n",
      "6329/6329 [==============================] - 0s 69us/sample - loss: 2.9764 - layer3_loss: 1.5458 - layer3_1_loss: 1.4308 - layer3_acc: 0.3125 - layer3_1_acc: 0.3542\n",
      "Epoch 82/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9761 - layer3_loss: 1.5447 - layer3_1_loss: 1.4310 - layer3_acc: 0.3109 - layer3_1_acc: 0.3571\n",
      "Epoch 83/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9758 - layer3_loss: 1.5470 - layer3_1_loss: 1.4296 - layer3_acc: 0.3132 - layer3_1_acc: 0.3519\n",
      "Epoch 84/1000\n",
      "6329/6329 [==============================] - 0s 79us/sample - loss: 2.9758 - layer3_loss: 1.5463 - layer3_1_loss: 1.4301 - layer3_acc: 0.3114 - layer3_1_acc: 0.3547\n",
      "Epoch 85/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9754 - layer3_loss: 1.5456 - layer3_1_loss: 1.4300 - layer3_acc: 0.3122 - layer3_1_acc: 0.3535\n",
      "Epoch 86/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9755 - layer3_loss: 1.5447 - layer3_1_loss: 1.4302 - layer3_acc: 0.3147 - layer3_1_acc: 0.3550\n",
      "Epoch 87/1000\n",
      "6329/6329 [==============================] - 1s 79us/sample - loss: 2.9761 - layer3_loss: 1.5459 - layer3_1_loss: 1.4300 - layer3_acc: 0.3127 - layer3_1_acc: 0.3544\n",
      "Epoch 88/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9757 - layer3_loss: 1.5463 - layer3_1_loss: 1.4302 - layer3_acc: 0.3116 - layer3_1_acc: 0.3552\n",
      "Epoch 89/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9758 - layer3_loss: 1.5472 - layer3_1_loss: 1.4277 - layer3_acc: 0.3095 - layer3_1_acc: 0.3584\n",
      "Epoch 90/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9753 - layer3_loss: 1.5462 - layer3_1_loss: 1.4298 - layer3_acc: 0.3103 - layer3_1_acc: 0.3547\n",
      "Epoch 91/1000\n",
      "6329/6329 [==============================] - 0s 69us/sample - loss: 2.9762 - layer3_loss: 1.5468 - layer3_1_loss: 1.4292 - layer3_acc: 0.3147 - layer3_1_acc: 0.3544\n",
      "Epoch 92/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9753 - layer3_loss: 1.5461 - layer3_1_loss: 1.4299 - layer3_acc: 0.3114 - layer3_1_acc: 0.3555\n",
      "Epoch 93/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9745 - layer3_loss: 1.5434 - layer3_1_loss: 1.4310 - layer3_acc: 0.3128 - layer3_1_acc: 0.3558\n",
      "Epoch 94/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9753 - layer3_loss: 1.5451 - layer3_1_loss: 1.4294 - layer3_acc: 0.3132 - layer3_1_acc: 0.3552\n",
      "Epoch 95/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9735 - layer3_loss: 1.5456 - layer3_1_loss: 1.4284 - layer3_acc: 0.3116 - layer3_1_acc: 0.3533\n",
      "Epoch 96/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9742 - layer3_loss: 1.5460 - layer3_1_loss: 1.4289 - layer3_acc: 0.3122 - layer3_1_acc: 0.3569\n",
      "Epoch 97/1000\n",
      "6329/6329 [==============================] - 1s 86us/sample - loss: 2.9738 - layer3_loss: 1.5452 - layer3_1_loss: 1.4286 - layer3_acc: 0.3094 - layer3_1_acc: 0.3576\n",
      "Epoch 98/1000\n",
      "6329/6329 [==============================] - 1s 94us/sample - loss: 2.9751 - layer3_loss: 1.5465 - layer3_1_loss: 1.4283 - layer3_acc: 0.3097 - layer3_1_acc: 0.3561\n",
      "Epoch 99/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9753 - layer3_loss: 1.5455 - layer3_1_loss: 1.4297 - layer3_acc: 0.3143 - layer3_1_acc: 0.3542\n",
      "Epoch 100/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9743 - layer3_loss: 1.5458 - layer3_1_loss: 1.4288 - layer3_acc: 0.3087 - layer3_1_acc: 0.3563\n",
      "Epoch 101/1000\n",
      "6329/6329 [==============================] - 0s 73us/sample - loss: 2.9744 - layer3_loss: 1.5458 - layer3_1_loss: 1.4283 - layer3_acc: 0.3125 - layer3_1_acc: 0.3579\n",
      "Epoch 102/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9742 - layer3_loss: 1.5447 - layer3_1_loss: 1.4295 - layer3_acc: 0.3091 - layer3_1_acc: 0.3612\n",
      "Epoch 103/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9732 - layer3_loss: 1.5447 - layer3_1_loss: 1.4285 - layer3_acc: 0.3116 - layer3_1_acc: 0.3590\n",
      "Epoch 104/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9739 - layer3_loss: 1.5456 - layer3_1_loss: 1.4285 - layer3_acc: 0.3105 - layer3_1_acc: 0.3582\n",
      "Epoch 105/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9737 - layer3_loss: 1.5452 - layer3_1_loss: 1.4278 - layer3_acc: 0.3092 - layer3_1_acc: 0.3596\n",
      "Epoch 106/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9733 - layer3_loss: 1.5465 - layer3_1_loss: 1.4268 - layer3_acc: 0.3119 - layer3_1_acc: 0.3552\n",
      "Epoch 107/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9737 - layer3_loss: 1.5450 - layer3_1_loss: 1.4287 - layer3_acc: 0.3098 - layer3_1_acc: 0.3580\n",
      "Epoch 108/1000\n",
      "6329/6329 [==============================] - 0s 69us/sample - loss: 2.9731 - layer3_loss: 1.5459 - layer3_1_loss: 1.4274 - layer3_acc: 0.3124 - layer3_1_acc: 0.3590\n",
      "Epoch 109/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9736 - layer3_loss: 1.5448 - layer3_1_loss: 1.4283 - layer3_acc: 0.3076 - layer3_1_acc: 0.3561\n",
      "Epoch 110/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9730 - layer3_loss: 1.5458 - layer3_1_loss: 1.4273 - layer3_acc: 0.3111 - layer3_1_acc: 0.3576\n",
      "Epoch 111/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9737 - layer3_loss: 1.5454 - layer3_1_loss: 1.4285 - layer3_acc: 0.3084 - layer3_1_acc: 0.3617\n",
      "Epoch 112/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9729 - layer3_loss: 1.5460 - layer3_1_loss: 1.4268 - layer3_acc: 0.3105 - layer3_1_acc: 0.3596\n",
      "Epoch 113/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9731 - layer3_loss: 1.5440 - layer3_1_loss: 1.4287 - layer3_acc: 0.3098 - layer3_1_acc: 0.3579\n",
      "Epoch 114/1000\n",
      "6329/6329 [==============================] - 0s 76us/sample - loss: 2.9732 - layer3_loss: 1.5462 - layer3_1_loss: 1.4265 - layer3_acc: 0.3067 - layer3_1_acc: 0.3568\n",
      "Epoch 115/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9736 - layer3_loss: 1.5453 - layer3_1_loss: 1.4280 - layer3_acc: 0.3114 - layer3_1_acc: 0.3546\n",
      "Epoch 116/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9735 - layer3_loss: 1.5454 - layer3_1_loss: 1.4285 - layer3_acc: 0.3113 - layer3_1_acc: 0.3552\n",
      "Epoch 117/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9714 - layer3_loss: 1.5439 - layer3_1_loss: 1.4277 - layer3_acc: 0.3070 - layer3_1_acc: 0.3631\n",
      "Epoch 118/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9727 - layer3_loss: 1.5442 - layer3_1_loss: 1.4280 - layer3_acc: 0.3095 - layer3_1_acc: 0.3582\n",
      "Epoch 119/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9735 - layer3_loss: 1.5450 - layer3_1_loss: 1.4281 - layer3_acc: 0.3133 - layer3_1_acc: 0.3552\n",
      "Epoch 120/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9722 - layer3_loss: 1.5455 - layer3_1_loss: 1.4267 - layer3_acc: 0.3098 - layer3_1_acc: 0.3614\n",
      "Epoch 121/1000\n",
      "6329/6329 [==============================] - 0s 79us/sample - loss: 2.9731 - layer3_loss: 1.5447 - layer3_1_loss: 1.4286 - layer3_acc: 0.3109 - layer3_1_acc: 0.3591\n",
      "Epoch 122/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9728 - layer3_loss: 1.5445 - layer3_1_loss: 1.4283 - layer3_acc: 0.3100 - layer3_1_acc: 0.3579\n",
      "Epoch 123/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9728 - layer3_loss: 1.5446 - layer3_1_loss: 1.4280 - layer3_acc: 0.3114 - layer3_1_acc: 0.3584\n",
      "Epoch 124/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9715 - layer3_loss: 1.5450 - layer3_1_loss: 1.4267 - layer3_acc: 0.3068 - layer3_1_acc: 0.3620\n",
      "Epoch 125/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9718 - layer3_loss: 1.5456 - layer3_1_loss: 1.4264 - layer3_acc: 0.3095 - layer3_1_acc: 0.3609\n",
      "Epoch 126/1000\n",
      "6329/6329 [==============================] - 1s 83us/sample - loss: 2.9720 - layer3_loss: 1.5451 - layer3_1_loss: 1.4276 - layer3_acc: 0.3113 - layer3_1_acc: 0.3561\n",
      "Epoch 127/1000\n",
      "6329/6329 [==============================] - 1s 83us/sample - loss: 2.9717 - layer3_loss: 1.5441 - layer3_1_loss: 1.4276 - layer3_acc: 0.3125 - layer3_1_acc: 0.3596\n",
      "Epoch 128/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9721 - layer3_loss: 1.5442 - layer3_1_loss: 1.4278 - layer3_acc: 0.3095 - layer3_1_acc: 0.3602\n",
      "Epoch 129/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9717 - layer3_loss: 1.5441 - layer3_1_loss: 1.4270 - layer3_acc: 0.3103 - layer3_1_acc: 0.3620\n",
      "Epoch 130/1000\n",
      "6329/6329 [==============================] - 1s 87us/sample - loss: 2.9715 - layer3_loss: 1.5441 - layer3_1_loss: 1.4272 - layer3_acc: 0.3100 - layer3_1_acc: 0.3598\n",
      "Epoch 131/1000\n",
      "6329/6329 [==============================] - 1s 96us/sample - loss: 2.9726 - layer3_loss: 1.5458 - layer3_1_loss: 1.4275 - layer3_acc: 0.3119 - layer3_1_acc: 0.3617\n",
      "Epoch 132/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9715 - layer3_loss: 1.5444 - layer3_1_loss: 1.4274 - layer3_acc: 0.3121 - layer3_1_acc: 0.3615\n",
      "Epoch 133/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9724 - layer3_loss: 1.5444 - layer3_1_loss: 1.4273 - layer3_acc: 0.3097 - layer3_1_acc: 0.3623\n",
      "Epoch 134/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329/6329 [==============================] - 0s 79us/sample - loss: 2.9714 - layer3_loss: 1.5449 - layer3_1_loss: 1.4265 - layer3_acc: 0.3079 - layer3_1_acc: 0.3609\n",
      "Epoch 135/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9717 - layer3_loss: 1.5430 - layer3_1_loss: 1.4279 - layer3_acc: 0.3111 - layer3_1_acc: 0.3560\n",
      "Epoch 136/1000\n",
      "6329/6329 [==============================] - 1s 79us/sample - loss: 2.9723 - layer3_loss: 1.5443 - layer3_1_loss: 1.4275 - layer3_acc: 0.3117 - layer3_1_acc: 0.3591\n",
      "Epoch 137/1000\n",
      "6329/6329 [==============================] - 0s 79us/sample - loss: 2.9712 - layer3_loss: 1.5440 - layer3_1_loss: 1.4267 - layer3_acc: 0.3098 - layer3_1_acc: 0.3612\n",
      "Epoch 138/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9711 - layer3_loss: 1.5433 - layer3_1_loss: 1.4274 - layer3_acc: 0.3124 - layer3_1_acc: 0.3631\n",
      "Epoch 139/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9710 - layer3_loss: 1.5448 - layer3_1_loss: 1.4262 - layer3_acc: 0.3119 - layer3_1_acc: 0.3598\n",
      "Epoch 140/1000\n",
      "6329/6329 [==============================] - 1s 88us/sample - loss: 2.9715 - layer3_loss: 1.5437 - layer3_1_loss: 1.4274 - layer3_acc: 0.3065 - layer3_1_acc: 0.3599\n",
      "Epoch 141/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9702 - layer3_loss: 1.5429 - layer3_1_loss: 1.4274 - layer3_acc: 0.3111 - layer3_1_acc: 0.3550\n",
      "Epoch 142/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9706 - layer3_loss: 1.5437 - layer3_1_loss: 1.4266 - layer3_acc: 0.3097 - layer3_1_acc: 0.3620\n",
      "Epoch 143/1000\n",
      "6329/6329 [==============================] - 1s 82us/sample - loss: 2.9711 - layer3_loss: 1.5441 - layer3_1_loss: 1.4274 - layer3_acc: 0.3140 - layer3_1_acc: 0.3599\n",
      "Epoch 144/1000\n",
      "6329/6329 [==============================] - 1s 87us/sample - loss: 2.9713 - layer3_loss: 1.5443 - layer3_1_loss: 1.4273 - layer3_acc: 0.3111 - layer3_1_acc: 0.3599\n",
      "Epoch 145/1000\n",
      "6329/6329 [==============================] - 1s 88us/sample - loss: 2.9718 - layer3_loss: 1.5448 - layer3_1_loss: 1.4267 - layer3_acc: 0.3089 - layer3_1_acc: 0.3593\n",
      "Epoch 146/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9712 - layer3_loss: 1.5448 - layer3_1_loss: 1.4262 - layer3_acc: 0.3094 - layer3_1_acc: 0.3599\n",
      "Epoch 147/1000\n",
      "6329/6329 [==============================] - 1s 82us/sample - loss: 2.9712 - layer3_loss: 1.5455 - layer3_1_loss: 1.4255 - layer3_acc: 0.3089 - layer3_1_acc: 0.3636\n",
      "Epoch 148/1000\n",
      "6329/6329 [==============================] - 1s 86us/sample - loss: 2.9715 - layer3_loss: 1.5438 - layer3_1_loss: 1.4274 - layer3_acc: 0.3087 - layer3_1_acc: 0.3587\n",
      "Epoch 149/1000\n",
      "6329/6329 [==============================] - 1s 86us/sample - loss: 2.9706 - layer3_loss: 1.5436 - layer3_1_loss: 1.4265 - layer3_acc: 0.3068 - layer3_1_acc: 0.3584\n",
      "Epoch 150/1000\n",
      "6329/6329 [==============================] - 1s 86us/sample - loss: 2.9698 - layer3_loss: 1.5440 - layer3_1_loss: 1.4261 - layer3_acc: 0.3114 - layer3_1_acc: 0.3595\n",
      "Epoch 151/1000\n",
      "6329/6329 [==============================] - 1s 85us/sample - loss: 2.9706 - layer3_loss: 1.5440 - layer3_1_loss: 1.4262 - layer3_acc: 0.3097 - layer3_1_acc: 0.3644\n",
      "Epoch 152/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9705 - layer3_loss: 1.5415 - layer3_1_loss: 1.4285 - layer3_acc: 0.3151 - layer3_1_acc: 0.3553\n",
      "Epoch 153/1000\n",
      "6329/6329 [==============================] - 1s 82us/sample - loss: 2.9705 - layer3_loss: 1.5438 - layer3_1_loss: 1.4268 - layer3_acc: 0.3095 - layer3_1_acc: 0.3621\n",
      "Epoch 154/1000\n",
      "6329/6329 [==============================] - 1s 86us/sample - loss: 2.9699 - layer3_loss: 1.5435 - layer3_1_loss: 1.4255 - layer3_acc: 0.3057 - layer3_1_acc: 0.3636\n",
      "Epoch 155/1000\n",
      "6329/6329 [==============================] - 0s 69us/sample - loss: 2.9705 - layer3_loss: 1.5434 - layer3_1_loss: 1.4266 - layer3_acc: 0.3106 - layer3_1_acc: 0.3561\n",
      "Epoch 156/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9702 - layer3_loss: 1.5434 - layer3_1_loss: 1.4268 - layer3_acc: 0.3081 - layer3_1_acc: 0.3596\n",
      "Epoch 157/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9700 - layer3_loss: 1.5429 - layer3_1_loss: 1.4264 - layer3_acc: 0.3095 - layer3_1_acc: 0.3615\n",
      "Epoch 158/1000\n",
      "6329/6329 [==============================] - 0s 76us/sample - loss: 2.9704 - layer3_loss: 1.5446 - layer3_1_loss: 1.4261 - layer3_acc: 0.3117 - layer3_1_acc: 0.3595\n",
      "Epoch 159/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9697 - layer3_loss: 1.5418 - layer3_1_loss: 1.4269 - layer3_acc: 0.3059 - layer3_1_acc: 0.3639\n",
      "Epoch 160/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9703 - layer3_loss: 1.5442 - layer3_1_loss: 1.4260 - layer3_acc: 0.3083 - layer3_1_acc: 0.3648\n",
      "Epoch 161/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9698 - layer3_loss: 1.5425 - layer3_1_loss: 1.4270 - layer3_acc: 0.3084 - layer3_1_acc: 0.3598\n",
      "Epoch 162/1000\n",
      "6329/6329 [==============================] - 1s 92us/sample - loss: 2.9705 - layer3_loss: 1.5441 - layer3_1_loss: 1.4281 - layer3_acc: 0.3079 - layer3_1_acc: 0.3574\n",
      "Epoch 163/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9704 - layer3_loss: 1.5433 - layer3_1_loss: 1.4266 - layer3_acc: 0.3092 - layer3_1_acc: 0.3609\n",
      "Epoch 164/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9702 - layer3_loss: 1.5439 - layer3_1_loss: 1.4256 - layer3_acc: 0.3086 - layer3_1_acc: 0.3614\n",
      "Epoch 165/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9706 - layer3_loss: 1.5439 - layer3_1_loss: 1.4267 - layer3_acc: 0.3130 - layer3_1_acc: 0.3604\n",
      "Epoch 166/1000\n",
      "6329/6329 [==============================] - 0s 69us/sample - loss: 2.9699 - layer3_loss: 1.5422 - layer3_1_loss: 1.4274 - layer3_acc: 0.3100 - layer3_1_acc: 0.3601\n",
      "Epoch 167/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9710 - layer3_loss: 1.5457 - layer3_1_loss: 1.4263 - layer3_acc: 0.3106 - layer3_1_acc: 0.3601\n",
      "Epoch 168/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9707 - layer3_loss: 1.5454 - layer3_1_loss: 1.4253 - layer3_acc: 0.3072 - layer3_1_acc: 0.3628\n",
      "Epoch 169/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9694 - layer3_loss: 1.5422 - layer3_1_loss: 1.4271 - layer3_acc: 0.3144 - layer3_1_acc: 0.3599\n",
      "Epoch 170/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9695 - layer3_loss: 1.5428 - layer3_1_loss: 1.4268 - layer3_acc: 0.3062 - layer3_1_acc: 0.3579\n",
      "Epoch 171/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9699 - layer3_loss: 1.5439 - layer3_1_loss: 1.4258 - layer3_acc: 0.3067 - layer3_1_acc: 0.3621\n",
      "Epoch 172/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9688 - layer3_loss: 1.5431 - layer3_1_loss: 1.4251 - layer3_acc: 0.3116 - layer3_1_acc: 0.3590\n",
      "Epoch 173/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9693 - layer3_loss: 1.5440 - layer3_1_loss: 1.4256 - layer3_acc: 0.3097 - layer3_1_acc: 0.3628\n",
      "Epoch 174/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9694 - layer3_loss: 1.5449 - layer3_1_loss: 1.4253 - layer3_acc: 0.3092 - layer3_1_acc: 0.3648\n",
      "Epoch 175/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9691 - layer3_loss: 1.5440 - layer3_1_loss: 1.4257 - layer3_acc: 0.3106 - layer3_1_acc: 0.3678\n",
      "Epoch 176/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9691 - layer3_loss: 1.5432 - layer3_1_loss: 1.4253 - layer3_acc: 0.3116 - layer3_1_acc: 0.3629\n",
      "Epoch 177/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9698 - layer3_loss: 1.5419 - layer3_1_loss: 1.4277 - layer3_acc: 0.3084 - layer3_1_acc: 0.3593\n",
      "Epoch 178/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9691 - layer3_loss: 1.5448 - layer3_1_loss: 1.4240 - layer3_acc: 0.3078 - layer3_1_acc: 0.3625\n",
      "Epoch 179/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9691 - layer3_loss: 1.5420 - layer3_1_loss: 1.4271 - layer3_acc: 0.3081 - layer3_1_acc: 0.3628\n",
      "Epoch 180/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9694 - layer3_loss: 1.5434 - layer3_1_loss: 1.4262 - layer3_acc: 0.3100 - layer3_1_acc: 0.3590\n",
      "Epoch 181/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9701 - layer3_loss: 1.5433 - layer3_1_loss: 1.4262 - layer3_acc: 0.3091 - layer3_1_acc: 0.3591\n",
      "Epoch 182/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9694 - layer3_loss: 1.5445 - layer3_1_loss: 1.4244 - layer3_acc: 0.3132 - layer3_1_acc: 0.3647\n",
      "Epoch 183/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9688 - layer3_loss: 1.5437 - layer3_1_loss: 1.4253 - layer3_acc: 0.3102 - layer3_1_acc: 0.3610\n",
      "Epoch 184/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9703 - layer3_loss: 1.5423 - layer3_1_loss: 1.4278 - layer3_acc: 0.3111 - layer3_1_acc: 0.3595\n",
      "Epoch 185/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9690 - layer3_loss: 1.5445 - layer3_1_loss: 1.4247 - layer3_acc: 0.3079 - layer3_1_acc: 0.3599\n",
      "Epoch 186/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9695 - layer3_loss: 1.5456 - layer3_1_loss: 1.4243 - layer3_acc: 0.3086 - layer3_1_acc: 0.3621\n",
      "Epoch 187/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9697 - layer3_loss: 1.5432 - layer3_1_loss: 1.4262 - layer3_acc: 0.3081 - layer3_1_acc: 0.3607\n",
      "Epoch 188/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9681 - layer3_loss: 1.5427 - layer3_1_loss: 1.4255 - layer3_acc: 0.3119 - layer3_1_acc: 0.3648\n",
      "Epoch 189/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9692 - layer3_loss: 1.5447 - layer3_1_loss: 1.4257 - layer3_acc: 0.3081 - layer3_1_acc: 0.3580\n",
      "Epoch 190/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9685 - layer3_loss: 1.5437 - layer3_1_loss: 1.4253 - layer3_acc: 0.3122 - layer3_1_acc: 0.3634\n",
      "Epoch 191/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9692 - layer3_loss: 1.5436 - layer3_1_loss: 1.4261 - layer3_acc: 0.3095 - layer3_1_acc: 0.3656\n",
      "Epoch 192/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9688 - layer3_loss: 1.5426 - layer3_1_loss: 1.4261 - layer3_acc: 0.3070 - layer3_1_acc: 0.3623\n",
      "Epoch 193/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9675 - layer3_loss: 1.5435 - layer3_1_loss: 1.4246 - layer3_acc: 0.3067 - layer3_1_acc: 0.3626\n",
      "Epoch 194/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9685 - layer3_loss: 1.5439 - layer3_1_loss: 1.4251 - layer3_acc: 0.3094 - layer3_1_acc: 0.3623\n",
      "Epoch 195/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9683 - layer3_loss: 1.5427 - layer3_1_loss: 1.4256 - layer3_acc: 0.3097 - layer3_1_acc: 0.3642\n",
      "Epoch 196/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9683 - layer3_loss: 1.5427 - layer3_1_loss: 1.4263 - layer3_acc: 0.3091 - layer3_1_acc: 0.3599\n",
      "Epoch 197/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9689 - layer3_loss: 1.5427 - layer3_1_loss: 1.4256 - layer3_acc: 0.3127 - layer3_1_acc: 0.3585\n",
      "Epoch 198/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9684 - layer3_loss: 1.5438 - layer3_1_loss: 1.4246 - layer3_acc: 0.3073 - layer3_1_acc: 0.3563\n",
      "Epoch 199/1000\n",
      "6329/6329 [==============================] - 1s 85us/sample - loss: 2.9684 - layer3_loss: 1.5426 - layer3_1_loss: 1.4257 - layer3_acc: 0.3098 - layer3_1_acc: 0.3620\n",
      "Epoch 200/1000\n",
      "6329/6329 [==============================] - 1s 89us/sample - loss: 2.9680 - layer3_loss: 1.5442 - layer3_1_loss: 1.4247 - layer3_acc: 0.3042 - layer3_1_acc: 0.3628\n",
      "Epoch 201/1000\n",
      "6329/6329 [==============================] - 1s 84us/sample - loss: 2.9694 - layer3_loss: 1.5433 - layer3_1_loss: 1.4264 - layer3_acc: 0.3065 - layer3_1_acc: 0.3536\n",
      "Epoch 202/1000\n",
      "6329/6329 [==============================] - 0s 73us/sample - loss: 2.9689 - layer3_loss: 1.5436 - layer3_1_loss: 1.4255 - layer3_acc: 0.3081 - layer3_1_acc: 0.3606\n",
      "Epoch 203/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9678 - layer3_loss: 1.5423 - layer3_1_loss: 1.4255 - layer3_acc: 0.3109 - layer3_1_acc: 0.3574\n",
      "Epoch 204/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9681 - layer3_loss: 1.5422 - layer3_1_loss: 1.4261 - layer3_acc: 0.3094 - layer3_1_acc: 0.3590\n",
      "Epoch 205/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9682 - layer3_loss: 1.5430 - layer3_1_loss: 1.4251 - layer3_acc: 0.3117 - layer3_1_acc: 0.3636\n",
      "Epoch 206/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9682 - layer3_loss: 1.5416 - layer3_1_loss: 1.4261 - layer3_acc: 0.3098 - layer3_1_acc: 0.3626\n",
      "Epoch 207/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9697 - layer3_loss: 1.5444 - layer3_1_loss: 1.4247 - layer3_acc: 0.3078 - layer3_1_acc: 0.3664\n",
      "Epoch 208/1000\n",
      "6329/6329 [==============================] - 1s 86us/sample - loss: 2.9683 - layer3_loss: 1.5431 - layer3_1_loss: 1.4260 - layer3_acc: 0.3064 - layer3_1_acc: 0.3614\n",
      "Epoch 209/1000\n",
      "6329/6329 [==============================] - 1s 107us/sample - loss: 2.9670 - layer3_loss: 1.5431 - layer3_1_loss: 1.4243 - layer3_acc: 0.3087 - layer3_1_acc: 0.3584\n",
      "Epoch 210/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9678 - layer3_loss: 1.5416 - layer3_1_loss: 1.4269 - layer3_acc: 0.3106 - layer3_1_acc: 0.3587\n",
      "Epoch 211/1000\n",
      "6329/6329 [==============================] - 1s 95us/sample - loss: 2.9675 - layer3_loss: 1.5438 - layer3_1_loss: 1.4240 - layer3_acc: 0.3081 - layer3_1_acc: 0.3623\n",
      "Epoch 212/1000\n",
      "6329/6329 [==============================] - 1s 89us/sample - loss: 2.9678 - layer3_loss: 1.5422 - layer3_1_loss: 1.4271 - layer3_acc: 0.3102 - layer3_1_acc: 0.3595\n",
      "Epoch 213/1000\n",
      "6329/6329 [==============================] - 1s 93us/sample - loss: 2.9682 - layer3_loss: 1.5436 - layer3_1_loss: 1.4247 - layer3_acc: 0.3079 - layer3_1_acc: 0.3644\n",
      "Epoch 214/1000\n",
      "6329/6329 [==============================] - 1s 85us/sample - loss: 2.9678 - layer3_loss: 1.5420 - layer3_1_loss: 1.4249 - layer3_acc: 0.3132 - layer3_1_acc: 0.3615\n",
      "Epoch 215/1000\n",
      "6329/6329 [==============================] - 1s 83us/sample - loss: 2.9673 - layer3_loss: 1.5434 - layer3_1_loss: 1.4233 - layer3_acc: 0.3062 - layer3_1_acc: 0.3637\n",
      "Epoch 216/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9679 - layer3_loss: 1.5422 - layer3_1_loss: 1.4250 - layer3_acc: 0.3095 - layer3_1_acc: 0.3591\n",
      "Epoch 217/1000\n",
      "6329/6329 [==============================] - 1s 84us/sample - loss: 2.9671 - layer3_loss: 1.5426 - layer3_1_loss: 1.4242 - layer3_acc: 0.3109 - layer3_1_acc: 0.3590\n",
      "Epoch 218/1000\n",
      "6329/6329 [==============================] - 1s 98us/sample - loss: 2.9674 - layer3_loss: 1.5416 - layer3_1_loss: 1.4256 - layer3_acc: 0.3127 - layer3_1_acc: 0.3580\n",
      "Epoch 219/1000\n",
      "6329/6329 [==============================] - 1s 88us/sample - loss: 2.9678 - layer3_loss: 1.5433 - layer3_1_loss: 1.4246 - layer3_acc: 0.3075 - layer3_1_acc: 0.3653\n",
      "Epoch 220/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9679 - layer3_loss: 1.5419 - layer3_1_loss: 1.4256 - layer3_acc: 0.3119 - layer3_1_acc: 0.3629\n",
      "Epoch 221/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9680 - layer3_loss: 1.5434 - layer3_1_loss: 1.4248 - layer3_acc: 0.3081 - layer3_1_acc: 0.3599\n",
      "Epoch 222/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9676 - layer3_loss: 1.5427 - layer3_1_loss: 1.4253 - layer3_acc: 0.3097 - layer3_1_acc: 0.3618\n",
      "Epoch 223/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9677 - layer3_loss: 1.5436 - layer3_1_loss: 1.4238 - layer3_acc: 0.3086 - layer3_1_acc: 0.3628\n",
      "Epoch 224/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9667 - layer3_loss: 1.5407 - layer3_1_loss: 1.4265 - layer3_acc: 0.3113 - layer3_1_acc: 0.3648\n",
      "Epoch 225/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9673 - layer3_loss: 1.5430 - layer3_1_loss: 1.4236 - layer3_acc: 0.3105 - layer3_1_acc: 0.3644\n",
      "Epoch 226/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9671 - layer3_loss: 1.5433 - layer3_1_loss: 1.4236 - layer3_acc: 0.3094 - layer3_1_acc: 0.3639\n",
      "Epoch 227/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9671 - layer3_loss: 1.5426 - layer3_1_loss: 1.4245 - layer3_acc: 0.3103 - layer3_1_acc: 0.3610\n",
      "Epoch 228/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9669 - layer3_loss: 1.5412 - layer3_1_loss: 1.4253 - layer3_acc: 0.3135 - layer3_1_acc: 0.3639\n",
      "Epoch 229/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9665 - layer3_loss: 1.5414 - layer3_1_loss: 1.4246 - layer3_acc: 0.3106 - layer3_1_acc: 0.3577\n",
      "Epoch 230/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9669 - layer3_loss: 1.5429 - layer3_1_loss: 1.4235 - layer3_acc: 0.3089 - layer3_1_acc: 0.3628\n",
      "Epoch 231/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9658 - layer3_loss: 1.5411 - layer3_1_loss: 1.4249 - layer3_acc: 0.3087 - layer3_1_acc: 0.3621\n",
      "Epoch 232/1000\n",
      "6329/6329 [==============================] - 1s 82us/sample - loss: 2.9669 - layer3_loss: 1.5436 - layer3_1_loss: 1.4232 - layer3_acc: 0.3098 - layer3_1_acc: 0.3651\n",
      "Epoch 233/1000\n",
      "6329/6329 [==============================] - 0s 79us/sample - loss: 2.9665 - layer3_loss: 1.5409 - layer3_1_loss: 1.4253 - layer3_acc: 0.3124 - layer3_1_acc: 0.3650\n",
      "Epoch 234/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9669 - layer3_loss: 1.5431 - layer3_1_loss: 1.4247 - layer3_acc: 0.3094 - layer3_1_acc: 0.3606\n",
      "Epoch 235/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9659 - layer3_loss: 1.5434 - layer3_1_loss: 1.4222 - layer3_acc: 0.3081 - layer3_1_acc: 0.3625\n",
      "Epoch 236/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9675 - layer3_loss: 1.5426 - layer3_1_loss: 1.4251 - layer3_acc: 0.3087 - layer3_1_acc: 0.3640\n",
      "Epoch 237/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9668 - layer3_loss: 1.5419 - layer3_1_loss: 1.4252 - layer3_acc: 0.3108 - layer3_1_acc: 0.3636\n",
      "Epoch 238/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9667 - layer3_loss: 1.5421 - layer3_1_loss: 1.4253 - layer3_acc: 0.3068 - layer3_1_acc: 0.3626\n",
      "Epoch 239/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9661 - layer3_loss: 1.5416 - layer3_1_loss: 1.4243 - layer3_acc: 0.3084 - layer3_1_acc: 0.3639\n",
      "Epoch 240/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9664 - layer3_loss: 1.5419 - layer3_1_loss: 1.4250 - layer3_acc: 0.3087 - layer3_1_acc: 0.3620\n",
      "Epoch 241/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9654 - layer3_loss: 1.5410 - layer3_1_loss: 1.4245 - layer3_acc: 0.3097 - layer3_1_acc: 0.3625\n",
      "Epoch 242/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9669 - layer3_loss: 1.5427 - layer3_1_loss: 1.4241 - layer3_acc: 0.3075 - layer3_1_acc: 0.3639\n",
      "Epoch 243/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9670 - layer3_loss: 1.5419 - layer3_1_loss: 1.4245 - layer3_acc: 0.3130 - layer3_1_acc: 0.3582\n",
      "Epoch 244/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9671 - layer3_loss: 1.5427 - layer3_1_loss: 1.4246 - layer3_acc: 0.3081 - layer3_1_acc: 0.3642\n",
      "Epoch 245/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9668 - layer3_loss: 1.5419 - layer3_1_loss: 1.4245 - layer3_acc: 0.3116 - layer3_1_acc: 0.3647\n",
      "Epoch 246/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9656 - layer3_loss: 1.5423 - layer3_1_loss: 1.4239 - layer3_acc: 0.3094 - layer3_1_acc: 0.3675\n",
      "Epoch 247/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9666 - layer3_loss: 1.5424 - layer3_1_loss: 1.4237 - layer3_acc: 0.3114 - layer3_1_acc: 0.3591\n",
      "Epoch 248/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9665 - layer3_loss: 1.5422 - layer3_1_loss: 1.4241 - layer3_acc: 0.3087 - layer3_1_acc: 0.3593\n",
      "Epoch 249/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9657 - layer3_loss: 1.5430 - layer3_1_loss: 1.4239 - layer3_acc: 0.3111 - layer3_1_acc: 0.3614\n",
      "Epoch 250/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9654 - layer3_loss: 1.5414 - layer3_1_loss: 1.4236 - layer3_acc: 0.3067 - layer3_1_acc: 0.3634\n",
      "Epoch 251/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9664 - layer3_loss: 1.5427 - layer3_1_loss: 1.4241 - layer3_acc: 0.3091 - layer3_1_acc: 0.3602\n",
      "Epoch 252/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9674 - layer3_loss: 1.5436 - layer3_1_loss: 1.4244 - layer3_acc: 0.3102 - layer3_1_acc: 0.3625\n",
      "Epoch 253/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9657 - layer3_loss: 1.5411 - layer3_1_loss: 1.4255 - layer3_acc: 0.3043 - layer3_1_acc: 0.3697\n",
      "Epoch 254/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9648 - layer3_loss: 1.5405 - layer3_1_loss: 1.4244 - layer3_acc: 0.3114 - layer3_1_acc: 0.3585\n",
      "Epoch 255/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9659 - layer3_loss: 1.5430 - layer3_1_loss: 1.4227 - layer3_acc: 0.3083 - layer3_1_acc: 0.3631\n",
      "Epoch 256/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9658 - layer3_loss: 1.5412 - layer3_1_loss: 1.4247 - layer3_acc: 0.3121 - layer3_1_acc: 0.3651\n",
      "Epoch 257/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9662 - layer3_loss: 1.5422 - layer3_1_loss: 1.4240 - layer3_acc: 0.3070 - layer3_1_acc: 0.3659\n",
      "Epoch 258/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9654 - layer3_loss: 1.5411 - layer3_1_loss: 1.4245 - layer3_acc: 0.3141 - layer3_1_acc: 0.3636\n",
      "Epoch 259/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9661 - layer3_loss: 1.5417 - layer3_1_loss: 1.4250 - layer3_acc: 0.3065 - layer3_1_acc: 0.3639\n",
      "Epoch 260/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9659 - layer3_loss: 1.5408 - layer3_1_loss: 1.4248 - layer3_acc: 0.3111 - layer3_1_acc: 0.3623\n",
      "Epoch 261/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9655 - layer3_loss: 1.5414 - layer3_1_loss: 1.4239 - layer3_acc: 0.3111 - layer3_1_acc: 0.3606\n",
      "Epoch 262/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9664 - layer3_loss: 1.5427 - layer3_1_loss: 1.4246 - layer3_acc: 0.3083 - layer3_1_acc: 0.3629\n",
      "Epoch 263/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9652 - layer3_loss: 1.5426 - layer3_1_loss: 1.4223 - layer3_acc: 0.3084 - layer3_1_acc: 0.3669\n",
      "Epoch 264/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9651 - layer3_loss: 1.5415 - layer3_1_loss: 1.4239 - layer3_acc: 0.3125 - layer3_1_acc: 0.3644\n",
      "Epoch 265/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9647 - layer3_loss: 1.5424 - layer3_1_loss: 1.4219 - layer3_acc: 0.3091 - layer3_1_acc: 0.3711\n",
      "Epoch 266/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9669 - layer3_loss: 1.5423 - layer3_1_loss: 1.4243 - layer3_acc: 0.3100 - layer3_1_acc: 0.3637\n",
      "Epoch 267/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9643 - layer3_loss: 1.5417 - layer3_1_loss: 1.4233 - layer3_acc: 0.3081 - layer3_1_acc: 0.3601\n",
      "Epoch 268/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9649 - layer3_loss: 1.5412 - layer3_1_loss: 1.4234 - layer3_acc: 0.3111 - layer3_1_acc: 0.3661\n",
      "Epoch 269/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9654 - layer3_loss: 1.5411 - layer3_1_loss: 1.4246 - layer3_acc: 0.3075 - layer3_1_acc: 0.3644\n",
      "Epoch 270/1000\n",
      "6329/6329 [==============================] - 1s 84us/sample - loss: 2.9654 - layer3_loss: 1.5405 - layer3_1_loss: 1.4245 - layer3_acc: 0.3049 - layer3_1_acc: 0.3577\n",
      "Epoch 271/1000\n",
      "6329/6329 [==============================] - 1s 82us/sample - loss: 2.9652 - layer3_loss: 1.5421 - layer3_1_loss: 1.4230 - layer3_acc: 0.3091 - layer3_1_acc: 0.3606\n",
      "Epoch 272/1000\n",
      "6329/6329 [==============================] - 0s 69us/sample - loss: 2.9658 - layer3_loss: 1.5425 - layer3_1_loss: 1.4241 - layer3_acc: 0.3114 - layer3_1_acc: 0.3604\n",
      "Epoch 273/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9649 - layer3_loss: 1.5415 - layer3_1_loss: 1.4240 - layer3_acc: 0.3100 - layer3_1_acc: 0.3650\n",
      "Epoch 274/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9642 - layer3_loss: 1.5414 - layer3_1_loss: 1.4226 - layer3_acc: 0.3089 - layer3_1_acc: 0.3705\n",
      "Epoch 275/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9658 - layer3_loss: 1.5412 - layer3_1_loss: 1.4241 - layer3_acc: 0.3098 - layer3_1_acc: 0.3670\n",
      "Epoch 276/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9642 - layer3_loss: 1.5405 - layer3_1_loss: 1.4236 - layer3_acc: 0.3116 - layer3_1_acc: 0.3625\n",
      "Epoch 277/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9643 - layer3_loss: 1.5423 - layer3_1_loss: 1.4229 - layer3_acc: 0.3095 - layer3_1_acc: 0.3631\n",
      "Epoch 278/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9640 - layer3_loss: 1.5404 - layer3_1_loss: 1.4240 - layer3_acc: 0.3079 - layer3_1_acc: 0.3574\n",
      "Epoch 279/1000\n",
      "6329/6329 [==============================] - 1s 110us/sample - loss: 2.9646 - layer3_loss: 1.5397 - layer3_1_loss: 1.4248 - layer3_acc: 0.3095 - layer3_1_acc: 0.3661\n",
      "Epoch 280/1000\n",
      "6329/6329 [==============================] - 0s 76us/sample - loss: 2.9651 - layer3_loss: 1.5409 - layer3_1_loss: 1.4236 - layer3_acc: 0.3116 - layer3_1_acc: 0.3629\n",
      "Epoch 281/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9648 - layer3_loss: 1.5415 - layer3_1_loss: 1.4237 - layer3_acc: 0.3097 - layer3_1_acc: 0.3629\n",
      "Epoch 282/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9640 - layer3_loss: 1.5406 - layer3_1_loss: 1.4232 - layer3_acc: 0.3095 - layer3_1_acc: 0.3675\n",
      "Epoch 283/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9638 - layer3_loss: 1.5413 - layer3_1_loss: 1.4216 - layer3_acc: 0.3089 - layer3_1_acc: 0.3670\n",
      "Epoch 284/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9650 - layer3_loss: 1.5419 - layer3_1_loss: 1.4230 - layer3_acc: 0.3111 - layer3_1_acc: 0.3642\n",
      "Epoch 285/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9645 - layer3_loss: 1.5414 - layer3_1_loss: 1.4235 - layer3_acc: 0.3084 - layer3_1_acc: 0.3639\n",
      "Epoch 286/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9643 - layer3_loss: 1.5420 - layer3_1_loss: 1.4230 - layer3_acc: 0.3087 - layer3_1_acc: 0.3620\n",
      "Epoch 287/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9645 - layer3_loss: 1.5419 - layer3_1_loss: 1.4229 - layer3_acc: 0.3105 - layer3_1_acc: 0.3663\n",
      "Epoch 288/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9651 - layer3_loss: 1.5410 - layer3_1_loss: 1.4236 - layer3_acc: 0.3062 - layer3_1_acc: 0.3658\n",
      "Epoch 289/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9650 - layer3_loss: 1.5423 - layer3_1_loss: 1.4230 - layer3_acc: 0.3076 - layer3_1_acc: 0.3620\n",
      "Epoch 290/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9642 - layer3_loss: 1.5407 - layer3_1_loss: 1.4240 - layer3_acc: 0.3133 - layer3_1_acc: 0.3688\n",
      "Epoch 291/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9652 - layer3_loss: 1.5419 - layer3_1_loss: 1.4241 - layer3_acc: 0.3079 - layer3_1_acc: 0.3634\n",
      "Epoch 292/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9639 - layer3_loss: 1.5414 - layer3_1_loss: 1.4219 - layer3_acc: 0.3138 - layer3_1_acc: 0.3648\n",
      "Epoch 293/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9643 - layer3_loss: 1.5415 - layer3_1_loss: 1.4222 - layer3_acc: 0.3070 - layer3_1_acc: 0.3702\n",
      "Epoch 294/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9632 - layer3_loss: 1.5403 - layer3_1_loss: 1.4223 - layer3_acc: 0.3086 - layer3_1_acc: 0.3614\n",
      "Epoch 295/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9642 - layer3_loss: 1.5400 - layer3_1_loss: 1.4237 - layer3_acc: 0.3075 - layer3_1_acc: 0.3609\n",
      "Epoch 296/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9638 - layer3_loss: 1.5403 - layer3_1_loss: 1.4236 - layer3_acc: 0.3114 - layer3_1_acc: 0.3648\n",
      "Epoch 297/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9643 - layer3_loss: 1.5408 - layer3_1_loss: 1.4243 - layer3_acc: 0.3109 - layer3_1_acc: 0.3647\n",
      "Epoch 298/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9646 - layer3_loss: 1.5407 - layer3_1_loss: 1.4234 - layer3_acc: 0.3108 - layer3_1_acc: 0.3651\n",
      "Epoch 299/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9634 - layer3_loss: 1.5410 - layer3_1_loss: 1.4228 - layer3_acc: 0.3086 - layer3_1_acc: 0.3700\n",
      "Epoch 300/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9631 - layer3_loss: 1.5406 - layer3_1_loss: 1.4223 - layer3_acc: 0.3083 - layer3_1_acc: 0.3655\n",
      "Epoch 301/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9630 - layer3_loss: 1.5418 - layer3_1_loss: 1.4223 - layer3_acc: 0.3108 - layer3_1_acc: 0.3618\n",
      "Epoch 302/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9631 - layer3_loss: 1.5396 - layer3_1_loss: 1.4239 - layer3_acc: 0.3124 - layer3_1_acc: 0.3647\n",
      "Epoch 303/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9645 - layer3_loss: 1.5407 - layer3_1_loss: 1.4236 - layer3_acc: 0.3078 - layer3_1_acc: 0.3664\n",
      "Epoch 304/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9629 - layer3_loss: 1.5411 - layer3_1_loss: 1.4218 - layer3_acc: 0.3154 - layer3_1_acc: 0.3639\n",
      "Epoch 305/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9643 - layer3_loss: 1.5401 - layer3_1_loss: 1.4236 - layer3_acc: 0.3083 - layer3_1_acc: 0.3672\n",
      "Epoch 306/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9643 - layer3_loss: 1.5410 - layer3_1_loss: 1.4238 - layer3_acc: 0.3111 - layer3_1_acc: 0.3658\n",
      "Epoch 307/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9629 - layer3_loss: 1.5397 - layer3_1_loss: 1.4231 - layer3_acc: 0.3143 - layer3_1_acc: 0.3661\n",
      "Epoch 308/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9630 - layer3_loss: 1.5398 - layer3_1_loss: 1.4232 - layer3_acc: 0.3130 - layer3_1_acc: 0.3631\n",
      "Epoch 309/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9631 - layer3_loss: 1.5405 - layer3_1_loss: 1.4225 - layer3_acc: 0.3102 - layer3_1_acc: 0.3704\n",
      "Epoch 310/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9632 - layer3_loss: 1.5406 - layer3_1_loss: 1.4225 - layer3_acc: 0.3106 - layer3_1_acc: 0.3648\n",
      "Epoch 311/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9627 - layer3_loss: 1.5400 - layer3_1_loss: 1.4224 - layer3_acc: 0.3076 - layer3_1_acc: 0.3659\n",
      "Epoch 312/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9643 - layer3_loss: 1.5402 - layer3_1_loss: 1.4248 - layer3_acc: 0.3127 - layer3_1_acc: 0.3612\n",
      "Epoch 313/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9629 - layer3_loss: 1.5419 - layer3_1_loss: 1.4217 - layer3_acc: 0.3103 - layer3_1_acc: 0.3689\n",
      "Epoch 314/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9641 - layer3_loss: 1.5417 - layer3_1_loss: 1.4220 - layer3_acc: 0.3098 - layer3_1_acc: 0.3656\n",
      "Epoch 315/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9631 - layer3_loss: 1.5402 - layer3_1_loss: 1.4224 - layer3_acc: 0.3098 - layer3_1_acc: 0.3667\n",
      "Epoch 316/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9626 - layer3_loss: 1.5411 - layer3_1_loss: 1.4220 - layer3_acc: 0.3091 - layer3_1_acc: 0.3607\n",
      "Epoch 317/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9641 - layer3_loss: 1.5402 - layer3_1_loss: 1.4232 - layer3_acc: 0.3072 - layer3_1_acc: 0.3658\n",
      "Epoch 318/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9624 - layer3_loss: 1.5418 - layer3_1_loss: 1.4208 - layer3_acc: 0.3147 - layer3_1_acc: 0.3615\n",
      "Epoch 319/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9621 - layer3_loss: 1.5391 - layer3_1_loss: 1.4235 - layer3_acc: 0.3157 - layer3_1_acc: 0.3670\n",
      "Epoch 320/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9635 - layer3_loss: 1.5399 - layer3_1_loss: 1.4230 - layer3_acc: 0.3095 - layer3_1_acc: 0.3651\n",
      "Epoch 321/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9629 - layer3_loss: 1.5404 - layer3_1_loss: 1.4222 - layer3_acc: 0.3102 - layer3_1_acc: 0.3713\n",
      "Epoch 322/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9642 - layer3_loss: 1.5427 - layer3_1_loss: 1.4218 - layer3_acc: 0.3100 - layer3_1_acc: 0.3672\n",
      "Epoch 323/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9633 - layer3_loss: 1.5414 - layer3_1_loss: 1.4223 - layer3_acc: 0.3106 - layer3_1_acc: 0.3650\n",
      "Epoch 324/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9626 - layer3_loss: 1.5397 - layer3_1_loss: 1.4229 - layer3_acc: 0.3098 - layer3_1_acc: 0.3658\n",
      "Epoch 325/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9624 - layer3_loss: 1.5410 - layer3_1_loss: 1.4220 - layer3_acc: 0.3098 - layer3_1_acc: 0.3642\n",
      "Epoch 326/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9617 - layer3_loss: 1.5396 - layer3_1_loss: 1.4218 - layer3_acc: 0.3109 - layer3_1_acc: 0.3688\n",
      "Epoch 327/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9630 - layer3_loss: 1.5395 - layer3_1_loss: 1.4233 - layer3_acc: 0.3114 - layer3_1_acc: 0.3664\n",
      "Epoch 328/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9630 - layer3_loss: 1.5421 - layer3_1_loss: 1.4219 - layer3_acc: 0.3111 - layer3_1_acc: 0.3694\n",
      "Epoch 329/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9628 - layer3_loss: 1.5403 - layer3_1_loss: 1.4226 - layer3_acc: 0.3073 - layer3_1_acc: 0.3669\n",
      "Epoch 330/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9627 - layer3_loss: 1.5400 - layer3_1_loss: 1.4233 - layer3_acc: 0.3076 - layer3_1_acc: 0.3642\n",
      "Epoch 331/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9627 - layer3_loss: 1.5414 - layer3_1_loss: 1.4208 - layer3_acc: 0.3141 - layer3_1_acc: 0.3634\n",
      "Epoch 332/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9628 - layer3_loss: 1.5396 - layer3_1_loss: 1.4230 - layer3_acc: 0.3119 - layer3_1_acc: 0.3678\n",
      "Epoch 333/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9636 - layer3_loss: 1.5401 - layer3_1_loss: 1.4241 - layer3_acc: 0.3116 - layer3_1_acc: 0.3634\n",
      "Epoch 334/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9625 - layer3_loss: 1.5403 - layer3_1_loss: 1.4215 - layer3_acc: 0.3073 - layer3_1_acc: 0.3681\n",
      "Epoch 335/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9620 - layer3_loss: 1.5416 - layer3_1_loss: 1.4217 - layer3_acc: 0.3140 - layer3_1_acc: 0.3694\n",
      "Epoch 336/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9629 - layer3_loss: 1.5405 - layer3_1_loss: 1.4223 - layer3_acc: 0.3127 - layer3_1_acc: 0.3651\n",
      "Epoch 337/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9618 - layer3_loss: 1.5404 - layer3_1_loss: 1.4213 - layer3_acc: 0.3102 - layer3_1_acc: 0.3670\n",
      "Epoch 338/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9622 - layer3_loss: 1.5395 - layer3_1_loss: 1.4227 - layer3_acc: 0.3147 - layer3_1_acc: 0.3686\n",
      "Epoch 339/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9612 - layer3_loss: 1.5400 - layer3_1_loss: 1.4210 - layer3_acc: 0.3100 - layer3_1_acc: 0.3651\n",
      "Epoch 340/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9620 - layer3_loss: 1.5406 - layer3_1_loss: 1.4210 - layer3_acc: 0.3065 - layer3_1_acc: 0.3689\n",
      "Epoch 341/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9627 - layer3_loss: 1.5395 - layer3_1_loss: 1.4236 - layer3_acc: 0.3132 - layer3_1_acc: 0.3634\n",
      "Epoch 342/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9616 - layer3_loss: 1.5405 - layer3_1_loss: 1.4212 - layer3_acc: 0.3089 - layer3_1_acc: 0.3681\n",
      "Epoch 343/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9626 - layer3_loss: 1.5398 - layer3_1_loss: 1.4224 - layer3_acc: 0.3116 - layer3_1_acc: 0.3591\n",
      "Epoch 344/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9618 - layer3_loss: 1.5391 - layer3_1_loss: 1.4222 - layer3_acc: 0.3138 - layer3_1_acc: 0.3670\n",
      "Epoch 345/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9639 - layer3_loss: 1.5407 - layer3_1_loss: 1.4229 - layer3_acc: 0.3100 - layer3_1_acc: 0.3650\n",
      "Epoch 346/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9628 - layer3_loss: 1.5413 - layer3_1_loss: 1.4213 - layer3_acc: 0.3076 - layer3_1_acc: 0.3651\n",
      "Epoch 347/1000\n",
      "6329/6329 [==============================] - 1s 83us/sample - loss: 2.9613 - layer3_loss: 1.5399 - layer3_1_loss: 1.4213 - layer3_acc: 0.3097 - layer3_1_acc: 0.3640\n",
      "Epoch 348/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9622 - layer3_loss: 1.5417 - layer3_1_loss: 1.4207 - layer3_acc: 0.3051 - layer3_1_acc: 0.3715\n",
      "Epoch 349/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9627 - layer3_loss: 1.5406 - layer3_1_loss: 1.4226 - layer3_acc: 0.3098 - layer3_1_acc: 0.3711\n",
      "Epoch 350/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9608 - layer3_loss: 1.5423 - layer3_1_loss: 1.4190 - layer3_acc: 0.3091 - layer3_1_acc: 0.3683\n",
      "Epoch 351/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9624 - layer3_loss: 1.5397 - layer3_1_loss: 1.4225 - layer3_acc: 0.3151 - layer3_1_acc: 0.3683\n",
      "Epoch 352/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9619 - layer3_loss: 1.5399 - layer3_1_loss: 1.4216 - layer3_acc: 0.3130 - layer3_1_acc: 0.3647\n",
      "Epoch 353/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9611 - layer3_loss: 1.5394 - layer3_1_loss: 1.4211 - layer3_acc: 0.3106 - layer3_1_acc: 0.3626\n",
      "Epoch 354/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9623 - layer3_loss: 1.5411 - layer3_1_loss: 1.4212 - layer3_acc: 0.3132 - layer3_1_acc: 0.3650\n",
      "Epoch 355/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9626 - layer3_loss: 1.5414 - layer3_1_loss: 1.4214 - layer3_acc: 0.3100 - layer3_1_acc: 0.3655\n",
      "Epoch 356/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9621 - layer3_loss: 1.5403 - layer3_1_loss: 1.4212 - layer3_acc: 0.3111 - layer3_1_acc: 0.3672\n",
      "Epoch 357/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9616 - layer3_loss: 1.5398 - layer3_1_loss: 1.4213 - layer3_acc: 0.3070 - layer3_1_acc: 0.3661\n",
      "Epoch 358/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9613 - layer3_loss: 1.5408 - layer3_1_loss: 1.4205 - layer3_acc: 0.3078 - layer3_1_acc: 0.3656\n",
      "Epoch 359/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9621 - layer3_loss: 1.5394 - layer3_1_loss: 1.4223 - layer3_acc: 0.3108 - layer3_1_acc: 0.3674\n",
      "Epoch 360/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9632 - layer3_loss: 1.5423 - layer3_1_loss: 1.4217 - layer3_acc: 0.3100 - layer3_1_acc: 0.3648\n",
      "Epoch 361/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9631 - layer3_loss: 1.5409 - layer3_1_loss: 1.4219 - layer3_acc: 0.3083 - layer3_1_acc: 0.3683\n",
      "Epoch 362/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9613 - layer3_loss: 1.5382 - layer3_1_loss: 1.4224 - layer3_acc: 0.3138 - layer3_1_acc: 0.3708\n",
      "Epoch 363/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9617 - layer3_loss: 1.5395 - layer3_1_loss: 1.4220 - layer3_acc: 0.3125 - layer3_1_acc: 0.3672\n",
      "Epoch 364/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9610 - layer3_loss: 1.5409 - layer3_1_loss: 1.4203 - layer3_acc: 0.3102 - layer3_1_acc: 0.3670\n",
      "Epoch 365/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9622 - layer3_loss: 1.5397 - layer3_1_loss: 1.4230 - layer3_acc: 0.3109 - layer3_1_acc: 0.3659\n",
      "Epoch 366/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9619 - layer3_loss: 1.5411 - layer3_1_loss: 1.4208 - layer3_acc: 0.3116 - layer3_1_acc: 0.3688\n",
      "Epoch 367/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9616 - layer3_loss: 1.5416 - layer3_1_loss: 1.4203 - layer3_acc: 0.3092 - layer3_1_acc: 0.3623\n",
      "Epoch 368/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9615 - layer3_loss: 1.5397 - layer3_1_loss: 1.4214 - layer3_acc: 0.3086 - layer3_1_acc: 0.3697\n",
      "Epoch 369/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9618 - layer3_loss: 1.5384 - layer3_1_loss: 1.4233 - layer3_acc: 0.3106 - layer3_1_acc: 0.3667\n",
      "Epoch 370/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9614 - layer3_loss: 1.5415 - layer3_1_loss: 1.4198 - layer3_acc: 0.3092 - layer3_1_acc: 0.3689\n",
      "Epoch 371/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9620 - layer3_loss: 1.5395 - layer3_1_loss: 1.4231 - layer3_acc: 0.3091 - layer3_1_acc: 0.3632\n",
      "Epoch 372/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9609 - layer3_loss: 1.5398 - layer3_1_loss: 1.4205 - layer3_acc: 0.3103 - layer3_1_acc: 0.3721\n",
      "Epoch 373/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9607 - layer3_loss: 1.5400 - layer3_1_loss: 1.4210 - layer3_acc: 0.3111 - layer3_1_acc: 0.3667\n",
      "Epoch 374/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9612 - layer3_loss: 1.5393 - layer3_1_loss: 1.4221 - layer3_acc: 0.3095 - layer3_1_acc: 0.3680\n",
      "Epoch 375/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9626 - layer3_loss: 1.5402 - layer3_1_loss: 1.4225 - layer3_acc: 0.3089 - layer3_1_acc: 0.3636\n",
      "Epoch 376/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9607 - layer3_loss: 1.5397 - layer3_1_loss: 1.4204 - layer3_acc: 0.3135 - layer3_1_acc: 0.3688\n",
      "Epoch 377/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9602 - layer3_loss: 1.5392 - layer3_1_loss: 1.4205 - layer3_acc: 0.3108 - layer3_1_acc: 0.3625\n",
      "Epoch 378/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9607 - layer3_loss: 1.5396 - layer3_1_loss: 1.4217 - layer3_acc: 0.3125 - layer3_1_acc: 0.3625\n",
      "Epoch 379/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9608 - layer3_loss: 1.5393 - layer3_1_loss: 1.4212 - layer3_acc: 0.3094 - layer3_1_acc: 0.3664\n",
      "Epoch 380/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9627 - layer3_loss: 1.5412 - layer3_1_loss: 1.4215 - layer3_acc: 0.3109 - layer3_1_acc: 0.3663\n",
      "Epoch 381/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9617 - layer3_loss: 1.5391 - layer3_1_loss: 1.4224 - layer3_acc: 0.3103 - layer3_1_acc: 0.3637\n",
      "Epoch 382/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9609 - layer3_loss: 1.5397 - layer3_1_loss: 1.4216 - layer3_acc: 0.3109 - layer3_1_acc: 0.3693\n",
      "Epoch 383/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9617 - layer3_loss: 1.5396 - layer3_1_loss: 1.4214 - layer3_acc: 0.3141 - layer3_1_acc: 0.3664\n",
      "Epoch 384/1000\n",
      "6329/6329 [==============================] - 0s 79us/sample - loss: 2.9605 - layer3_loss: 1.5387 - layer3_1_loss: 1.4211 - layer3_acc: 0.3097 - layer3_1_acc: 0.3719\n",
      "Epoch 385/1000\n",
      "6329/6329 [==============================] - 1s 82us/sample - loss: 2.9609 - layer3_loss: 1.5395 - layer3_1_loss: 1.4217 - layer3_acc: 0.3111 - layer3_1_acc: 0.3685\n",
      "Epoch 386/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9618 - layer3_loss: 1.5402 - layer3_1_loss: 1.4223 - layer3_acc: 0.3067 - layer3_1_acc: 0.3648\n",
      "Epoch 387/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9614 - layer3_loss: 1.5399 - layer3_1_loss: 1.4205 - layer3_acc: 0.3114 - layer3_1_acc: 0.3655\n",
      "Epoch 388/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9609 - layer3_loss: 1.5394 - layer3_1_loss: 1.4222 - layer3_acc: 0.3121 - layer3_1_acc: 0.3686\n",
      "Epoch 389/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9613 - layer3_loss: 1.5394 - layer3_1_loss: 1.4213 - layer3_acc: 0.3157 - layer3_1_acc: 0.3661\n",
      "Epoch 390/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9615 - layer3_loss: 1.5393 - layer3_1_loss: 1.4215 - layer3_acc: 0.3124 - layer3_1_acc: 0.3680\n",
      "Epoch 391/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9607 - layer3_loss: 1.5401 - layer3_1_loss: 1.4203 - layer3_acc: 0.3121 - layer3_1_acc: 0.3686\n",
      "Epoch 392/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9611 - layer3_loss: 1.5401 - layer3_1_loss: 1.4207 - layer3_acc: 0.3109 - layer3_1_acc: 0.3683\n",
      "Epoch 393/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9599 - layer3_loss: 1.5393 - layer3_1_loss: 1.4199 - layer3_acc: 0.3089 - layer3_1_acc: 0.3670\n",
      "Epoch 394/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9601 - layer3_loss: 1.5375 - layer3_1_loss: 1.4218 - layer3_acc: 0.3136 - layer3_1_acc: 0.3678\n",
      "Epoch 395/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9604 - layer3_loss: 1.5398 - layer3_1_loss: 1.4208 - layer3_acc: 0.3116 - layer3_1_acc: 0.3678\n",
      "Epoch 396/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9610 - layer3_loss: 1.5400 - layer3_1_loss: 1.4207 - layer3_acc: 0.3135 - layer3_1_acc: 0.3667\n",
      "Epoch 397/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9617 - layer3_loss: 1.5410 - layer3_1_loss: 1.4210 - layer3_acc: 0.3140 - layer3_1_acc: 0.3686\n",
      "Epoch 398/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9611 - layer3_loss: 1.5394 - layer3_1_loss: 1.4217 - layer3_acc: 0.3114 - layer3_1_acc: 0.3685\n",
      "Epoch 399/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9599 - layer3_loss: 1.5386 - layer3_1_loss: 1.4211 - layer3_acc: 0.3106 - layer3_1_acc: 0.3661\n",
      "Epoch 400/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9603 - layer3_loss: 1.5406 - layer3_1_loss: 1.4197 - layer3_acc: 0.3113 - layer3_1_acc: 0.3724\n",
      "Epoch 401/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9625 - layer3_loss: 1.5412 - layer3_1_loss: 1.4216 - layer3_acc: 0.3125 - layer3_1_acc: 0.3675\n",
      "Epoch 402/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9602 - layer3_loss: 1.5401 - layer3_1_loss: 1.4199 - layer3_acc: 0.3116 - layer3_1_acc: 0.3672\n",
      "Epoch 403/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9609 - layer3_loss: 1.5387 - layer3_1_loss: 1.4216 - layer3_acc: 0.3108 - layer3_1_acc: 0.3708\n",
      "Epoch 404/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9595 - layer3_loss: 1.5400 - layer3_1_loss: 1.4207 - layer3_acc: 0.3166 - layer3_1_acc: 0.3704\n",
      "Epoch 405/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9601 - layer3_loss: 1.5396 - layer3_1_loss: 1.4209 - layer3_acc: 0.3124 - layer3_1_acc: 0.3685\n",
      "Epoch 406/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9602 - layer3_loss: 1.5389 - layer3_1_loss: 1.4209 - layer3_acc: 0.3121 - layer3_1_acc: 0.3700\n",
      "Epoch 407/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9610 - layer3_loss: 1.5404 - layer3_1_loss: 1.4208 - layer3_acc: 0.3102 - layer3_1_acc: 0.3648\n",
      "Epoch 408/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9604 - layer3_loss: 1.5399 - layer3_1_loss: 1.4204 - layer3_acc: 0.3133 - layer3_1_acc: 0.3700\n",
      "Epoch 409/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9602 - layer3_loss: 1.5390 - layer3_1_loss: 1.4210 - layer3_acc: 0.3086 - layer3_1_acc: 0.3685\n",
      "Epoch 410/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9608 - layer3_loss: 1.5382 - layer3_1_loss: 1.4231 - layer3_acc: 0.3144 - layer3_1_acc: 0.3674\n",
      "Epoch 411/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9613 - layer3_loss: 1.5396 - layer3_1_loss: 1.4217 - layer3_acc: 0.3125 - layer3_1_acc: 0.3667\n",
      "Epoch 412/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9600 - layer3_loss: 1.5387 - layer3_1_loss: 1.4206 - layer3_acc: 0.3087 - layer3_1_acc: 0.3647\n",
      "Epoch 413/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9600 - layer3_loss: 1.5390 - layer3_1_loss: 1.4206 - layer3_acc: 0.3125 - layer3_1_acc: 0.3658\n",
      "Epoch 414/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9600 - layer3_loss: 1.5397 - layer3_1_loss: 1.4199 - layer3_acc: 0.3149 - layer3_1_acc: 0.3639\n",
      "Epoch 415/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9601 - layer3_loss: 1.5405 - layer3_1_loss: 1.4188 - layer3_acc: 0.3124 - layer3_1_acc: 0.3689\n",
      "Epoch 416/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9599 - layer3_loss: 1.5382 - layer3_1_loss: 1.4220 - layer3_acc: 0.3105 - layer3_1_acc: 0.3675\n",
      "Epoch 417/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9594 - layer3_loss: 1.5395 - layer3_1_loss: 1.4199 - layer3_acc: 0.3154 - layer3_1_acc: 0.3674\n",
      "Epoch 418/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9605 - layer3_loss: 1.5394 - layer3_1_loss: 1.4206 - layer3_acc: 0.3146 - layer3_1_acc: 0.3726\n",
      "Epoch 419/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9599 - layer3_loss: 1.5387 - layer3_1_loss: 1.4207 - layer3_acc: 0.3143 - layer3_1_acc: 0.3664\n",
      "Epoch 420/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9596 - layer3_loss: 1.5399 - layer3_1_loss: 1.4203 - layer3_acc: 0.3072 - layer3_1_acc: 0.3677\n",
      "Epoch 421/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9602 - layer3_loss: 1.5401 - layer3_1_loss: 1.4199 - layer3_acc: 0.3133 - layer3_1_acc: 0.3718\n",
      "Epoch 422/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9606 - layer3_loss: 1.5383 - layer3_1_loss: 1.4221 - layer3_acc: 0.3155 - layer3_1_acc: 0.3675\n",
      "Epoch 423/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9606 - layer3_loss: 1.5388 - layer3_1_loss: 1.4216 - layer3_acc: 0.3125 - layer3_1_acc: 0.3689\n",
      "Epoch 424/1000\n",
      "6329/6329 [==============================] - 1s 86us/sample - loss: 2.9600 - layer3_loss: 1.5389 - layer3_1_loss: 1.4205 - layer3_acc: 0.3105 - layer3_1_acc: 0.3672\n",
      "Epoch 425/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9598 - layer3_loss: 1.5378 - layer3_1_loss: 1.4211 - layer3_acc: 0.3098 - layer3_1_acc: 0.3705\n",
      "Epoch 426/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9602 - layer3_loss: 1.5386 - layer3_1_loss: 1.4209 - layer3_acc: 0.3117 - layer3_1_acc: 0.3669\n",
      "Epoch 427/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9604 - layer3_loss: 1.5402 - layer3_1_loss: 1.4202 - layer3_acc: 0.3119 - layer3_1_acc: 0.3713\n",
      "Epoch 428/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9599 - layer3_loss: 1.5400 - layer3_1_loss: 1.4199 - layer3_acc: 0.3086 - layer3_1_acc: 0.3680\n",
      "Epoch 429/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9597 - layer3_loss: 1.5384 - layer3_1_loss: 1.4218 - layer3_acc: 0.3113 - layer3_1_acc: 0.3651\n",
      "Epoch 430/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9598 - layer3_loss: 1.5398 - layer3_1_loss: 1.4205 - layer3_acc: 0.3094 - layer3_1_acc: 0.3655\n",
      "Epoch 431/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9599 - layer3_loss: 1.5391 - layer3_1_loss: 1.4210 - layer3_acc: 0.3132 - layer3_1_acc: 0.3664\n",
      "Epoch 432/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9594 - layer3_loss: 1.5390 - layer3_1_loss: 1.4201 - layer3_acc: 0.3125 - layer3_1_acc: 0.3675\n",
      "Epoch 433/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9595 - layer3_loss: 1.5398 - layer3_1_loss: 1.4199 - layer3_acc: 0.3157 - layer3_1_acc: 0.3663\n",
      "Epoch 434/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9608 - layer3_loss: 1.5384 - layer3_1_loss: 1.4224 - layer3_acc: 0.3143 - layer3_1_acc: 0.3719\n",
      "Epoch 435/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9612 - layer3_loss: 1.5411 - layer3_1_loss: 1.4198 - layer3_acc: 0.3160 - layer3_1_acc: 0.3674\n",
      "Epoch 436/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9589 - layer3_loss: 1.5391 - layer3_1_loss: 1.4196 - layer3_acc: 0.3136 - layer3_1_acc: 0.3708\n",
      "Epoch 437/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9595 - layer3_loss: 1.5395 - layer3_1_loss: 1.4195 - layer3_acc: 0.3144 - layer3_1_acc: 0.3689\n",
      "Epoch 438/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9604 - layer3_loss: 1.5398 - layer3_1_loss: 1.4209 - layer3_acc: 0.3117 - layer3_1_acc: 0.3658\n",
      "Epoch 439/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9599 - layer3_loss: 1.5395 - layer3_1_loss: 1.4208 - layer3_acc: 0.3157 - layer3_1_acc: 0.3625\n",
      "Epoch 440/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9581 - layer3_loss: 1.5382 - layer3_1_loss: 1.4199 - layer3_acc: 0.3116 - layer3_1_acc: 0.3713\n",
      "Epoch 441/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9604 - layer3_loss: 1.5400 - layer3_1_loss: 1.4200 - layer3_acc: 0.3128 - layer3_1_acc: 0.3680\n",
      "Epoch 442/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9586 - layer3_loss: 1.5381 - layer3_1_loss: 1.4205 - layer3_acc: 0.3089 - layer3_1_acc: 0.3653\n",
      "Epoch 443/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9581 - layer3_loss: 1.5392 - layer3_1_loss: 1.4189 - layer3_acc: 0.3122 - layer3_1_acc: 0.3716\n",
      "Epoch 444/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9595 - layer3_loss: 1.5390 - layer3_1_loss: 1.4215 - layer3_acc: 0.3102 - layer3_1_acc: 0.3659\n",
      "Epoch 445/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9598 - layer3_loss: 1.5386 - layer3_1_loss: 1.4217 - layer3_acc: 0.3136 - layer3_1_acc: 0.3667\n",
      "Epoch 446/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9596 - layer3_loss: 1.5390 - layer3_1_loss: 1.4208 - layer3_acc: 0.3117 - layer3_1_acc: 0.3680\n",
      "Epoch 447/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9587 - layer3_loss: 1.5391 - layer3_1_loss: 1.4197 - layer3_acc: 0.3102 - layer3_1_acc: 0.3653\n",
      "Epoch 448/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9579 - layer3_loss: 1.5379 - layer3_1_loss: 1.4195 - layer3_acc: 0.3136 - layer3_1_acc: 0.3705\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329/6329 [==============================] - 0s 79us/sample - loss: 2.9593 - layer3_loss: 1.5382 - layer3_1_loss: 1.4210 - layer3_acc: 0.3133 - layer3_1_acc: 0.3670\n",
      "Epoch 450/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9595 - layer3_loss: 1.5400 - layer3_1_loss: 1.4192 - layer3_acc: 0.3143 - layer3_1_acc: 0.3655\n",
      "Epoch 451/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9585 - layer3_loss: 1.5412 - layer3_1_loss: 1.4177 - layer3_acc: 0.3100 - layer3_1_acc: 0.3713\n",
      "Epoch 452/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9586 - layer3_loss: 1.5374 - layer3_1_loss: 1.4215 - layer3_acc: 0.3111 - layer3_1_acc: 0.3670\n",
      "Epoch 453/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9585 - layer3_loss: 1.5401 - layer3_1_loss: 1.4188 - layer3_acc: 0.3130 - layer3_1_acc: 0.3696\n",
      "Epoch 454/1000\n",
      "6329/6329 [==============================] - 0s 73us/sample - loss: 2.9591 - layer3_loss: 1.5391 - layer3_1_loss: 1.4203 - layer3_acc: 0.3062 - layer3_1_acc: 0.3688\n",
      "Epoch 455/1000\n",
      "6329/6329 [==============================] - 0s 69us/sample - loss: 2.9602 - layer3_loss: 1.5382 - layer3_1_loss: 1.4222 - layer3_acc: 0.3146 - layer3_1_acc: 0.3650\n",
      "Epoch 456/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9585 - layer3_loss: 1.5393 - layer3_1_loss: 1.4186 - layer3_acc: 0.3092 - layer3_1_acc: 0.3754\n",
      "Epoch 457/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9587 - layer3_loss: 1.5390 - layer3_1_loss: 1.4204 - layer3_acc: 0.3124 - layer3_1_acc: 0.3667\n",
      "Epoch 458/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9590 - layer3_loss: 1.5386 - layer3_1_loss: 1.4201 - layer3_acc: 0.3108 - layer3_1_acc: 0.3656\n",
      "Epoch 459/1000\n",
      "6329/6329 [==============================] - 1s 91us/sample - loss: 2.9591 - layer3_loss: 1.5383 - layer3_1_loss: 1.4206 - layer3_acc: 0.3146 - layer3_1_acc: 0.3691\n",
      "Epoch 460/1000\n",
      "6329/6329 [==============================] - 1s 97us/sample - loss: 2.9582 - layer3_loss: 1.5374 - layer3_1_loss: 1.4219 - layer3_acc: 0.3143 - layer3_1_acc: 0.3628\n",
      "Epoch 461/1000\n",
      "6329/6329 [==============================] - 1s 88us/sample - loss: 2.9585 - layer3_loss: 1.5407 - layer3_1_loss: 1.4183 - layer3_acc: 0.3106 - layer3_1_acc: 0.3656\n",
      "Epoch 462/1000\n",
      "6329/6329 [==============================] - 0s 76us/sample - loss: 2.9600 - layer3_loss: 1.5396 - layer3_1_loss: 1.4200 - layer3_acc: 0.3114 - layer3_1_acc: 0.3680\n",
      "Epoch 463/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9577 - layer3_loss: 1.5384 - layer3_1_loss: 1.4193 - layer3_acc: 0.3133 - layer3_1_acc: 0.3705\n",
      "Epoch 464/1000\n",
      "6329/6329 [==============================] - 0s 79us/sample - loss: 2.9592 - layer3_loss: 1.5384 - layer3_1_loss: 1.4207 - layer3_acc: 0.3113 - layer3_1_acc: 0.3693\n",
      "Epoch 465/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9595 - layer3_loss: 1.5417 - layer3_1_loss: 1.4184 - layer3_acc: 0.3095 - layer3_1_acc: 0.3753\n",
      "Epoch 466/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9574 - layer3_loss: 1.5371 - layer3_1_loss: 1.4200 - layer3_acc: 0.3155 - layer3_1_acc: 0.3658\n",
      "Epoch 467/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9587 - layer3_loss: 1.5384 - layer3_1_loss: 1.4199 - layer3_acc: 0.3127 - layer3_1_acc: 0.3678\n",
      "Epoch 468/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9592 - layer3_loss: 1.5399 - layer3_1_loss: 1.4201 - layer3_acc: 0.3138 - layer3_1_acc: 0.3699\n",
      "Epoch 469/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9582 - layer3_loss: 1.5412 - layer3_1_loss: 1.4175 - layer3_acc: 0.3116 - layer3_1_acc: 0.3705\n",
      "Epoch 470/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9602 - layer3_loss: 1.5396 - layer3_1_loss: 1.4209 - layer3_acc: 0.3133 - layer3_1_acc: 0.3667\n",
      "Epoch 471/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9583 - layer3_loss: 1.5380 - layer3_1_loss: 1.4194 - layer3_acc: 0.3116 - layer3_1_acc: 0.3693\n",
      "Epoch 472/1000\n",
      "6329/6329 [==============================] - 1s 79us/sample - loss: 2.9581 - layer3_loss: 1.5375 - layer3_1_loss: 1.4207 - layer3_acc: 0.3087 - layer3_1_acc: 0.3674\n",
      "Epoch 473/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9580 - layer3_loss: 1.5386 - layer3_1_loss: 1.4189 - layer3_acc: 0.3106 - layer3_1_acc: 0.3707\n",
      "Epoch 474/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9589 - layer3_loss: 1.5380 - layer3_1_loss: 1.4211 - layer3_acc: 0.3078 - layer3_1_acc: 0.3672\n",
      "Epoch 475/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9584 - layer3_loss: 1.5386 - layer3_1_loss: 1.4199 - layer3_acc: 0.3102 - layer3_1_acc: 0.3689\n",
      "Epoch 476/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9576 - layer3_loss: 1.5373 - layer3_1_loss: 1.4198 - layer3_acc: 0.3116 - layer3_1_acc: 0.3724\n",
      "Epoch 477/1000\n",
      "6329/6329 [==============================] - 0s 69us/sample - loss: 2.9583 - layer3_loss: 1.5391 - layer3_1_loss: 1.4197 - layer3_acc: 0.3128 - layer3_1_acc: 0.3713\n",
      "Epoch 478/1000\n",
      "6329/6329 [==============================] - 0s 73us/sample - loss: 2.9577 - layer3_loss: 1.5392 - layer3_1_loss: 1.4187 - layer3_acc: 0.3106 - layer3_1_acc: 0.3678\n",
      "Epoch 479/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9586 - layer3_loss: 1.5394 - layer3_1_loss: 1.4190 - layer3_acc: 0.3073 - layer3_1_acc: 0.3680\n",
      "Epoch 480/1000\n",
      "6329/6329 [==============================] - 0s 69us/sample - loss: 2.9600 - layer3_loss: 1.5397 - layer3_1_loss: 1.4209 - layer3_acc: 0.3119 - layer3_1_acc: 0.3634\n",
      "Epoch 481/1000\n",
      "6329/6329 [==============================] - 0s 73us/sample - loss: 2.9590 - layer3_loss: 1.5382 - layer3_1_loss: 1.4204 - layer3_acc: 0.3127 - layer3_1_acc: 0.3691\n",
      "Epoch 482/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9582 - layer3_loss: 1.5397 - layer3_1_loss: 1.4187 - layer3_acc: 0.3136 - layer3_1_acc: 0.3696\n",
      "Epoch 483/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9591 - layer3_loss: 1.5397 - layer3_1_loss: 1.4194 - layer3_acc: 0.3100 - layer3_1_acc: 0.3685\n",
      "Epoch 484/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9571 - layer3_loss: 1.5365 - layer3_1_loss: 1.4202 - layer3_acc: 0.3168 - layer3_1_acc: 0.3655\n",
      "Epoch 485/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9588 - layer3_loss: 1.5393 - layer3_1_loss: 1.4193 - layer3_acc: 0.3158 - layer3_1_acc: 0.3656\n",
      "Epoch 486/1000\n",
      "6329/6329 [==============================] - 0s 76us/sample - loss: 2.9581 - layer3_loss: 1.5390 - layer3_1_loss: 1.4195 - layer3_acc: 0.3075 - layer3_1_acc: 0.3726\n",
      "Epoch 487/1000\n",
      "6329/6329 [==============================] - 1s 82us/sample - loss: 2.9578 - layer3_loss: 1.5378 - layer3_1_loss: 1.4199 - layer3_acc: 0.3135 - layer3_1_acc: 0.3651\n",
      "Epoch 488/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9584 - layer3_loss: 1.5392 - layer3_1_loss: 1.4190 - layer3_acc: 0.3114 - layer3_1_acc: 0.3669\n",
      "Epoch 489/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9568 - layer3_loss: 1.5377 - layer3_1_loss: 1.4187 - layer3_acc: 0.3138 - layer3_1_acc: 0.3681\n",
      "Epoch 490/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9580 - layer3_loss: 1.5386 - layer3_1_loss: 1.4196 - layer3_acc: 0.3147 - layer3_1_acc: 0.3670\n",
      "Epoch 491/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9580 - layer3_loss: 1.5377 - layer3_1_loss: 1.4200 - layer3_acc: 0.3100 - layer3_1_acc: 0.3678\n",
      "Epoch 492/1000\n",
      "6329/6329 [==============================] - 1s 85us/sample - loss: 2.9584 - layer3_loss: 1.5387 - layer3_1_loss: 1.4199 - layer3_acc: 0.3136 - layer3_1_acc: 0.3659\n",
      "Epoch 493/1000\n",
      "6329/6329 [==============================] - 1s 83us/sample - loss: 2.9583 - layer3_loss: 1.5393 - layer3_1_loss: 1.4187 - layer3_acc: 0.3133 - layer3_1_acc: 0.3699\n",
      "Epoch 494/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329/6329 [==============================] - 0s 69us/sample - loss: 2.9575 - layer3_loss: 1.5389 - layer3_1_loss: 1.4189 - layer3_acc: 0.3124 - layer3_1_acc: 0.3678\n",
      "Epoch 495/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9573 - layer3_loss: 1.5369 - layer3_1_loss: 1.4205 - layer3_acc: 0.3151 - layer3_1_acc: 0.3666\n",
      "Epoch 496/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9567 - layer3_loss: 1.5388 - layer3_1_loss: 1.4176 - layer3_acc: 0.3146 - layer3_1_acc: 0.3697\n",
      "Epoch 497/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9576 - layer3_loss: 1.5394 - layer3_1_loss: 1.4180 - layer3_acc: 0.3152 - layer3_1_acc: 0.3677\n",
      "Epoch 498/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9566 - layer3_loss: 1.5364 - layer3_1_loss: 1.4199 - layer3_acc: 0.3157 - layer3_1_acc: 0.3699\n",
      "Epoch 499/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9561 - layer3_loss: 1.5381 - layer3_1_loss: 1.4179 - layer3_acc: 0.3127 - layer3_1_acc: 0.3718\n",
      "Epoch 500/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9565 - layer3_loss: 1.5371 - layer3_1_loss: 1.4193 - layer3_acc: 0.3163 - layer3_1_acc: 0.3670\n",
      "Epoch 501/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9578 - layer3_loss: 1.5381 - layer3_1_loss: 1.4196 - layer3_acc: 0.3109 - layer3_1_acc: 0.3707\n",
      "Epoch 502/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9580 - layer3_loss: 1.5402 - layer3_1_loss: 1.4180 - layer3_acc: 0.3143 - layer3_1_acc: 0.3663\n",
      "Epoch 503/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9573 - layer3_loss: 1.5384 - layer3_1_loss: 1.4192 - layer3_acc: 0.3125 - layer3_1_acc: 0.3642\n",
      "Epoch 504/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9564 - layer3_loss: 1.5360 - layer3_1_loss: 1.4200 - layer3_acc: 0.3103 - layer3_1_acc: 0.3737\n",
      "Epoch 505/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9583 - layer3_loss: 1.5392 - layer3_1_loss: 1.4191 - layer3_acc: 0.3119 - layer3_1_acc: 0.3704\n",
      "Epoch 506/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9586 - layer3_loss: 1.5390 - layer3_1_loss: 1.4190 - layer3_acc: 0.3136 - layer3_1_acc: 0.3688\n",
      "Epoch 507/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9572 - layer3_loss: 1.5392 - layer3_1_loss: 1.4179 - layer3_acc: 0.3128 - layer3_1_acc: 0.3663\n",
      "Epoch 508/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9577 - layer3_loss: 1.5388 - layer3_1_loss: 1.4193 - layer3_acc: 0.3127 - layer3_1_acc: 0.3612\n",
      "Epoch 509/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9577 - layer3_loss: 1.5385 - layer3_1_loss: 1.4188 - layer3_acc: 0.3117 - layer3_1_acc: 0.3707\n",
      "Epoch 510/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9569 - layer3_loss: 1.5372 - layer3_1_loss: 1.4194 - layer3_acc: 0.3149 - layer3_1_acc: 0.3659\n",
      "Epoch 511/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9579 - layer3_loss: 1.5389 - layer3_1_loss: 1.4194 - layer3_acc: 0.3143 - layer3_1_acc: 0.3674\n",
      "Epoch 512/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9583 - layer3_loss: 1.5381 - layer3_1_loss: 1.4198 - layer3_acc: 0.3105 - layer3_1_acc: 0.3708\n",
      "Epoch 513/1000\n",
      "6329/6329 [==============================] - 0s 69us/sample - loss: 2.9571 - layer3_loss: 1.5381 - layer3_1_loss: 1.4190 - layer3_acc: 0.3100 - layer3_1_acc: 0.3664\n",
      "Epoch 514/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9568 - layer3_loss: 1.5380 - layer3_1_loss: 1.4198 - layer3_acc: 0.3141 - layer3_1_acc: 0.3661\n",
      "Epoch 515/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9581 - layer3_loss: 1.5385 - layer3_1_loss: 1.4190 - layer3_acc: 0.3122 - layer3_1_acc: 0.3721\n",
      "Epoch 516/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9576 - layer3_loss: 1.5383 - layer3_1_loss: 1.4196 - layer3_acc: 0.3157 - layer3_1_acc: 0.3697\n",
      "Epoch 517/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9567 - layer3_loss: 1.5373 - layer3_1_loss: 1.4190 - layer3_acc: 0.3125 - layer3_1_acc: 0.3715\n",
      "Epoch 518/1000\n",
      "6329/6329 [==============================] - 0s 69us/sample - loss: 2.9576 - layer3_loss: 1.5389 - layer3_1_loss: 1.4197 - layer3_acc: 0.3141 - layer3_1_acc: 0.3656\n",
      "Epoch 519/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9579 - layer3_loss: 1.5392 - layer3_1_loss: 1.4190 - layer3_acc: 0.3152 - layer3_1_acc: 0.3656\n",
      "Epoch 520/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9575 - layer3_loss: 1.5366 - layer3_1_loss: 1.4204 - layer3_acc: 0.3165 - layer3_1_acc: 0.3656\n",
      "Epoch 521/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9572 - layer3_loss: 1.5377 - layer3_1_loss: 1.4193 - layer3_acc: 0.3094 - layer3_1_acc: 0.3721\n",
      "Epoch 522/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9572 - layer3_loss: 1.5379 - layer3_1_loss: 1.4187 - layer3_acc: 0.3138 - layer3_1_acc: 0.3685\n",
      "Epoch 523/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9565 - layer3_loss: 1.5369 - layer3_1_loss: 1.4199 - layer3_acc: 0.3138 - layer3_1_acc: 0.3705\n",
      "Epoch 524/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9562 - layer3_loss: 1.5371 - layer3_1_loss: 1.4189 - layer3_acc: 0.3144 - layer3_1_acc: 0.3656\n",
      "Epoch 525/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9564 - layer3_loss: 1.5368 - layer3_1_loss: 1.4193 - layer3_acc: 0.3125 - layer3_1_acc: 0.3700\n",
      "Epoch 526/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9564 - layer3_loss: 1.5387 - layer3_1_loss: 1.4177 - layer3_acc: 0.3111 - layer3_1_acc: 0.3719\n",
      "Epoch 527/1000\n",
      "6329/6329 [==============================] - 0s 69us/sample - loss: 2.9574 - layer3_loss: 1.5365 - layer3_1_loss: 1.4205 - layer3_acc: 0.3144 - layer3_1_acc: 0.3639\n",
      "Epoch 528/1000\n",
      "6329/6329 [==============================] - 0s 76us/sample - loss: 2.9566 - layer3_loss: 1.5388 - layer3_1_loss: 1.4177 - layer3_acc: 0.3116 - layer3_1_acc: 0.3711\n",
      "Epoch 529/1000\n",
      "6329/6329 [==============================] - 1s 85us/sample - loss: 2.9570 - layer3_loss: 1.5390 - layer3_1_loss: 1.4180 - layer3_acc: 0.3122 - layer3_1_acc: 0.3681\n",
      "Epoch 530/1000\n",
      "6329/6329 [==============================] - 0s 79us/sample - loss: 2.9575 - layer3_loss: 1.5378 - layer3_1_loss: 1.4196 - layer3_acc: 0.3103 - layer3_1_acc: 0.3617\n",
      "Epoch 531/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9568 - layer3_loss: 1.5391 - layer3_1_loss: 1.4187 - layer3_acc: 0.3114 - layer3_1_acc: 0.3704\n",
      "Epoch 532/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9579 - layer3_loss: 1.5378 - layer3_1_loss: 1.4205 - layer3_acc: 0.3158 - layer3_1_acc: 0.3636\n",
      "Epoch 533/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9563 - layer3_loss: 1.5376 - layer3_1_loss: 1.4185 - layer3_acc: 0.3174 - layer3_1_acc: 0.3718\n",
      "Epoch 534/1000\n",
      "6329/6329 [==============================] - 0s 69us/sample - loss: 2.9583 - layer3_loss: 1.5384 - layer3_1_loss: 1.4201 - layer3_acc: 0.3102 - layer3_1_acc: 0.3675\n",
      "Epoch 535/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9568 - layer3_loss: 1.5378 - layer3_1_loss: 1.4188 - layer3_acc: 0.3116 - layer3_1_acc: 0.3655\n",
      "Epoch 536/1000\n",
      "6329/6329 [==============================] - 0s 69us/sample - loss: 2.9573 - layer3_loss: 1.5383 - layer3_1_loss: 1.4187 - layer3_acc: 0.3122 - layer3_1_acc: 0.3689\n",
      "Epoch 537/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9551 - layer3_loss: 1.5368 - layer3_1_loss: 1.4189 - layer3_acc: 0.3155 - layer3_1_acc: 0.3637\n",
      "Epoch 538/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9563 - layer3_loss: 1.5363 - layer3_1_loss: 1.4205 - layer3_acc: 0.3140 - layer3_1_acc: 0.3659\n",
      "Epoch 539/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9564 - layer3_loss: 1.5385 - layer3_1_loss: 1.4173 - layer3_acc: 0.3124 - layer3_1_acc: 0.3626\n",
      "Epoch 540/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9554 - layer3_loss: 1.5374 - layer3_1_loss: 1.4183 - layer3_acc: 0.3127 - layer3_1_acc: 0.3645\n",
      "Epoch 541/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9574 - layer3_loss: 1.5375 - layer3_1_loss: 1.4194 - layer3_acc: 0.3113 - layer3_1_acc: 0.3656\n",
      "Epoch 542/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9571 - layer3_loss: 1.5399 - layer3_1_loss: 1.4179 - layer3_acc: 0.3097 - layer3_1_acc: 0.3670\n",
      "Epoch 543/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9561 - layer3_loss: 1.5380 - layer3_1_loss: 1.4179 - layer3_acc: 0.3132 - layer3_1_acc: 0.3653\n",
      "Epoch 544/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9560 - layer3_loss: 1.5387 - layer3_1_loss: 1.4186 - layer3_acc: 0.3141 - layer3_1_acc: 0.3707\n",
      "Epoch 545/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9567 - layer3_loss: 1.5388 - layer3_1_loss: 1.4179 - layer3_acc: 0.3141 - layer3_1_acc: 0.3689\n",
      "Epoch 546/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9562 - layer3_loss: 1.5393 - layer3_1_loss: 1.4175 - layer3_acc: 0.3113 - layer3_1_acc: 0.3617\n",
      "Epoch 547/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9553 - layer3_loss: 1.5376 - layer3_1_loss: 1.4177 - layer3_acc: 0.3127 - layer3_1_acc: 0.3689\n",
      "Epoch 548/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9565 - layer3_loss: 1.5359 - layer3_1_loss: 1.4207 - layer3_acc: 0.3157 - layer3_1_acc: 0.3696\n",
      "Epoch 549/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9573 - layer3_loss: 1.5377 - layer3_1_loss: 1.4187 - layer3_acc: 0.3149 - layer3_1_acc: 0.3670\n",
      "Epoch 550/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9572 - layer3_loss: 1.5385 - layer3_1_loss: 1.4187 - layer3_acc: 0.3119 - layer3_1_acc: 0.3751\n",
      "Epoch 551/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9554 - layer3_loss: 1.5368 - layer3_1_loss: 1.4190 - layer3_acc: 0.3168 - layer3_1_acc: 0.3664\n",
      "Epoch 552/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9560 - layer3_loss: 1.5369 - layer3_1_loss: 1.4205 - layer3_acc: 0.3111 - layer3_1_acc: 0.3702\n",
      "Epoch 553/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9560 - layer3_loss: 1.5364 - layer3_1_loss: 1.4192 - layer3_acc: 0.3157 - layer3_1_acc: 0.3707\n",
      "Epoch 554/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9557 - layer3_loss: 1.5357 - layer3_1_loss: 1.4196 - layer3_acc: 0.3170 - layer3_1_acc: 0.3651\n",
      "Epoch 555/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9560 - layer3_loss: 1.5383 - layer3_1_loss: 1.4170 - layer3_acc: 0.3128 - layer3_1_acc: 0.3686\n",
      "Epoch 556/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9564 - layer3_loss: 1.5372 - layer3_1_loss: 1.4188 - layer3_acc: 0.3133 - layer3_1_acc: 0.3689\n",
      "Epoch 557/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9559 - layer3_loss: 1.5353 - layer3_1_loss: 1.4208 - layer3_acc: 0.3168 - layer3_1_acc: 0.3647\n",
      "Epoch 558/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9566 - layer3_loss: 1.5390 - layer3_1_loss: 1.4181 - layer3_acc: 0.3154 - layer3_1_acc: 0.3691\n",
      "Epoch 559/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9567 - layer3_loss: 1.5376 - layer3_1_loss: 1.4190 - layer3_acc: 0.3149 - layer3_1_acc: 0.3683\n",
      "Epoch 560/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9560 - layer3_loss: 1.5379 - layer3_1_loss: 1.4178 - layer3_acc: 0.3125 - layer3_1_acc: 0.3696\n",
      "Epoch 561/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9562 - layer3_loss: 1.5372 - layer3_1_loss: 1.4185 - layer3_acc: 0.3113 - layer3_1_acc: 0.3710\n",
      "Epoch 562/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9562 - layer3_loss: 1.5374 - layer3_1_loss: 1.4191 - layer3_acc: 0.3111 - layer3_1_acc: 0.3678\n",
      "Epoch 563/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9562 - layer3_loss: 1.5391 - layer3_1_loss: 1.4168 - layer3_acc: 0.3124 - layer3_1_acc: 0.3697\n",
      "Epoch 564/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9552 - layer3_loss: 1.5373 - layer3_1_loss: 1.4177 - layer3_acc: 0.3147 - layer3_1_acc: 0.3670\n",
      "Epoch 565/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9562 - layer3_loss: 1.5359 - layer3_1_loss: 1.4199 - layer3_acc: 0.3089 - layer3_1_acc: 0.3663\n",
      "Epoch 566/1000\n",
      "6329/6329 [==============================] - 1s 83us/sample - loss: 2.9552 - layer3_loss: 1.5363 - layer3_1_loss: 1.4183 - layer3_acc: 0.3097 - layer3_1_acc: 0.3683\n",
      "Epoch 567/1000\n",
      "6329/6329 [==============================] - 0s 76us/sample - loss: 2.9558 - layer3_loss: 1.5375 - layer3_1_loss: 1.4176 - layer3_acc: 0.3146 - layer3_1_acc: 0.3644\n",
      "Epoch 568/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9552 - layer3_loss: 1.5366 - layer3_1_loss: 1.4185 - layer3_acc: 0.3157 - layer3_1_acc: 0.3686\n",
      "Epoch 569/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9568 - layer3_loss: 1.5389 - layer3_1_loss: 1.4177 - layer3_acc: 0.3124 - layer3_1_acc: 0.3659\n",
      "Epoch 570/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9556 - layer3_loss: 1.5355 - layer3_1_loss: 1.4199 - layer3_acc: 0.3135 - layer3_1_acc: 0.3702\n",
      "Epoch 571/1000\n",
      "6329/6329 [==============================] - 1s 89us/sample - loss: 2.9562 - layer3_loss: 1.5384 - layer3_1_loss: 1.4181 - layer3_acc: 0.3149 - layer3_1_acc: 0.3601\n",
      "Epoch 572/1000\n",
      "6329/6329 [==============================] - 1s 88us/sample - loss: 2.9552 - layer3_loss: 1.5354 - layer3_1_loss: 1.4200 - layer3_acc: 0.3144 - layer3_1_acc: 0.3677\n",
      "Epoch 573/1000\n",
      "6329/6329 [==============================] - 1s 91us/sample - loss: 2.9556 - layer3_loss: 1.5378 - layer3_1_loss: 1.4174 - layer3_acc: 0.3102 - layer3_1_acc: 0.3653\n",
      "Epoch 574/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9567 - layer3_loss: 1.5382 - layer3_1_loss: 1.4181 - layer3_acc: 0.3109 - layer3_1_acc: 0.3631\n",
      "Epoch 575/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9565 - layer3_loss: 1.5381 - layer3_1_loss: 1.4183 - layer3_acc: 0.3140 - layer3_1_acc: 0.3707\n",
      "Epoch 576/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9559 - layer3_loss: 1.5380 - layer3_1_loss: 1.4182 - layer3_acc: 0.3089 - layer3_1_acc: 0.3724\n",
      "Epoch 577/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9554 - layer3_loss: 1.5369 - layer3_1_loss: 1.4184 - layer3_acc: 0.3176 - layer3_1_acc: 0.3639\n",
      "Epoch 578/1000\n",
      "6329/6329 [==============================] - 1s 83us/sample - loss: 2.9559 - layer3_loss: 1.5366 - layer3_1_loss: 1.4189 - layer3_acc: 0.3149 - layer3_1_acc: 0.3685\n",
      "Epoch 579/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9572 - layer3_loss: 1.5389 - layer3_1_loss: 1.4179 - layer3_acc: 0.3100 - layer3_1_acc: 0.3697\n",
      "Epoch 580/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9550 - layer3_loss: 1.5352 - layer3_1_loss: 1.4189 - layer3_acc: 0.3162 - layer3_1_acc: 0.3683\n",
      "Epoch 581/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9551 - layer3_loss: 1.5361 - layer3_1_loss: 1.4181 - layer3_acc: 0.3171 - layer3_1_acc: 0.3656\n",
      "Epoch 582/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9549 - layer3_loss: 1.5393 - layer3_1_loss: 1.4165 - layer3_acc: 0.3157 - layer3_1_acc: 0.3707\n",
      "Epoch 583/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9558 - layer3_loss: 1.5393 - layer3_1_loss: 1.4175 - layer3_acc: 0.3140 - layer3_1_acc: 0.3636\n",
      "Epoch 584/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9563 - layer3_loss: 1.5369 - layer3_1_loss: 1.4191 - layer3_acc: 0.3141 - layer3_1_acc: 0.3650\n",
      "Epoch 585/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9556 - layer3_loss: 1.5382 - layer3_1_loss: 1.4185 - layer3_acc: 0.3106 - layer3_1_acc: 0.3702\n",
      "Epoch 586/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9549 - layer3_loss: 1.5379 - layer3_1_loss: 1.4167 - layer3_acc: 0.3117 - layer3_1_acc: 0.3661\n",
      "Epoch 587/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9557 - layer3_loss: 1.5369 - layer3_1_loss: 1.4187 - layer3_acc: 0.3143 - layer3_1_acc: 0.3664\n",
      "Epoch 588/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9563 - layer3_loss: 1.5365 - layer3_1_loss: 1.4199 - layer3_acc: 0.3125 - layer3_1_acc: 0.3691\n",
      "Epoch 589/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9549 - layer3_loss: 1.5378 - layer3_1_loss: 1.4177 - layer3_acc: 0.3163 - layer3_1_acc: 0.3705\n",
      "Epoch 590/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9560 - layer3_loss: 1.5359 - layer3_1_loss: 1.4196 - layer3_acc: 0.3143 - layer3_1_acc: 0.3691\n",
      "Epoch 591/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9542 - layer3_loss: 1.5367 - layer3_1_loss: 1.4178 - layer3_acc: 0.3173 - layer3_1_acc: 0.3680\n",
      "Epoch 592/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9561 - layer3_loss: 1.5386 - layer3_1_loss: 1.4180 - layer3_acc: 0.3141 - layer3_1_acc: 0.3632\n",
      "Epoch 593/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9552 - layer3_loss: 1.5362 - layer3_1_loss: 1.4189 - layer3_acc: 0.3149 - layer3_1_acc: 0.3694\n",
      "Epoch 594/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9544 - layer3_loss: 1.5377 - layer3_1_loss: 1.4164 - layer3_acc: 0.3087 - layer3_1_acc: 0.3757\n",
      "Epoch 595/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9562 - layer3_loss: 1.5356 - layer3_1_loss: 1.4200 - layer3_acc: 0.3122 - layer3_1_acc: 0.3653\n",
      "Epoch 596/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9556 - layer3_loss: 1.5384 - layer3_1_loss: 1.4172 - layer3_acc: 0.3087 - layer3_1_acc: 0.3669\n",
      "Epoch 597/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9559 - layer3_loss: 1.5386 - layer3_1_loss: 1.4186 - layer3_acc: 0.3079 - layer3_1_acc: 0.3694\n",
      "Epoch 598/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9548 - layer3_loss: 1.5380 - layer3_1_loss: 1.4179 - layer3_acc: 0.3127 - layer3_1_acc: 0.3675\n",
      "Epoch 599/1000\n",
      "6329/6329 [==============================] - 0s 73us/sample - loss: 2.9556 - layer3_loss: 1.5372 - layer3_1_loss: 1.4180 - layer3_acc: 0.3105 - layer3_1_acc: 0.3694\n",
      "Epoch 600/1000\n",
      "6329/6329 [==============================] - 1s 83us/sample - loss: 2.9543 - layer3_loss: 1.5364 - layer3_1_loss: 1.4177 - layer3_acc: 0.3163 - layer3_1_acc: 0.3723\n",
      "Epoch 601/1000\n",
      "6329/6329 [==============================] - 1s 84us/sample - loss: 2.9541 - layer3_loss: 1.5367 - layer3_1_loss: 1.4181 - layer3_acc: 0.3136 - layer3_1_acc: 0.3669\n",
      "Epoch 602/1000\n",
      "6329/6329 [==============================] - 0s 69us/sample - loss: 2.9561 - layer3_loss: 1.5365 - layer3_1_loss: 1.4191 - layer3_acc: 0.3116 - layer3_1_acc: 0.3710\n",
      "Epoch 603/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9553 - layer3_loss: 1.5362 - layer3_1_loss: 1.4191 - layer3_acc: 0.3166 - layer3_1_acc: 0.3655\n",
      "Epoch 604/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9547 - layer3_loss: 1.5384 - layer3_1_loss: 1.4165 - layer3_acc: 0.3114 - layer3_1_acc: 0.3685\n",
      "Epoch 605/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9539 - layer3_loss: 1.5351 - layer3_1_loss: 1.4191 - layer3_acc: 0.3146 - layer3_1_acc: 0.3702\n",
      "Epoch 606/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9541 - layer3_loss: 1.5372 - layer3_1_loss: 1.4164 - layer3_acc: 0.3143 - layer3_1_acc: 0.3694\n",
      "Epoch 607/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9547 - layer3_loss: 1.5370 - layer3_1_loss: 1.4181 - layer3_acc: 0.3152 - layer3_1_acc: 0.3650\n",
      "Epoch 608/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9556 - layer3_loss: 1.5378 - layer3_1_loss: 1.4185 - layer3_acc: 0.3152 - layer3_1_acc: 0.3669\n",
      "Epoch 609/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9544 - layer3_loss: 1.5359 - layer3_1_loss: 1.4182 - layer3_acc: 0.3119 - layer3_1_acc: 0.3691\n",
      "Epoch 610/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9549 - layer3_loss: 1.5367 - layer3_1_loss: 1.4180 - layer3_acc: 0.3140 - layer3_1_acc: 0.3689\n",
      "Epoch 611/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9554 - layer3_loss: 1.5352 - layer3_1_loss: 1.4193 - layer3_acc: 0.3179 - layer3_1_acc: 0.3675\n",
      "Epoch 612/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9552 - layer3_loss: 1.5364 - layer3_1_loss: 1.4184 - layer3_acc: 0.3127 - layer3_1_acc: 0.3702\n",
      "Epoch 613/1000\n",
      "6329/6329 [==============================] - 1s 84us/sample - loss: 2.9558 - layer3_loss: 1.5384 - layer3_1_loss: 1.4172 - layer3_acc: 0.3146 - layer3_1_acc: 0.3683\n",
      "Epoch 614/1000\n",
      "6329/6329 [==============================] - 1s 84us/sample - loss: 2.9536 - layer3_loss: 1.5359 - layer3_1_loss: 1.4169 - layer3_acc: 0.3174 - layer3_1_acc: 0.3688\n",
      "Epoch 615/1000\n",
      "6329/6329 [==============================] - 1s 82us/sample - loss: 2.9547 - layer3_loss: 1.5368 - layer3_1_loss: 1.4179 - layer3_acc: 0.3132 - layer3_1_acc: 0.3669\n",
      "Epoch 616/1000\n",
      "6329/6329 [==============================] - 1s 83us/sample - loss: 2.9560 - layer3_loss: 1.5369 - layer3_1_loss: 1.4196 - layer3_acc: 0.3141 - layer3_1_acc: 0.3674\n",
      "Epoch 617/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9546 - layer3_loss: 1.5351 - layer3_1_loss: 1.4187 - layer3_acc: 0.3157 - layer3_1_acc: 0.3694\n",
      "Epoch 618/1000\n",
      "6329/6329 [==============================] - 1s 83us/sample - loss: 2.9538 - layer3_loss: 1.5367 - layer3_1_loss: 1.4175 - layer3_acc: 0.3138 - layer3_1_acc: 0.3702\n",
      "Epoch 619/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9541 - layer3_loss: 1.5353 - layer3_1_loss: 1.4182 - layer3_acc: 0.3168 - layer3_1_acc: 0.3677\n",
      "Epoch 620/1000\n",
      "6329/6329 [==============================] - 1s 88us/sample - loss: 2.9547 - layer3_loss: 1.5367 - layer3_1_loss: 1.4180 - layer3_acc: 0.3166 - layer3_1_acc: 0.3689\n",
      "Epoch 621/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9553 - layer3_loss: 1.5367 - layer3_1_loss: 1.4181 - layer3_acc: 0.3125 - layer3_1_acc: 0.3724\n",
      "Epoch 622/1000\n",
      "6329/6329 [==============================] - 0s 73us/sample - loss: 2.9544 - layer3_loss: 1.5364 - layer3_1_loss: 1.4180 - layer3_acc: 0.3117 - layer3_1_acc: 0.3689\n",
      "Epoch 623/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9542 - layer3_loss: 1.5378 - layer3_1_loss: 1.4166 - layer3_acc: 0.3108 - layer3_1_acc: 0.3732\n",
      "Epoch 624/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9538 - layer3_loss: 1.5367 - layer3_1_loss: 1.4178 - layer3_acc: 0.3176 - layer3_1_acc: 0.3648\n",
      "Epoch 625/1000\n",
      "6329/6329 [==============================] - 1s 79us/sample - loss: 2.9537 - layer3_loss: 1.5361 - layer3_1_loss: 1.4173 - layer3_acc: 0.3105 - layer3_1_acc: 0.3647\n",
      "Epoch 626/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9540 - layer3_loss: 1.5371 - layer3_1_loss: 1.4174 - layer3_acc: 0.3130 - layer3_1_acc: 0.3711\n",
      "Epoch 627/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9544 - layer3_loss: 1.5361 - layer3_1_loss: 1.4186 - layer3_acc: 0.3122 - layer3_1_acc: 0.3647\n",
      "Epoch 628/1000\n",
      "6329/6329 [==============================] - 1s 85us/sample - loss: 2.9551 - layer3_loss: 1.5367 - layer3_1_loss: 1.4181 - layer3_acc: 0.3151 - layer3_1_acc: 0.3683\n",
      "Epoch 629/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329/6329 [==============================] - 1s 82us/sample - loss: 2.9542 - layer3_loss: 1.5377 - layer3_1_loss: 1.4167 - layer3_acc: 0.3122 - layer3_1_acc: 0.3705\n",
      "Epoch 630/1000\n",
      "6329/6329 [==============================] - 1s 79us/sample - loss: 2.9544 - layer3_loss: 1.5353 - layer3_1_loss: 1.4187 - layer3_acc: 0.3160 - layer3_1_acc: 0.3677\n",
      "Epoch 631/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9553 - layer3_loss: 1.5379 - layer3_1_loss: 1.4178 - layer3_acc: 0.3113 - layer3_1_acc: 0.3672\n",
      "Epoch 632/1000\n",
      "6329/6329 [==============================] - 1s 99us/sample - loss: 2.9545 - layer3_loss: 1.5383 - layer3_1_loss: 1.4170 - layer3_acc: 0.3119 - layer3_1_acc: 0.3651\n",
      "Epoch 633/1000\n",
      "6329/6329 [==============================] - 1s 97us/sample - loss: 2.9547 - layer3_loss: 1.5365 - layer3_1_loss: 1.4176 - layer3_acc: 0.3138 - layer3_1_acc: 0.3705\n",
      "Epoch 634/1000\n",
      "6329/6329 [==============================] - 1s 87us/sample - loss: 2.9555 - layer3_loss: 1.5373 - layer3_1_loss: 1.4181 - layer3_acc: 0.3133 - layer3_1_acc: 0.3699\n",
      "Epoch 635/1000\n",
      "6329/6329 [==============================] - 1s 79us/sample - loss: 2.9538 - layer3_loss: 1.5348 - layer3_1_loss: 1.4184 - layer3_acc: 0.3181 - layer3_1_acc: 0.3686\n",
      "Epoch 636/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9542 - layer3_loss: 1.5364 - layer3_1_loss: 1.4176 - layer3_acc: 0.3154 - layer3_1_acc: 0.3659\n",
      "Epoch 637/1000\n",
      "6329/6329 [==============================] - 0s 76us/sample - loss: 2.9544 - layer3_loss: 1.5362 - layer3_1_loss: 1.4176 - layer3_acc: 0.3130 - layer3_1_acc: 0.3675\n",
      "Epoch 638/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9525 - layer3_loss: 1.5367 - layer3_1_loss: 1.4164 - layer3_acc: 0.3133 - layer3_1_acc: 0.3637\n",
      "Epoch 639/1000\n",
      "6329/6329 [==============================] - 0s 76us/sample - loss: 2.9551 - layer3_loss: 1.5355 - layer3_1_loss: 1.4191 - layer3_acc: 0.3158 - layer3_1_acc: 0.3674\n",
      "Epoch 640/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9531 - layer3_loss: 1.5351 - layer3_1_loss: 1.4174 - layer3_acc: 0.3154 - layer3_1_acc: 0.3707\n",
      "Epoch 641/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9550 - layer3_loss: 1.5369 - layer3_1_loss: 1.4179 - layer3_acc: 0.3160 - layer3_1_acc: 0.3688\n",
      "Epoch 642/1000\n",
      "6329/6329 [==============================] - 1s 79us/sample - loss: 2.9543 - layer3_loss: 1.5385 - layer3_1_loss: 1.4162 - layer3_acc: 0.3128 - layer3_1_acc: 0.3708\n",
      "Epoch 643/1000\n",
      "6329/6329 [==============================] - 1s 92us/sample - loss: 2.9541 - layer3_loss: 1.5338 - layer3_1_loss: 1.4202 - layer3_acc: 0.3170 - layer3_1_acc: 0.3675\n",
      "Epoch 644/1000\n",
      "6329/6329 [==============================] - 1s 113us/sample - loss: 2.9539 - layer3_loss: 1.5369 - layer3_1_loss: 1.4173 - layer3_acc: 0.3125 - layer3_1_acc: 0.3705\n",
      "Epoch 645/1000\n",
      "6329/6329 [==============================] - 1s 110us/sample - loss: 2.9536 - layer3_loss: 1.5370 - layer3_1_loss: 1.4160 - layer3_acc: 0.3149 - layer3_1_acc: 0.3702\n",
      "Epoch 646/1000\n",
      "6329/6329 [==============================] - 1s 96us/sample - loss: 2.9542 - layer3_loss: 1.5361 - layer3_1_loss: 1.4178 - layer3_acc: 0.3151 - layer3_1_acc: 0.3716\n",
      "Epoch 647/1000\n",
      "6329/6329 [==============================] - 1s 104us/sample - loss: 2.9541 - layer3_loss: 1.5370 - layer3_1_loss: 1.4173 - layer3_acc: 0.3154 - layer3_1_acc: 0.3683\n",
      "Epoch 648/1000\n",
      "6329/6329 [==============================] - 1s 112us/sample - loss: 2.9554 - layer3_loss: 1.5382 - layer3_1_loss: 1.4181 - layer3_acc: 0.3155 - layer3_1_acc: 0.3685\n",
      "Epoch 649/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9547 - layer3_loss: 1.5342 - layer3_1_loss: 1.4196 - layer3_acc: 0.3177 - layer3_1_acc: 0.3656\n",
      "Epoch 650/1000\n",
      "6329/6329 [==============================] - 1s 87us/sample - loss: 2.9547 - layer3_loss: 1.5368 - layer3_1_loss: 1.4176 - layer3_acc: 0.3171 - layer3_1_acc: 0.3678\n",
      "Epoch 651/1000\n",
      "6329/6329 [==============================] - 1s 84us/sample - loss: 2.9552 - layer3_loss: 1.5364 - layer3_1_loss: 1.4187 - layer3_acc: 0.3124 - layer3_1_acc: 0.3683\n",
      "Epoch 652/1000\n",
      "6329/6329 [==============================] - 1s 82us/sample - loss: 2.9549 - layer3_loss: 1.5377 - layer3_1_loss: 1.4167 - layer3_acc: 0.3130 - layer3_1_acc: 0.3664\n",
      "Epoch 653/1000\n",
      "6329/6329 [==============================] - 1s 122us/sample - loss: 2.9553 - layer3_loss: 1.5357 - layer3_1_loss: 1.4194 - layer3_acc: 0.3130 - layer3_1_acc: 0.3688\n",
      "Epoch 654/1000\n",
      "6329/6329 [==============================] - 1s 101us/sample - loss: 2.9533 - layer3_loss: 1.5359 - layer3_1_loss: 1.4170 - layer3_acc: 0.3151 - layer3_1_acc: 0.3647\n",
      "Epoch 655/1000\n",
      "6329/6329 [==============================] - 1s 104us/sample - loss: 2.9542 - layer3_loss: 1.5373 - layer3_1_loss: 1.4168 - layer3_acc: 0.3147 - layer3_1_acc: 0.3669\n",
      "Epoch 656/1000\n",
      "6329/6329 [==============================] - 1s 95us/sample - loss: 2.9539 - layer3_loss: 1.5373 - layer3_1_loss: 1.4178 - layer3_acc: 0.3181 - layer3_1_acc: 0.3686\n",
      "Epoch 657/1000\n",
      "6329/6329 [==============================] - 1s 94us/sample - loss: 2.9534 - layer3_loss: 1.5371 - layer3_1_loss: 1.4157 - layer3_acc: 0.3166 - layer3_1_acc: 0.3726\n",
      "Epoch 658/1000\n",
      "6329/6329 [==============================] - 1s 93us/sample - loss: 2.9536 - layer3_loss: 1.5374 - layer3_1_loss: 1.4156 - layer3_acc: 0.3138 - layer3_1_acc: 0.3696\n",
      "Epoch 659/1000\n",
      "6329/6329 [==============================] - 1s 102us/sample - loss: 2.9528 - layer3_loss: 1.5363 - layer3_1_loss: 1.4160 - layer3_acc: 0.3140 - layer3_1_acc: 0.3691\n",
      "Epoch 660/1000\n",
      "6329/6329 [==============================] - 1s 107us/sample - loss: 2.9544 - layer3_loss: 1.5362 - layer3_1_loss: 1.4183 - layer3_acc: 0.3190 - layer3_1_acc: 0.3704\n",
      "Epoch 661/1000\n",
      "6329/6329 [==============================] - 1s 102us/sample - loss: 2.9536 - layer3_loss: 1.5367 - layer3_1_loss: 1.4166 - layer3_acc: 0.3138 - layer3_1_acc: 0.3629\n",
      "Epoch 662/1000\n",
      "6329/6329 [==============================] - 1s 92us/sample - loss: 2.9533 - layer3_loss: 1.5343 - layer3_1_loss: 1.4193 - layer3_acc: 0.3166 - layer3_1_acc: 0.3658\n",
      "Epoch 663/1000\n",
      "6329/6329 [==============================] - 1s 97us/sample - loss: 2.9545 - layer3_loss: 1.5379 - layer3_1_loss: 1.4165 - layer3_acc: 0.3127 - layer3_1_acc: 0.3669\n",
      "Epoch 664/1000\n",
      "6329/6329 [==============================] - 1s 101us/sample - loss: 2.9531 - layer3_loss: 1.5358 - layer3_1_loss: 1.4172 - layer3_acc: 0.3165 - layer3_1_acc: 0.3656\n",
      "Epoch 665/1000\n",
      "6329/6329 [==============================] - 1s 96us/sample - loss: 2.9537 - layer3_loss: 1.5355 - layer3_1_loss: 1.4173 - layer3_acc: 0.3151 - layer3_1_acc: 0.3696\n",
      "Epoch 666/1000\n",
      "6329/6329 [==============================] - 1s 113us/sample - loss: 2.9531 - layer3_loss: 1.5367 - layer3_1_loss: 1.4171 - layer3_acc: 0.3116 - layer3_1_acc: 0.3681\n",
      "Epoch 667/1000\n",
      "6329/6329 [==============================] - 1s 95us/sample - loss: 2.9536 - layer3_loss: 1.5355 - layer3_1_loss: 1.4176 - layer3_acc: 0.3138 - layer3_1_acc: 0.3694\n",
      "Epoch 668/1000\n",
      "6329/6329 [==============================] - 1s 102us/sample - loss: 2.9523 - layer3_loss: 1.5362 - layer3_1_loss: 1.4168 - layer3_acc: 0.3187 - layer3_1_acc: 0.3685\n",
      "Epoch 669/1000\n",
      "6329/6329 [==============================] - 1s 96us/sample - loss: 2.9537 - layer3_loss: 1.5368 - layer3_1_loss: 1.4174 - layer3_acc: 0.3136 - layer3_1_acc: 0.3683\n",
      "Epoch 670/1000\n",
      "6329/6329 [==============================] - 1s 84us/sample - loss: 2.9533 - layer3_loss: 1.5357 - layer3_1_loss: 1.4169 - layer3_acc: 0.3158 - layer3_1_acc: 0.3686\n",
      "Epoch 671/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9536 - layer3_loss: 1.5350 - layer3_1_loss: 1.4185 - layer3_acc: 0.3138 - layer3_1_acc: 0.3696\n",
      "Epoch 672/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9537 - layer3_loss: 1.5383 - layer3_1_loss: 1.4151 - layer3_acc: 0.3109 - layer3_1_acc: 0.3746\n",
      "Epoch 673/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9537 - layer3_loss: 1.5347 - layer3_1_loss: 1.4186 - layer3_acc: 0.3141 - layer3_1_acc: 0.3645\n",
      "Epoch 674/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9541 - layer3_loss: 1.5362 - layer3_1_loss: 1.4176 - layer3_acc: 0.3162 - layer3_1_acc: 0.3708\n",
      "Epoch 675/1000\n",
      "6329/6329 [==============================] - 1s 86us/sample - loss: 2.9538 - layer3_loss: 1.5361 - layer3_1_loss: 1.4182 - layer3_acc: 0.3140 - layer3_1_acc: 0.3669\n",
      "Epoch 676/1000\n",
      "6329/6329 [==============================] - 1s 79us/sample - loss: 2.9530 - layer3_loss: 1.5352 - layer3_1_loss: 1.4184 - layer3_acc: 0.3162 - layer3_1_acc: 0.3696\n",
      "Epoch 677/1000\n",
      "6329/6329 [==============================] - 1s 79us/sample - loss: 2.9534 - layer3_loss: 1.5363 - layer3_1_loss: 1.4163 - layer3_acc: 0.3160 - layer3_1_acc: 0.3689\n",
      "Epoch 678/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9538 - layer3_loss: 1.5354 - layer3_1_loss: 1.4185 - layer3_acc: 0.3136 - layer3_1_acc: 0.3730\n",
      "Epoch 679/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9540 - layer3_loss: 1.5379 - layer3_1_loss: 1.4162 - layer3_acc: 0.3149 - layer3_1_acc: 0.3691\n",
      "Epoch 680/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9537 - layer3_loss: 1.5360 - layer3_1_loss: 1.4177 - layer3_acc: 0.3149 - layer3_1_acc: 0.3661\n",
      "Epoch 681/1000\n",
      "6329/6329 [==============================] - 0s 76us/sample - loss: 2.9530 - layer3_loss: 1.5337 - layer3_1_loss: 1.4190 - layer3_acc: 0.3166 - layer3_1_acc: 0.3670\n",
      "Epoch 682/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9535 - layer3_loss: 1.5351 - layer3_1_loss: 1.4183 - layer3_acc: 0.3121 - layer3_1_acc: 0.3670\n",
      "Epoch 683/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9528 - layer3_loss: 1.5364 - layer3_1_loss: 1.4170 - layer3_acc: 0.3179 - layer3_1_acc: 0.3642\n",
      "Epoch 684/1000\n",
      "6329/6329 [==============================] - 1s 82us/sample - loss: 2.9539 - layer3_loss: 1.5357 - layer3_1_loss: 1.4188 - layer3_acc: 0.3151 - layer3_1_acc: 0.3699\n",
      "Epoch 685/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9536 - layer3_loss: 1.5365 - layer3_1_loss: 1.4174 - layer3_acc: 0.3147 - layer3_1_acc: 0.3685\n",
      "Epoch 686/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9535 - layer3_loss: 1.5350 - layer3_1_loss: 1.4184 - layer3_acc: 0.3177 - layer3_1_acc: 0.3693\n",
      "Epoch 687/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9526 - layer3_loss: 1.5364 - layer3_1_loss: 1.4159 - layer3_acc: 0.3195 - layer3_1_acc: 0.3650\n",
      "Epoch 688/1000\n",
      "6329/6329 [==============================] - 1s 93us/sample - loss: 2.9536 - layer3_loss: 1.5364 - layer3_1_loss: 1.4168 - layer3_acc: 0.3141 - layer3_1_acc: 0.3737\n",
      "Epoch 689/1000\n",
      "6329/6329 [==============================] - 1s 98us/sample - loss: 2.9541 - layer3_loss: 1.5370 - layer3_1_loss: 1.4190 - layer3_acc: 0.3171 - layer3_1_acc: 0.3686\n",
      "Epoch 690/1000\n",
      "6329/6329 [==============================] - 1s 94us/sample - loss: 2.9508 - layer3_loss: 1.5346 - layer3_1_loss: 1.4174 - layer3_acc: 0.3111 - layer3_1_acc: 0.3677\n",
      "Epoch 691/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9534 - layer3_loss: 1.5356 - layer3_1_loss: 1.4177 - layer3_acc: 0.3160 - layer3_1_acc: 0.3685\n",
      "Epoch 692/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9532 - layer3_loss: 1.5338 - layer3_1_loss: 1.4192 - layer3_acc: 0.3176 - layer3_1_acc: 0.3636\n",
      "Epoch 693/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9532 - layer3_loss: 1.5354 - layer3_1_loss: 1.4171 - layer3_acc: 0.3143 - layer3_1_acc: 0.3667\n",
      "Epoch 694/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9539 - layer3_loss: 1.5363 - layer3_1_loss: 1.4172 - layer3_acc: 0.3146 - layer3_1_acc: 0.3697\n",
      "Epoch 695/1000\n",
      "6329/6329 [==============================] - 0s 79us/sample - loss: 2.9530 - layer3_loss: 1.5327 - layer3_1_loss: 1.4200 - layer3_acc: 0.3179 - layer3_1_acc: 0.3656\n",
      "Epoch 696/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9525 - layer3_loss: 1.5371 - layer3_1_loss: 1.4158 - layer3_acc: 0.3130 - layer3_1_acc: 0.3719\n",
      "Epoch 697/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9547 - layer3_loss: 1.5375 - layer3_1_loss: 1.4167 - layer3_acc: 0.3173 - layer3_1_acc: 0.3707\n",
      "Epoch 698/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9526 - layer3_loss: 1.5355 - layer3_1_loss: 1.4179 - layer3_acc: 0.3152 - layer3_1_acc: 0.3715\n",
      "Epoch 699/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9542 - layer3_loss: 1.5358 - layer3_1_loss: 1.4177 - layer3_acc: 0.3151 - layer3_1_acc: 0.3647\n",
      "Epoch 700/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9546 - layer3_loss: 1.5356 - layer3_1_loss: 1.4193 - layer3_acc: 0.3146 - layer3_1_acc: 0.3636\n",
      "Epoch 701/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9522 - layer3_loss: 1.5349 - layer3_1_loss: 1.4171 - layer3_acc: 0.3119 - layer3_1_acc: 0.3674\n",
      "Epoch 702/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9527 - layer3_loss: 1.5372 - layer3_1_loss: 1.4154 - layer3_acc: 0.3119 - layer3_1_acc: 0.3797\n",
      "Epoch 703/1000\n",
      "6329/6329 [==============================] - 0s 76us/sample - loss: 2.9531 - layer3_loss: 1.5365 - layer3_1_loss: 1.4168 - layer3_acc: 0.3162 - layer3_1_acc: 0.3697\n",
      "Epoch 704/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9521 - layer3_loss: 1.5348 - layer3_1_loss: 1.4171 - layer3_acc: 0.3154 - layer3_1_acc: 0.3696\n",
      "Epoch 705/1000\n",
      "6329/6329 [==============================] - 0s 79us/sample - loss: 2.9522 - layer3_loss: 1.5341 - layer3_1_loss: 1.4182 - layer3_acc: 0.3171 - layer3_1_acc: 0.3683\n",
      "Epoch 706/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9534 - layer3_loss: 1.5347 - layer3_1_loss: 1.4182 - layer3_acc: 0.3163 - layer3_1_acc: 0.3686\n",
      "Epoch 707/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9529 - layer3_loss: 1.5365 - layer3_1_loss: 1.4166 - layer3_acc: 0.3151 - layer3_1_acc: 0.3659\n",
      "Epoch 708/1000\n",
      "6329/6329 [==============================] - 1s 82us/sample - loss: 2.9534 - layer3_loss: 1.5369 - layer3_1_loss: 1.4161 - layer3_acc: 0.3152 - layer3_1_acc: 0.3663\n",
      "Epoch 709/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9522 - layer3_loss: 1.5337 - layer3_1_loss: 1.4185 - layer3_acc: 0.3163 - layer3_1_acc: 0.3670\n",
      "Epoch 710/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9530 - layer3_loss: 1.5359 - layer3_1_loss: 1.4166 - layer3_acc: 0.3132 - layer3_1_acc: 0.3683\n",
      "Epoch 711/1000\n",
      "6329/6329 [==============================] - 0s 79us/sample - loss: 2.9527 - layer3_loss: 1.5365 - layer3_1_loss: 1.4163 - layer3_acc: 0.3151 - layer3_1_acc: 0.3661\n",
      "Epoch 712/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9518 - layer3_loss: 1.5346 - layer3_1_loss: 1.4178 - layer3_acc: 0.3187 - layer3_1_acc: 0.3609\n",
      "Epoch 713/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9516 - layer3_loss: 1.5346 - layer3_1_loss: 1.4165 - layer3_acc: 0.3108 - layer3_1_acc: 0.3732\n",
      "Epoch 714/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9526 - layer3_loss: 1.5358 - layer3_1_loss: 1.4167 - layer3_acc: 0.3144 - layer3_1_acc: 0.3658\n",
      "Epoch 715/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9526 - layer3_loss: 1.5345 - layer3_1_loss: 1.4172 - layer3_acc: 0.3157 - layer3_1_acc: 0.3637\n",
      "Epoch 716/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9530 - layer3_loss: 1.5336 - layer3_1_loss: 1.4192 - layer3_acc: 0.3151 - layer3_1_acc: 0.3685\n",
      "Epoch 717/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9529 - layer3_loss: 1.5351 - layer3_1_loss: 1.4173 - layer3_acc: 0.3149 - layer3_1_acc: 0.3686\n",
      "Epoch 718/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9523 - layer3_loss: 1.5356 - layer3_1_loss: 1.4167 - layer3_acc: 0.3181 - layer3_1_acc: 0.3719\n",
      "Epoch 719/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9525 - layer3_loss: 1.5359 - layer3_1_loss: 1.4159 - layer3_acc: 0.3200 - layer3_1_acc: 0.3680\n",
      "Epoch 720/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9533 - layer3_loss: 1.5372 - layer3_1_loss: 1.4162 - layer3_acc: 0.3124 - layer3_1_acc: 0.3677\n",
      "Epoch 721/1000\n",
      "6329/6329 [==============================] - 1s 92us/sample - loss: 2.9510 - layer3_loss: 1.5349 - layer3_1_loss: 1.4168 - layer3_acc: 0.3170 - layer3_1_acc: 0.3677\n",
      "Epoch 722/1000\n",
      "6329/6329 [==============================] - 1s 84us/sample - loss: 2.9532 - layer3_loss: 1.5339 - layer3_1_loss: 1.4193 - layer3_acc: 0.3105 - layer3_1_acc: 0.3724\n",
      "Epoch 723/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9526 - layer3_loss: 1.5370 - layer3_1_loss: 1.4153 - layer3_acc: 0.3176 - layer3_1_acc: 0.3693\n",
      "Epoch 724/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9532 - layer3_loss: 1.5343 - layer3_1_loss: 1.4190 - layer3_acc: 0.3200 - layer3_1_acc: 0.3678\n",
      "Epoch 725/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9523 - layer3_loss: 1.5359 - layer3_1_loss: 1.4171 - layer3_acc: 0.3173 - layer3_1_acc: 0.3700\n",
      "Epoch 726/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9523 - layer3_loss: 1.5343 - layer3_1_loss: 1.4177 - layer3_acc: 0.3147 - layer3_1_acc: 0.3702\n",
      "Epoch 727/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9521 - layer3_loss: 1.5354 - layer3_1_loss: 1.4171 - layer3_acc: 0.3170 - layer3_1_acc: 0.3647\n",
      "Epoch 728/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9532 - layer3_loss: 1.5354 - layer3_1_loss: 1.4174 - layer3_acc: 0.3166 - layer3_1_acc: 0.3696\n",
      "Epoch 729/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9520 - layer3_loss: 1.5351 - layer3_1_loss: 1.4167 - layer3_acc: 0.3147 - layer3_1_acc: 0.3621\n",
      "Epoch 730/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9525 - layer3_loss: 1.5358 - layer3_1_loss: 1.4167 - layer3_acc: 0.3171 - layer3_1_acc: 0.3677\n",
      "Epoch 731/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9523 - layer3_loss: 1.5352 - layer3_1_loss: 1.4166 - layer3_acc: 0.3190 - layer3_1_acc: 0.3708\n",
      "Epoch 732/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9527 - layer3_loss: 1.5358 - layer3_1_loss: 1.4170 - layer3_acc: 0.3146 - layer3_1_acc: 0.3699\n",
      "Epoch 733/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9526 - layer3_loss: 1.5353 - layer3_1_loss: 1.4167 - layer3_acc: 0.3158 - layer3_1_acc: 0.3658\n",
      "Epoch 734/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9524 - layer3_loss: 1.5332 - layer3_1_loss: 1.4188 - layer3_acc: 0.3168 - layer3_1_acc: 0.3645\n",
      "Epoch 735/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9514 - layer3_loss: 1.5348 - layer3_1_loss: 1.4163 - layer3_acc: 0.3209 - layer3_1_acc: 0.3602\n",
      "Epoch 736/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9524 - layer3_loss: 1.5374 - layer3_1_loss: 1.4166 - layer3_acc: 0.3144 - layer3_1_acc: 0.3705\n",
      "Epoch 737/1000\n",
      "6329/6329 [==============================] - 0s 79us/sample - loss: 2.9523 - layer3_loss: 1.5349 - layer3_1_loss: 1.4171 - layer3_acc: 0.3122 - layer3_1_acc: 0.3710\n",
      "Epoch 738/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9528 - layer3_loss: 1.5372 - layer3_1_loss: 1.4164 - layer3_acc: 0.3151 - layer3_1_acc: 0.3716\n",
      "Epoch 739/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9527 - layer3_loss: 1.5354 - layer3_1_loss: 1.4169 - layer3_acc: 0.3165 - layer3_1_acc: 0.3678\n",
      "Epoch 740/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9528 - layer3_loss: 1.5358 - layer3_1_loss: 1.4167 - layer3_acc: 0.3182 - layer3_1_acc: 0.3686\n",
      "Epoch 741/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9530 - layer3_loss: 1.5344 - layer3_1_loss: 1.4186 - layer3_acc: 0.3146 - layer3_1_acc: 0.3713\n",
      "Epoch 742/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9514 - layer3_loss: 1.5349 - layer3_1_loss: 1.4167 - layer3_acc: 0.3170 - layer3_1_acc: 0.3681\n",
      "Epoch 743/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9531 - layer3_loss: 1.5362 - layer3_1_loss: 1.4171 - layer3_acc: 0.3170 - layer3_1_acc: 0.3711\n",
      "Epoch 744/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9523 - layer3_loss: 1.5357 - layer3_1_loss: 1.4170 - layer3_acc: 0.3147 - layer3_1_acc: 0.3694\n",
      "Epoch 745/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9513 - layer3_loss: 1.5352 - layer3_1_loss: 1.4164 - layer3_acc: 0.3171 - layer3_1_acc: 0.3663\n",
      "Epoch 746/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9527 - layer3_loss: 1.5356 - layer3_1_loss: 1.4167 - layer3_acc: 0.3165 - layer3_1_acc: 0.3691\n",
      "Epoch 747/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9509 - layer3_loss: 1.5334 - layer3_1_loss: 1.4173 - layer3_acc: 0.3144 - layer3_1_acc: 0.3672\n",
      "Epoch 748/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9527 - layer3_loss: 1.5372 - layer3_1_loss: 1.4164 - layer3_acc: 0.3138 - layer3_1_acc: 0.3675\n",
      "Epoch 749/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9527 - layer3_loss: 1.5335 - layer3_1_loss: 1.4186 - layer3_acc: 0.3196 - layer3_1_acc: 0.3659\n",
      "Epoch 750/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9512 - layer3_loss: 1.5349 - layer3_1_loss: 1.4163 - layer3_acc: 0.3147 - layer3_1_acc: 0.3713\n",
      "Epoch 751/1000\n",
      "6329/6329 [==============================] - 0s 62us/sample - loss: 2.9513 - layer3_loss: 1.5343 - layer3_1_loss: 1.4168 - layer3_acc: 0.3128 - layer3_1_acc: 0.3680\n",
      "Epoch 752/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9524 - layer3_loss: 1.5352 - layer3_1_loss: 1.4172 - layer3_acc: 0.3174 - layer3_1_acc: 0.3674\n",
      "Epoch 753/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9521 - layer3_loss: 1.5350 - layer3_1_loss: 1.4164 - layer3_acc: 0.3147 - layer3_1_acc: 0.3705\n",
      "Epoch 754/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9518 - layer3_loss: 1.5340 - layer3_1_loss: 1.4172 - layer3_acc: 0.3143 - layer3_1_acc: 0.3672\n",
      "Epoch 755/1000\n",
      "6329/6329 [==============================] - 0s 63us/sample - loss: 2.9519 - layer3_loss: 1.5350 - layer3_1_loss: 1.4167 - layer3_acc: 0.3151 - layer3_1_acc: 0.3661\n",
      "Epoch 756/1000\n",
      "6329/6329 [==============================] - 0s 79us/sample - loss: 2.9516 - layer3_loss: 1.5350 - layer3_1_loss: 1.4177 - layer3_acc: 0.3149 - layer3_1_acc: 0.3688\n",
      "Epoch 757/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9514 - layer3_loss: 1.5352 - layer3_1_loss: 1.4161 - layer3_acc: 0.3133 - layer3_1_acc: 0.3696\n",
      "Epoch 758/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9518 - layer3_loss: 1.5361 - layer3_1_loss: 1.4167 - layer3_acc: 0.3155 - layer3_1_acc: 0.3737\n",
      "Epoch 759/1000\n",
      "6329/6329 [==============================] - 0s 67us/sample - loss: 2.9511 - layer3_loss: 1.5339 - layer3_1_loss: 1.4170 - layer3_acc: 0.3171 - layer3_1_acc: 0.3693\n",
      "Epoch 760/1000\n",
      "6329/6329 [==============================] - 0s 64us/sample - loss: 2.9523 - layer3_loss: 1.5349 - layer3_1_loss: 1.4171 - layer3_acc: 0.3179 - layer3_1_acc: 0.3655\n",
      "Epoch 761/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9511 - layer3_loss: 1.5353 - layer3_1_loss: 1.4160 - layer3_acc: 0.3128 - layer3_1_acc: 0.3655\n",
      "Epoch 762/1000\n",
      "6329/6329 [==============================] - 1s 79us/sample - loss: 2.9534 - layer3_loss: 1.5376 - layer3_1_loss: 1.4162 - layer3_acc: 0.3111 - layer3_1_acc: 0.3721\n",
      "Epoch 763/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9515 - layer3_loss: 1.5330 - layer3_1_loss: 1.4183 - layer3_acc: 0.3192 - layer3_1_acc: 0.3716\n",
      "Epoch 764/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329/6329 [==============================] - 0s 76us/sample - loss: 2.9535 - layer3_loss: 1.5373 - layer3_1_loss: 1.4160 - layer3_acc: 0.3162 - layer3_1_acc: 0.3678\n",
      "Epoch 765/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9527 - layer3_loss: 1.5359 - layer3_1_loss: 1.4168 - layer3_acc: 0.3173 - layer3_1_acc: 0.3680\n",
      "Epoch 766/1000\n",
      "6329/6329 [==============================] - 1s 79us/sample - loss: 2.9524 - layer3_loss: 1.5358 - layer3_1_loss: 1.4170 - layer3_acc: 0.3157 - layer3_1_acc: 0.3702\n",
      "Epoch 767/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9527 - layer3_loss: 1.5353 - layer3_1_loss: 1.4176 - layer3_acc: 0.3181 - layer3_1_acc: 0.3734\n",
      "Epoch 768/1000\n",
      "6329/6329 [==============================] - 0s 68us/sample - loss: 2.9532 - layer3_loss: 1.5350 - layer3_1_loss: 1.4189 - layer3_acc: 0.3162 - layer3_1_acc: 0.3655\n",
      "Epoch 769/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9529 - layer3_loss: 1.5361 - layer3_1_loss: 1.4161 - layer3_acc: 0.3141 - layer3_1_acc: 0.3710\n",
      "Epoch 770/1000\n",
      "6329/6329 [==============================] - 0s 65us/sample - loss: 2.9520 - layer3_loss: 1.5345 - layer3_1_loss: 1.4169 - layer3_acc: 0.3163 - layer3_1_acc: 0.3686\n",
      "Epoch 771/1000\n",
      "6329/6329 [==============================] - 0s 66us/sample - loss: 2.9508 - layer3_loss: 1.5344 - layer3_1_loss: 1.4166 - layer3_acc: 0.3185 - layer3_1_acc: 0.3670\n",
      "Epoch 772/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9516 - layer3_loss: 1.5347 - layer3_1_loss: 1.4163 - layer3_acc: 0.3195 - layer3_1_acc: 0.3639\n",
      "Epoch 773/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9516 - layer3_loss: 1.5355 - layer3_1_loss: 1.4158 - layer3_acc: 0.3168 - layer3_1_acc: 0.3700\n",
      "Epoch 774/1000\n",
      "6329/6329 [==============================] - 1s 94us/sample - loss: 2.9508 - layer3_loss: 1.5337 - layer3_1_loss: 1.4175 - layer3_acc: 0.3188 - layer3_1_acc: 0.3675\n",
      "Epoch 775/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9524 - layer3_loss: 1.5353 - layer3_1_loss: 1.4172 - layer3_acc: 0.3195 - layer3_1_acc: 0.3656\n",
      "Epoch 776/1000\n",
      "6329/6329 [==============================] - 1s 87us/sample - loss: 2.9524 - layer3_loss: 1.5339 - layer3_1_loss: 1.4181 - layer3_acc: 0.3165 - layer3_1_acc: 0.3666\n",
      "Epoch 777/1000\n",
      "6329/6329 [==============================] - 1s 85us/sample - loss: 2.9512 - layer3_loss: 1.5335 - layer3_1_loss: 1.4175 - layer3_acc: 0.3176 - layer3_1_acc: 0.3710\n",
      "Epoch 778/1000\n",
      "6329/6329 [==============================] - 1s 88us/sample - loss: 2.9509 - layer3_loss: 1.5346 - layer3_1_loss: 1.4161 - layer3_acc: 0.3138 - layer3_1_acc: 0.3678\n",
      "Epoch 779/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9509 - layer3_loss: 1.5342 - layer3_1_loss: 1.4169 - layer3_acc: 0.3141 - layer3_1_acc: 0.3680\n",
      "Epoch 780/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9520 - layer3_loss: 1.5339 - layer3_1_loss: 1.4177 - layer3_acc: 0.3171 - layer3_1_acc: 0.3699\n",
      "Epoch 781/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9515 - layer3_loss: 1.5356 - layer3_1_loss: 1.4151 - layer3_acc: 0.3190 - layer3_1_acc: 0.3705\n",
      "Epoch 782/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9508 - layer3_loss: 1.5351 - layer3_1_loss: 1.4171 - layer3_acc: 0.3154 - layer3_1_acc: 0.3655\n",
      "Epoch 783/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9514 - layer3_loss: 1.5353 - layer3_1_loss: 1.4165 - layer3_acc: 0.3193 - layer3_1_acc: 0.3651\n",
      "Epoch 784/1000\n",
      "6329/6329 [==============================] - 0s 76us/sample - loss: 2.9526 - layer3_loss: 1.5355 - layer3_1_loss: 1.4177 - layer3_acc: 0.3138 - layer3_1_acc: 0.3696\n",
      "Epoch 785/1000\n",
      "6329/6329 [==============================] - 0s 76us/sample - loss: 2.9521 - layer3_loss: 1.5350 - layer3_1_loss: 1.4184 - layer3_acc: 0.3168 - layer3_1_acc: 0.3723\n",
      "Epoch 786/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9519 - layer3_loss: 1.5343 - layer3_1_loss: 1.4171 - layer3_acc: 0.3154 - layer3_1_acc: 0.3674\n",
      "Epoch 787/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9525 - layer3_loss: 1.5350 - layer3_1_loss: 1.4174 - layer3_acc: 0.3149 - layer3_1_acc: 0.3710\n",
      "Epoch 788/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9517 - layer3_loss: 1.5345 - layer3_1_loss: 1.4178 - layer3_acc: 0.3138 - layer3_1_acc: 0.3745\n",
      "Epoch 789/1000\n",
      "6329/6329 [==============================] - 1s 85us/sample - loss: 2.9512 - layer3_loss: 1.5350 - layer3_1_loss: 1.4165 - layer3_acc: 0.3160 - layer3_1_acc: 0.3656\n",
      "Epoch 790/1000\n",
      "6329/6329 [==============================] - 1s 87us/sample - loss: 2.9506 - layer3_loss: 1.5347 - layer3_1_loss: 1.4163 - layer3_acc: 0.3157 - layer3_1_acc: 0.3697\n",
      "Epoch 791/1000\n",
      "6329/6329 [==============================] - 1s 85us/sample - loss: 2.9509 - layer3_loss: 1.5339 - layer3_1_loss: 1.4175 - layer3_acc: 0.3177 - layer3_1_acc: 0.3674\n",
      "Epoch 792/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9520 - layer3_loss: 1.5365 - layer3_1_loss: 1.4170 - layer3_acc: 0.3173 - layer3_1_acc: 0.3636\n",
      "Epoch 793/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9530 - layer3_loss: 1.5348 - layer3_1_loss: 1.4173 - layer3_acc: 0.3168 - layer3_1_acc: 0.3674\n",
      "Epoch 794/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9514 - layer3_loss: 1.5344 - layer3_1_loss: 1.4166 - layer3_acc: 0.3174 - layer3_1_acc: 0.3707\n",
      "Epoch 795/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9518 - layer3_loss: 1.5347 - layer3_1_loss: 1.4170 - layer3_acc: 0.3146 - layer3_1_acc: 0.3644\n",
      "Epoch 796/1000\n",
      "6329/6329 [==============================] - 0s 69us/sample - loss: 2.9516 - layer3_loss: 1.5340 - layer3_1_loss: 1.4167 - layer3_acc: 0.3133 - layer3_1_acc: 0.3707\n",
      "Epoch 797/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9508 - layer3_loss: 1.5342 - layer3_1_loss: 1.4161 - layer3_acc: 0.3207 - layer3_1_acc: 0.3666\n",
      "Epoch 798/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9522 - layer3_loss: 1.5328 - layer3_1_loss: 1.4194 - layer3_acc: 0.3151 - layer3_1_acc: 0.3683\n",
      "Epoch 799/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9516 - layer3_loss: 1.5350 - layer3_1_loss: 1.4159 - layer3_acc: 0.3138 - layer3_1_acc: 0.3689\n",
      "Epoch 800/1000\n",
      "6329/6329 [==============================] - 1s 85us/sample - loss: 2.9513 - layer3_loss: 1.5353 - layer3_1_loss: 1.4154 - layer3_acc: 0.3151 - layer3_1_acc: 0.3680\n",
      "Epoch 801/1000\n",
      "6329/6329 [==============================] - 0s 73us/sample - loss: 2.9514 - layer3_loss: 1.5348 - layer3_1_loss: 1.4173 - layer3_acc: 0.3124 - layer3_1_acc: 0.3735\n",
      "Epoch 802/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9512 - layer3_loss: 1.5358 - layer3_1_loss: 1.4157 - layer3_acc: 0.3158 - layer3_1_acc: 0.3678\n",
      "Epoch 803/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9525 - layer3_loss: 1.5348 - layer3_1_loss: 1.4173 - layer3_acc: 0.3160 - layer3_1_acc: 0.3686\n",
      "Epoch 804/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9502 - layer3_loss: 1.5332 - layer3_1_loss: 1.4163 - layer3_acc: 0.3185 - layer3_1_acc: 0.3675\n",
      "Epoch 805/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9510 - layer3_loss: 1.5336 - layer3_1_loss: 1.4169 - layer3_acc: 0.3165 - layer3_1_acc: 0.3677\n",
      "Epoch 806/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9518 - layer3_loss: 1.5348 - layer3_1_loss: 1.4174 - layer3_acc: 0.3209 - layer3_1_acc: 0.3672\n",
      "Epoch 807/1000\n",
      "6329/6329 [==============================] - 0s 73us/sample - loss: 2.9506 - layer3_loss: 1.5347 - layer3_1_loss: 1.4156 - layer3_acc: 0.3179 - layer3_1_acc: 0.3735\n",
      "Epoch 808/1000\n",
      "6329/6329 [==============================] - 0s 72us/sample - loss: 2.9507 - layer3_loss: 1.5339 - layer3_1_loss: 1.4169 - layer3_acc: 0.3173 - layer3_1_acc: 0.3729\n",
      "Epoch 809/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329/6329 [==============================] - 1s 88us/sample - loss: 2.9512 - layer3_loss: 1.5343 - layer3_1_loss: 1.4170 - layer3_acc: 0.3166 - layer3_1_acc: 0.3721\n",
      "Epoch 810/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9509 - layer3_loss: 1.5345 - layer3_1_loss: 1.4169 - layer3_acc: 0.3203 - layer3_1_acc: 0.3634\n",
      "Epoch 811/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9512 - layer3_loss: 1.5340 - layer3_1_loss: 1.4177 - layer3_acc: 0.3114 - layer3_1_acc: 0.3713\n",
      "Epoch 812/1000\n",
      "6329/6329 [==============================] - 1s 85us/sample - loss: 2.9505 - layer3_loss: 1.5343 - layer3_1_loss: 1.4163 - layer3_acc: 0.3170 - layer3_1_acc: 0.3688\n",
      "Epoch 813/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9510 - layer3_loss: 1.5350 - layer3_1_loss: 1.4161 - layer3_acc: 0.3187 - layer3_1_acc: 0.3710\n",
      "Epoch 814/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9515 - layer3_loss: 1.5339 - layer3_1_loss: 1.4175 - layer3_acc: 0.3187 - layer3_1_acc: 0.3700\n",
      "Epoch 815/1000\n",
      "6329/6329 [==============================] - 1s 89us/sample - loss: 2.9517 - layer3_loss: 1.5355 - layer3_1_loss: 1.4161 - layer3_acc: 0.3171 - layer3_1_acc: 0.3685\n",
      "Epoch 816/1000\n",
      "6329/6329 [==============================] - 1s 88us/sample - loss: 2.9509 - layer3_loss: 1.5340 - layer3_1_loss: 1.4166 - layer3_acc: 0.3176 - layer3_1_acc: 0.3672\n",
      "Epoch 817/1000\n",
      "6329/6329 [==============================] - 1s 92us/sample - loss: 2.9517 - layer3_loss: 1.5352 - layer3_1_loss: 1.4167 - layer3_acc: 0.3162 - layer3_1_acc: 0.3651\n",
      "Epoch 818/1000\n",
      "6329/6329 [==============================] - 1s 93us/sample - loss: 2.9516 - layer3_loss: 1.5341 - layer3_1_loss: 1.4169 - layer3_acc: 0.3168 - layer3_1_acc: 0.3667\n",
      "Epoch 819/1000\n",
      "6329/6329 [==============================] - 1s 92us/sample - loss: 2.9510 - layer3_loss: 1.5356 - layer3_1_loss: 1.4161 - layer3_acc: 0.3211 - layer3_1_acc: 0.36850s - loss: 2.9558 - layer3_loss: 1.5262 - layer3_1_loss: 1.4296 - layer3_acc: 0.3256 - layer3_1_ac\n",
      "Epoch 820/1000\n",
      "6329/6329 [==============================] - 1s 100us/sample - loss: 2.9509 - layer3_loss: 1.5329 - layer3_1_loss: 1.4179 - layer3_acc: 0.3182 - layer3_1_acc: 0.3672\n",
      "Epoch 821/1000\n",
      "6329/6329 [==============================] - 1s 115us/sample - loss: 2.9523 - layer3_loss: 1.5353 - layer3_1_loss: 1.4165 - layer3_acc: 0.3170 - layer3_1_acc: 0.3678\n",
      "Epoch 822/1000\n",
      "6329/6329 [==============================] - 1s 112us/sample - loss: 2.9509 - layer3_loss: 1.5340 - layer3_1_loss: 1.4166 - layer3_acc: 0.3151 - layer3_1_acc: 0.3645\n",
      "Epoch 823/1000\n",
      "6329/6329 [==============================] - 1s 97us/sample - loss: 2.9520 - layer3_loss: 1.5347 - layer3_1_loss: 1.4169 - layer3_acc: 0.3140 - layer3_1_acc: 0.3667\n",
      "Epoch 824/1000\n",
      "6329/6329 [==============================] - 1s 100us/sample - loss: 2.9518 - layer3_loss: 1.5354 - layer3_1_loss: 1.4162 - layer3_acc: 0.3157 - layer3_1_acc: 0.3704\n",
      "Epoch 825/1000\n",
      "6329/6329 [==============================] - 1s 86us/sample - loss: 2.9514 - layer3_loss: 1.5337 - layer3_1_loss: 1.4173 - layer3_acc: 0.3152 - layer3_1_acc: 0.36970s - loss: 2.9606 - layer3_loss: 1.5468 - layer3_1_loss: 1.4138 - layer3_acc: 0.3188 - layer3_1_acc\n",
      "Epoch 826/1000\n",
      "6329/6329 [==============================] - 1s 84us/sample - loss: 2.9513 - layer3_loss: 1.5334 - layer3_1_loss: 1.4181 - layer3_acc: 0.3179 - layer3_1_acc: 0.3699\n",
      "Epoch 827/1000\n",
      "6329/6329 [==============================] - 1s 100us/sample - loss: 2.9505 - layer3_loss: 1.5343 - layer3_1_loss: 1.4159 - layer3_acc: 0.3176 - layer3_1_acc: 0.3726\n",
      "Epoch 828/1000\n",
      "6329/6329 [==============================] - 1s 85us/sample - loss: 2.9509 - layer3_loss: 1.5345 - layer3_1_loss: 1.4167 - layer3_acc: 0.3203 - layer3_1_acc: 0.3711\n",
      "Epoch 829/1000\n",
      "6329/6329 [==============================] - 1s 83us/sample - loss: 2.9513 - layer3_loss: 1.5351 - layer3_1_loss: 1.4166 - layer3_acc: 0.3192 - layer3_1_acc: 0.3661\n",
      "Epoch 830/1000\n",
      "6329/6329 [==============================] - 1s 84us/sample - loss: 2.9518 - layer3_loss: 1.5344 - layer3_1_loss: 1.4170 - layer3_acc: 0.3154 - layer3_1_acc: 0.3708\n",
      "Epoch 831/1000\n",
      "6329/6329 [==============================] - 1s 90us/sample - loss: 2.9504 - layer3_loss: 1.5326 - layer3_1_loss: 1.4176 - layer3_acc: 0.3200 - layer3_1_acc: 0.3693\n",
      "Epoch 832/1000\n",
      "6329/6329 [==============================] - 1s 88us/sample - loss: 2.9522 - layer3_loss: 1.5352 - layer3_1_loss: 1.4169 - layer3_acc: 0.3147 - layer3_1_acc: 0.3675\n",
      "Epoch 833/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9508 - layer3_loss: 1.5337 - layer3_1_loss: 1.4176 - layer3_acc: 0.3162 - layer3_1_acc: 0.3670\n",
      "Epoch 834/1000\n",
      "6329/6329 [==============================] - 1s 85us/sample - loss: 2.9494 - layer3_loss: 1.5335 - layer3_1_loss: 1.4156 - layer3_acc: 0.3165 - layer3_1_acc: 0.3674\n",
      "Epoch 835/1000\n",
      "6329/6329 [==============================] - 1s 87us/sample - loss: 2.9501 - layer3_loss: 1.5328 - layer3_1_loss: 1.4178 - layer3_acc: 0.3165 - layer3_1_acc: 0.3683\n",
      "Epoch 836/1000\n",
      "6329/6329 [==============================] - 1s 87us/sample - loss: 2.9507 - layer3_loss: 1.5354 - layer3_1_loss: 1.4162 - layer3_acc: 0.3222 - layer3_1_acc: 0.3719\n",
      "Epoch 837/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9519 - layer3_loss: 1.5341 - layer3_1_loss: 1.4179 - layer3_acc: 0.3179 - layer3_1_acc: 0.3669\n",
      "Epoch 838/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9506 - layer3_loss: 1.5348 - layer3_1_loss: 1.4157 - layer3_acc: 0.3215 - layer3_1_acc: 0.3675\n",
      "Epoch 839/1000\n",
      "6329/6329 [==============================] - 1s 82us/sample - loss: 2.9515 - layer3_loss: 1.5338 - layer3_1_loss: 1.4173 - layer3_acc: 0.3162 - layer3_1_acc: 0.3659\n",
      "Epoch 840/1000\n",
      "6329/6329 [==============================] - 1s 92us/sample - loss: 2.9505 - layer3_loss: 1.5342 - layer3_1_loss: 1.4159 - layer3_acc: 0.3143 - layer3_1_acc: 0.3718\n",
      "Epoch 841/1000\n",
      "6329/6329 [==============================] - 1s 90us/sample - loss: 2.9510 - layer3_loss: 1.5335 - layer3_1_loss: 1.4171 - layer3_acc: 0.3155 - layer3_1_acc: 0.3681\n",
      "Epoch 842/1000\n",
      "6329/6329 [==============================] - 1s 95us/sample - loss: 2.9502 - layer3_loss: 1.5343 - layer3_1_loss: 1.4160 - layer3_acc: 0.3171 - layer3_1_acc: 0.3677\n",
      "Epoch 843/1000\n",
      "6329/6329 [==============================] - 1s 90us/sample - loss: 2.9509 - layer3_loss: 1.5343 - layer3_1_loss: 1.4169 - layer3_acc: 0.3160 - layer3_1_acc: 0.3670\n",
      "Epoch 844/1000\n",
      "6329/6329 [==============================] - 1s 94us/sample - loss: 2.9514 - layer3_loss: 1.5343 - layer3_1_loss: 1.4175 - layer3_acc: 0.3204 - layer3_1_acc: 0.3666\n",
      "Epoch 845/1000\n",
      "6329/6329 [==============================] - 1s 87us/sample - loss: 2.9501 - layer3_loss: 1.5348 - layer3_1_loss: 1.4158 - layer3_acc: 0.3190 - layer3_1_acc: 0.3674\n",
      "Epoch 846/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9504 - layer3_loss: 1.5338 - layer3_1_loss: 1.4172 - layer3_acc: 0.3198 - layer3_1_acc: 0.3677\n",
      "Epoch 847/1000\n",
      "6329/6329 [==============================] - 1s 92us/sample - loss: 2.9504 - layer3_loss: 1.5336 - layer3_1_loss: 1.4173 - layer3_acc: 0.3196 - layer3_1_acc: 0.3691\n",
      "Epoch 848/1000\n",
      "6329/6329 [==============================] - 1s 104us/sample - loss: 2.9502 - layer3_loss: 1.5334 - layer3_1_loss: 1.4160 - layer3_acc: 0.3222 - layer3_1_acc: 0.3664\n",
      "Epoch 849/1000\n",
      "6329/6329 [==============================] - 1s 110us/sample - loss: 2.9514 - layer3_loss: 1.5347 - layer3_1_loss: 1.4168 - layer3_acc: 0.3190 - layer3_1_acc: 0.3653\n",
      "Epoch 850/1000\n",
      "6329/6329 [==============================] - 1s 100us/sample - loss: 2.9510 - layer3_loss: 1.5363 - layer3_1_loss: 1.4151 - layer3_acc: 0.3146 - layer3_1_acc: 0.3765\n",
      "Epoch 851/1000\n",
      "6329/6329 [==============================] - 1s 93us/sample - loss: 2.9507 - layer3_loss: 1.5337 - layer3_1_loss: 1.4173 - layer3_acc: 0.3209 - layer3_1_acc: 0.3680\n",
      "Epoch 852/1000\n",
      "6329/6329 [==============================] - 1s 88us/sample - loss: 2.9512 - layer3_loss: 1.5341 - layer3_1_loss: 1.4169 - layer3_acc: 0.3212 - layer3_1_acc: 0.3672\n",
      "Epoch 853/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329/6329 [==============================] - 1s 88us/sample - loss: 2.9514 - layer3_loss: 1.5350 - layer3_1_loss: 1.4164 - layer3_acc: 0.3132 - layer3_1_acc: 0.3702\n",
      "Epoch 854/1000\n",
      "6329/6329 [==============================] - 1s 89us/sample - loss: 2.9502 - layer3_loss: 1.5350 - layer3_1_loss: 1.4148 - layer3_acc: 0.3177 - layer3_1_acc: 0.3677\n",
      "Epoch 855/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9502 - layer3_loss: 1.5338 - layer3_1_loss: 1.4167 - layer3_acc: 0.3143 - layer3_1_acc: 0.3677\n",
      "Epoch 856/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9507 - layer3_loss: 1.5356 - layer3_1_loss: 1.4146 - layer3_acc: 0.3181 - layer3_1_acc: 0.3686\n",
      "Epoch 857/1000\n",
      "6329/6329 [==============================] - 1s 79us/sample - loss: 2.9497 - layer3_loss: 1.5334 - layer3_1_loss: 1.4170 - layer3_acc: 0.3207 - layer3_1_acc: 0.3693\n",
      "Epoch 858/1000\n",
      "6329/6329 [==============================] - 1s 84us/sample - loss: 2.9492 - layer3_loss: 1.5331 - layer3_1_loss: 1.4156 - layer3_acc: 0.3203 - layer3_1_acc: 0.3704\n",
      "Epoch 859/1000\n",
      "6329/6329 [==============================] - 1s 86us/sample - loss: 2.9498 - layer3_loss: 1.5347 - layer3_1_loss: 1.4157 - layer3_acc: 0.3171 - layer3_1_acc: 0.3697\n",
      "Epoch 860/1000\n",
      "6329/6329 [==============================] - 1s 87us/sample - loss: 2.9512 - layer3_loss: 1.5340 - layer3_1_loss: 1.4163 - layer3_acc: 0.3149 - layer3_1_acc: 0.3724\n",
      "Epoch 861/1000\n",
      "6329/6329 [==============================] - 1s 79us/sample - loss: 2.9507 - layer3_loss: 1.5336 - layer3_1_loss: 1.4166 - layer3_acc: 0.3168 - layer3_1_acc: 0.3659\n",
      "Epoch 862/1000\n",
      "6329/6329 [==============================] - 1s 83us/sample - loss: 2.9505 - layer3_loss: 1.5335 - layer3_1_loss: 1.4176 - layer3_acc: 0.3209 - layer3_1_acc: 0.3680\n",
      "Epoch 863/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9495 - layer3_loss: 1.5328 - layer3_1_loss: 1.4169 - layer3_acc: 0.3193 - layer3_1_acc: 0.3686\n",
      "Epoch 864/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9520 - layer3_loss: 1.5361 - layer3_1_loss: 1.4164 - layer3_acc: 0.3193 - layer3_1_acc: 0.3700\n",
      "Epoch 865/1000\n",
      "6329/6329 [==============================] - 1s 79us/sample - loss: 2.9502 - layer3_loss: 1.5337 - layer3_1_loss: 1.4166 - layer3_acc: 0.3188 - layer3_1_acc: 0.3658\n",
      "Epoch 866/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9510 - layer3_loss: 1.5334 - layer3_1_loss: 1.4174 - layer3_acc: 0.3181 - layer3_1_acc: 0.3674\n",
      "Epoch 867/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9500 - layer3_loss: 1.5344 - layer3_1_loss: 1.4160 - layer3_acc: 0.3173 - layer3_1_acc: 0.3702\n",
      "Epoch 868/1000\n",
      "6329/6329 [==============================] - 1s 83us/sample - loss: 2.9511 - layer3_loss: 1.5339 - layer3_1_loss: 1.4170 - layer3_acc: 0.3184 - layer3_1_acc: 0.3669\n",
      "Epoch 869/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9504 - layer3_loss: 1.5354 - layer3_1_loss: 1.4153 - layer3_acc: 0.3154 - layer3_1_acc: 0.3716\n",
      "Epoch 870/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9515 - layer3_loss: 1.5341 - layer3_1_loss: 1.4177 - layer3_acc: 0.3165 - layer3_1_acc: 0.3651\n",
      "Epoch 871/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9510 - layer3_loss: 1.5344 - layer3_1_loss: 1.4161 - layer3_acc: 0.3116 - layer3_1_acc: 0.3681\n",
      "Epoch 872/1000\n",
      "6329/6329 [==============================] - 1s 84us/sample - loss: 2.9495 - layer3_loss: 1.5345 - layer3_1_loss: 1.4151 - layer3_acc: 0.3182 - layer3_1_acc: 0.3705\n",
      "Epoch 873/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9498 - layer3_loss: 1.5318 - layer3_1_loss: 1.4174 - layer3_acc: 0.3204 - layer3_1_acc: 0.3691\n",
      "Epoch 874/1000\n",
      "6329/6329 [==============================] - 1s 82us/sample - loss: 2.9496 - layer3_loss: 1.5336 - layer3_1_loss: 1.4168 - layer3_acc: 0.3173 - layer3_1_acc: 0.3743\n",
      "Epoch 875/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9500 - layer3_loss: 1.5337 - layer3_1_loss: 1.4168 - layer3_acc: 0.3193 - layer3_1_acc: 0.3667\n",
      "Epoch 876/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9492 - layer3_loss: 1.5324 - layer3_1_loss: 1.4157 - layer3_acc: 0.3196 - layer3_1_acc: 0.3688\n",
      "Epoch 877/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9500 - layer3_loss: 1.5326 - layer3_1_loss: 1.4170 - layer3_acc: 0.3211 - layer3_1_acc: 0.3640\n",
      "Epoch 878/1000\n",
      "6329/6329 [==============================] - 1s 103us/sample - loss: 2.9503 - layer3_loss: 1.5326 - layer3_1_loss: 1.4169 - layer3_acc: 0.3170 - layer3_1_acc: 0.3691\n",
      "Epoch 879/1000\n",
      "6329/6329 [==============================] - 1s 103us/sample - loss: 2.9484 - layer3_loss: 1.5329 - layer3_1_loss: 1.4149 - layer3_acc: 0.3154 - layer3_1_acc: 0.3683\n",
      "Epoch 880/1000\n",
      "6329/6329 [==============================] - 1s 87us/sample - loss: 2.9503 - layer3_loss: 1.5343 - layer3_1_loss: 1.4160 - layer3_acc: 0.3195 - layer3_1_acc: 0.3632\n",
      "Epoch 881/1000\n",
      "6329/6329 [==============================] - 1s 84us/sample - loss: 2.9488 - layer3_loss: 1.5345 - layer3_1_loss: 1.4147 - layer3_acc: 0.3135 - layer3_1_acc: 0.3686\n",
      "Epoch 882/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9509 - layer3_loss: 1.5334 - layer3_1_loss: 1.4175 - layer3_acc: 0.3198 - layer3_1_acc: 0.3625\n",
      "Epoch 883/1000\n",
      "6329/6329 [==============================] - 1s 83us/sample - loss: 2.9495 - layer3_loss: 1.5347 - layer3_1_loss: 1.4148 - layer3_acc: 0.3182 - layer3_1_acc: 0.3713\n",
      "Epoch 884/1000\n",
      "6329/6329 [==============================] - 1s 79us/sample - loss: 2.9505 - layer3_loss: 1.5346 - layer3_1_loss: 1.4159 - layer3_acc: 0.3185 - layer3_1_acc: 0.3669\n",
      "Epoch 885/1000\n",
      "6329/6329 [==============================] - 1s 83us/sample - loss: 2.9510 - layer3_loss: 1.5350 - layer3_1_loss: 1.4155 - layer3_acc: 0.3133 - layer3_1_acc: 0.3675\n",
      "Epoch 886/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9502 - layer3_loss: 1.5331 - layer3_1_loss: 1.4170 - layer3_acc: 0.3163 - layer3_1_acc: 0.3693\n",
      "Epoch 887/1000\n",
      "6329/6329 [==============================] - 1s 83us/sample - loss: 2.9500 - layer3_loss: 1.5341 - layer3_1_loss: 1.4159 - layer3_acc: 0.3166 - layer3_1_acc: 0.3636\n",
      "Epoch 888/1000\n",
      "6329/6329 [==============================] - 1s 82us/sample - loss: 2.9503 - layer3_loss: 1.5337 - layer3_1_loss: 1.4165 - layer3_acc: 0.3200 - layer3_1_acc: 0.3655\n",
      "Epoch 889/1000\n",
      "6329/6329 [==============================] - 1s 86us/sample - loss: 2.9505 - layer3_loss: 1.5330 - layer3_1_loss: 1.4176 - layer3_acc: 0.3214 - layer3_1_acc: 0.3655\n",
      "Epoch 890/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9491 - layer3_loss: 1.5334 - layer3_1_loss: 1.4158 - layer3_acc: 0.3163 - layer3_1_acc: 0.3663\n",
      "Epoch 891/1000\n",
      "6329/6329 [==============================] - 1s 83us/sample - loss: 2.9491 - layer3_loss: 1.5330 - layer3_1_loss: 1.4164 - layer3_acc: 0.3174 - layer3_1_acc: 0.3719\n",
      "Epoch 892/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9501 - layer3_loss: 1.5357 - layer3_1_loss: 1.4149 - layer3_acc: 0.3147 - layer3_1_acc: 0.3691\n",
      "Epoch 893/1000\n",
      "6329/6329 [==============================] - 1s 82us/sample - loss: 2.9505 - layer3_loss: 1.5341 - layer3_1_loss: 1.4162 - layer3_acc: 0.3181 - layer3_1_acc: 0.3704\n",
      "Epoch 894/1000\n",
      "6329/6329 [==============================] - 1s 79us/sample - loss: 2.9503 - layer3_loss: 1.5355 - layer3_1_loss: 1.4151 - layer3_acc: 0.3237 - layer3_1_acc: 0.3628\n",
      "Epoch 895/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9506 - layer3_loss: 1.5331 - layer3_1_loss: 1.4166 - layer3_acc: 0.3177 - layer3_1_acc: 0.3694\n",
      "Epoch 896/1000\n",
      "6329/6329 [==============================] - 1s 79us/sample - loss: 2.9501 - layer3_loss: 1.5331 - layer3_1_loss: 1.4173 - layer3_acc: 0.3177 - layer3_1_acc: 0.3647\n",
      "Epoch 897/1000\n",
      "6329/6329 [==============================] - 1s 85us/sample - loss: 2.9497 - layer3_loss: 1.5334 - layer3_1_loss: 1.4159 - layer3_acc: 0.3182 - layer3_1_acc: 0.3699\n",
      "Epoch 898/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9500 - layer3_loss: 1.5346 - layer3_1_loss: 1.4163 - layer3_acc: 0.3168 - layer3_1_acc: 0.3672\n",
      "Epoch 899/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9495 - layer3_loss: 1.5326 - layer3_1_loss: 1.4175 - layer3_acc: 0.3185 - layer3_1_acc: 0.3664\n",
      "Epoch 900/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9518 - layer3_loss: 1.5341 - layer3_1_loss: 1.4170 - layer3_acc: 0.3185 - layer3_1_acc: 0.3675\n",
      "Epoch 901/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9497 - layer3_loss: 1.5334 - layer3_1_loss: 1.4163 - layer3_acc: 0.3200 - layer3_1_acc: 0.3664\n",
      "Epoch 902/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9494 - layer3_loss: 1.5332 - layer3_1_loss: 1.4157 - layer3_acc: 0.3214 - layer3_1_acc: 0.3681\n",
      "Epoch 903/1000\n",
      "6329/6329 [==============================] - 0s 79us/sample - loss: 2.9499 - layer3_loss: 1.5350 - layer3_1_loss: 1.4150 - layer3_acc: 0.3109 - layer3_1_acc: 0.3719\n",
      "Epoch 904/1000\n",
      "6329/6329 [==============================] - 0s 76us/sample - loss: 2.9506 - layer3_loss: 1.5334 - layer3_1_loss: 1.4177 - layer3_acc: 0.3226 - layer3_1_acc: 0.3688\n",
      "Epoch 905/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9500 - layer3_loss: 1.5355 - layer3_1_loss: 1.4144 - layer3_acc: 0.3198 - layer3_1_acc: 0.3663\n",
      "Epoch 906/1000\n",
      "6329/6329 [==============================] - 0s 76us/sample - loss: 2.9499 - layer3_loss: 1.5320 - layer3_1_loss: 1.4180 - layer3_acc: 0.3185 - layer3_1_acc: 0.3647\n",
      "Epoch 907/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9495 - layer3_loss: 1.5361 - layer3_1_loss: 1.4142 - layer3_acc: 0.3198 - layer3_1_acc: 0.3666\n",
      "Epoch 908/1000\n",
      "6329/6329 [==============================] - 1s 89us/sample - loss: 2.9495 - layer3_loss: 1.5334 - layer3_1_loss: 1.4159 - layer3_acc: 0.3203 - layer3_1_acc: 0.3675\n",
      "Epoch 909/1000\n",
      "6329/6329 [==============================] - 1s 96us/sample - loss: 2.9493 - layer3_loss: 1.5334 - layer3_1_loss: 1.4152 - layer3_acc: 0.3165 - layer3_1_acc: 0.3669\n",
      "Epoch 910/1000\n",
      "6329/6329 [==============================] - 1s 89us/sample - loss: 2.9490 - layer3_loss: 1.5336 - layer3_1_loss: 1.4157 - layer3_acc: 0.3184 - layer3_1_acc: 0.3659\n",
      "Epoch 911/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9513 - layer3_loss: 1.5349 - layer3_1_loss: 1.4165 - layer3_acc: 0.3200 - layer3_1_acc: 0.3708\n",
      "Epoch 912/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9499 - layer3_loss: 1.5334 - layer3_1_loss: 1.4157 - layer3_acc: 0.3163 - layer3_1_acc: 0.3683\n",
      "Epoch 913/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9489 - layer3_loss: 1.5312 - layer3_1_loss: 1.4177 - layer3_acc: 0.3242 - layer3_1_acc: 0.3650\n",
      "Epoch 914/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9492 - layer3_loss: 1.5342 - layer3_1_loss: 1.4145 - layer3_acc: 0.3200 - layer3_1_acc: 0.3694\n",
      "Epoch 915/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9497 - layer3_loss: 1.5340 - layer3_1_loss: 1.4149 - layer3_acc: 0.3190 - layer3_1_acc: 0.3642\n",
      "Epoch 916/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9506 - layer3_loss: 1.5348 - layer3_1_loss: 1.4157 - layer3_acc: 0.3166 - layer3_1_acc: 0.3683\n",
      "Epoch 917/1000\n",
      "6329/6329 [==============================] - 0s 76us/sample - loss: 2.9494 - layer3_loss: 1.5339 - layer3_1_loss: 1.4157 - layer3_acc: 0.3152 - layer3_1_acc: 0.3685\n",
      "Epoch 918/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9494 - layer3_loss: 1.5320 - layer3_1_loss: 1.4175 - layer3_acc: 0.3165 - layer3_1_acc: 0.3650\n",
      "Epoch 919/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9505 - layer3_loss: 1.5330 - layer3_1_loss: 1.4173 - layer3_acc: 0.3174 - layer3_1_acc: 0.3636\n",
      "Epoch 920/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9494 - layer3_loss: 1.5335 - layer3_1_loss: 1.4168 - layer3_acc: 0.3222 - layer3_1_acc: 0.3689\n",
      "Epoch 921/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9499 - layer3_loss: 1.5334 - layer3_1_loss: 1.4161 - layer3_acc: 0.3188 - layer3_1_acc: 0.3680\n",
      "Epoch 922/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9485 - layer3_loss: 1.5330 - layer3_1_loss: 1.4158 - layer3_acc: 0.3215 - layer3_1_acc: 0.3670\n",
      "Epoch 923/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9488 - layer3_loss: 1.5337 - layer3_1_loss: 1.4151 - layer3_acc: 0.3155 - layer3_1_acc: 0.3710\n",
      "Epoch 924/1000\n",
      "6329/6329 [==============================] - 0s 79us/sample - loss: 2.9495 - layer3_loss: 1.5334 - layer3_1_loss: 1.4157 - layer3_acc: 0.3157 - layer3_1_acc: 0.3705\n",
      "Epoch 925/1000\n",
      "6329/6329 [==============================] - 0s 76us/sample - loss: 2.9494 - layer3_loss: 1.5339 - layer3_1_loss: 1.4163 - layer3_acc: 0.3171 - layer3_1_acc: 0.3680\n",
      "Epoch 926/1000\n",
      "6329/6329 [==============================] - 1s 79us/sample - loss: 2.9496 - layer3_loss: 1.5338 - layer3_1_loss: 1.4153 - layer3_acc: 0.3200 - layer3_1_acc: 0.3661\n",
      "Epoch 927/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9502 - layer3_loss: 1.5343 - layer3_1_loss: 1.4164 - layer3_acc: 0.3188 - layer3_1_acc: 0.37290s - loss: 2.9478 - layer3_loss: 1.5551 - layer3_1_loss: 1.3927 - layer3_acc: 0.3053 - layer3_1_acc:\n",
      "Epoch 928/1000\n",
      "6329/6329 [==============================] - 1s 79us/sample - loss: 2.9490 - layer3_loss: 1.5331 - layer3_1_loss: 1.4154 - layer3_acc: 0.3195 - layer3_1_acc: 0.3689\n",
      "Epoch 929/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9493 - layer3_loss: 1.5330 - layer3_1_loss: 1.4168 - layer3_acc: 0.3187 - layer3_1_acc: 0.3674\n",
      "Epoch 930/1000\n",
      "6329/6329 [==============================] - 0s 79us/sample - loss: 2.9488 - layer3_loss: 1.5349 - layer3_1_loss: 1.4134 - layer3_acc: 0.3157 - layer3_1_acc: 0.3743\n",
      "Epoch 931/1000\n",
      "6329/6329 [==============================] - 0s 76us/sample - loss: 2.9489 - layer3_loss: 1.5319 - layer3_1_loss: 1.4169 - layer3_acc: 0.3176 - layer3_1_acc: 0.3618\n",
      "Epoch 932/1000\n",
      "6329/6329 [==============================] - 0s 79us/sample - loss: 2.9484 - layer3_loss: 1.5324 - layer3_1_loss: 1.4156 - layer3_acc: 0.3184 - layer3_1_acc: 0.3696\n",
      "Epoch 933/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9495 - layer3_loss: 1.5331 - layer3_1_loss: 1.4158 - layer3_acc: 0.3144 - layer3_1_acc: 0.3623\n",
      "Epoch 934/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9492 - layer3_loss: 1.5335 - layer3_1_loss: 1.4148 - layer3_acc: 0.3155 - layer3_1_acc: 0.3666\n",
      "Epoch 935/1000\n",
      "6329/6329 [==============================] - 0s 76us/sample - loss: 2.9481 - layer3_loss: 1.5334 - layer3_1_loss: 1.4146 - layer3_acc: 0.3200 - layer3_1_acc: 0.3707\n",
      "Epoch 936/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9492 - layer3_loss: 1.5328 - layer3_1_loss: 1.4165 - layer3_acc: 0.3181 - layer3_1_acc: 0.3639\n",
      "Epoch 937/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9492 - layer3_loss: 1.5340 - layer3_1_loss: 1.4156 - layer3_acc: 0.3200 - layer3_1_acc: 0.3636\n",
      "Epoch 938/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9485 - layer3_loss: 1.5343 - layer3_1_loss: 1.4144 - layer3_acc: 0.3207 - layer3_1_acc: 0.3697\n",
      "Epoch 939/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9492 - layer3_loss: 1.5316 - layer3_1_loss: 1.4175 - layer3_acc: 0.3209 - layer3_1_acc: 0.3615\n",
      "Epoch 940/1000\n",
      "6329/6329 [==============================] - 1s 88us/sample - loss: 2.9484 - layer3_loss: 1.5331 - layer3_1_loss: 1.4160 - layer3_acc: 0.3160 - layer3_1_acc: 0.3670\n",
      "Epoch 941/1000\n",
      "6329/6329 [==============================] - 1s 91us/sample - loss: 2.9480 - layer3_loss: 1.5318 - layer3_1_loss: 1.4159 - layer3_acc: 0.3207 - layer3_1_acc: 0.3696\n",
      "Epoch 942/1000\n",
      "6329/6329 [==============================] - 1s 83us/sample - loss: 2.9490 - layer3_loss: 1.5314 - layer3_1_loss: 1.4171 - layer3_acc: 0.3206 - layer3_1_acc: 0.3640\n",
      "Epoch 943/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329/6329 [==============================] - 0s 73us/sample - loss: 2.9486 - layer3_loss: 1.5322 - layer3_1_loss: 1.4163 - layer3_acc: 0.3219 - layer3_1_acc: 0.3659\n",
      "Epoch 944/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9497 - layer3_loss: 1.5337 - layer3_1_loss: 1.4161 - layer3_acc: 0.3171 - layer3_1_acc: 0.3631\n",
      "Epoch 945/1000\n",
      "6329/6329 [==============================] - 0s 76us/sample - loss: 2.9488 - layer3_loss: 1.5323 - layer3_1_loss: 1.4159 - layer3_acc: 0.3204 - layer3_1_acc: 0.3637\n",
      "Epoch 946/1000\n",
      "6329/6329 [==============================] - 1s 86us/sample - loss: 2.9492 - layer3_loss: 1.5337 - layer3_1_loss: 1.4154 - layer3_acc: 0.3173 - layer3_1_acc: 0.3680\n",
      "Epoch 947/1000\n",
      "6329/6329 [==============================] - 1s 91us/sample - loss: 2.9488 - layer3_loss: 1.5331 - layer3_1_loss: 1.4166 - layer3_acc: 0.3146 - layer3_1_acc: 0.3625\n",
      "Epoch 948/1000\n",
      "6329/6329 [==============================] - 1s 87us/sample - loss: 2.9482 - layer3_loss: 1.5341 - layer3_1_loss: 1.4143 - layer3_acc: 0.3187 - layer3_1_acc: 0.3688\n",
      "Epoch 949/1000\n",
      "6329/6329 [==============================] - 1s 84us/sample - loss: 2.9495 - layer3_loss: 1.5333 - layer3_1_loss: 1.4161 - layer3_acc: 0.3192 - layer3_1_acc: 0.3651\n",
      "Epoch 950/1000\n",
      "6329/6329 [==============================] - 1s 83us/sample - loss: 2.9480 - layer3_loss: 1.5323 - layer3_1_loss: 1.4153 - layer3_acc: 0.3209 - layer3_1_acc: 0.3681\n",
      "Epoch 951/1000\n",
      "6329/6329 [==============================] - 1s 84us/sample - loss: 2.9488 - layer3_loss: 1.5350 - layer3_1_loss: 1.4145 - layer3_acc: 0.3170 - layer3_1_acc: 0.3719\n",
      "Epoch 952/1000\n",
      "6329/6329 [==============================] - 1s 85us/sample - loss: 2.9486 - layer3_loss: 1.5336 - layer3_1_loss: 1.4161 - layer3_acc: 0.3168 - layer3_1_acc: 0.3689\n",
      "Epoch 953/1000\n",
      "6329/6329 [==============================] - 1s 87us/sample - loss: 2.9488 - layer3_loss: 1.5324 - layer3_1_loss: 1.4163 - layer3_acc: 0.3188 - layer3_1_acc: 0.36450s - loss: 2.9527 - layer3_loss: 1.5340 - layer3_1_loss: 1.4186 - layer3_acc: 0.3291 - layer3_1_acc\n",
      "Epoch 954/1000\n",
      "6329/6329 [==============================] - 1s 86us/sample - loss: 2.9493 - layer3_loss: 1.5339 - layer3_1_loss: 1.4157 - layer3_acc: 0.3225 - layer3_1_acc: 0.3672\n",
      "Epoch 955/1000\n",
      "6329/6329 [==============================] - 1s 87us/sample - loss: 2.9489 - layer3_loss: 1.5329 - layer3_1_loss: 1.4165 - layer3_acc: 0.3192 - layer3_1_acc: 0.3704\n",
      "Epoch 956/1000\n",
      "6329/6329 [==============================] - 1s 87us/sample - loss: 2.9486 - layer3_loss: 1.5336 - layer3_1_loss: 1.4155 - layer3_acc: 0.3195 - layer3_1_acc: 0.3719\n",
      "Epoch 957/1000\n",
      "6329/6329 [==============================] - 1s 82us/sample - loss: 2.9490 - layer3_loss: 1.5339 - layer3_1_loss: 1.4155 - layer3_acc: 0.3187 - layer3_1_acc: 0.3648\n",
      "Epoch 958/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9482 - layer3_loss: 1.5316 - layer3_1_loss: 1.4166 - layer3_acc: 0.3185 - layer3_1_acc: 0.3675\n",
      "Epoch 959/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9489 - layer3_loss: 1.5323 - layer3_1_loss: 1.4168 - layer3_acc: 0.3200 - layer3_1_acc: 0.3691\n",
      "Epoch 960/1000\n",
      "6329/6329 [==============================] - 1s 81us/sample - loss: 2.9489 - layer3_loss: 1.5334 - layer3_1_loss: 1.4157 - layer3_acc: 0.3195 - layer3_1_acc: 0.3672\n",
      "Epoch 961/1000\n",
      "6329/6329 [==============================] - 1s 90us/sample - loss: 2.9490 - layer3_loss: 1.5328 - layer3_1_loss: 1.4163 - layer3_acc: 0.3171 - layer3_1_acc: 0.3636\n",
      "Epoch 962/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9491 - layer3_loss: 1.5341 - layer3_1_loss: 1.4152 - layer3_acc: 0.3204 - layer3_1_acc: 0.3639\n",
      "Epoch 963/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9479 - layer3_loss: 1.5320 - layer3_1_loss: 1.4156 - layer3_acc: 0.3207 - layer3_1_acc: 0.3672\n",
      "Epoch 964/1000\n",
      "6329/6329 [==============================] - 0s 78us/sample - loss: 2.9484 - layer3_loss: 1.5337 - layer3_1_loss: 1.4160 - layer3_acc: 0.3185 - layer3_1_acc: 0.3648\n",
      "Epoch 965/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9483 - layer3_loss: 1.5330 - layer3_1_loss: 1.4145 - layer3_acc: 0.3193 - layer3_1_acc: 0.3666\n",
      "Epoch 966/1000\n",
      "6329/6329 [==============================] - 0s 79us/sample - loss: 2.9476 - layer3_loss: 1.5319 - layer3_1_loss: 1.4163 - layer3_acc: 0.3184 - layer3_1_acc: 0.3716\n",
      "Epoch 967/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9485 - layer3_loss: 1.5328 - layer3_1_loss: 1.4150 - layer3_acc: 0.3185 - layer3_1_acc: 0.3702\n",
      "Epoch 968/1000\n",
      "6329/6329 [==============================] - 0s 76us/sample - loss: 2.9489 - layer3_loss: 1.5331 - layer3_1_loss: 1.4151 - layer3_acc: 0.3170 - layer3_1_acc: 0.3658\n",
      "Epoch 969/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9493 - layer3_loss: 1.5330 - layer3_1_loss: 1.4156 - layer3_acc: 0.3185 - layer3_1_acc: 0.3699\n",
      "Epoch 970/1000\n",
      "6329/6329 [==============================] - 1s 94us/sample - loss: 2.9485 - layer3_loss: 1.5330 - layer3_1_loss: 1.4147 - layer3_acc: 0.3209 - layer3_1_acc: 0.3666\n",
      "Epoch 971/1000\n",
      "6329/6329 [==============================] - 1s 105us/sample - loss: 2.9486 - layer3_loss: 1.5316 - layer3_1_loss: 1.4169 - layer3_acc: 0.3192 - layer3_1_acc: 0.3702\n",
      "Epoch 972/1000\n",
      "6329/6329 [==============================] - 1s 101us/sample - loss: 2.9488 - layer3_loss: 1.5330 - layer3_1_loss: 1.4155 - layer3_acc: 0.3204 - layer3_1_acc: 0.3640\n",
      "Epoch 973/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9494 - layer3_loss: 1.5343 - layer3_1_loss: 1.4157 - layer3_acc: 0.3168 - layer3_1_acc: 0.3711\n",
      "Epoch 974/1000\n",
      "6329/6329 [==============================] - 0s 79us/sample - loss: 2.9497 - layer3_loss: 1.5321 - layer3_1_loss: 1.4165 - layer3_acc: 0.3165 - layer3_1_acc: 0.3655\n",
      "Epoch 975/1000\n",
      "6329/6329 [==============================] - 1s 83us/sample - loss: 2.9487 - layer3_loss: 1.5320 - layer3_1_loss: 1.4172 - layer3_acc: 0.3214 - layer3_1_acc: 0.3618\n",
      "Epoch 976/1000\n",
      "6329/6329 [==============================] - 1s 95us/sample - loss: 2.9483 - layer3_loss: 1.5322 - layer3_1_loss: 1.4156 - layer3_acc: 0.3195 - layer3_1_acc: 0.3636\n",
      "Epoch 977/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9472 - layer3_loss: 1.5320 - layer3_1_loss: 1.4147 - layer3_acc: 0.3162 - layer3_1_acc: 0.3645\n",
      "Epoch 978/1000\n",
      "6329/6329 [==============================] - 0s 79us/sample - loss: 2.9511 - layer3_loss: 1.5346 - layer3_1_loss: 1.4166 - layer3_acc: 0.3190 - layer3_1_acc: 0.3667\n",
      "Epoch 979/1000\n",
      "6329/6329 [==============================] - 1s 83us/sample - loss: 2.9477 - layer3_loss: 1.5326 - layer3_1_loss: 1.4156 - layer3_acc: 0.3215 - layer3_1_acc: 0.3640\n",
      "Epoch 980/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9485 - layer3_loss: 1.5337 - layer3_1_loss: 1.4149 - layer3_acc: 0.3176 - layer3_1_acc: 0.3675\n",
      "Epoch 981/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9482 - layer3_loss: 1.5328 - layer3_1_loss: 1.4155 - layer3_acc: 0.3192 - layer3_1_acc: 0.3696\n",
      "Epoch 982/1000\n",
      "6329/6329 [==============================] - 1s 80us/sample - loss: 2.9482 - layer3_loss: 1.5329 - layer3_1_loss: 1.4158 - layer3_acc: 0.3168 - layer3_1_acc: 0.3664\n",
      "Epoch 983/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9492 - layer3_loss: 1.5342 - layer3_1_loss: 1.4143 - layer3_acc: 0.3192 - layer3_1_acc: 0.3713\n",
      "Epoch 984/1000\n",
      "6329/6329 [==============================] - 0s 73us/sample - loss: 2.9473 - layer3_loss: 1.5325 - layer3_1_loss: 1.4147 - layer3_acc: 0.3200 - layer3_1_acc: 0.3678\n",
      "Epoch 985/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9476 - layer3_loss: 1.5331 - layer3_1_loss: 1.4148 - layer3_acc: 0.3181 - layer3_1_acc: 0.3680\n",
      "Epoch 986/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9484 - layer3_loss: 1.5343 - layer3_1_loss: 1.4143 - layer3_acc: 0.3195 - layer3_1_acc: 0.3607\n",
      "Epoch 987/1000\n",
      "6329/6329 [==============================] - 0s 70us/sample - loss: 2.9476 - layer3_loss: 1.5328 - layer3_1_loss: 1.4155 - layer3_acc: 0.3170 - layer3_1_acc: 0.3670\n",
      "Epoch 988/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329/6329 [==============================] - 0s 73us/sample - loss: 2.9483 - layer3_loss: 1.5336 - layer3_1_loss: 1.4151 - layer3_acc: 0.3193 - layer3_1_acc: 0.3664\n",
      "Epoch 989/1000\n",
      "6329/6329 [==============================] - 0s 71us/sample - loss: 2.9477 - layer3_loss: 1.5327 - layer3_1_loss: 1.4147 - layer3_acc: 0.3160 - layer3_1_acc: 0.3677\n",
      "Epoch 990/1000\n",
      "6329/6329 [==============================] - 0s 76us/sample - loss: 2.9486 - layer3_loss: 1.5327 - layer3_1_loss: 1.4154 - layer3_acc: 0.3215 - layer3_1_acc: 0.3642\n",
      "Epoch 991/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9481 - layer3_loss: 1.5317 - layer3_1_loss: 1.4176 - layer3_acc: 0.3212 - layer3_1_acc: 0.3599\n",
      "Epoch 992/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9492 - layer3_loss: 1.5334 - layer3_1_loss: 1.4165 - layer3_acc: 0.3200 - layer3_1_acc: 0.3663\n",
      "Epoch 993/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9489 - layer3_loss: 1.5303 - layer3_1_loss: 1.4182 - layer3_acc: 0.3219 - layer3_1_acc: 0.3670\n",
      "Epoch 994/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9466 - layer3_loss: 1.5317 - layer3_1_loss: 1.4149 - layer3_acc: 0.3198 - layer3_1_acc: 0.3719\n",
      "Epoch 995/1000\n",
      "6329/6329 [==============================] - 0s 76us/sample - loss: 2.9482 - layer3_loss: 1.5323 - layer3_1_loss: 1.4159 - layer3_acc: 0.3188 - layer3_1_acc: 0.3642\n",
      "Epoch 996/1000\n",
      "6329/6329 [==============================] - 1s 82us/sample - loss: 2.9475 - layer3_loss: 1.5323 - layer3_1_loss: 1.4144 - layer3_acc: 0.3188 - layer3_1_acc: 0.3715\n",
      "Epoch 997/1000\n",
      "6329/6329 [==============================] - 0s 77us/sample - loss: 2.9482 - layer3_loss: 1.5325 - layer3_1_loss: 1.4158 - layer3_acc: 0.3201 - layer3_1_acc: 0.3644\n",
      "Epoch 998/1000\n",
      "6329/6329 [==============================] - 0s 75us/sample - loss: 2.9488 - layer3_loss: 1.5339 - layer3_1_loss: 1.4144 - layer3_acc: 0.3171 - layer3_1_acc: 0.3683\n",
      "Epoch 999/1000\n",
      "6329/6329 [==============================] - 1s 90us/sample - loss: 2.9487 - layer3_loss: 1.5312 - layer3_1_loss: 1.4167 - layer3_acc: 0.3177 - layer3_1_acc: 0.3672\n",
      "Epoch 1000/1000\n",
      "6329/6329 [==============================] - 0s 74us/sample - loss: 2.9479 - layer3_loss: 1.5328 - layer3_1_loss: 1.4154 - layer3_acc: 0.3155 - layer3_1_acc: 0.3700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['loss', 'layer3_loss', 'layer3_1_loss', 'layer3_acc', 'layer3_1_acc']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(21,))\n",
    "d = tf.keras.layers.Dense(6, activation='softmax', name='out')\n",
    "\n",
    "layer1 = layers.Dense(10, activation=\"relu\", name=\"layer1\")\n",
    "layer2 = layers.Dense(20, activation=\"relu\", name=\"layer2\")\n",
    "layer3 = layers.Dense(6, activation=\"softmax\", name=\"layer3\")\n",
    "b = layer3(layer2(layer1(inputs)))\n",
    "\n",
    "output_1 = b\n",
    "output_2 = b\n",
    "model = tf.keras.models.Model(\n",
    "   inputs=inputs, outputs=[output_1, output_2])\n",
    "model.compile(optimizer=\"Adam\", loss='sparse_categorical_crossentropy', metrics=[ \"acc\"])\n",
    "history = model.fit(x, (y1, y2), batch_size=20, epochs=1000)\n",
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 0s 201us/sample - loss: 3.0303 - layer3_loss: 1.5885 - layer3_1_loss: 1.4419 - layer3_acc: 0.2713 - layer3_1_acc: 0.3480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.0303180000998755, 1.5884597, 1.4418584, 0.2713068, 0.34801137]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test02,( yout1, yout2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'layer3_loss', 'layer3_1_loss', 'layer3_acc', 'layer3_1_acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['layer3_loss'])\n",
    "plt.plot(history.history['layer3_1_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['home', 'away'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'layer3_loss', 'layer3_1_loss', 'layer3_acc', 'layer3_1_acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['layer3_acc'])\n",
    "plt.plot(history.history['layer3_1_acc'])\n",
    "plt.title('model acc')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['home', 'away'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(train_X02)\n",
    "y_test_pred = model.predict(test_X02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_goal(arr, team):\n",
    "    a=0\n",
    "    retVal=np.empty((arr[0].size+1))\n",
    "    games = int(arr[team].size / arr[team][1].size)\n",
    "    for i in range(0, games):\n",
    "        for j in range(0, (arr[team][i].size)):\n",
    "            if a < arr[team][i][j]:\n",
    "                a = arr[team][i][j]\n",
    "                retVal[i] = j\n",
    "        a = 0\n",
    "    return retVal\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predHome = pred_goal(y_test_pred, 0)\n",
    "predAway = pred_goal(y_test_pred, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "5.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "4.0\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,predHome.size):\n",
    "    if predHome[i] > 1: \n",
    "        print(predHome[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree_diff(yoriginal,ypred):\n",
    "    val = abs(yoriginal - ypred)\n",
    "    switcher = {\n",
    "        0: 1, # yoriginal = ypred\n",
    "        1: 0.8, # diff of 1. Exple original 1 predicted 2 => 0.75\n",
    "        2: 0.6,\n",
    "        3: 0.4,\n",
    "        4: 0.2, # diff of 4. Exple original 0 predicted 4\n",
    "        5: 0\n",
    "    }\n",
    "    return switcher.get(val, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality model home goals TRAIN 0.75198863636364\n"
     ]
    }
   ],
   "source": [
    "quality_model_home_goals=0\n",
    "\n",
    "for valorg,valpred in zip(yout1,predHome):\n",
    "    quality_model_home_goals += degree_diff(valorg,valpred)\n",
    "    \n",
    "quality_model_home_goals = quality_model_home_goals / len(yout1)\n",
    "print (\"Quality model home goals TRAIN\", quality_model_home_goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality model away goals TRAIN 0.8096590909090935\n"
     ]
    }
   ],
   "source": [
    "quality_model_away_goals=0\n",
    "\n",
    "for valorg,valpred in zip(yout2,predAway):\n",
    "    quality_model_away_goals += degree_diff(valorg,valpred)\n",
    "    \n",
    "quality_model_away_goals = quality_model_away_goals / len(yout2)\n",
    "print (\"Quality model away goals TRAIN\", quality_model_away_goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7808238636363667"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_quality = (quality_model_home_goals + quality_model_away_goals)/2\n",
    "final_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Updated_Regression_Model_ANN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
