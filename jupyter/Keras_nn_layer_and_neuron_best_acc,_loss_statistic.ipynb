{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/thu-soccer/project/blob/master/colab/colab_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "FtJth4hT577a",
    "outputId": "ce296e87-fcd1-4261-8057-6daacd747370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19781 train examples\n",
      "1042 test examples\n",
      "6681 train examples\n",
      "352 test examples\n",
      "6681 train examples\n",
      "352 test examples\n",
      "6646 train examples\n",
      "350 test examples\n",
      "6646 train examples\n",
      "350 test examples\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 999)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow_core.estimator import inputs\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "\n",
    "from  IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "\n",
    "def normalize_and_encode(dataframe):\n",
    "    column_names_to_not_normalize = ['result']\n",
    "    column_names_to_normalize = [x for x in list(dataframe) if x not in column_names_to_not_normalize ]\n",
    "    x = dataframe[column_names_to_normalize].values\n",
    "    x_scaled = preprocessing.normalize(x)\n",
    "    df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = dataframe.index)\n",
    "    dataframe[column_names_to_normalize] = df_temp\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit([ \"H\", \"A\", \"D\"])\n",
    "    dataframe.loc[:,['result']]=le.transform(dataframe['result'])\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "def get_X_and_y(dataframe):\n",
    "    X = dataframe.drop(columns=['result']).values\n",
    "    y = dataframe[['result']].values\n",
    "    return X,y\n",
    "\n",
    "df01 = pd.read_csv('../data/sliding01.csv', sep=',', index_col=0)\n",
    "df02 = pd.read_csv('../data/sliding02_shots.csv', sep=',', index_col=0)\n",
    "df03 = pd.read_csv('../data/sliding03_shots_extra.csv', sep=',', index_col=0)\n",
    "df04 = pd.read_csv('../data/sliding04_shots_and_possession.csv', sep=',', index_col=0)\n",
    "df05 = pd.read_csv('../data/sliding05_shots_and_possession_extra.csv', sep=',', index_col=0)\n",
    "\n",
    "n01 = normalize_and_encode(df01)\n",
    "n02 = normalize_and_encode(df02)\n",
    "n03 = normalize_and_encode(df03)\n",
    "n04 = normalize_and_encode(df04)\n",
    "n05 = normalize_and_encode(df05)\n",
    "\n",
    "train01, test01 = train_test_split(n01, test_size=0.05)\n",
    "print(len(train01), 'train examples')\n",
    "print(len(test01), 'test examples')\n",
    "\n",
    "train02, test02 = train_test_split(n02, test_size=0.05)\n",
    "print(len(train02), 'train examples')\n",
    "print(len(test02), 'test examples')\n",
    "\n",
    "train03, test03 = train_test_split(n03, test_size=0.05)\n",
    "print(len(train03), 'train examples')\n",
    "print(len(test03), 'test examples')\n",
    "\n",
    "train04, test04 = train_test_split(n04, test_size=0.05)\n",
    "print(len(train04), 'train examples')\n",
    "print(len(test04), 'test examples')\n",
    "\n",
    "train05, test05 = train_test_split(n05, test_size=0.05)\n",
    "print(len(train04), 'train examples')\n",
    "print(len(test04), 'test examples')\n",
    "\n",
    "train_X01,train_y01 = get_X_and_y(train01)\n",
    "train_X02,train_y02 = get_X_and_y(train02)\n",
    "train_X03,train_y03 = get_X_and_y(train03)\n",
    "train_X04,train_y04 = get_X_and_y(train04)\n",
    "train_X05,train_y05 = get_X_and_y(train05)\n",
    "\n",
    "test_X01,test_y01 = get_X_and_y(test01)\n",
    "test_X02,test_y02 = get_X_and_y(test02)\n",
    "test_X03,test_y03 = get_X_and_y(test03)\n",
    "test_X04,test_y04 = get_X_and_y(test04)\n",
    "test_X05,test_y05 = get_X_and_y(test05)\n",
    "\n",
    "\n",
    "#Many models train better if you gradually reduce the learning rate during training. Use optimizers.schedules to reduce the learning rate over time:\n",
    "#The code sets a schedules.InverseTimeDecay to hyperbolically decrease the learning rate to 1/2 of the base rate at 1000 epochs, 1/3 at 2000 epochs and so on.\n",
    "\n",
    "def get_lr_schedule(train, batch_size):\n",
    "    lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "    0.001,\n",
    "    decay_steps=(len(train)//batch_size)*1000,\n",
    "    decay_rate=1,\n",
    "    staircase=False)\n",
    "    return lr_schedule\n",
    "\n",
    "def get_optimizer(train, batch_size):\n",
    "    return tf.keras.optimizers.Adam(get_lr_schedule(train, batch_size))\n",
    "\n",
    "\n",
    "#Each model in this tutorial will use the same training configuration. So set these up in a reusable way, starting with the list of callbacks.\n",
    "#The training for this tutorial runs for many short epochs. To reduce the logging noise use the tfdocs.EpochDots which simply a . for each epoch and, and a full set of metrics every 100 epochs.\n",
    "\n",
    "def get_callbacks(name):\n",
    "    return [\n",
    "        tfdocs.modeling.EpochDots(),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200),\n",
    "        #tf.keras.callbacks.TensorBoard(logdir/name), # Jupyter Notebook\n",
    "        #tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1) # Google Colab\n",
    "      ]\n",
    "\n",
    "def compile_and_fit(model, name, X, y, validation_split, batch_size, optimizer=None, max_epochs=1000):\n",
    "    if optimizer is None:\n",
    "        optimizer = get_optimizer(X, batch_size)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "     \n",
    "    history = model.fit(\n",
    "        X,\n",
    "        y,\n",
    "        validation_split=validation_split,\n",
    "        batch_size=batch_size,\n",
    "#        steps_per_epoch = 50, # (len(train_X01)//batch_size,\n",
    "        epochs=max_epochs,\n",
    "        callbacks=get_callbacks(name),\n",
    "        verbose=0)\n",
    "    \n",
    "    model.save(\"../model/%s.h5\" %name) \n",
    "    \n",
    "    return history\n",
    "\n",
    "def plot_history(model_history):\n",
    "\tplt.plot(model_history.history['accuracy'])\n",
    "\tplt.plot(model_history.history['val_accuracy'])\n",
    "\tplt.title(\"%s accuracy\" %model_history)\n",
    "\tplt.ylabel('accuracy')\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.legend(['train', 'val'], loc='upper left')\n",
    "\tplt.show()\n",
    "\t\n",
    "\tplt.plot(model_history.history['loss'])\n",
    "\tplt.plot(model_history.history['val_loss'])\n",
    "\tplt.title(\"%s loss\" %model_history)\n",
    "\tplt.ylabel('loss')\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.legend(['train', 'val'], loc='upper left')\n",
    "\tplt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "C5oCSP7gaQ9y",
    "outputId": "6e0a4bc2-e646-4474-bad8-bd213594e680"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.049957</td>\n",
       "      <td>0.165301</td>\n",
       "      <td>0.330601</td>\n",
       "      <td>0.183667</td>\n",
       "      <td>0.110200</td>\n",
       "      <td>0.073467</td>\n",
       "      <td>0.514268</td>\n",
       "      <td>0.367334</td>\n",
       "      <td>0.073467</td>\n",
       "      <td>0.073467</td>\n",
       "      <td>0.220401</td>\n",
       "      <td>0.293868</td>\n",
       "      <td>0.514268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.077897</td>\n",
       "      <td>0.103862</td>\n",
       "      <td>0.121172</td>\n",
       "      <td>0.103862</td>\n",
       "      <td>0.138483</td>\n",
       "      <td>0.103862</td>\n",
       "      <td>0.553931</td>\n",
       "      <td>0.415448</td>\n",
       "      <td>0.138483</td>\n",
       "      <td>0.103862</td>\n",
       "      <td>0.103862</td>\n",
       "      <td>0.484690</td>\n",
       "      <td>0.415448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.109311</td>\n",
       "      <td>0.117119</td>\n",
       "      <td>0.105407</td>\n",
       "      <td>0.195198</td>\n",
       "      <td>0.078079</td>\n",
       "      <td>0.117119</td>\n",
       "      <td>0.390396</td>\n",
       "      <td>0.312317</td>\n",
       "      <td>0.156158</td>\n",
       "      <td>0.156158</td>\n",
       "      <td>0.078079</td>\n",
       "      <td>0.585594</td>\n",
       "      <td>0.507514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.068789</td>\n",
       "      <td>0.117049</td>\n",
       "      <td>0.155945</td>\n",
       "      <td>0.180075</td>\n",
       "      <td>0.108045</td>\n",
       "      <td>0.072030</td>\n",
       "      <td>0.648271</td>\n",
       "      <td>0.396166</td>\n",
       "      <td>0.108045</td>\n",
       "      <td>0.108045</td>\n",
       "      <td>0.144060</td>\n",
       "      <td>0.360151</td>\n",
       "      <td>0.396166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.108097</td>\n",
       "      <td>0.154424</td>\n",
       "      <td>0.205899</td>\n",
       "      <td>0.102949</td>\n",
       "      <td>0.205899</td>\n",
       "      <td>0.205899</td>\n",
       "      <td>0.308848</td>\n",
       "      <td>0.463272</td>\n",
       "      <td>0.051475</td>\n",
       "      <td>0.308848</td>\n",
       "      <td>0.154424</td>\n",
       "      <td>0.360322</td>\n",
       "      <td>0.514746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20818</th>\n",
       "      <td>2</td>\n",
       "      <td>0.162536</td>\n",
       "      <td>0.123527</td>\n",
       "      <td>0.055262</td>\n",
       "      <td>0.097521</td>\n",
       "      <td>0.065014</td>\n",
       "      <td>0.162536</td>\n",
       "      <td>0.260057</td>\n",
       "      <td>0.487607</td>\n",
       "      <td>0.065014</td>\n",
       "      <td>0.130029</td>\n",
       "      <td>0.130029</td>\n",
       "      <td>0.325071</td>\n",
       "      <td>0.682650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20819</th>\n",
       "      <td>2</td>\n",
       "      <td>0.061498</td>\n",
       "      <td>0.110696</td>\n",
       "      <td>0.113771</td>\n",
       "      <td>0.092247</td>\n",
       "      <td>0.092247</td>\n",
       "      <td>0.122995</td>\n",
       "      <td>0.307489</td>\n",
       "      <td>0.584228</td>\n",
       "      <td>0.030749</td>\n",
       "      <td>0.122995</td>\n",
       "      <td>0.153744</td>\n",
       "      <td>0.215242</td>\n",
       "      <td>0.645726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20820</th>\n",
       "      <td>2</td>\n",
       "      <td>0.073697</td>\n",
       "      <td>0.153535</td>\n",
       "      <td>0.184242</td>\n",
       "      <td>0.122828</td>\n",
       "      <td>0.163770</td>\n",
       "      <td>0.122828</td>\n",
       "      <td>0.409426</td>\n",
       "      <td>0.368484</td>\n",
       "      <td>0.204713</td>\n",
       "      <td>0.081885</td>\n",
       "      <td>0.122828</td>\n",
       "      <td>0.614139</td>\n",
       "      <td>0.368484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20821</th>\n",
       "      <td>2</td>\n",
       "      <td>0.044350</td>\n",
       "      <td>0.175065</td>\n",
       "      <td>0.300111</td>\n",
       "      <td>0.066691</td>\n",
       "      <td>0.100037</td>\n",
       "      <td>0.166729</td>\n",
       "      <td>0.400149</td>\n",
       "      <td>0.466840</td>\n",
       "      <td>0.100037</td>\n",
       "      <td>0.100037</td>\n",
       "      <td>0.133383</td>\n",
       "      <td>0.366803</td>\n",
       "      <td>0.533532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20822</th>\n",
       "      <td>2</td>\n",
       "      <td>0.055791</td>\n",
       "      <td>0.140313</td>\n",
       "      <td>0.175391</td>\n",
       "      <td>0.200447</td>\n",
       "      <td>0.033408</td>\n",
       "      <td>0.100223</td>\n",
       "      <td>0.334078</td>\n",
       "      <td>0.267263</td>\n",
       "      <td>0.133631</td>\n",
       "      <td>0.033408</td>\n",
       "      <td>0.167039</td>\n",
       "      <td>0.467709</td>\n",
       "      <td>0.668156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20823 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       result  odds-home  odds-draw  odds-away  home-wins  home-draws  \\\n",
       "0           2   0.049957   0.165301   0.330601   0.183667    0.110200   \n",
       "1           1   0.077897   0.103862   0.121172   0.103862    0.138483   \n",
       "2           1   0.109311   0.117119   0.105407   0.195198    0.078079   \n",
       "3           0   0.068789   0.117049   0.155945   0.180075    0.108045   \n",
       "4           2   0.108097   0.154424   0.205899   0.102949    0.205899   \n",
       "...       ...        ...        ...        ...        ...         ...   \n",
       "20818       2   0.162536   0.123527   0.055262   0.097521    0.065014   \n",
       "20819       2   0.061498   0.110696   0.113771   0.092247    0.092247   \n",
       "20820       2   0.073697   0.153535   0.184242   0.122828    0.163770   \n",
       "20821       2   0.044350   0.175065   0.300111   0.066691    0.100037   \n",
       "20822       2   0.055791   0.140313   0.175391   0.200447    0.033408   \n",
       "\n",
       "       home-losses  home-goals  home-opposition-goals  away-wins  away-draws  \\\n",
       "0         0.073467    0.514268               0.367334   0.073467    0.073467   \n",
       "1         0.103862    0.553931               0.415448   0.138483    0.103862   \n",
       "2         0.117119    0.390396               0.312317   0.156158    0.156158   \n",
       "3         0.072030    0.648271               0.396166   0.108045    0.108045   \n",
       "4         0.205899    0.308848               0.463272   0.051475    0.308848   \n",
       "...            ...         ...                    ...        ...         ...   \n",
       "20818     0.162536    0.260057               0.487607   0.065014    0.130029   \n",
       "20819     0.122995    0.307489               0.584228   0.030749    0.122995   \n",
       "20820     0.122828    0.409426               0.368484   0.204713    0.081885   \n",
       "20821     0.166729    0.400149               0.466840   0.100037    0.100037   \n",
       "20822     0.100223    0.334078               0.267263   0.133631    0.033408   \n",
       "\n",
       "       away-losses  away-goals  away-opposition-goals  \n",
       "0         0.220401    0.293868               0.514268  \n",
       "1         0.103862    0.484690               0.415448  \n",
       "2         0.078079    0.585594               0.507514  \n",
       "3         0.144060    0.360151               0.396166  \n",
       "4         0.154424    0.360322               0.514746  \n",
       "...            ...         ...                    ...  \n",
       "20818     0.130029    0.325071               0.682650  \n",
       "20819     0.153744    0.215242               0.645726  \n",
       "20820     0.122828    0.614139               0.368484  \n",
       "20821     0.133383    0.366803               0.533532  \n",
       "20822     0.167039    0.467709               0.668156  \n",
       "\n",
       "[20823 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "colab_type": "code",
    "id": "UCnuh-duaSip",
    "outputId": "9ec7f29c-b38b-46c6-a6bb-d1904d8dfb17"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.012482</td>\n",
       "      <td>0.011769</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.010699</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.039230</td>\n",
       "      <td>0.057061</td>\n",
       "      <td>0.488587</td>\n",
       "      <td>0.238944</td>\n",
       "      <td>0.417260</td>\n",
       "      <td>0.189015</td>\n",
       "      <td>0.028531</td>\n",
       "      <td>0.007133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053495</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.574178</td>\n",
       "      <td>0.278173</td>\n",
       "      <td>0.256775</td>\n",
       "      <td>0.106990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.010640</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.022166</td>\n",
       "      <td>0.029555</td>\n",
       "      <td>0.059110</td>\n",
       "      <td>0.495044</td>\n",
       "      <td>0.236439</td>\n",
       "      <td>0.557848</td>\n",
       "      <td>0.284465</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.014777</td>\n",
       "      <td>0.040638</td>\n",
       "      <td>0.066498</td>\n",
       "      <td>0.384213</td>\n",
       "      <td>0.162552</td>\n",
       "      <td>0.321409</td>\n",
       "      <td>0.132997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.007188</td>\n",
       "      <td>0.012795</td>\n",
       "      <td>0.015805</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.037632</td>\n",
       "      <td>0.056448</td>\n",
       "      <td>0.451585</td>\n",
       "      <td>0.218266</td>\n",
       "      <td>0.466638</td>\n",
       "      <td>0.210740</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.022579</td>\n",
       "      <td>0.041395</td>\n",
       "      <td>0.056448</td>\n",
       "      <td>0.504270</td>\n",
       "      <td>0.222029</td>\n",
       "      <td>0.376321</td>\n",
       "      <td>0.173108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.010289</td>\n",
       "      <td>0.010289</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.015829</td>\n",
       "      <td>0.006332</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.069647</td>\n",
       "      <td>0.037989</td>\n",
       "      <td>0.560339</td>\n",
       "      <td>0.259592</td>\n",
       "      <td>0.234266</td>\n",
       "      <td>0.117133</td>\n",
       "      <td>0.018995</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.060149</td>\n",
       "      <td>0.025326</td>\n",
       "      <td>0.535013</td>\n",
       "      <td>0.300747</td>\n",
       "      <td>0.357730</td>\n",
       "      <td>0.183614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>0.020384</td>\n",
       "      <td>0.064551</td>\n",
       "      <td>0.023782</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.050961</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.546982</td>\n",
       "      <td>0.244613</td>\n",
       "      <td>0.251408</td>\n",
       "      <td>0.105320</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.016987</td>\n",
       "      <td>0.033974</td>\n",
       "      <td>0.057756</td>\n",
       "      <td>0.485829</td>\n",
       "      <td>0.234421</td>\n",
       "      <td>0.455252</td>\n",
       "      <td>0.234421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7028</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020289</td>\n",
       "      <td>0.015420</td>\n",
       "      <td>0.006898</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.040578</td>\n",
       "      <td>0.048694</td>\n",
       "      <td>0.324626</td>\n",
       "      <td>0.174487</td>\n",
       "      <td>0.474766</td>\n",
       "      <td>0.243470</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.040578</td>\n",
       "      <td>0.085214</td>\n",
       "      <td>0.482881</td>\n",
       "      <td>0.235354</td>\n",
       "      <td>0.454477</td>\n",
       "      <td>0.263759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>2</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.017929</td>\n",
       "      <td>0.018427</td>\n",
       "      <td>0.014941</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.024901</td>\n",
       "      <td>0.044822</td>\n",
       "      <td>0.104584</td>\n",
       "      <td>0.443238</td>\n",
       "      <td>0.234070</td>\n",
       "      <td>0.458179</td>\n",
       "      <td>0.229089</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.019921</td>\n",
       "      <td>0.024901</td>\n",
       "      <td>0.034861</td>\n",
       "      <td>0.104584</td>\n",
       "      <td>0.517941</td>\n",
       "      <td>0.273911</td>\n",
       "      <td>0.313753</td>\n",
       "      <td>0.129485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7030</th>\n",
       "      <td>2</td>\n",
       "      <td>0.007617</td>\n",
       "      <td>0.015870</td>\n",
       "      <td>0.019044</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.016928</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.516293</td>\n",
       "      <td>0.249683</td>\n",
       "      <td>0.389336</td>\n",
       "      <td>0.211596</td>\n",
       "      <td>0.021160</td>\n",
       "      <td>0.008464</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.063479</td>\n",
       "      <td>0.038087</td>\n",
       "      <td>0.355481</td>\n",
       "      <td>0.181972</td>\n",
       "      <td>0.499366</td>\n",
       "      <td>0.236987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031</th>\n",
       "      <td>2</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.020806</td>\n",
       "      <td>0.035667</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.019815</td>\n",
       "      <td>0.047556</td>\n",
       "      <td>0.055483</td>\n",
       "      <td>0.491416</td>\n",
       "      <td>0.245708</td>\n",
       "      <td>0.392341</td>\n",
       "      <td>0.198152</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.015852</td>\n",
       "      <td>0.043593</td>\n",
       "      <td>0.067372</td>\n",
       "      <td>0.408193</td>\n",
       "      <td>0.210041</td>\n",
       "      <td>0.483490</td>\n",
       "      <td>0.214004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>2</td>\n",
       "      <td>0.006541</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.020563</td>\n",
       "      <td>0.023501</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.039168</td>\n",
       "      <td>0.031334</td>\n",
       "      <td>0.411259</td>\n",
       "      <td>0.254589</td>\n",
       "      <td>0.493511</td>\n",
       "      <td>0.211505</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.007834</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.050918</td>\n",
       "      <td>0.074418</td>\n",
       "      <td>0.446510</td>\n",
       "      <td>0.246755</td>\n",
       "      <td>0.415176</td>\n",
       "      <td>0.180171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7033 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result  odds-home  odds-draw  odds-away  home-wins  home-draws  \\\n",
       "0          2   0.012482   0.011769   0.007489   0.003566    0.010699   \n",
       "1          1   0.009236   0.012191   0.010640   0.011083    0.003694   \n",
       "2          0   0.007188   0.012795   0.015805   0.015053    0.007526   \n",
       "3          2   0.010289   0.010289   0.007281   0.015829    0.006332   \n",
       "4          2   0.004077   0.020384   0.064551   0.023782    0.006795   \n",
       "...      ...        ...        ...        ...        ...         ...   \n",
       "7028       2   0.020289   0.015420   0.006898   0.016231    0.008116   \n",
       "7029       2   0.009960   0.017929   0.018427   0.014941    0.009960   \n",
       "7030       2   0.007617   0.015870   0.019044   0.012696    0.012696   \n",
       "7031       2   0.005271   0.020806   0.035667   0.007926    0.011889   \n",
       "7032       2   0.006541   0.016450   0.020563   0.023501    0.003917   \n",
       "\n",
       "      home-losses  home-goals  home-opposition-goals  home-shots  \\\n",
       "0        0.021398    0.039230               0.057061    0.488587   \n",
       "1        0.022166    0.029555               0.059110    0.495044   \n",
       "2        0.015053    0.037632               0.056448    0.451585   \n",
       "3        0.009497    0.069647               0.037989    0.560339   \n",
       "4        0.003397    0.050961               0.027179    0.546982   \n",
       "...           ...         ...                    ...         ...   \n",
       "7028     0.016231    0.040578               0.048694    0.324626   \n",
       "7029     0.024901    0.044822               0.104584    0.443238   \n",
       "7030     0.016928    0.033855               0.033855    0.516293   \n",
       "7031     0.019815    0.047556               0.055483    0.491416   \n",
       "7032     0.011750    0.039168               0.031334    0.411259   \n",
       "\n",
       "      home-shots_on_target  home-opposition_shots  \\\n",
       "0                 0.238944               0.417260   \n",
       "1                 0.236439               0.557848   \n",
       "2                 0.218266               0.466638   \n",
       "3                 0.259592               0.234266   \n",
       "4                 0.244613               0.251408   \n",
       "...                    ...                    ...   \n",
       "7028              0.174487               0.474766   \n",
       "7029              0.234070               0.458179   \n",
       "7030              0.249683               0.389336   \n",
       "7031              0.245708               0.392341   \n",
       "7032              0.254589               0.493511   \n",
       "\n",
       "      home-opposition_shots_on_target  away-wins  away-draws  away-losses  \\\n",
       "0                            0.189015   0.028531    0.007133     0.000000   \n",
       "1                            0.284465   0.011083    0.011083     0.014777   \n",
       "2                            0.210740   0.007526    0.007526     0.022579   \n",
       "3                            0.117133   0.018995    0.009497     0.003166   \n",
       "4                            0.105320   0.010192    0.006795     0.016987   \n",
       "...                               ...        ...         ...          ...   \n",
       "7028                         0.243470   0.008116    0.016231     0.016231   \n",
       "7029                         0.229089   0.004980    0.019921     0.024901   \n",
       "7030                         0.211596   0.021160    0.008464     0.012696   \n",
       "7031                         0.198152   0.011889    0.011889     0.015852   \n",
       "7032                         0.211505   0.011750    0.007834     0.019584   \n",
       "\n",
       "      away-goals  away-opposition-goals  away-shots  away-shots_on_target  \\\n",
       "0       0.053495               0.021398    0.574178              0.278173   \n",
       "1       0.040638               0.066498    0.384213              0.162552   \n",
       "2       0.041395               0.056448    0.504270              0.222029   \n",
       "3       0.060149               0.025326    0.535013              0.300747   \n",
       "4       0.033974               0.057756    0.485829              0.234421   \n",
       "...          ...                    ...         ...                   ...   \n",
       "7028    0.040578               0.085214    0.482881              0.235354   \n",
       "7029    0.034861               0.104584    0.517941              0.273911   \n",
       "7030    0.063479               0.038087    0.355481              0.181972   \n",
       "7031    0.043593               0.067372    0.408193              0.210041   \n",
       "7032    0.050918               0.074418    0.446510              0.246755   \n",
       "\n",
       "      away-opposition_shots  away-opposition_shots_on_target  \n",
       "0                  0.256775                         0.106990  \n",
       "1                  0.321409                         0.132997  \n",
       "2                  0.376321                         0.173108  \n",
       "3                  0.357730                         0.183614  \n",
       "4                  0.455252                         0.234421  \n",
       "...                     ...                              ...  \n",
       "7028               0.454477                         0.263759  \n",
       "7029               0.313753                         0.129485  \n",
       "7030               0.499366                         0.236987  \n",
       "7031               0.483490                         0.214004  \n",
       "7032               0.415176                         0.180171  \n",
       "\n",
       "[7033 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "colab_type": "code",
    "id": "iUgEWCcJaTKx",
    "outputId": "a30e80e8-8b13-43cf-988d-0fa22e73fd94"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "      <th>home_shot_accuracy</th>\n",
       "      <th>home_shot_efficiency</th>\n",
       "      <th>home_opposition_shot_accuracy</th>\n",
       "      <th>home_opposition_shot_efficiency</th>\n",
       "      <th>away_shot_accuracy</th>\n",
       "      <th>away_shot_efficiency</th>\n",
       "      <th>away_opposition_shot_accuracy</th>\n",
       "      <th>away_opposition_shot_efficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.012482</td>\n",
       "      <td>0.011769</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.010699</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.039229</td>\n",
       "      <td>0.057061</td>\n",
       "      <td>0.488583</td>\n",
       "      <td>0.238942</td>\n",
       "      <td>0.417257</td>\n",
       "      <td>0.189014</td>\n",
       "      <td>0.028530</td>\n",
       "      <td>0.007133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053495</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.574174</td>\n",
       "      <td>0.278171</td>\n",
       "      <td>0.256774</td>\n",
       "      <td>0.106989</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.001616</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.000713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.010640</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.022166</td>\n",
       "      <td>0.029555</td>\n",
       "      <td>0.059109</td>\n",
       "      <td>0.495039</td>\n",
       "      <td>0.236437</td>\n",
       "      <td>0.557843</td>\n",
       "      <td>0.284463</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.014777</td>\n",
       "      <td>0.040638</td>\n",
       "      <td>0.066498</td>\n",
       "      <td>0.384210</td>\n",
       "      <td>0.162550</td>\n",
       "      <td>0.321406</td>\n",
       "      <td>0.132996</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.001884</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.001847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.007188</td>\n",
       "      <td>0.012795</td>\n",
       "      <td>0.015805</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.037632</td>\n",
       "      <td>0.056448</td>\n",
       "      <td>0.451581</td>\n",
       "      <td>0.218264</td>\n",
       "      <td>0.466634</td>\n",
       "      <td>0.210738</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.022579</td>\n",
       "      <td>0.041395</td>\n",
       "      <td>0.056448</td>\n",
       "      <td>0.504266</td>\n",
       "      <td>0.222028</td>\n",
       "      <td>0.376318</td>\n",
       "      <td>0.173106</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.001731</td>\n",
       "      <td>0.001227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.010289</td>\n",
       "      <td>0.010289</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.015829</td>\n",
       "      <td>0.006331</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.069646</td>\n",
       "      <td>0.037989</td>\n",
       "      <td>0.560335</td>\n",
       "      <td>0.259590</td>\n",
       "      <td>0.234264</td>\n",
       "      <td>0.117132</td>\n",
       "      <td>0.018994</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.060149</td>\n",
       "      <td>0.025326</td>\n",
       "      <td>0.535009</td>\n",
       "      <td>0.300745</td>\n",
       "      <td>0.357728</td>\n",
       "      <td>0.183613</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.000437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>0.020384</td>\n",
       "      <td>0.064550</td>\n",
       "      <td>0.023782</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.050961</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.546979</td>\n",
       "      <td>0.244612</td>\n",
       "      <td>0.251406</td>\n",
       "      <td>0.105319</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.016987</td>\n",
       "      <td>0.033974</td>\n",
       "      <td>0.057756</td>\n",
       "      <td>0.485826</td>\n",
       "      <td>0.234419</td>\n",
       "      <td>0.455249</td>\n",
       "      <td>0.234419</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.000837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7028</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020289</td>\n",
       "      <td>0.015420</td>\n",
       "      <td>0.006898</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.040578</td>\n",
       "      <td>0.048693</td>\n",
       "      <td>0.324623</td>\n",
       "      <td>0.174485</td>\n",
       "      <td>0.474761</td>\n",
       "      <td>0.243467</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.040578</td>\n",
       "      <td>0.085213</td>\n",
       "      <td>0.482876</td>\n",
       "      <td>0.235351</td>\n",
       "      <td>0.454472</td>\n",
       "      <td>0.263756</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.001311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>2</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.017928</td>\n",
       "      <td>0.018426</td>\n",
       "      <td>0.014940</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.044821</td>\n",
       "      <td>0.104582</td>\n",
       "      <td>0.443228</td>\n",
       "      <td>0.234064</td>\n",
       "      <td>0.458168</td>\n",
       "      <td>0.229084</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.019920</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.034861</td>\n",
       "      <td>0.104582</td>\n",
       "      <td>0.517929</td>\n",
       "      <td>0.273905</td>\n",
       "      <td>0.313745</td>\n",
       "      <td>0.129482</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.004022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7030</th>\n",
       "      <td>2</td>\n",
       "      <td>0.007617</td>\n",
       "      <td>0.015870</td>\n",
       "      <td>0.019043</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.016927</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.516288</td>\n",
       "      <td>0.249680</td>\n",
       "      <td>0.389332</td>\n",
       "      <td>0.211593</td>\n",
       "      <td>0.021159</td>\n",
       "      <td>0.008464</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.063478</td>\n",
       "      <td>0.038087</td>\n",
       "      <td>0.355477</td>\n",
       "      <td>0.181970</td>\n",
       "      <td>0.499360</td>\n",
       "      <td>0.236985</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.000680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031</th>\n",
       "      <td>2</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.020806</td>\n",
       "      <td>0.035667</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.019815</td>\n",
       "      <td>0.047556</td>\n",
       "      <td>0.055482</td>\n",
       "      <td>0.491412</td>\n",
       "      <td>0.245706</td>\n",
       "      <td>0.392337</td>\n",
       "      <td>0.198150</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.015852</td>\n",
       "      <td>0.043593</td>\n",
       "      <td>0.067371</td>\n",
       "      <td>0.408189</td>\n",
       "      <td>0.210039</td>\n",
       "      <td>0.483486</td>\n",
       "      <td>0.214002</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>2</td>\n",
       "      <td>0.006541</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.020563</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.039167</td>\n",
       "      <td>0.031334</td>\n",
       "      <td>0.411255</td>\n",
       "      <td>0.254586</td>\n",
       "      <td>0.493506</td>\n",
       "      <td>0.211503</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.007833</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.050917</td>\n",
       "      <td>0.074418</td>\n",
       "      <td>0.446505</td>\n",
       "      <td>0.246753</td>\n",
       "      <td>0.415172</td>\n",
       "      <td>0.180169</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.001618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7033 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result  odds-home  odds-draw  odds-away  home-wins  home-draws  \\\n",
       "0          2   0.012482   0.011769   0.007489   0.003566    0.010699   \n",
       "1          1   0.009236   0.012191   0.010640   0.011083    0.003694   \n",
       "2          0   0.007188   0.012795   0.015805   0.015053    0.007526   \n",
       "3          2   0.010289   0.010289   0.007281   0.015829    0.006331   \n",
       "4          2   0.004077   0.020384   0.064550   0.023782    0.006795   \n",
       "...      ...        ...        ...        ...        ...         ...   \n",
       "7028       2   0.020289   0.015420   0.006898   0.016231    0.008116   \n",
       "7029       2   0.009960   0.017928   0.018426   0.014940    0.009960   \n",
       "7030       2   0.007617   0.015870   0.019043   0.012696    0.012696   \n",
       "7031       2   0.005271   0.020806   0.035667   0.007926    0.011889   \n",
       "7032       2   0.006541   0.016450   0.020563   0.023500    0.003917   \n",
       "\n",
       "      home-losses  home-goals  home-opposition-goals  home-shots  \\\n",
       "0        0.021398    0.039229               0.057061    0.488583   \n",
       "1        0.022166    0.029555               0.059109    0.495039   \n",
       "2        0.015053    0.037632               0.056448    0.451581   \n",
       "3        0.009497    0.069646               0.037989    0.560335   \n",
       "4        0.003397    0.050961               0.027179    0.546979   \n",
       "...           ...         ...                    ...         ...   \n",
       "7028     0.016231    0.040578               0.048693    0.324623   \n",
       "7029     0.024900    0.044821               0.104582    0.443228   \n",
       "7030     0.016927    0.033855               0.033855    0.516288   \n",
       "7031     0.019815    0.047556               0.055482    0.491412   \n",
       "7032     0.011750    0.039167               0.031334    0.411255   \n",
       "\n",
       "      home-shots_on_target  home-opposition_shots  \\\n",
       "0                 0.238942               0.417257   \n",
       "1                 0.236437               0.557843   \n",
       "2                 0.218264               0.466634   \n",
       "3                 0.259590               0.234264   \n",
       "4                 0.244612               0.251406   \n",
       "...                    ...                    ...   \n",
       "7028              0.174485               0.474761   \n",
       "7029              0.234064               0.458168   \n",
       "7030              0.249680               0.389332   \n",
       "7031              0.245706               0.392337   \n",
       "7032              0.254586               0.493506   \n",
       "\n",
       "      home-opposition_shots_on_target  away-wins  away-draws  away-losses  \\\n",
       "0                            0.189014   0.028530    0.007133     0.000000   \n",
       "1                            0.284463   0.011083    0.011083     0.014777   \n",
       "2                            0.210738   0.007526    0.007526     0.022579   \n",
       "3                            0.117132   0.018994    0.009497     0.003166   \n",
       "4                            0.105319   0.010192    0.006795     0.016987   \n",
       "...                               ...        ...         ...          ...   \n",
       "7028                         0.243467   0.008116    0.016231     0.016231   \n",
       "7029                         0.229084   0.004980    0.019920     0.024900   \n",
       "7030                         0.211593   0.021159    0.008464     0.012696   \n",
       "7031                         0.198150   0.011889    0.011889     0.015852   \n",
       "7032                         0.211503   0.011750    0.007833     0.019584   \n",
       "\n",
       "      away-goals  away-opposition-goals  away-shots  away-shots_on_target  \\\n",
       "0       0.053495               0.021398    0.574174              0.278171   \n",
       "1       0.040638               0.066498    0.384210              0.162550   \n",
       "2       0.041395               0.056448    0.504266              0.222028   \n",
       "3       0.060149               0.025326    0.535009              0.300745   \n",
       "4       0.033974               0.057756    0.485826              0.234419   \n",
       "...          ...                    ...         ...                   ...   \n",
       "7028    0.040578               0.085213    0.482876              0.235351   \n",
       "7029    0.034861               0.104582    0.517929              0.273905   \n",
       "7030    0.063478               0.038087    0.355477              0.181970   \n",
       "7031    0.043593               0.067371    0.408189              0.210039   \n",
       "7032    0.050917               0.074418    0.446505              0.246753   \n",
       "\n",
       "      away-opposition_shots  away-opposition_shots_on_target  \\\n",
       "0                  0.256774                         0.106989   \n",
       "1                  0.321406                         0.132996   \n",
       "2                  0.376318                         0.173106   \n",
       "3                  0.357728                         0.183613   \n",
       "4                  0.455249                         0.234419   \n",
       "...                     ...                              ...   \n",
       "7028               0.454472                         0.263756   \n",
       "7029               0.313745                         0.129482   \n",
       "7030               0.499360                         0.236985   \n",
       "7031               0.483486                         0.214002   \n",
       "7032               0.415172                         0.180169   \n",
       "\n",
       "      home_shot_accuracy  home_shot_efficiency  home_opposition_shot_accuracy  \\\n",
       "0               0.001744              0.000586                       0.001616   \n",
       "1               0.001764              0.000462                       0.001884   \n",
       "2               0.001819              0.000649                       0.001699   \n",
       "3               0.001467              0.000849                       0.001583   \n",
       "4               0.001519              0.000708                       0.001423   \n",
       "...                  ...                   ...                            ...   \n",
       "7028            0.002181              0.000944                       0.002081   \n",
       "7029            0.002630              0.000954                       0.002490   \n",
       "7030            0.002047              0.000574                       0.002300   \n",
       "7031            0.001981              0.000767                       0.002002   \n",
       "7032            0.002425              0.000603                       0.001679   \n",
       "\n",
       "      home_opposition_shot_efficiency  away_shot_accuracy  \\\n",
       "0                            0.001077            0.001728   \n",
       "1                            0.000768            0.001563   \n",
       "2                            0.001008            0.001657   \n",
       "3                            0.001027            0.001780   \n",
       "4                            0.000877            0.001639   \n",
       "...                               ...                 ...   \n",
       "7028                         0.000812            0.001978   \n",
       "7029                         0.002274            0.002634   \n",
       "7030                         0.000677            0.002166   \n",
       "7031                         0.001110            0.002039   \n",
       "7032                         0.000580            0.002164   \n",
       "\n",
       "      away_shot_efficiency  away_opposition_shot_accuracy  \\\n",
       "0                 0.000686                       0.001486   \n",
       "1                 0.000924                       0.001529   \n",
       "2                 0.000702                       0.001731   \n",
       "3                 0.000633                       0.001625   \n",
       "4                 0.000492                       0.001749   \n",
       "...                    ...                            ...   \n",
       "7028              0.000700                       0.002355   \n",
       "7029              0.000634                       0.002055   \n",
       "7030              0.001476                       0.002008   \n",
       "7031              0.000823                       0.001754   \n",
       "7032              0.000808                       0.001700   \n",
       "\n",
       "      away_opposition_shot_efficiency  \n",
       "0                            0.000713  \n",
       "1                            0.001847  \n",
       "2                            0.001227  \n",
       "3                            0.000437  \n",
       "4                            0.000837  \n",
       "...                               ...  \n",
       "7028                         0.001311  \n",
       "7029                         0.004022  \n",
       "7030                         0.000680  \n",
       "7031                         0.001248  \n",
       "7032                         0.001618  \n",
       "\n",
       "[7033 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "colab_type": "code",
    "id": "tPTv1eKnaTy6",
    "outputId": "a438f9c7-fdce-4e67-a4fc-8af1bf8e89e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-possession</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>home-opposition_possession</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-possession</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "      <th>away-opposition_possession</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.003146</td>\n",
       "      <td>0.006291</td>\n",
       "      <td>0.011534</td>\n",
       "      <td>0.016777</td>\n",
       "      <td>0.143652</td>\n",
       "      <td>0.070253</td>\n",
       "      <td>0.504354</td>\n",
       "      <td>0.122681</td>\n",
       "      <td>0.055573</td>\n",
       "      <td>0.449829</td>\n",
       "      <td>0.008388</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015728</td>\n",
       "      <td>0.006291</td>\n",
       "      <td>0.168817</td>\n",
       "      <td>0.081787</td>\n",
       "      <td>0.505403</td>\n",
       "      <td>0.075496</td>\n",
       "      <td>0.031457</td>\n",
       "      <td>0.448781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.002343</td>\n",
       "      <td>0.005094</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.019356</td>\n",
       "      <td>0.012225</td>\n",
       "      <td>0.192540</td>\n",
       "      <td>0.090667</td>\n",
       "      <td>0.550114</td>\n",
       "      <td>0.070292</td>\n",
       "      <td>0.036674</td>\n",
       "      <td>0.375911</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.019356</td>\n",
       "      <td>0.008150</td>\n",
       "      <td>0.172165</td>\n",
       "      <td>0.096779</td>\n",
       "      <td>0.558264</td>\n",
       "      <td>0.115116</td>\n",
       "      <td>0.059086</td>\n",
       "      <td>0.368780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>0.019859</td>\n",
       "      <td>0.007317</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.015678</td>\n",
       "      <td>0.008362</td>\n",
       "      <td>0.168280</td>\n",
       "      <td>0.075256</td>\n",
       "      <td>0.498568</td>\n",
       "      <td>0.077346</td>\n",
       "      <td>0.032402</td>\n",
       "      <td>0.452578</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>0.009407</td>\n",
       "      <td>0.018814</td>\n",
       "      <td>0.137968</td>\n",
       "      <td>0.064803</td>\n",
       "      <td>0.443171</td>\n",
       "      <td>0.145285</td>\n",
       "      <td>0.074210</td>\n",
       "      <td>0.507975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>0.011549</td>\n",
       "      <td>0.107092</td>\n",
       "      <td>0.049346</td>\n",
       "      <td>0.460917</td>\n",
       "      <td>0.139640</td>\n",
       "      <td>0.080844</td>\n",
       "      <td>0.494515</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.005250</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>0.016799</td>\n",
       "      <td>0.121791</td>\n",
       "      <td>0.056696</td>\n",
       "      <td>0.430469</td>\n",
       "      <td>0.137540</td>\n",
       "      <td>0.067195</td>\n",
       "      <td>0.524963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002715</td>\n",
       "      <td>0.003394</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>0.015665</td>\n",
       "      <td>0.016709</td>\n",
       "      <td>0.130540</td>\n",
       "      <td>0.065792</td>\n",
       "      <td>0.454281</td>\n",
       "      <td>0.159781</td>\n",
       "      <td>0.076236</td>\n",
       "      <td>0.496054</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.013576</td>\n",
       "      <td>0.016709</td>\n",
       "      <td>0.107565</td>\n",
       "      <td>0.053260</td>\n",
       "      <td>0.456369</td>\n",
       "      <td>0.144117</td>\n",
       "      <td>0.079369</td>\n",
       "      <td>0.493965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6991</th>\n",
       "      <td>2</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>0.012650</td>\n",
       "      <td>0.084331</td>\n",
       "      <td>0.045328</td>\n",
       "      <td>0.436415</td>\n",
       "      <td>0.123335</td>\n",
       "      <td>0.063249</td>\n",
       "      <td>0.521801</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>0.022137</td>\n",
       "      <td>0.125443</td>\n",
       "      <td>0.061140</td>\n",
       "      <td>0.410062</td>\n",
       "      <td>0.118064</td>\n",
       "      <td>0.068519</td>\n",
       "      <td>0.549208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6992</th>\n",
       "      <td>2</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.022398</td>\n",
       "      <td>0.094925</td>\n",
       "      <td>0.050129</td>\n",
       "      <td>0.417030</td>\n",
       "      <td>0.098125</td>\n",
       "      <td>0.049062</td>\n",
       "      <td>0.553551</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.007466</td>\n",
       "      <td>0.022398</td>\n",
       "      <td>0.110924</td>\n",
       "      <td>0.058662</td>\n",
       "      <td>0.447961</td>\n",
       "      <td>0.067194</td>\n",
       "      <td>0.027731</td>\n",
       "      <td>0.522621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6993</th>\n",
       "      <td>2</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.004780</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.004249</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.129584</td>\n",
       "      <td>0.062667</td>\n",
       "      <td>0.476910</td>\n",
       "      <td>0.097719</td>\n",
       "      <td>0.053108</td>\n",
       "      <td>0.489656</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.015932</td>\n",
       "      <td>0.009559</td>\n",
       "      <td>0.089221</td>\n",
       "      <td>0.045673</td>\n",
       "      <td>0.525769</td>\n",
       "      <td>0.125335</td>\n",
       "      <td>0.059481</td>\n",
       "      <td>0.439734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6994</th>\n",
       "      <td>2</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.005523</td>\n",
       "      <td>0.009468</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.005260</td>\n",
       "      <td>0.012624</td>\n",
       "      <td>0.014728</td>\n",
       "      <td>0.130447</td>\n",
       "      <td>0.065223</td>\n",
       "      <td>0.557555</td>\n",
       "      <td>0.104147</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.399757</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.004208</td>\n",
       "      <td>0.011572</td>\n",
       "      <td>0.017884</td>\n",
       "      <td>0.108355</td>\n",
       "      <td>0.055756</td>\n",
       "      <td>0.460772</td>\n",
       "      <td>0.128343</td>\n",
       "      <td>0.056808</td>\n",
       "      <td>0.496540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>2</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>0.004406</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.006294</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.010491</td>\n",
       "      <td>0.008393</td>\n",
       "      <td>0.110153</td>\n",
       "      <td>0.068190</td>\n",
       "      <td>0.568601</td>\n",
       "      <td>0.132184</td>\n",
       "      <td>0.056650</td>\n",
       "      <td>0.386061</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>0.013638</td>\n",
       "      <td>0.019932</td>\n",
       "      <td>0.119595</td>\n",
       "      <td>0.066092</td>\n",
       "      <td>0.487822</td>\n",
       "      <td>0.111202</td>\n",
       "      <td>0.048258</td>\n",
       "      <td>0.466840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6996 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result  odds-home  odds-draw  odds-away  home-wins  home-draws  \\\n",
       "0          2   0.003670   0.003460   0.002202   0.001049    0.003146   \n",
       "1          2   0.003311   0.003311   0.002343   0.005094    0.002037   \n",
       "2          2   0.001254   0.006271   0.019859   0.007317    0.002090   \n",
       "3          0   0.002499   0.003465   0.003150   0.003150    0.003150   \n",
       "4          0   0.002715   0.003394   0.002924   0.004177    0.001044   \n",
       "...      ...        ...        ...        ...        ...         ...   \n",
       "6991       2   0.005271   0.004006   0.001792   0.004217    0.002108   \n",
       "6992       2   0.002133   0.003840   0.003946   0.003200    0.002133   \n",
       "6993       2   0.001912   0.003983   0.004780   0.003186    0.003186   \n",
       "6994       2   0.001399   0.005523   0.009468   0.002104    0.003156   \n",
       "6995       2   0.001752   0.004406   0.005508   0.006294    0.001049   \n",
       "\n",
       "      home-losses  home-goals  home-opposition-goals  home-shots  \\\n",
       "0        0.006291    0.011534               0.016777    0.143652   \n",
       "1        0.003056    0.019356               0.012225    0.192540   \n",
       "2        0.001045    0.015678               0.008362    0.168280   \n",
       "3        0.004200    0.009449               0.011549    0.107092   \n",
       "4        0.005222    0.015665               0.016709    0.130540   \n",
       "...           ...         ...                    ...         ...   \n",
       "6991     0.004217    0.010541               0.012650    0.084331   \n",
       "6992     0.005333    0.009599               0.022398    0.094925   \n",
       "6993     0.004249    0.008497               0.008497    0.129584   \n",
       "6994     0.005260    0.012624               0.014728    0.130447   \n",
       "6995     0.003147    0.010491               0.008393    0.110153   \n",
       "\n",
       "      home-shots_on_target  home-possession  home-opposition_shots  \\\n",
       "0                 0.070253         0.504354               0.122681   \n",
       "1                 0.090667         0.550114               0.070292   \n",
       "2                 0.075256         0.498568               0.077346   \n",
       "3                 0.049346         0.460917               0.139640   \n",
       "4                 0.065792         0.454281               0.159781   \n",
       "...                    ...              ...                    ...   \n",
       "6991              0.045328         0.436415               0.123335   \n",
       "6992              0.050129         0.417030               0.098125   \n",
       "6993              0.062667         0.476910               0.097719   \n",
       "6994              0.065223         0.557555               0.104147   \n",
       "6995              0.068190         0.568601               0.132184   \n",
       "\n",
       "      home-opposition_shots_on_target  home-opposition_possession  away-wins  \\\n",
       "0                            0.055573                    0.449829   0.008388   \n",
       "1                            0.036674                    0.375911   0.006112   \n",
       "2                            0.032402                    0.452578   0.002090   \n",
       "3                            0.080844                    0.494515   0.003150   \n",
       "4                            0.076236                    0.496054   0.004177   \n",
       "...                               ...                         ...        ...   \n",
       "6991                         0.063249                    0.521801   0.002108   \n",
       "6992                         0.049062                    0.553551   0.001067   \n",
       "6993                         0.053108                    0.489656   0.005311   \n",
       "6994                         0.052600                    0.399757   0.003156   \n",
       "6995                         0.056650                    0.386061   0.003147   \n",
       "\n",
       "      away-draws  away-losses  away-goals  away-opposition-goals  away-shots  \\\n",
       "0       0.002097     0.000000    0.015728               0.006291    0.168817   \n",
       "1       0.003056     0.001019    0.019356               0.008150    0.172165   \n",
       "2       0.002090     0.006271    0.009407               0.018814    0.137968   \n",
       "3       0.002100     0.005250    0.009449               0.016799    0.121791   \n",
       "4       0.003133     0.003133    0.013576               0.016709    0.107565   \n",
       "...          ...          ...         ...                    ...         ...   \n",
       "6991    0.004217     0.004217    0.010541               0.022137    0.125443   \n",
       "6992    0.004266     0.005333    0.007466               0.022398    0.110924   \n",
       "6993    0.002124     0.003186    0.015932               0.009559    0.089221   \n",
       "6994    0.003156     0.004208    0.011572               0.017884    0.108355   \n",
       "6995    0.002098     0.005245    0.013638               0.019932    0.119595   \n",
       "\n",
       "      away-shots_on_target  away-possession  away-opposition_shots  \\\n",
       "0                 0.081787         0.505403               0.075496   \n",
       "1                 0.096779         0.558264               0.115116   \n",
       "2                 0.064803         0.443171               0.145285   \n",
       "3                 0.056696         0.430469               0.137540   \n",
       "4                 0.053260         0.456369               0.144117   \n",
       "...                    ...              ...                    ...   \n",
       "6991              0.061140         0.410062               0.118064   \n",
       "6992              0.058662         0.447961               0.067194   \n",
       "6993              0.045673         0.525769               0.125335   \n",
       "6994              0.055756         0.460772               0.128343   \n",
       "6995              0.066092         0.487822               0.111202   \n",
       "\n",
       "      away-opposition_shots_on_target  away-opposition_possession  \n",
       "0                            0.031457                    0.448781  \n",
       "1                            0.059086                    0.368780  \n",
       "2                            0.074210                    0.507975  \n",
       "3                            0.067195                    0.524963  \n",
       "4                            0.079369                    0.493965  \n",
       "...                               ...                         ...  \n",
       "6991                         0.068519                    0.549208  \n",
       "6992                         0.027731                    0.522621  \n",
       "6993                         0.059481                    0.439734  \n",
       "6994                         0.056808                    0.496540  \n",
       "6995                         0.048258                    0.466840  \n",
       "\n",
       "[6996 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "colab_type": "code",
    "id": "wHXHdefzaUcP",
    "outputId": "55ce72c7-6329-4541-c391-a10303b02d3c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-possession</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>home-opposition_possession</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-possession</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "      <th>away-opposition_possession</th>\n",
       "      <th>home_shot_accuracy</th>\n",
       "      <th>home_shot_efficiency</th>\n",
       "      <th>home_opposition_shot_accuracy</th>\n",
       "      <th>home_opposition_shot_efficiency</th>\n",
       "      <th>away_shot_accuracy</th>\n",
       "      <th>away_shot_efficiency</th>\n",
       "      <th>away_opposition_shot_accuracy</th>\n",
       "      <th>away_opposition_shot_efficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.003146</td>\n",
       "      <td>0.006291</td>\n",
       "      <td>0.011534</td>\n",
       "      <td>0.016777</td>\n",
       "      <td>0.143652</td>\n",
       "      <td>0.070253</td>\n",
       "      <td>0.504354</td>\n",
       "      <td>0.122681</td>\n",
       "      <td>0.055573</td>\n",
       "      <td>0.449829</td>\n",
       "      <td>0.008388</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015728</td>\n",
       "      <td>0.006291</td>\n",
       "      <td>0.168817</td>\n",
       "      <td>0.081787</td>\n",
       "      <td>0.505402</td>\n",
       "      <td>0.075496</td>\n",
       "      <td>0.031457</td>\n",
       "      <td>0.448780</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.002343</td>\n",
       "      <td>0.005094</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.019356</td>\n",
       "      <td>0.012225</td>\n",
       "      <td>0.192540</td>\n",
       "      <td>0.090667</td>\n",
       "      <td>0.550114</td>\n",
       "      <td>0.070292</td>\n",
       "      <td>0.036674</td>\n",
       "      <td>0.375911</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.019356</td>\n",
       "      <td>0.008150</td>\n",
       "      <td>0.172165</td>\n",
       "      <td>0.096779</td>\n",
       "      <td>0.558263</td>\n",
       "      <td>0.115116</td>\n",
       "      <td>0.059086</td>\n",
       "      <td>0.368780</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.000141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>0.019859</td>\n",
       "      <td>0.007317</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.015678</td>\n",
       "      <td>0.008362</td>\n",
       "      <td>0.168280</td>\n",
       "      <td>0.075255</td>\n",
       "      <td>0.498567</td>\n",
       "      <td>0.077346</td>\n",
       "      <td>0.032402</td>\n",
       "      <td>0.452578</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>0.009407</td>\n",
       "      <td>0.018814</td>\n",
       "      <td>0.137968</td>\n",
       "      <td>0.064803</td>\n",
       "      <td>0.443171</td>\n",
       "      <td>0.145285</td>\n",
       "      <td>0.074210</td>\n",
       "      <td>0.507974</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.000265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>0.011549</td>\n",
       "      <td>0.107092</td>\n",
       "      <td>0.049346</td>\n",
       "      <td>0.460917</td>\n",
       "      <td>0.139640</td>\n",
       "      <td>0.080844</td>\n",
       "      <td>0.494515</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.005250</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>0.016799</td>\n",
       "      <td>0.121791</td>\n",
       "      <td>0.056696</td>\n",
       "      <td>0.430469</td>\n",
       "      <td>0.137540</td>\n",
       "      <td>0.067195</td>\n",
       "      <td>0.524962</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002715</td>\n",
       "      <td>0.003394</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>0.015665</td>\n",
       "      <td>0.016709</td>\n",
       "      <td>0.130540</td>\n",
       "      <td>0.065792</td>\n",
       "      <td>0.454280</td>\n",
       "      <td>0.159781</td>\n",
       "      <td>0.076236</td>\n",
       "      <td>0.496053</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.013576</td>\n",
       "      <td>0.016709</td>\n",
       "      <td>0.107565</td>\n",
       "      <td>0.053260</td>\n",
       "      <td>0.456369</td>\n",
       "      <td>0.144117</td>\n",
       "      <td>0.079369</td>\n",
       "      <td>0.493965</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6991</th>\n",
       "      <td>2</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>0.012650</td>\n",
       "      <td>0.084331</td>\n",
       "      <td>0.045328</td>\n",
       "      <td>0.436415</td>\n",
       "      <td>0.123335</td>\n",
       "      <td>0.063249</td>\n",
       "      <td>0.521800</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>0.022137</td>\n",
       "      <td>0.125443</td>\n",
       "      <td>0.061140</td>\n",
       "      <td>0.410061</td>\n",
       "      <td>0.118064</td>\n",
       "      <td>0.068519</td>\n",
       "      <td>0.549208</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.000341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6992</th>\n",
       "      <td>2</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.022398</td>\n",
       "      <td>0.094925</td>\n",
       "      <td>0.050129</td>\n",
       "      <td>0.417030</td>\n",
       "      <td>0.098125</td>\n",
       "      <td>0.049062</td>\n",
       "      <td>0.553551</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.007466</td>\n",
       "      <td>0.022398</td>\n",
       "      <td>0.110923</td>\n",
       "      <td>0.058661</td>\n",
       "      <td>0.447960</td>\n",
       "      <td>0.067194</td>\n",
       "      <td>0.027731</td>\n",
       "      <td>0.522620</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6993</th>\n",
       "      <td>2</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.004780</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.004249</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.129583</td>\n",
       "      <td>0.062667</td>\n",
       "      <td>0.476909</td>\n",
       "      <td>0.097719</td>\n",
       "      <td>0.053108</td>\n",
       "      <td>0.489655</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.015932</td>\n",
       "      <td>0.009559</td>\n",
       "      <td>0.089221</td>\n",
       "      <td>0.045673</td>\n",
       "      <td>0.525769</td>\n",
       "      <td>0.125335</td>\n",
       "      <td>0.059481</td>\n",
       "      <td>0.439734</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.000171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6994</th>\n",
       "      <td>2</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.005523</td>\n",
       "      <td>0.009468</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.005260</td>\n",
       "      <td>0.012624</td>\n",
       "      <td>0.014728</td>\n",
       "      <td>0.130447</td>\n",
       "      <td>0.065223</td>\n",
       "      <td>0.557555</td>\n",
       "      <td>0.104147</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.399756</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.004208</td>\n",
       "      <td>0.011572</td>\n",
       "      <td>0.017884</td>\n",
       "      <td>0.108355</td>\n",
       "      <td>0.055755</td>\n",
       "      <td>0.460772</td>\n",
       "      <td>0.128343</td>\n",
       "      <td>0.056807</td>\n",
       "      <td>0.496539</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>2</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>0.004406</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.006294</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.010491</td>\n",
       "      <td>0.008393</td>\n",
       "      <td>0.110153</td>\n",
       "      <td>0.068190</td>\n",
       "      <td>0.568600</td>\n",
       "      <td>0.132184</td>\n",
       "      <td>0.056650</td>\n",
       "      <td>0.386061</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>0.013638</td>\n",
       "      <td>0.019932</td>\n",
       "      <td>0.119595</td>\n",
       "      <td>0.066092</td>\n",
       "      <td>0.487821</td>\n",
       "      <td>0.111202</td>\n",
       "      <td>0.048258</td>\n",
       "      <td>0.466840</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6996 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result  odds-home  odds-draw  odds-away  home-wins  home-draws  \\\n",
       "0          2   0.003670   0.003460   0.002202   0.001049    0.003146   \n",
       "1          2   0.003311   0.003311   0.002343   0.005094    0.002037   \n",
       "2          2   0.001254   0.006271   0.019859   0.007317    0.002090   \n",
       "3          0   0.002499   0.003465   0.003150   0.003150    0.003150   \n",
       "4          0   0.002715   0.003394   0.002924   0.004177    0.001044   \n",
       "...      ...        ...        ...        ...        ...         ...   \n",
       "6991       2   0.005271   0.004006   0.001792   0.004217    0.002108   \n",
       "6992       2   0.002133   0.003840   0.003946   0.003200    0.002133   \n",
       "6993       2   0.001912   0.003983   0.004780   0.003186    0.003186   \n",
       "6994       2   0.001399   0.005523   0.009468   0.002104    0.003156   \n",
       "6995       2   0.001752   0.004406   0.005508   0.006294    0.001049   \n",
       "\n",
       "      home-losses  home-goals  home-opposition-goals  home-shots  \\\n",
       "0        0.006291    0.011534               0.016777    0.143652   \n",
       "1        0.003056    0.019356               0.012225    0.192540   \n",
       "2        0.001045    0.015678               0.008362    0.168280   \n",
       "3        0.004200    0.009449               0.011549    0.107092   \n",
       "4        0.005222    0.015665               0.016709    0.130540   \n",
       "...           ...         ...                    ...         ...   \n",
       "6991     0.004217    0.010541               0.012650    0.084331   \n",
       "6992     0.005333    0.009599               0.022398    0.094925   \n",
       "6993     0.004249    0.008497               0.008497    0.129583   \n",
       "6994     0.005260    0.012624               0.014728    0.130447   \n",
       "6995     0.003147    0.010491               0.008393    0.110153   \n",
       "\n",
       "      home-shots_on_target  home-possession  home-opposition_shots  \\\n",
       "0                 0.070253         0.504354               0.122681   \n",
       "1                 0.090667         0.550114               0.070292   \n",
       "2                 0.075255         0.498567               0.077346   \n",
       "3                 0.049346         0.460917               0.139640   \n",
       "4                 0.065792         0.454280               0.159781   \n",
       "...                    ...              ...                    ...   \n",
       "6991              0.045328         0.436415               0.123335   \n",
       "6992              0.050129         0.417030               0.098125   \n",
       "6993              0.062667         0.476909               0.097719   \n",
       "6994              0.065223         0.557555               0.104147   \n",
       "6995              0.068190         0.568600               0.132184   \n",
       "\n",
       "      home-opposition_shots_on_target  home-opposition_possession  away-wins  \\\n",
       "0                            0.055573                    0.449829   0.008388   \n",
       "1                            0.036674                    0.375911   0.006112   \n",
       "2                            0.032402                    0.452578   0.002090   \n",
       "3                            0.080844                    0.494515   0.003150   \n",
       "4                            0.076236                    0.496053   0.004177   \n",
       "...                               ...                         ...        ...   \n",
       "6991                         0.063249                    0.521800   0.002108   \n",
       "6992                         0.049062                    0.553551   0.001067   \n",
       "6993                         0.053108                    0.489655   0.005311   \n",
       "6994                         0.052600                    0.399756   0.003156   \n",
       "6995                         0.056650                    0.386061   0.003147   \n",
       "\n",
       "      away-draws  away-losses  away-goals  away-opposition-goals  away-shots  \\\n",
       "0       0.002097     0.000000    0.015728               0.006291    0.168817   \n",
       "1       0.003056     0.001019    0.019356               0.008150    0.172165   \n",
       "2       0.002090     0.006271    0.009407               0.018814    0.137968   \n",
       "3       0.002100     0.005250    0.009449               0.016799    0.121791   \n",
       "4       0.003133     0.003133    0.013576               0.016709    0.107565   \n",
       "...          ...          ...         ...                    ...         ...   \n",
       "6991    0.004217     0.004217    0.010541               0.022137    0.125443   \n",
       "6992    0.004266     0.005333    0.007466               0.022398    0.110923   \n",
       "6993    0.002124     0.003186    0.015932               0.009559    0.089221   \n",
       "6994    0.003156     0.004208    0.011572               0.017884    0.108355   \n",
       "6995    0.002098     0.005245    0.013638               0.019932    0.119595   \n",
       "\n",
       "      away-shots_on_target  away-possession  away-opposition_shots  \\\n",
       "0                 0.081787         0.505402               0.075496   \n",
       "1                 0.096779         0.558263               0.115116   \n",
       "2                 0.064803         0.443171               0.145285   \n",
       "3                 0.056696         0.430469               0.137540   \n",
       "4                 0.053260         0.456369               0.144117   \n",
       "...                    ...              ...                    ...   \n",
       "6991              0.061140         0.410061               0.118064   \n",
       "6992              0.058661         0.447960               0.067194   \n",
       "6993              0.045673         0.525769               0.125335   \n",
       "6994              0.055755         0.460772               0.128343   \n",
       "6995              0.066092         0.487821               0.111202   \n",
       "\n",
       "      away-opposition_shots_on_target  away-opposition_possession  \\\n",
       "0                            0.031457                    0.448780   \n",
       "1                            0.059086                    0.368780   \n",
       "2                            0.074210                    0.507974   \n",
       "3                            0.067195                    0.524962   \n",
       "4                            0.079369                    0.493965   \n",
       "...                               ...                         ...   \n",
       "6991                         0.068519                    0.549208   \n",
       "6992                         0.027731                    0.522620   \n",
       "6993                         0.059481                    0.439734   \n",
       "6994                         0.056807                    0.496539   \n",
       "6995                         0.048258                    0.466840   \n",
       "\n",
       "      home_shot_accuracy  home_shot_efficiency  home_opposition_shot_accuracy  \\\n",
       "0               0.000513              0.000172                       0.000475   \n",
       "1               0.000480              0.000217                       0.000532   \n",
       "2               0.000467              0.000218                       0.000438   \n",
       "3               0.000484              0.000201                       0.000608   \n",
       "4               0.000526              0.000249                       0.000498   \n",
       "...                  ...                   ...                            ...   \n",
       "6991            0.000567              0.000245                       0.000541   \n",
       "6992            0.000563              0.000204                       0.000533   \n",
       "6993            0.000514              0.000144                       0.000577   \n",
       "6994            0.000526              0.000204                       0.000531   \n",
       "6995            0.000649              0.000161                       0.000450   \n",
       "\n",
       "      home_opposition_shot_efficiency  away_shot_accuracy  \\\n",
       "0                            0.000317            0.000508   \n",
       "1                            0.000340            0.000573   \n",
       "2                            0.000270            0.000491   \n",
       "3                            0.000150            0.000489   \n",
       "4                            0.000229            0.000517   \n",
       "...                               ...                 ...   \n",
       "6991                         0.000211            0.000514   \n",
       "6992                         0.000487            0.000564   \n",
       "6993                         0.000170            0.000544   \n",
       "6994                         0.000295            0.000541   \n",
       "6995                         0.000155            0.000580   \n",
       "\n",
       "      away_shot_efficiency  away_opposition_shot_accuracy  \\\n",
       "0                 0.000202                       0.000437   \n",
       "1                 0.000204                       0.000523   \n",
       "2                 0.000152                       0.000534   \n",
       "3                 0.000175                       0.000513   \n",
       "4                 0.000266                       0.000575   \n",
       "...                    ...                            ...   \n",
       "6991              0.000182                       0.000612   \n",
       "6992              0.000136                       0.000440   \n",
       "6993              0.000371                       0.000504   \n",
       "6994              0.000218                       0.000466   \n",
       "6995              0.000216                       0.000455   \n",
       "\n",
       "      away_opposition_shot_efficiency  \n",
       "0                            0.000210  \n",
       "1                            0.000141  \n",
       "2                            0.000265  \n",
       "3                            0.000262  \n",
       "4                            0.000220  \n",
       "...                               ...  \n",
       "6991                         0.000341  \n",
       "6992                         0.000861  \n",
       "6993                         0.000171  \n",
       "6994                         0.000331  \n",
       "6995                         0.000433  \n",
       "\n",
       "[6996 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Backup:\n",
    "\n",
    "## I. First Attempt:\n",
    "\n",
    "### Model01:\n",
    "\n",
    "model01 = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(11, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "Test Score: 0.9784467357591566\n",
    "Test Accuracy: 0.5393474\n",
    "### Model02:\n",
    "\n",
    "model02 = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.Dense(32, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "Test Score: 0.9985063346949491\n",
    "Test Accuracy: 0.5113636\n",
    "### Model03:\n",
    "\n",
    "model03 = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(20, activation='relu'),\n",
    "  layers.Dense(10, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "Test Score: 0.9796081943945452\n",
    "Test Accuracy: 0.5255682\n",
    "### Model04:\n",
    "\n",
    "model04 = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(50, activation='relu'),\n",
    "  layers.Dense(30, activation='relu'),\n",
    "  layers.Dense(10, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "Test Score: 0.970786578314645\n",
    "Test Accuracy: 0.5228571\n",
    "### Model05:\n",
    "\n",
    "model05 = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(66, activation='relu'),\n",
    "  layers.Dense(55, activation='relu'),\n",
    "  layers.Dense(44, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(22, activation='relu'),\n",
    "  layers.Dense(11, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "Test Score: 1.013617993082319\n",
    "Test Accuracy: 0.52\n",
    "\n",
    "\n",
    "## II. Layer & Neuron Variantion:\n",
    "### 1 Hidden Layer:\n",
    "#### High Amount of Neurons (H):\n",
    "##### Model01:\n",
    "\n",
    "model01-H1-H = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H1-H = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H1-H = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H1-H = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H1-H = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "##### Model01:\n",
    "\n",
    "model01-H1-M = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H1-M = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H1-M = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H1-M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H1-M = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "##### Model01:\n",
    "\n",
    "model01-H1-L = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H1-L = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H1-L = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H1-L = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H1-L = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "### 2 Hidden Layers:\n",
    "#### High Amount of Neurons (H):\n",
    "##### Model01:\n",
    "\n",
    "model01-H2-H = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H2-H = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H2-H = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H2-H = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H2-H = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "##### Model01:\n",
    "\n",
    "model01-H2-M = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H2-M = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H2-M = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H2-M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H2-M = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "##### Model01:\n",
    "\n",
    "model01-H2-L = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H2-L = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H2-L = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H2-L = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H2-L = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "### 3 Hidden Layers:\n",
    "#### High Amount of Neurons (H):\n",
    "##### Model01:\n",
    "\n",
    "model01-H3-H = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H3-H = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H3-H = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H3-H = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H3-H = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "##### Model01:\n",
    "\n",
    "model01-H3-M = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H3-M = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H3-M = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H3-M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H3-M = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "##### Model01:\n",
    "\n",
    "model01-H3-L = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H3-L = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H3-L = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H3-L = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H3-L = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Funnel Architecture:\n",
    "##### Model01:\n",
    "\n",
    "model01-H3-F = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(10, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H3-F = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(18, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H3-F = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(22, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(11, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H3-F = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(20, activation='relu'),\n",
    "  layers.Dense(15, activation='relu'),\n",
    "  layers.Dense(11, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H3-F = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(19, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "### 4 Hidden Layers:\n",
    "#### High Amount of Neurons (H):\n",
    "##### Model01:\n",
    "\n",
    "model01-H4-H = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H4-H = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H4-H = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H4-H = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H4-H = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "##### Model01:\n",
    "\n",
    "model01-H4-M = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H4-M = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H4-M = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H4-M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H4-M = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "##### Model01:\n",
    "\n",
    "model01-H4-L = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H4-L = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H4-L = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H4-L = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H4-L = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Funnel Architecture:\n",
    "##### Model01:\n",
    "\n",
    "model01-H4-F = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(10, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H4-F = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(18, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H4-F = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(22, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(11, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H4-F = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(20, activation='relu'),\n",
    "  layers.Dense(15, activation='relu'),\n",
    "  layers.Dense(11, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H4-F = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(19, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HtHfSEgO6sUN",
    "outputId": "b7fd6a48-30f1-470e-f92b-118a7046a09a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lisa\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 406\n",
      "Trainable params: 406\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, acc:0.2930,  loss:1.1098,  val_acc:0.3333,  val_loss:1.0958,  \n",
      "....................................................................................................\n",
      "Epoch: 100, acc:0.5374,  loss:0.9680,  val_acc:0.5176,  val_loss:0.9858,  \n",
      "....................................................................................................\n",
      "Epoch: 200, acc:0.5358,  loss:0.9669,  val_acc:0.5155,  val_loss:0.9847,  \n",
      ".....................................................Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 90        \n",
      "=================================================================\n",
      "Total params: 1,830\n",
      "Trainable params: 1,830\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, acc:0.2667,  loss:1.1056,  val_acc:0.4428,  val_loss:1.0902,  \n",
      "....................................................................................................\n",
      "Epoch: 100, acc:0.5320,  loss:0.9729,  val_acc:0.5228,  val_loss:0.9984,  \n",
      "....................................................................................................\n",
      "Epoch: 200, acc:0.5350,  loss:0.9651,  val_acc:0.5213,  val_loss:0.9953,  \n",
      "....................................................................................................\n",
      "Epoch: 300, acc:0.5402,  loss:0.9602,  val_acc:0.5153,  val_loss:0.9916,  \n",
      "....................................................................................................\n",
      "Epoch: 400, acc:0.5417,  loss:0.9577,  val_acc:0.5131,  val_loss:0.9908,  \n",
      "....................................................................................................\n",
      "Epoch: 500, acc:0.5434,  loss:0.9562,  val_acc:0.5131,  val_loss:0.9905,  \n",
      ".............................................................Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 78        \n",
      "=================================================================\n",
      "Total params: 1,378\n",
      "Trainable params: 1,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, acc:0.4626,  loss:1.0795,  val_acc:0.4519,  val_loss:1.0805,  \n",
      "....................................................................................................\n",
      "Epoch: 100, acc:0.5226,  loss:0.9870,  val_acc:0.5248,  val_loss:0.9850,  \n",
      "....................................................................................................\n",
      "Epoch: 200, acc:0.5280,  loss:0.9789,  val_acc:0.5293,  val_loss:0.9792,  \n",
      "....................................................................................................\n",
      "Epoch: 300, acc:0.5331,  loss:0.9733,  val_acc:0.5353,  val_loss:0.9749,  \n",
      "....................................................................................................\n",
      "Epoch: 400, acc:0.5335,  loss:0.9700,  val_acc:0.5308,  val_loss:0.9750,  \n",
      "....................................................................................................\n",
      "Epoch: 500, acc:0.5324,  loss:0.9681,  val_acc:0.5316,  val_loss:0.9744,  \n",
      "....................................................................................................\n",
      "Epoch: 600, acc:0.5342,  loss:0.9669,  val_acc:0.5406,  val_loss:0.9722,  \n",
      "....................................................................................................\n",
      "Epoch: 700, acc:0.5359,  loss:0.9655,  val_acc:0.5353,  val_loss:0.9721,  \n",
      "....................................................................................................\n",
      "Epoch: 800, acc:0.5327,  loss:0.9641,  val_acc:0.5406,  val_loss:0.9709,  \n",
      "....................................................................................................\n",
      "Epoch: 900, acc:0.5363,  loss:0.9636,  val_acc:0.5383,  val_loss:0.9708,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, acc:0.5356,  loss:0.9627,  val_acc:0.5398,  val_loss:0.9718,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, acc:0.5369,  loss:0.9616,  val_acc:0.5406,  val_loss:0.9705,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, acc:0.5397,  loss:0.9614,  val_acc:0.5421,  val_loss:0.9685,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, acc:0.5367,  loss:0.9609,  val_acc:0.5414,  val_loss:0.9700,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, acc:0.5384,  loss:0.9600,  val_acc:0.5421,  val_loss:0.9688,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, acc:0.5403,  loss:0.9605,  val_acc:0.5383,  val_loss:0.9731,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, acc:0.5391,  loss:0.9591,  val_acc:0.5414,  val_loss:0.9693,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, acc:0.5403,  loss:0.9588,  val_acc:0.5406,  val_loss:0.9688,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, acc:0.5412,  loss:0.9585,  val_acc:0.5414,  val_loss:0.9683,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, acc:0.5395,  loss:0.9580,  val_acc:0.5414,  val_loss:0.9679,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, acc:0.5393,  loss:0.9579,  val_acc:0.5444,  val_loss:0.9690,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, acc:0.5397,  loss:0.9575,  val_acc:0.5391,  val_loss:0.9686,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, acc:0.5404,  loss:0.9573,  val_acc:0.5414,  val_loss:0.9683,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, acc:0.5395,  loss:0.9571,  val_acc:0.5406,  val_loss:0.9673,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 2400, acc:0.5395,  loss:0.9567,  val_acc:0.5406,  val_loss:0.9675,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, acc:0.5393,  loss:0.9566,  val_acc:0.5421,  val_loss:0.9672,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, acc:0.5397,  loss:0.9563,  val_acc:0.5414,  val_loss:0.9674,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, acc:0.5408,  loss:0.9565,  val_acc:0.5429,  val_loss:0.9664,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, acc:0.5418,  loss:0.9560,  val_acc:0.5414,  val_loss:0.9664,  \n",
      "..............................................Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 102       \n",
      "=================================================================\n",
      "Total params: 2,346\n",
      "Trainable params: 2,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, acc:0.4631,  loss:1.0854,  val_acc:0.4496,  val_loss:1.0782,  \n",
      "....................................................................................................\n",
      "Epoch: 100, acc:0.5241,  loss:0.9862,  val_acc:0.5068,  val_loss:1.0028,  \n",
      "....................................................................................................\n",
      "Epoch: 200, acc:0.5312,  loss:0.9792,  val_acc:0.5038,  val_loss:0.9964,  \n",
      "....................................................................................................\n",
      "Epoch: 300, acc:0.5342,  loss:0.9744,  val_acc:0.5098,  val_loss:0.9913,  \n",
      "....................................................................................................\n",
      "Epoch: 400, acc:0.5401,  loss:0.9715,  val_acc:0.5098,  val_loss:0.9881,  \n",
      "....................................................................................................\n",
      "Epoch: 500, acc:0.5374,  loss:0.9694,  val_acc:0.5113,  val_loss:0.9852,  \n",
      "....................................................................................................\n",
      "Epoch: 600, acc:0.5412,  loss:0.9667,  val_acc:0.5113,  val_loss:0.9830,  \n",
      "....................................................................................................\n",
      "Epoch: 700, acc:0.5408,  loss:0.9661,  val_acc:0.5105,  val_loss:0.9815,  \n",
      "....................................................................................................\n",
      "Epoch: 800, acc:0.5425,  loss:0.9653,  val_acc:0.5083,  val_loss:0.9817,  \n",
      "....................................................................................................\n",
      "Epoch: 900, acc:0.5429,  loss:0.9645,  val_acc:0.5098,  val_loss:0.9792,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, acc:0.5436,  loss:0.9630,  val_acc:0.5045,  val_loss:0.9791,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, acc:0.5438,  loss:0.9622,  val_acc:0.5090,  val_loss:0.9783,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, acc:0.5446,  loss:0.9615,  val_acc:0.5075,  val_loss:0.9772,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, acc:0.5446,  loss:0.9611,  val_acc:0.5075,  val_loss:0.9770,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, acc:0.5457,  loss:0.9606,  val_acc:0.5090,  val_loss:0.9765,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, acc:0.5463,  loss:0.9607,  val_acc:0.5090,  val_loss:0.9767,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, acc:0.5472,  loss:0.9604,  val_acc:0.5128,  val_loss:0.9762,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, acc:0.5474,  loss:0.9598,  val_acc:0.5105,  val_loss:0.9760,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, acc:0.5465,  loss:0.9595,  val_acc:0.5105,  val_loss:0.9759,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, acc:0.5474,  loss:0.9597,  val_acc:0.5075,  val_loss:0.9760,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, acc:0.5455,  loss:0.9598,  val_acc:0.5113,  val_loss:0.9766,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, acc:0.5457,  loss:0.9595,  val_acc:0.5128,  val_loss:0.9754,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, acc:0.5465,  loss:0.9588,  val_acc:0.5128,  val_loss:0.9758,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, acc:0.5468,  loss:0.9587,  val_acc:0.5143,  val_loss:0.9767,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, acc:0.5457,  loss:0.9589,  val_acc:0.5090,  val_loss:0.9756,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, acc:0.5480,  loss:0.9584,  val_acc:0.5120,  val_loss:0.9752,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, acc:0.5467,  loss:0.9584,  val_acc:0.5105,  val_loss:0.9754,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, acc:0.5446,  loss:0.9584,  val_acc:0.5120,  val_loss:0.9755,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, acc:0.5472,  loss:0.9579,  val_acc:0.5128,  val_loss:0.9752,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, acc:0.5480,  loss:0.9578,  val_acc:0.5113,  val_loss:0.9756,  \n",
      "....................................................................................................\n",
      "Epoch: 3000, acc:0.5485,  loss:0.9578,  val_acc:0.5098,  val_loss:0.9757,  \n",
      ".........Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 9)                 126       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 3)                 30        \n",
      "=================================================================\n",
      "Total params: 338\n",
      "Trainable params: 338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, acc:0.4472,  loss:1.0843,  val_acc:0.4478,  val_loss:1.0767,  \n",
      "....................................................................................................\n",
      "Epoch: 100, acc:0.5360,  loss:0.9679,  val_acc:0.5150,  val_loss:0.9851,  \n",
      "....................................................................................................\n",
      "Epoch: 200, acc:0.5358,  loss:0.9666,  val_acc:0.5150,  val_loss:0.9857,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....................................................Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 14)                420       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 3)                 45        \n",
      "=================================================================\n",
      "Total params: 1,335\n",
      "Trainable params: 1,335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, acc:0.3222,  loss:1.0988,  val_acc:0.4435,  val_loss:1.0906,  \n",
      "....................................................................................................\n",
      "Epoch: 100, acc:0.5299,  loss:0.9762,  val_acc:0.5153,  val_loss:1.0007,  \n",
      "....................................................................................................\n",
      "Epoch: 200, acc:0.5342,  loss:0.9676,  val_acc:0.5206,  val_loss:0.9947,  \n",
      "....................................................................................................\n",
      "Epoch: 300, acc:0.5400,  loss:0.9629,  val_acc:0.5153,  val_loss:0.9926,  \n",
      "....................................................................................................\n",
      "Epoch: 400, acc:0.5415,  loss:0.9605,  val_acc:0.5153,  val_loss:0.9920,  \n",
      "....................................................................................................\n",
      "Epoch: 500, acc:0.5425,  loss:0.9587,  val_acc:0.5138,  val_loss:0.9915,  \n",
      "....................................................................................................\n",
      "Epoch: 600, acc:0.5425,  loss:0.9576,  val_acc:0.5123,  val_loss:0.9917,  \n",
      "....................................................................................................\n",
      "Epoch: 700, acc:0.5438,  loss:0.9573,  val_acc:0.5108,  val_loss:0.9903,  \n",
      "....................................................................................................\n",
      "Epoch: 800, acc:0.5460,  loss:0.9569,  val_acc:0.5138,  val_loss:0.9916,  \n",
      "....................................................................................................\n",
      "Epoch: 900, acc:0.5453,  loss:0.9567,  val_acc:0.5123,  val_loss:0.9909,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, acc:0.5449,  loss:0.9574,  val_acc:0.5108,  val_loss:0.9899,  \n",
      "...........Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 13)                338       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 1,030\n",
      "Trainable params: 1,030\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, acc:0.4626,  loss:1.0719,  val_acc:0.4519,  val_loss:1.0708,  \n",
      "....................................................................................................\n",
      "Epoch: 100, acc:0.5196,  loss:0.9902,  val_acc:0.5263,  val_loss:0.9857,  \n",
      "....................................................................................................\n",
      "Epoch: 200, acc:0.5241,  loss:0.9814,  val_acc:0.5308,  val_loss:0.9798,  \n",
      "....................................................................................................\n",
      "Epoch: 300, acc:0.5322,  loss:0.9757,  val_acc:0.5376,  val_loss:0.9761,  \n",
      "....................................................................................................\n",
      "Epoch: 400, acc:0.5324,  loss:0.9722,  val_acc:0.5301,  val_loss:0.9776,  \n",
      "....................................................................................................\n",
      "Epoch: 500, acc:0.5337,  loss:0.9694,  val_acc:0.5376,  val_loss:0.9739,  \n",
      "....................................................................................................\n",
      "Epoch: 600, acc:0.5344,  loss:0.9679,  val_acc:0.5414,  val_loss:0.9743,  \n",
      "....................................................................................................\n",
      "Epoch: 700, acc:0.5335,  loss:0.9667,  val_acc:0.5331,  val_loss:0.9759,  \n",
      "....................................................................................................\n",
      "Epoch: 800, acc:0.5342,  loss:0.9653,  val_acc:0.5429,  val_loss:0.9734,  \n",
      "....................................................................................................\n",
      "Epoch: 900, acc:0.5352,  loss:0.9644,  val_acc:0.5414,  val_loss:0.9721,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, acc:0.5371,  loss:0.9648,  val_acc:0.5391,  val_loss:0.9718,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, acc:0.5356,  loss:0.9630,  val_acc:0.5398,  val_loss:0.9723,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, acc:0.5359,  loss:0.9627,  val_acc:0.5398,  val_loss:0.9731,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, acc:0.5367,  loss:0.9619,  val_acc:0.5376,  val_loss:0.9714,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, acc:0.5384,  loss:0.9619,  val_acc:0.5414,  val_loss:0.9721,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, acc:0.5393,  loss:0.9610,  val_acc:0.5406,  val_loss:0.9705,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, acc:0.5357,  loss:0.9611,  val_acc:0.5421,  val_loss:0.9723,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, acc:0.5380,  loss:0.9616,  val_acc:0.5398,  val_loss:0.9710,  \n",
      ".Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                544       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 1,717\n",
      "Trainable params: 1,717\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, acc:0.4631,  loss:1.0598,  val_acc:0.4496,  val_loss:1.0649,  \n",
      "....................................................................................................\n",
      "Epoch: 100, acc:0.5233,  loss:0.9874,  val_acc:0.5090,  val_loss:1.0041,  \n",
      "....................................................................................................\n",
      "Epoch: 200, acc:0.5307,  loss:0.9784,  val_acc:0.5180,  val_loss:0.9965,  \n",
      "....................................................................................................\n",
      "Epoch: 300, acc:0.5340,  loss:0.9745,  val_acc:0.5098,  val_loss:0.9915,  \n",
      "....................................................................................................\n",
      "Epoch: 400, acc:0.5397,  loss:0.9715,  val_acc:0.5090,  val_loss:0.9882,  \n",
      "....................................................................................................\n",
      "Epoch: 500, acc:0.5406,  loss:0.9693,  val_acc:0.5075,  val_loss:0.9860,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 600, acc:0.5386,  loss:0.9690,  val_acc:0.5068,  val_loss:0.9848,  \n",
      "....................................................................................................\n",
      "Epoch: 700, acc:0.5399,  loss:0.9682,  val_acc:0.5083,  val_loss:0.9829,  \n",
      "....................................................................................................\n",
      "Epoch: 800, acc:0.5418,  loss:0.9659,  val_acc:0.5105,  val_loss:0.9817,  \n",
      "....................................................................................................\n",
      "Epoch: 900, acc:0.5404,  loss:0.9650,  val_acc:0.5075,  val_loss:0.9814,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, acc:0.5433,  loss:0.9643,  val_acc:0.5150,  val_loss:0.9801,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, acc:0.5438,  loss:0.9638,  val_acc:0.5143,  val_loss:0.9794,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, acc:0.5435,  loss:0.9631,  val_acc:0.5105,  val_loss:0.9794,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, acc:0.5457,  loss:0.9628,  val_acc:0.5128,  val_loss:0.9786,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, acc:0.5451,  loss:0.9624,  val_acc:0.5128,  val_loss:0.9782,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, acc:0.5444,  loss:0.9620,  val_acc:0.5135,  val_loss:0.9780,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, acc:0.5459,  loss:0.9619,  val_acc:0.5113,  val_loss:0.9780,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, acc:0.5457,  loss:0.9616,  val_acc:0.5143,  val_loss:0.9778,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, acc:0.5459,  loss:0.9615,  val_acc:0.5098,  val_loss:0.9778,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, acc:0.5448,  loss:0.9614,  val_acc:0.5173,  val_loss:0.9776,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, acc:0.5463,  loss:0.9610,  val_acc:0.5105,  val_loss:0.9775,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, acc:0.5476,  loss:0.9612,  val_acc:0.5158,  val_loss:0.9775,  \n",
      ".............Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 4)                 56        \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 253\n",
      "Trainable params: 253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, acc:0.4237,  loss:1.0809,  val_acc:0.4430,  val_loss:1.0817,  \n",
      "....................................................................................................\n",
      "Epoch: 100, acc:0.5354,  loss:0.9690,  val_acc:0.5153,  val_loss:0.9833,  \n",
      "....................................................................................................\n",
      "Epoch: 200, acc:0.5348,  loss:0.9681,  val_acc:0.5178,  val_loss:0.9832,  \n",
      "...............................................................................Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 7)                 210       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 3)                 24        \n",
      "=================================================================\n",
      "Total params: 1,104\n",
      "Trainable params: 1,104\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, acc:0.4177,  loss:1.0959,  val_acc:0.4435,  val_loss:1.0926,  \n",
      "....................................................................................................\n",
      "Epoch: 100, acc:0.5279,  loss:0.9787,  val_acc:0.5153,  val_loss:1.0042,  \n",
      "....................................................................................................\n",
      "Epoch: 200, acc:0.5331,  loss:0.9686,  val_acc:0.5153,  val_loss:0.9951,  \n",
      "....................................................................................................\n",
      "Epoch: 300, acc:0.5376,  loss:0.9632,  val_acc:0.5153,  val_loss:0.9923,  \n",
      "....................................................................................................\n",
      "Epoch: 400, acc:0.5397,  loss:0.9603,  val_acc:0.5138,  val_loss:0.9914,  \n",
      "....................................................................................................\n",
      "Epoch: 500, acc:0.5427,  loss:0.9586,  val_acc:0.5153,  val_loss:0.9910,  \n",
      "....................................................................................................\n",
      "Epoch: 600, acc:0.5445,  loss:0.9579,  val_acc:0.5176,  val_loss:0.9930,  \n",
      "....................................................................................................\n",
      "Epoch: 700, acc:0.5449,  loss:0.9573,  val_acc:0.5176,  val_loss:0.9914,  \n",
      "....................................................................................................\n",
      "Epoch: 800, acc:0.5455,  loss:0.9569,  val_acc:0.5153,  val_loss:0.9914,  \n",
      "..................................................Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 6)                 156       \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 827\n",
      "Trainable params: 827\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, acc:0.4626,  loss:1.0865,  val_acc:0.4504,  val_loss:1.0835,  \n",
      "....................................................................................................\n",
      "Epoch: 100, acc:0.5199,  loss:0.9902,  val_acc:0.5226,  val_loss:0.9876,  \n",
      "....................................................................................................\n",
      "Epoch: 200, acc:0.5243,  loss:0.9837,  val_acc:0.5271,  val_loss:0.9816,  \n",
      "....................................................................................................\n",
      "Epoch: 300, acc:0.5265,  loss:0.9789,  val_acc:0.5316,  val_loss:0.9783,  \n",
      "....................................................................................................\n",
      "Epoch: 400, acc:0.5325,  loss:0.9749,  val_acc:0.5293,  val_loss:0.9772,  \n",
      "....................................................................................................\n",
      "Epoch: 500, acc:0.5325,  loss:0.9732,  val_acc:0.5383,  val_loss:0.9749,  \n",
      "....................................................................................................\n",
      "Epoch: 600, acc:0.5320,  loss:0.9717,  val_acc:0.5353,  val_loss:0.9735,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 700, acc:0.5354,  loss:0.9701,  val_acc:0.5376,  val_loss:0.9745,  \n",
      "....................................................................................................\n",
      "Epoch: 800, acc:0.5350,  loss:0.9686,  val_acc:0.5376,  val_loss:0.9735,  \n",
      "....................................................................................................\n",
      "Epoch: 900, acc:0.5363,  loss:0.9677,  val_acc:0.5346,  val_loss:0.9737,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, acc:0.5352,  loss:0.9671,  val_acc:0.5429,  val_loss:0.9715,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, acc:0.5350,  loss:0.9663,  val_acc:0.5391,  val_loss:0.9722,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, acc:0.5356,  loss:0.9659,  val_acc:0.5406,  val_loss:0.9710,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, acc:0.5367,  loss:0.9655,  val_acc:0.5361,  val_loss:0.9728,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, acc:0.5348,  loss:0.9649,  val_acc:0.5391,  val_loss:0.9707,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, acc:0.5356,  loss:0.9644,  val_acc:0.5391,  val_loss:0.9716,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, acc:0.5365,  loss:0.9638,  val_acc:0.5383,  val_loss:0.9700,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, acc:0.5389,  loss:0.9637,  val_acc:0.5361,  val_loss:0.9689,  \n",
      "...............................................................................................Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 8)                 272       \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 1,421\n",
      "Trainable params: 1,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, acc:0.2647,  loss:1.1077,  val_acc:0.2880,  val_loss:1.0999,  \n",
      "....................................................................................................\n",
      "Epoch: 100, acc:0.5226,  loss:0.9923,  val_acc:0.5083,  val_loss:1.0066,  \n",
      "....................................................................................................\n",
      "Epoch: 200, acc:0.5265,  loss:0.9831,  val_acc:0.5090,  val_loss:0.9986,  \n",
      "....................................................................................................\n",
      "Epoch: 300, acc:0.5344,  loss:0.9779,  val_acc:0.5135,  val_loss:0.9938,  \n",
      "....................................................................................................\n",
      "Epoch: 400, acc:0.5357,  loss:0.9741,  val_acc:0.5143,  val_loss:0.9906,  \n",
      "....................................................................................................\n",
      "Epoch: 500, acc:0.5372,  loss:0.9723,  val_acc:0.5113,  val_loss:0.9882,  \n",
      "....................................................................................................\n",
      "Epoch: 600, acc:0.5406,  loss:0.9708,  val_acc:0.5083,  val_loss:0.9865,  \n",
      "....................................................................................................\n",
      "Epoch: 700, acc:0.5397,  loss:0.9698,  val_acc:0.5075,  val_loss:0.9857,  \n",
      "....................................................................................................\n",
      "Epoch: 800, acc:0.5429,  loss:0.9678,  val_acc:0.5098,  val_loss:0.9843,  \n",
      "....................................................................................................\n",
      "Epoch: 900, acc:0.5423,  loss:0.9674,  val_acc:0.5090,  val_loss:0.9829,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, acc:0.5427,  loss:0.9667,  val_acc:0.5105,  val_loss:0.9819,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, acc:0.5423,  loss:0.9660,  val_acc:0.5113,  val_loss:0.9808,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, acc:0.5419,  loss:0.9653,  val_acc:0.5098,  val_loss:0.9803,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, acc:0.5419,  loss:0.9648,  val_acc:0.5120,  val_loss:0.9794,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, acc:0.5425,  loss:0.9644,  val_acc:0.5090,  val_loss:0.9788,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, acc:0.5418,  loss:0.9640,  val_acc:0.5098,  val_loss:0.9785,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, acc:0.5412,  loss:0.9636,  val_acc:0.5128,  val_loss:0.9781,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, acc:0.5421,  loss:0.9636,  val_acc:0.5105,  val_loss:0.9781,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, acc:0.5427,  loss:0.9640,  val_acc:0.5105,  val_loss:0.9784,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, acc:0.5433,  loss:0.9629,  val_acc:0.5098,  val_loss:0.9775,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, acc:0.5431,  loss:0.9626,  val_acc:0.5120,  val_loss:0.9769,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, acc:0.5444,  loss:0.9625,  val_acc:0.5158,  val_loss:0.9766,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, acc:0.5448,  loss:0.9621,  val_acc:0.5128,  val_loss:0.9765,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, acc:0.5436,  loss:0.9622,  val_acc:0.5158,  val_loss:0.9762,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, acc:0.5455,  loss:0.9619,  val_acc:0.5158,  val_loss:0.9760,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, acc:0.5453,  loss:0.9619,  val_acc:0.5158,  val_loss:0.9758,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, acc:0.5446,  loss:0.9617,  val_acc:0.5173,  val_loss:0.9757,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, acc:0.5453,  loss:0.9616,  val_acc:0.5060,  val_loss:0.9759,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, acc:0.5453,  loss:0.9617,  val_acc:0.5165,  val_loss:0.9753,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, acc:0.5448,  loss:0.9615,  val_acc:0.5165,  val_loss:0.9755,  \n",
      "...................................................Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 588\n",
      "Trainable params: 588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, acc:0.4632,  loss:1.0876,  val_acc:0.4476,  val_loss:1.0813,  \n",
      "....................................................................................................\n",
      "Epoch: 100, acc:0.5339,  loss:0.9687,  val_acc:0.5183,  val_loss:0.9829,  \n",
      "....................................................................................................\n",
      "Epoch: 200, acc:0.5370,  loss:0.9671,  val_acc:0.5193,  val_loss:0.9838,  \n",
      "....................................................................................................\n",
      "Epoch: 300, acc:0.5366,  loss:0.9659,  val_acc:0.5173,  val_loss:0.9855,  \n",
      "............Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 3)                 90        \n",
      "=================================================================\n",
      "Total params: 2,700\n",
      "Trainable params: 2,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, acc:0.2506,  loss:1.1111,  val_acc:0.3306,  val_loss:1.0956,  \n",
      "....................................................................................................\n",
      "Epoch: 100, acc:0.5326,  loss:0.9691,  val_acc:0.5146,  val_loss:0.9971,  \n",
      "....................................................................................................\n",
      "Epoch: 200, acc:0.5376,  loss:0.9621,  val_acc:0.5176,  val_loss:0.9923,  \n",
      "....................................................................................................\n",
      "Epoch: 300, acc:0.5421,  loss:0.9588,  val_acc:0.5146,  val_loss:0.9909,  \n",
      "....................................................................................................\n",
      "Epoch: 400, acc:0.5475,  loss:0.9576,  val_acc:0.5168,  val_loss:0.9903,  \n",
      "....................................................................................................\n",
      "Epoch: 500, acc:0.5445,  loss:0.9576,  val_acc:0.5146,  val_loss:0.9902,  \n",
      "....................................................................................................\n",
      "Epoch: 600, acc:0.5455,  loss:0.9560,  val_acc:0.5168,  val_loss:0.9906,  \n",
      "....................................................................................................\n",
      "Epoch: 700, acc:0.5451,  loss:0.9556,  val_acc:0.5161,  val_loss:0.9907,  \n",
      "................................................Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 3)                 78        \n",
      "=================================================================\n",
      "Total params: 2,028\n",
      "Trainable params: 2,028\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, acc:0.2647,  loss:1.1019,  val_acc:0.4519,  val_loss:1.0932,  \n",
      "....................................................................................................\n",
      "Epoch: 100, acc:0.5209,  loss:0.9855,  val_acc:0.5233,  val_loss:0.9840,  \n",
      "....................................................................................................\n",
      "Epoch: 200, acc:0.5275,  loss:0.9778,  val_acc:0.5226,  val_loss:0.9787,  \n",
      "....................................................................................................\n",
      "Epoch: 300, acc:0.5312,  loss:0.9713,  val_acc:0.5346,  val_loss:0.9737,  \n",
      "....................................................................................................\n",
      "Epoch: 400, acc:0.5339,  loss:0.9687,  val_acc:0.5368,  val_loss:0.9724,  \n",
      "....................................................................................................\n",
      "Epoch: 500, acc:0.5356,  loss:0.9662,  val_acc:0.5383,  val_loss:0.9726,  \n",
      "....................................................................................................\n",
      "Epoch: 600, acc:0.5359,  loss:0.9652,  val_acc:0.5391,  val_loss:0.9718,  \n",
      "....................................................................................................\n",
      "Epoch: 700, acc:0.5388,  loss:0.9633,  val_acc:0.5361,  val_loss:0.9701,  \n",
      "....................................................................................................\n",
      "Epoch: 800, acc:0.5374,  loss:0.9621,  val_acc:0.5376,  val_loss:0.9695,  \n",
      "....................................................................................................\n",
      "Epoch: 900, acc:0.5391,  loss:0.9612,  val_acc:0.5376,  val_loss:0.9691,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, acc:0.5397,  loss:0.9611,  val_acc:0.5376,  val_loss:0.9684,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, acc:0.5395,  loss:0.9600,  val_acc:0.5368,  val_loss:0.9696,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, acc:0.5412,  loss:0.9609,  val_acc:0.5331,  val_loss:0.9704,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, acc:0.5404,  loss:0.9597,  val_acc:0.5376,  val_loss:0.9685,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, acc:0.5410,  loss:0.9588,  val_acc:0.5383,  val_loss:0.9679,  \n",
      "............................................................................Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 3)                 102       \n",
      "=================================================================\n",
      "Total params: 3,468\n",
      "Trainable params: 3,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, acc:0.3422,  loss:1.0967,  val_acc:0.4496,  val_loss:1.0884,  \n",
      "....................................................................................................\n",
      "Epoch: 100, acc:0.5250,  loss:0.9848,  val_acc:0.5075,  val_loss:0.9998,  \n",
      "....................................................................................................\n",
      "Epoch: 200, acc:0.5337,  loss:0.9749,  val_acc:0.5075,  val_loss:0.9929,  \n",
      "....................................................................................................\n",
      "Epoch: 300, acc:0.5359,  loss:0.9707,  val_acc:0.5090,  val_loss:0.9895,  \n",
      "....................................................................................................\n",
      "Epoch: 400, acc:0.5354,  loss:0.9714,  val_acc:0.5105,  val_loss:0.9851,  \n",
      "....................................................................................................\n",
      "Epoch: 500, acc:0.5410,  loss:0.9668,  val_acc:0.5105,  val_loss:0.9828,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 600, acc:0.5410,  loss:0.9654,  val_acc:0.5098,  val_loss:0.9808,  \n",
      "....................................................................................................\n",
      "Epoch: 700, acc:0.5414,  loss:0.9644,  val_acc:0.5075,  val_loss:0.9797,  \n",
      "....................................................................................................\n",
      "Epoch: 800, acc:0.5414,  loss:0.9641,  val_acc:0.5068,  val_loss:0.9791,  \n",
      "....................................................................................................\n",
      "Epoch: 900, acc:0.5404,  loss:0.9638,  val_acc:0.5105,  val_loss:0.9782,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, acc:0.5440,  loss:0.9633,  val_acc:0.5090,  val_loss:0.9772,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, acc:0.5423,  loss:0.9621,  val_acc:0.5105,  val_loss:0.9774,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, acc:0.5450,  loss:0.9618,  val_acc:0.5143,  val_loss:0.9764,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, acc:0.5440,  loss:0.9610,  val_acc:0.5120,  val_loss:0.9762,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, acc:0.5429,  loss:0.9607,  val_acc:0.5173,  val_loss:0.9761,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, acc:0.5440,  loss:0.9620,  val_acc:0.5158,  val_loss:0.9759,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, acc:0.5448,  loss:0.9605,  val_acc:0.5120,  val_loss:0.9761,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, acc:0.5457,  loss:0.9607,  val_acc:0.5083,  val_loss:0.9761,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, acc:0.5440,  loss:0.9599,  val_acc:0.5158,  val_loss:0.9757,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, acc:0.5431,  loss:0.9603,  val_acc:0.5105,  val_loss:0.9758,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, acc:0.5433,  loss:0.9599,  val_acc:0.5150,  val_loss:0.9754,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, acc:0.5450,  loss:0.9599,  val_acc:0.5150,  val_loss:0.9755,  \n",
      "................Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 9)                 126       \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 3)                 30        \n",
      "=================================================================\n",
      "Total params: 428\n",
      "Trainable params: 428\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, acc:0.3684,  loss:1.0958,  val_acc:0.4455,  val_loss:1.0909,  \n",
      "....................................................................................................\n",
      "Epoch: 100, acc:0.5370,  loss:0.9691,  val_acc:0.5178,  val_loss:0.9827,  \n",
      "....................................................................................................\n",
      "Epoch: 200, acc:0.5363,  loss:0.9680,  val_acc:0.5166,  val_loss:0.9834,  \n",
      "....................................................................................................\n",
      "Epoch: 300, acc:0.5360,  loss:0.9676,  val_acc:0.5176,  val_loss:0.9825,  \n",
      "....................................................................................................\n",
      "Epoch: 400, acc:0.5362,  loss:0.9672,  val_acc:0.5173,  val_loss:0.9830,  \n",
      "....................................................................................................\n",
      "Epoch: 500, acc:0.5375,  loss:0.9668,  val_acc:0.5183,  val_loss:0.9824,  \n",
      "....................................................................................................\n",
      "Epoch: 600, acc:0.5387,  loss:0.9668,  val_acc:0.5168,  val_loss:0.9846,  \n",
      ".............................Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_56 (Dense)             (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 14)                420       \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 14)                210       \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 3)                 45        \n",
      "=================================================================\n",
      "Total params: 1,545\n",
      "Trainable params: 1,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, acc:0.4517,  loss:1.0921,  val_acc:0.4435,  val_loss:1.0860,  \n",
      "....................................................................................................\n",
      "Epoch: 100, acc:0.5309,  loss:0.9730,  val_acc:0.5198,  val_loss:0.9989,  \n",
      "....................................................................................................\n",
      "Epoch: 200, acc:0.5374,  loss:0.9643,  val_acc:0.5168,  val_loss:0.9926,  \n",
      "....................................................................................................\n",
      "Epoch: 300, acc:0.5419,  loss:0.9604,  val_acc:0.5198,  val_loss:0.9896,  \n",
      "....................................................................................................\n",
      "Epoch: 400, acc:0.5404,  loss:0.9593,  val_acc:0.5198,  val_loss:0.9897,  \n",
      "....................................................................................................\n",
      "Epoch: 500, acc:0.5408,  loss:0.9585,  val_acc:0.5123,  val_loss:0.9886,  \n",
      "....................................................................................................\n",
      "Epoch: 600, acc:0.5414,  loss:0.9574,  val_acc:0.5123,  val_loss:0.9880,  \n",
      "....................................................................................................\n",
      "Epoch: 700, acc:0.5408,  loss:0.9593,  val_acc:0.5176,  val_loss:0.9904,  \n",
      "....................................................................................................\n",
      "Epoch: 800, acc:0.5432,  loss:0.9573,  val_acc:0.5176,  val_loss:0.9899,  \n",
      "....................................................................................................\n",
      "Epoch: 900, acc:0.5421,  loss:0.9573,  val_acc:0.5131,  val_loss:0.9875,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, acc:0.5430,  loss:0.9562,  val_acc:0.5191,  val_loss:0.9886,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, acc:0.5447,  loss:0.9561,  val_acc:0.5146,  val_loss:0.9881,  \n",
      ".............................................Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_60 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 13)                338       \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 1,212\n",
      "Trainable params: 1,212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, acc:0.2622,  loss:1.0999,  val_acc:0.4444,  val_loss:1.0956,  \n",
      "....................................................................................................\n",
      "Epoch: 100, acc:0.5207,  loss:0.9911,  val_acc:0.5278,  val_loss:0.9867,  \n",
      "....................................................................................................\n",
      "Epoch: 200, acc:0.5265,  loss:0.9829,  val_acc:0.5286,  val_loss:0.9813,  \n",
      "....................................................................................................\n",
      "Epoch: 300, acc:0.5327,  loss:0.9766,  val_acc:0.5391,  val_loss:0.9760,  \n",
      "....................................................................................................\n",
      "Epoch: 400, acc:0.5331,  loss:0.9733,  val_acc:0.5406,  val_loss:0.9746,  \n",
      "....................................................................................................\n",
      "Epoch: 500, acc:0.5365,  loss:0.9716,  val_acc:0.5436,  val_loss:0.9716,  \n",
      "....................................................................................................\n",
      "Epoch: 600, acc:0.5327,  loss:0.9696,  val_acc:0.5436,  val_loss:0.9731,  \n",
      "....................................................................................................\n",
      "Epoch: 700, acc:0.5337,  loss:0.9685,  val_acc:0.5398,  val_loss:0.9708,  \n",
      "....................................................................................................\n",
      "Epoch: 800, acc:0.5354,  loss:0.9670,  val_acc:0.5414,  val_loss:0.9738,  \n",
      "....................................................................................................\n",
      "Epoch: 900, acc:0.5350,  loss:0.9666,  val_acc:0.5421,  val_loss:0.9697,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, acc:0.5359,  loss:0.9658,  val_acc:0.5444,  val_loss:0.9695,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, acc:0.5337,  loss:0.9657,  val_acc:0.5436,  val_loss:0.9701,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, acc:0.5356,  loss:0.9649,  val_acc:0.5429,  val_loss:0.9687,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, acc:0.5378,  loss:0.9642,  val_acc:0.5444,  val_loss:0.9727,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, acc:0.5352,  loss:0.9641,  val_acc:0.5444,  val_loss:0.9687,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, acc:0.5372,  loss:0.9638,  val_acc:0.5429,  val_loss:0.9686,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, acc:0.5374,  loss:0.9636,  val_acc:0.5444,  val_loss:0.9695,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, acc:0.5399,  loss:0.9634,  val_acc:0.5406,  val_loss:0.9669,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, acc:0.5386,  loss:0.9633,  val_acc:0.5398,  val_loss:0.9665,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, acc:0.5384,  loss:0.9632,  val_acc:0.5406,  val_loss:0.9667,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, acc:0.5393,  loss:0.9628,  val_acc:0.5421,  val_loss:0.9667,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, acc:0.5378,  loss:0.9631,  val_acc:0.5474,  val_loss:0.9686,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, acc:0.5403,  loss:0.9627,  val_acc:0.5436,  val_loss:0.9667,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, acc:0.5401,  loss:0.9625,  val_acc:0.5429,  val_loss:0.9667,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, acc:0.5403,  loss:0.9625,  val_acc:0.5406,  val_loss:0.9661,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, acc:0.5393,  loss:0.9622,  val_acc:0.5459,  val_loss:0.9691,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, acc:0.5403,  loss:0.9622,  val_acc:0.5436,  val_loss:0.9667,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, acc:0.5376,  loss:0.9630,  val_acc:0.5481,  val_loss:0.9683,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, acc:0.5399,  loss:0.9619,  val_acc:0.5429,  val_loss:0.9661,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, acc:0.5419,  loss:0.9620,  val_acc:0.5444,  val_loss:0.9662,  \n",
      "....................................................................................................\n",
      "Epoch: 3000, acc:0.5391,  loss:0.9618,  val_acc:0.5429,  val_loss:0.9662,  \n",
      "....................................................................................................\n",
      "Epoch: 3100, acc:0.5397,  loss:0.9617,  val_acc:0.5444,  val_loss:0.9660,  \n",
      "...................................Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_64 (Dense)             (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 16)                544       \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 1,989\n",
      "Trainable params: 1,989\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, acc:0.2812,  loss:1.1026,  val_acc:0.2977,  val_loss:1.0965,  \n",
      "....................................................................................................\n",
      "Epoch: 100, acc:0.5237,  loss:0.9871,  val_acc:0.5098,  val_loss:1.0028,  \n",
      "....................................................................................................\n",
      "Epoch: 200, acc:0.5282,  loss:0.9803,  val_acc:0.5098,  val_loss:0.9960,  \n",
      "....................................................................................................\n",
      "Epoch: 300, acc:0.5329,  loss:0.9751,  val_acc:0.5090,  val_loss:0.9904,  \n",
      "....................................................................................................\n",
      "Epoch: 400, acc:0.5399,  loss:0.9707,  val_acc:0.5068,  val_loss:0.9873,  \n",
      "....................................................................................................\n",
      "Epoch: 500, acc:0.5369,  loss:0.9708,  val_acc:0.5105,  val_loss:0.9857,  \n",
      "....................................................................................................\n",
      "Epoch: 600, acc:0.5369,  loss:0.9681,  val_acc:0.5098,  val_loss:0.9834,  \n",
      "....................................................................................................\n",
      "Epoch: 700, acc:0.5395,  loss:0.9664,  val_acc:0.5105,  val_loss:0.9821,  \n",
      "....................................................................................................\n",
      "Epoch: 800, acc:0.5393,  loss:0.9652,  val_acc:0.5098,  val_loss:0.9810,  \n",
      "....................................................................................................\n",
      "Epoch: 900, acc:0.5416,  loss:0.9641,  val_acc:0.5083,  val_loss:0.9792,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 1000, acc:0.5425,  loss:0.9634,  val_acc:0.5173,  val_loss:0.9784,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, acc:0.5435,  loss:0.9625,  val_acc:0.5105,  val_loss:0.9767,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, acc:0.5436,  loss:0.9629,  val_acc:0.5068,  val_loss:0.9762,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, acc:0.5427,  loss:0.9618,  val_acc:0.5083,  val_loss:0.9760,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, acc:0.5440,  loss:0.9628,  val_acc:0.5128,  val_loss:0.9753,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, acc:0.5451,  loss:0.9608,  val_acc:0.5090,  val_loss:0.9756,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, acc:0.5465,  loss:0.9604,  val_acc:0.5120,  val_loss:0.9745,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, acc:0.5457,  loss:0.9604,  val_acc:0.5195,  val_loss:0.9740,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, acc:0.5446,  loss:0.9607,  val_acc:0.5128,  val_loss:0.9743,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, acc:0.5455,  loss:0.9599,  val_acc:0.5150,  val_loss:0.9740,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, acc:0.5459,  loss:0.9597,  val_acc:0.5098,  val_loss:0.9743,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, acc:0.5485,  loss:0.9595,  val_acc:0.5128,  val_loss:0.9737,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, acc:0.5482,  loss:0.9592,  val_acc:0.5188,  val_loss:0.9734,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, acc:0.5467,  loss:0.9590,  val_acc:0.5105,  val_loss:0.9742,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, acc:0.5467,  loss:0.9600,  val_acc:0.5143,  val_loss:0.9757,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, acc:0.5455,  loss:0.9595,  val_acc:0.5211,  val_loss:0.9742,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, acc:0.5478,  loss:0.9587,  val_acc:0.5226,  val_loss:0.9731,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, acc:0.5483,  loss:0.9584,  val_acc:0.5203,  val_loss:0.9729,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, acc:0.5457,  loss:0.9592,  val_acc:0.5218,  val_loss:0.9729,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, acc:0.5455,  loss:0.9590,  val_acc:0.5143,  val_loss:0.9734,  \n",
      "....................................................................................................\n",
      "Epoch: 3000, acc:0.5483,  loss:0.9580,  val_acc:0.5218,  val_loss:0.9730,  \n",
      "....................................................................................................\n",
      "Epoch: 3100, acc:0.5451,  loss:0.9586,  val_acc:0.5203,  val_loss:0.9730,  \n",
      "....................................................................................................\n",
      "Epoch: 3200, acc:0.5465,  loss:0.9581,  val_acc:0.5195,  val_loss:0.9734,  \n",
      "....................................................................................................\n",
      "Epoch: 3300, acc:0.5463,  loss:0.9578,  val_acc:0.5180,  val_loss:0.9731,  \n",
      ".......Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_68 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 4)                 56        \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 273\n",
      "Trainable params: 273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, acc:0.4635,  loss:1.0721,  val_acc:0.4476,  val_loss:1.0708,  \n",
      "....................................................................................................\n",
      "Epoch: 100, acc:0.5361,  loss:0.9710,  val_acc:0.5163,  val_loss:0.9855,  \n",
      "....................................................................................................\n",
      "Epoch: 200, acc:0.5356,  loss:0.9684,  val_acc:0.5153,  val_loss:0.9856,  \n",
      "....................................................................................................\n",
      "Epoch: 300, acc:0.5356,  loss:0.9676,  val_acc:0.5181,  val_loss:0.9843,  \n",
      "....................................................................................................\n",
      "Epoch: 400, acc:0.5371,  loss:0.9671,  val_acc:0.5143,  val_loss:0.9854,  \n",
      "....................................................................................................\n",
      "Epoch: 500, acc:0.5356,  loss:0.9670,  val_acc:0.5155,  val_loss:0.9838,  \n",
      "....................................................................Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_72 (Dense)             (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 7)                 210       \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 3)                 24        \n",
      "=================================================================\n",
      "Total params: 1,160\n",
      "Trainable params: 1,160\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, acc:0.2595,  loss:1.1064,  val_acc:0.2805,  val_loss:1.0961,  \n",
      "....................................................................................................\n",
      "Epoch: 100, acc:0.5322,  loss:0.9728,  val_acc:0.5198,  val_loss:1.0005,  \n",
      "....................................................................................................\n",
      "Epoch: 200, acc:0.5369,  loss:0.9654,  val_acc:0.5191,  val_loss:0.9958,  \n",
      "....................................................................................................\n",
      "Epoch: 300, acc:0.5393,  loss:0.9608,  val_acc:0.5153,  val_loss:0.9925,  \n",
      "....................................................................................................\n",
      "Epoch: 400, acc:0.5432,  loss:0.9593,  val_acc:0.5138,  val_loss:0.9915,  \n",
      "....................................................................................................\n",
      "Epoch: 500, acc:0.5436,  loss:0.9575,  val_acc:0.5138,  val_loss:0.9915,  \n",
      "....................................................................................................\n",
      "Epoch: 600, acc:0.5434,  loss:0.9566,  val_acc:0.5183,  val_loss:0.9922,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................................Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_76 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 6)                 156       \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 869\n",
      "Trainable params: 869\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, acc:0.4263,  loss:1.0856,  val_acc:0.4519,  val_loss:1.0726,  \n",
      "....................................................................................................\n",
      "Epoch: 100, acc:0.5241,  loss:0.9873,  val_acc:0.5203,  val_loss:0.9878,  \n",
      "....................................................................................................\n",
      "Epoch: 200, acc:0.5286,  loss:0.9786,  val_acc:0.5286,  val_loss:0.9806,  \n",
      "....................................................................................................\n",
      "Epoch: 300, acc:0.5312,  loss:0.9728,  val_acc:0.5376,  val_loss:0.9752,  \n",
      "....................................................................................................\n",
      "Epoch: 400, acc:0.5309,  loss:0.9692,  val_acc:0.5414,  val_loss:0.9742,  \n",
      "....................................................................................................\n",
      "Epoch: 500, acc:0.5327,  loss:0.9688,  val_acc:0.5383,  val_loss:0.9720,  \n",
      "....................................................................................................\n",
      "Epoch: 600, acc:0.5344,  loss:0.9654,  val_acc:0.5391,  val_loss:0.9744,  \n",
      "....................................................................................................\n",
      "Epoch: 700, acc:0.5361,  loss:0.9675,  val_acc:0.5398,  val_loss:0.9701,  \n",
      "....................................................................................................\n",
      "Epoch: 800, acc:0.5365,  loss:0.9625,  val_acc:0.5398,  val_loss:0.9700,  \n",
      "....................................................................................................\n",
      "Epoch: 900, acc:0.5391,  loss:0.9615,  val_acc:0.5398,  val_loss:0.9694,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, acc:0.5376,  loss:0.9619,  val_acc:0.5398,  val_loss:0.9691,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, acc:0.5382,  loss:0.9618,  val_acc:0.5398,  val_loss:0.9686,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, acc:0.5391,  loss:0.9597,  val_acc:0.5383,  val_loss:0.9681,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, acc:0.5389,  loss:0.9598,  val_acc:0.5391,  val_loss:0.9685,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, acc:0.5374,  loss:0.9601,  val_acc:0.5421,  val_loss:0.9705,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, acc:0.5421,  loss:0.9593,  val_acc:0.5451,  val_loss:0.9690,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, acc:0.5397,  loss:0.9587,  val_acc:0.5436,  val_loss:0.9703,  \n",
      "..................................................Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_80 (Dense)             (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 8)                 272       \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 1,493\n",
      "Trainable params: 1,493\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, acc:0.4468,  loss:1.0910,  val_acc:0.4496,  val_loss:1.0891,  \n",
      "....................................................................................................\n",
      "Epoch: 100, acc:0.5231,  loss:0.9888,  val_acc:0.5083,  val_loss:1.0045,  \n",
      "....................................................................................................\n",
      "Epoch: 200, acc:0.5288,  loss:0.9824,  val_acc:0.5083,  val_loss:0.9992,  \n",
      "....................................................................................................\n",
      "Epoch: 300, acc:0.5325,  loss:0.9783,  val_acc:0.5120,  val_loss:0.9952,  \n",
      "....................................................................................................\n",
      "Epoch: 400, acc:0.5335,  loss:0.9772,  val_acc:0.5158,  val_loss:0.9917,  \n",
      "....................................................................................................\n",
      "Epoch: 500, acc:0.5374,  loss:0.9729,  val_acc:0.5135,  val_loss:0.9892,  \n",
      "....................................................................................................\n",
      "Epoch: 600, acc:0.5395,  loss:0.9718,  val_acc:0.5128,  val_loss:0.9877,  \n",
      "....................................................................................................\n",
      "Epoch: 700, acc:0.5380,  loss:0.9706,  val_acc:0.5128,  val_loss:0.9872,  \n",
      "....................................................................................................\n",
      "Epoch: 800, acc:0.5399,  loss:0.9691,  val_acc:0.5083,  val_loss:0.9849,  \n",
      "....................................................................................................\n",
      "Epoch: 900, acc:0.5401,  loss:0.9681,  val_acc:0.5098,  val_loss:0.9834,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, acc:0.5388,  loss:0.9677,  val_acc:0.5120,  val_loss:0.9836,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, acc:0.5410,  loss:0.9669,  val_acc:0.5105,  val_loss:0.9811,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, acc:0.5384,  loss:0.9667,  val_acc:0.5105,  val_loss:0.9806,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, acc:0.5414,  loss:0.9661,  val_acc:0.5120,  val_loss:0.9810,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, acc:0.5416,  loss:0.9657,  val_acc:0.5135,  val_loss:0.9793,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, acc:0.5412,  loss:0.9651,  val_acc:0.5158,  val_loss:0.9785,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, acc:0.5408,  loss:0.9649,  val_acc:0.5113,  val_loss:0.9783,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, acc:0.5406,  loss:0.9644,  val_acc:0.5150,  val_loss:0.9775,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, acc:0.5412,  loss:0.9642,  val_acc:0.5090,  val_loss:0.9770,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, acc:0.5408,  loss:0.9640,  val_acc:0.5105,  val_loss:0.9773,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 2000, acc:0.5418,  loss:0.9638,  val_acc:0.5068,  val_loss:0.9765,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, acc:0.5421,  loss:0.9636,  val_acc:0.5090,  val_loss:0.9760,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, acc:0.5421,  loss:0.9634,  val_acc:0.5105,  val_loss:0.9759,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, acc:0.5436,  loss:0.9630,  val_acc:0.5128,  val_loss:0.9764,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, acc:0.5418,  loss:0.9640,  val_acc:0.5113,  val_loss:0.9759,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, acc:0.5431,  loss:0.9631,  val_acc:0.5098,  val_loss:0.9752,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, acc:0.5429,  loss:0.9633,  val_acc:0.5120,  val_loss:0.9758,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, acc:0.5427,  loss:0.9629,  val_acc:0.5120,  val_loss:0.9748,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, acc:0.5423,  loss:0.9630,  val_acc:0.5143,  val_loss:0.9747,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, acc:0.5429,  loss:0.9629,  val_acc:0.5098,  val_loss:0.9748,  \n",
      "....................................................................................................\n",
      "Epoch: 3000, acc:0.5433,  loss:0.9627,  val_acc:0.5083,  val_loss:0.9745,  \n",
      "....................................................................................................\n",
      "Epoch: 3100, acc:0.5429,  loss:0.9627,  val_acc:0.5120,  val_loss:0.9743,  \n",
      "....................................................................................................\n",
      "Epoch: 3200, acc:0.5433,  loss:0.9630,  val_acc:0.5128,  val_loss:0.9751,  \n",
      "....................................................................................................\n",
      "Epoch: 3300, acc:0.5429,  loss:0.9627,  val_acc:0.5120,  val_loss:0.9742,  \n",
      "....................................................................................................\n",
      "Epoch: 3400, acc:0.5433,  loss:0.9631,  val_acc:0.5203,  val_loss:0.9738,  \n",
      "....................................................................................................\n",
      "Epoch: 3500, acc:0.5425,  loss:0.9628,  val_acc:0.5120,  val_loss:0.9745,  \n",
      "....................................................................................................\n",
      "Epoch: 3600, acc:0.5427,  loss:0.9627,  val_acc:0.5203,  val_loss:0.9735,  \n",
      "....................................................................................................\n",
      "Epoch: 3700, acc:0.5446,  loss:0.9628,  val_acc:0.5143,  val_loss:0.9736,  \n",
      "....................................................................................................\n",
      "Epoch: 3800, acc:0.5435,  loss:0.9624,  val_acc:0.5188,  val_loss:0.9734,  \n",
      "....................................................................................................\n",
      "Epoch: 3900, acc:0.5421,  loss:0.9625,  val_acc:0.5143,  val_loss:0.9736,  \n",
      "....................................................................................................\n",
      "Epoch: 4000, acc:0.5435,  loss:0.9627,  val_acc:0.5211,  val_loss:0.9732,  \n",
      "....................................................................................................\n",
      "Epoch: 4100, acc:0.5438,  loss:0.9628,  val_acc:0.5143,  val_loss:0.9737,  \n",
      ".........................................................................Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_84 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 770\n",
      "Trainable params: 770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, acc:0.4635,  loss:1.0763,  val_acc:0.4476,  val_loss:1.0702,  \n",
      "....................................................................................................\n",
      "Epoch: 100, acc:0.5348,  loss:0.9687,  val_acc:0.5178,  val_loss:0.9837,  \n",
      "....................................................................................................\n",
      "Epoch: 200, acc:0.5363,  loss:0.9673,  val_acc:0.5176,  val_loss:0.9837,  \n",
      ".................................Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_89 (Dense)             (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 3)                 102       \n",
      "=================================================================\n",
      "Total params: 4,590\n",
      "Trainable params: 4,590\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, acc:0.4631,  loss:1.0821,  val_acc:0.4496,  val_loss:1.0759,  \n",
      "....................................................................................................\n",
      "Epoch: 100, acc:0.5273,  loss:0.9831,  val_acc:0.5098,  val_loss:1.0065,  \n",
      "....................................................................................................\n",
      "Epoch: 200, acc:0.5363,  loss:0.9724,  val_acc:0.5105,  val_loss:0.9946,  \n",
      "....................................................................................................\n",
      "Epoch: 300, acc:0.5310,  loss:0.9710,  val_acc:0.5120,  val_loss:0.9918,  \n",
      "....................................................................................................\n",
      "Epoch: 400, acc:0.5359,  loss:0.9678,  val_acc:0.5075,  val_loss:0.9862,  \n",
      "....................................................................................................\n",
      "Epoch: 500, acc:0.5404,  loss:0.9645,  val_acc:0.5068,  val_loss:0.9827,  \n",
      "....................................................................................................\n",
      "Epoch: 600, acc:0.5404,  loss:0.9641,  val_acc:0.5068,  val_loss:0.9848,  \n",
      "....................................................................................................\n",
      "Epoch: 700, acc:0.5442,  loss:0.9619,  val_acc:0.5173,  val_loss:0.9782,  \n",
      "....................................................................................................\n",
      "Epoch: 800, acc:0.5451,  loss:0.9607,  val_acc:0.5090,  val_loss:0.9779,  \n",
      "....................................................................................................\n",
      "Epoch: 900, acc:0.5382,  loss:0.9619,  val_acc:0.5256,  val_loss:0.9791,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 1000, acc:0.5476,  loss:0.9594,  val_acc:0.5120,  val_loss:0.9777,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, acc:0.5485,  loss:0.9585,  val_acc:0.5120,  val_loss:0.9767,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, acc:0.5352,  loss:0.9652,  val_acc:0.5226,  val_loss:0.9780,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, acc:0.5468,  loss:0.9583,  val_acc:0.5203,  val_loss:0.9747,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, acc:0.5491,  loss:0.9573,  val_acc:0.5150,  val_loss:0.9759,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, acc:0.5504,  loss:0.9561,  val_acc:0.5188,  val_loss:0.9742,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, acc:0.5485,  loss:0.9558,  val_acc:0.5188,  val_loss:0.9748,  \n",
      "........................Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_94 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 9)                 126       \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 3)                 30        \n",
      "=================================================================\n",
      "Total params: 518\n",
      "Trainable params: 518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, acc:0.3186,  loss:1.0965,  val_acc:0.4473,  val_loss:1.0914,  \n",
      "....................................................................................................\n",
      "Epoch: 100, acc:0.5372,  loss:0.9679,  val_acc:0.5153,  val_loss:0.9841,  \n",
      "....................................................................................................\n",
      "Epoch: 200, acc:0.5366,  loss:0.9678,  val_acc:0.5166,  val_loss:0.9844,  \n",
      "....................................................................................................\n",
      "Epoch: 300, acc:0.5355,  loss:0.9666,  val_acc:0.5145,  val_loss:0.9846,  \n",
      "............................"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model03_H3_M' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-69999565969b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[1;31m# H3_M\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[0msize_histories\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model01_H3_M'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompile_and_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel01_H3_M\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model01_H3_M'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_X01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m \u001b[0msize_histories\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model03_H3_M'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompile_and_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel03_H3_M\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model03_H3_M'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_X03\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y03\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m \u001b[0msize_histories\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model04_H3_M'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompile_and_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel04_H3_M\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model04_H3_M'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_X04\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y04\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[0msize_histories\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model05_H3_M'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompile_and_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel05_H3_M\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model05_H3_M'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_X05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model03_H3_M' is not defined"
     ]
    }
   ],
   "source": [
    "# Jupyter notebook\n",
    "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "shutil.rmtree(logdir, ignore_errors=True)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 128*8\n",
    "EPOCHS=10000\n",
    "validation_split = 0.2\n",
    "size_histories = {}\n",
    "\n",
    "##### Model01:\n",
    "\n",
    "model01_H1_H = tf.keras.Sequential([\n",
    "    layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "    layers.Dense(13, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H1_H = tf.keras.Sequential([\n",
    "    layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "    layers.Dense(29, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04_H1_H = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H1_H = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "##### Model01:\n",
    "\n",
    "model01_H1_M = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H1_M = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04_H1_M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H1_M = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "##### Model01:\n",
    "\n",
    "model01_H1_L = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H1_L = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04_H1_L = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H1_L = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "### 2 Hidden Layers:\n",
    "#### High Amount of Neurons (H):\n",
    "##### Model01:\n",
    "\n",
    "model01_H2_H = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H2_H = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04_H2_H = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H2_H = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "##### Model01:\n",
    "\n",
    "model01_H2_M = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H2_M = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04_H2_M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H2_M = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "##### Model01:\n",
    "\n",
    "model01_H2_L = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H2_L = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04_H2_L = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H2_L = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "### 3 Hidden Layers:\n",
    "#### High Amount of Neurons (H):\n",
    "##### Model01:\n",
    "\n",
    "model01_H3_H = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H3_H = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "##### Model01:\n",
    "\n",
    "model01_H3_M = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02_H3_M = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model03_H3_M = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04_H3_M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H3_M = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "##### Model01:\n",
    "\n",
    "model01_H3_L = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H3_L = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04_H3_L = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H3_L = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Funnel Architecture:\n",
    "##### Model01:\n",
    "\n",
    "model01_H3_F = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(10, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H3_F = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(22, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(11, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H3_F = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(19, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "### 4 Hidden Layers:\n",
    "#### High Amount of Neurons (H):\n",
    "##### Model01:\n",
    "\n",
    "model01_H4_H = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H4_H = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H4_H = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "##### Model01:\n",
    "\n",
    "model01_H4_M = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04_H4_M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H4_M = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "##### Model01:\n",
    "\n",
    "model01_H4_L = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H4_L = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H4_L = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Funnel Architecture:\n",
    "##### Model01:\n",
    "\n",
    "model01_H4_F = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(10, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H4_F = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(22, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(11, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04_H4_F = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(20, activation='relu'),\n",
    "  layers.Dense(15, activation='relu'),\n",
    "  layers.Dense(11, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H4_F = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(19, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# H1_H\n",
    "size_histories['model01_H1_H'] = compile_and_fit(model01_H1_H, 'model01_H1_H', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03_H1_H'] = compile_and_fit(model03_H1_H, 'model03_H1_H', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04_H1_H'] = compile_and_fit(model04_H1_H, 'model04_H1_H', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H1_H'] = compile_and_fit(model05_H1_H, 'model05_H1_H', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H1_M\n",
    "size_histories['model01_H1_M'] = compile_and_fit(model01_H1_M, 'model01_H1_M', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03_H1_M'] = compile_and_fit(model03_H1_M, 'model03_H1_M', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04_H1_M'] = compile_and_fit(model04_H1_M, 'model04_H1_M', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H1_M'] = compile_and_fit(model05_H1_M, 'model05_H1_M', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H1_L\n",
    "size_histories['model01_H1_L'] = compile_and_fit(model01_H1_L, 'model01_H1_L', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03_H1_L'] = compile_and_fit(model03_H1_L, 'model03_H1_L', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04_H1_L'] = compile_and_fit(model04_H1_L, 'model04_H1_L', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H1_L'] = compile_and_fit(model05_H1_L, 'model05_H1_L', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H2_H\n",
    "size_histories['model01_H2_H'] = compile_and_fit(model01_H2_H, 'model01_H2_H', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03_H2_H'] = compile_and_fit(model03_H2_H, 'model03_H2_H', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04_H2_H'] = compile_and_fit(model04_H2_H, 'model04_H2_H', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H2_H'] = compile_and_fit(model05_H2_H, 'model05_H2_H', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H2_M\n",
    "size_histories['model01_H2_M'] = compile_and_fit(model01_H2_M, 'model01_H2_M', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03_H2_M'] = compile_and_fit(model03_H2_M, 'model03_H2_M', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04_H2_M'] = compile_and_fit(model04_H2_M, 'model04_H2_M', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H2_M'] = compile_and_fit(model05_H2_M, 'model05_H2_M', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H2_L\n",
    "size_histories['model01_H2_L'] = compile_and_fit(model01_H2_L, 'model01_H2_L', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03_H2_L'] = compile_and_fit(model03_H2_L, 'model03_H2_L', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04_H2_L'] = compile_and_fit(model04_H2_L, 'model04_H2_L', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H2_L'] = compile_and_fit(model05_H2_L, 'model05_H2_L', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3_H\n",
    "size_histories['model01_H3_H'] = compile_and_fit(model01_H3_H, 'model01_H3_H', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H3_H'] = compile_and_fit(model05_H3_H, 'model05_H3_H', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3_M\n",
    "size_histories['model01_H3_M'] = compile_and_fit(model01_H3_M, 'model01_H3_M', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03_H3_M'] = compile_and_fit(model03_H3_M, 'model03_H3_M', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04_H3_M'] = compile_and_fit(model04_H3_M, 'model04_H3_M', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H3_M'] = compile_and_fit(model05_H3_M, 'model05_H3_M', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3_L\n",
    "size_histories['model01_H3_L'] = compile_and_fit(model01_H3_L, 'model01_H3_L', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03_H3_L'] = compile_and_fit(model03_H3_L, 'model03_H3_L', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04_H3_L'] = compile_and_fit(model04_H3_L, 'model04_H3_L', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H3_L'] = compile_and_fit(model05_H3_L, 'model05_H3_L', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3_F\n",
    "size_histories['model01_H3_F'] = compile_and_fit(model01_H3_F, 'model01_H3_F', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03_H3_F'] = compile_and_fit(model03_H3_F, 'model03_H3_F', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H3_F'] = compile_and_fit(model05_H3_F, 'model05_H3_F', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H4_H\n",
    "size_histories['model01_H4_H'] = compile_and_fit(model01_H4_H, 'model01_H4_H', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03_H4_H'] = compile_and_fit(model03_H4_H, 'model03_H4_H', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H4_H'] = compile_and_fit(model05_H4_H, 'model05_H4_H', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H4_M\n",
    "size_histories['model01_H4_M'] = compile_and_fit(model01_H4_M, 'model01_H4_M', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04_H4_M'] = compile_and_fit(model04_H4_M, 'model04_H4_M', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H4_M'] = compile_and_fit(model05_H4_M, 'model05_H4_M', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H4_L\n",
    "size_histories['model03_H4_L'] = compile_and_fit(model03_H4_L, 'model03_H4_L', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04_H4_L'] = compile_and_fit(model04_H4_L, 'model04_H4_L', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H4_F\n",
    "size_histories['model01_H4_F'] = compile_and_fit(model01_H4_F, 'model01_H4_F', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03_H4_F'] = compile_and_fit(model03_H4_F, 'model03_H4_F', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04_H4_F'] = compile_and_fit(model04_H4_F, 'model04_H4_F', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H4_F'] = compile_and_fit(model05_H4_F, 'model05_H4_F', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "1DwuhGCJH2yL",
    "outputId": "13ba4f8a-0516-4937-d37a-8b0130fc5a56"
   },
   "outputs": [],
   "source": [
    "# H1_H\n",
    "score = load_model('../model/model01_H1_H.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model01_H1_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03_H1_H.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H1_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04_H1_H.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04_H1_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H1_H.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H1_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H1_M\n",
    "score = load_model('../model/model01_H1_M.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model01_H1_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03_H1_M.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H1_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04_H1_M.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04_H1_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H1_M.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H1_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H1_L\n",
    "score = load_model('../model/model01_H1_L.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model01_H1_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03_H1_L.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H1_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04_H1_L.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04_H1_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H1_L.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H1_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H2_H\n",
    "score = load_model('../model/model01_H2_H.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model01_H2_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03_H2_H.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H2_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04_H2_H.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04_H2_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H2_H.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H2_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H2_M\n",
    "score = load_model('../model/model01_H2_M.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model01_H2_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "\n",
    "score = load_model('../model/model03_H2_M.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H2_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04_H2_M.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04_H2_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H2_M.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H2_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H2_L\n",
    "score = load_model('../model/model01_H2_L.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model01_H2_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03_H2_L.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H2_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04_H2_L.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04_H2_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H2_L.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H2_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H3_H\n",
    "score = load_model('../model/model01_H3_H.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model01_H3_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H3_H.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H3_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H3_M\n",
    "score = load_model('../model/model01_H3_M.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model01_H3_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03_H3_M.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H3_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04_H3_M.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04_H3_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H3_M.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H3_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H3_L\n",
    "score = load_model('../model/model01_H3_L.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model01_H3_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03_H3_L.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H3_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04_H3_L.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04_H3_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H3_L.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H3_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H3_F\n",
    "score = load_model('../model/model01_H3_F.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model01_H3_F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03_H3_F.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H3_F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H3_F.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H3_F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H4_H\n",
    "score = load_model('../model/model01_H4_H.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model01_H4_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03_H4_H.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H4_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H4_H.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H4_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H4_M\n",
    "score = load_model('../model/model01_H4_M.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model01_H4_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04_H4_M.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04_H4_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H4_M.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H4_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H4_L\n",
    "\n",
    "score = load_model('../model/model03_H4_L.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H4_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "\n",
    "score = load_model('../model/model05_H4_L.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H4_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H4_F\n",
    "score = load_model('../model/model01_H4_F.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model01_H4_F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03_H4_F.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H4_F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04_H4_F.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04_H4_F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H4_F.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H4_F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "colab-nn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
