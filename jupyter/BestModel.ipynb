{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model using Keras Sequantial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "FtJth4hT577a",
    "outputId": "ce296e87-fcd1-4261-8057-6daacd747370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329 train examples\n",
      "704 test examples\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 999)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow_core.estimator import inputs\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "\n",
    "from  IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "\n",
    "def normalize_and_encode(dataframe):\n",
    "    column_names_to_not_normalize = ['result']\n",
    "    column_names_to_normalize = [x for x in list(dataframe) if x not in column_names_to_not_normalize ]\n",
    "    x = dataframe[column_names_to_normalize].values\n",
    "    x_scaled = preprocessing.normalize(x)\n",
    "    df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = dataframe.index)\n",
    "    dataframe[column_names_to_normalize] = df_temp\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit([ \"H\", \"A\", \"D\"])\n",
    "    dataframe.loc[:,['result']]=le.transform(dataframe['result'])\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "def get_X_and_y(dataframe):\n",
    "    X = dataframe.drop(columns=['result']).values\n",
    "    y = dataframe[['result']].values\n",
    "    return X,y\n",
    "\n",
    "\n",
    "df02 = pd.read_csv('../data/sliding02_shots.csv', sep=',', index_col=0)\n",
    "\n",
    "n02 = normalize_and_encode(df02)\n",
    "\n",
    "train02, test02 = train_test_split(n02, test_size=0.1, shuffle=False)\n",
    "print(len(train02), 'train examples')\n",
    "print(len(test02), 'test examples')\n",
    "\n",
    "\n",
    "train_X02,train_y02 = get_X_and_y(train02)\n",
    "\n",
    "test_X02,test_y02 = get_X_and_y(test02)\n",
    "\n",
    "\n",
    "#Many models train better if you gradually reduce the learning rate during training. Use optimizers.schedules to reduce the learning rate over time:\n",
    "#The code sets a schedules.InverseTimeDecay to hyperbolically decrease the learning rate to 1/2 of the base rate at 1000 epochs, 1/3 at 2000 epochs and so on.\n",
    "\n",
    "def get_lr_schedule(train, batch_size):\n",
    "    lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "    0.001,\n",
    "    decay_steps=(len(train)//batch_size)*1000,\n",
    "    decay_rate=1,\n",
    "    staircase=False)\n",
    "    return lr_schedule\n",
    "\n",
    "def get_optimizer(train, batch_size):\n",
    "    return tf.keras.optimizers.Adam(get_lr_schedule(train, batch_size))\n",
    "\n",
    "\n",
    "#Each model in this tutorial will use the same training configuration. So set these up in a reusable way, starting with the list of callbacks.\n",
    "#The training for this tutorial runs for many short epochs. To reduce the logging noise use the tfdocs.EpochDots which simply a . for each epoch and, and a full set of metrics every 100 epochs.\n",
    "\n",
    "def get_callbacks(name):\n",
    "    return [\n",
    "        tfdocs.modeling.EpochDots(),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200),\n",
    "        #tf.keras.callbacks.TensorBoard(logdir/name), # Jupyter Notebook\n",
    "        #tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1) # Google Colab\n",
    "      ]\n",
    "\n",
    "def compile_and_fit(model, name, X, y, validation_split, batch_size, optimizer=None, max_epochs=1000):\n",
    "    if optimizer is None:\n",
    "        optimizer = get_optimizer(X, batch_size)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy','mse', 'mae', 'mape'])\n",
    "\n",
    "    model.summary()\n",
    "     \n",
    "    history = model.fit(\n",
    "        X,\n",
    "        y,\n",
    "        validation_split=validation_split,\n",
    "        batch_size=batch_size,\n",
    "#        steps_per_epoch = 50, # (len(train_X01)//batch_size,\n",
    "        epochs=max_epochs,\n",
    "        callbacks=get_callbacks(name),\n",
    "        verbose=0)\n",
    "    \n",
    "    model.save(\"../model/%s.h5\" %name) \n",
    "    \n",
    "    return history\n",
    "\n",
    "def plot_history(model_history):\n",
    "\tplt.plot(model_history.history['accuracy'])\n",
    "\tplt.plot(model_history.history['val_accuracy'])\n",
    "\tplt.title(\"%s accuracy\" %model_history)\n",
    "\tplt.ylabel('accuracy')\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.legend(['train', 'val'], loc='upper left')\n",
    "\tplt.show()\n",
    "\t\n",
    "\tplt.plot(model_history.history['loss'])\n",
    "\tplt.plot(model_history.history['val_loss'])\n",
    "\tplt.title(\"%s loss\" %model_history)\n",
    "\tplt.ylabel('loss')\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.legend(['train', 'val'], loc='upper left')\n",
    "\tplt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.012482</td>\n",
       "      <td>0.011769</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.010699</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.039230</td>\n",
       "      <td>0.057061</td>\n",
       "      <td>0.488587</td>\n",
       "      <td>0.238944</td>\n",
       "      <td>0.417260</td>\n",
       "      <td>0.189015</td>\n",
       "      <td>0.028531</td>\n",
       "      <td>0.007133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053495</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.574178</td>\n",
       "      <td>0.278173</td>\n",
       "      <td>0.256775</td>\n",
       "      <td>0.106990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.010640</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.022166</td>\n",
       "      <td>0.029555</td>\n",
       "      <td>0.059110</td>\n",
       "      <td>0.495044</td>\n",
       "      <td>0.236439</td>\n",
       "      <td>0.557848</td>\n",
       "      <td>0.284465</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.014777</td>\n",
       "      <td>0.040638</td>\n",
       "      <td>0.066498</td>\n",
       "      <td>0.384213</td>\n",
       "      <td>0.162552</td>\n",
       "      <td>0.321409</td>\n",
       "      <td>0.132997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007188</td>\n",
       "      <td>0.012795</td>\n",
       "      <td>0.015805</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.037632</td>\n",
       "      <td>0.056448</td>\n",
       "      <td>0.451585</td>\n",
       "      <td>0.218266</td>\n",
       "      <td>0.466638</td>\n",
       "      <td>0.210740</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.022579</td>\n",
       "      <td>0.041395</td>\n",
       "      <td>0.056448</td>\n",
       "      <td>0.504270</td>\n",
       "      <td>0.222029</td>\n",
       "      <td>0.376321</td>\n",
       "      <td>0.173108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010289</td>\n",
       "      <td>0.010289</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.015829</td>\n",
       "      <td>0.006332</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.069647</td>\n",
       "      <td>0.037989</td>\n",
       "      <td>0.560339</td>\n",
       "      <td>0.259592</td>\n",
       "      <td>0.234266</td>\n",
       "      <td>0.117133</td>\n",
       "      <td>0.018995</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.060149</td>\n",
       "      <td>0.025326</td>\n",
       "      <td>0.535013</td>\n",
       "      <td>0.300747</td>\n",
       "      <td>0.357730</td>\n",
       "      <td>0.183614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>0.020384</td>\n",
       "      <td>0.064551</td>\n",
       "      <td>0.023782</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.050961</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.546982</td>\n",
       "      <td>0.244613</td>\n",
       "      <td>0.251408</td>\n",
       "      <td>0.105320</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.016987</td>\n",
       "      <td>0.033974</td>\n",
       "      <td>0.057756</td>\n",
       "      <td>0.485829</td>\n",
       "      <td>0.234421</td>\n",
       "      <td>0.455252</td>\n",
       "      <td>0.234421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7028</td>\n",
       "      <td>2</td>\n",
       "      <td>0.020289</td>\n",
       "      <td>0.015420</td>\n",
       "      <td>0.006898</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.040578</td>\n",
       "      <td>0.048694</td>\n",
       "      <td>0.324626</td>\n",
       "      <td>0.174487</td>\n",
       "      <td>0.474766</td>\n",
       "      <td>0.243470</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.040578</td>\n",
       "      <td>0.085214</td>\n",
       "      <td>0.482881</td>\n",
       "      <td>0.235354</td>\n",
       "      <td>0.454477</td>\n",
       "      <td>0.263759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7029</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.017929</td>\n",
       "      <td>0.018427</td>\n",
       "      <td>0.014941</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.024901</td>\n",
       "      <td>0.044822</td>\n",
       "      <td>0.104584</td>\n",
       "      <td>0.443238</td>\n",
       "      <td>0.234070</td>\n",
       "      <td>0.458179</td>\n",
       "      <td>0.229089</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.019921</td>\n",
       "      <td>0.024901</td>\n",
       "      <td>0.034861</td>\n",
       "      <td>0.104584</td>\n",
       "      <td>0.517941</td>\n",
       "      <td>0.273911</td>\n",
       "      <td>0.313753</td>\n",
       "      <td>0.129485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7030</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007617</td>\n",
       "      <td>0.015870</td>\n",
       "      <td>0.019044</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.016928</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.516293</td>\n",
       "      <td>0.249683</td>\n",
       "      <td>0.389336</td>\n",
       "      <td>0.211596</td>\n",
       "      <td>0.021160</td>\n",
       "      <td>0.008464</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.063479</td>\n",
       "      <td>0.038087</td>\n",
       "      <td>0.355481</td>\n",
       "      <td>0.181972</td>\n",
       "      <td>0.499366</td>\n",
       "      <td>0.236987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7031</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.020806</td>\n",
       "      <td>0.035667</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.019815</td>\n",
       "      <td>0.047556</td>\n",
       "      <td>0.055483</td>\n",
       "      <td>0.491416</td>\n",
       "      <td>0.245708</td>\n",
       "      <td>0.392341</td>\n",
       "      <td>0.198152</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.015852</td>\n",
       "      <td>0.043593</td>\n",
       "      <td>0.067372</td>\n",
       "      <td>0.408193</td>\n",
       "      <td>0.210041</td>\n",
       "      <td>0.483490</td>\n",
       "      <td>0.214004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7032</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006541</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.020563</td>\n",
       "      <td>0.023501</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.039168</td>\n",
       "      <td>0.031334</td>\n",
       "      <td>0.411259</td>\n",
       "      <td>0.254589</td>\n",
       "      <td>0.493511</td>\n",
       "      <td>0.211505</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.007834</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.050918</td>\n",
       "      <td>0.074418</td>\n",
       "      <td>0.446510</td>\n",
       "      <td>0.246755</td>\n",
       "      <td>0.415176</td>\n",
       "      <td>0.180171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7033 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result  odds-home  odds-draw  odds-away  home-wins  home-draws  \\\n",
       "0          2   0.012482   0.011769   0.007489   0.003566    0.010699   \n",
       "1          1   0.009236   0.012191   0.010640   0.011083    0.003694   \n",
       "2          0   0.007188   0.012795   0.015805   0.015053    0.007526   \n",
       "3          2   0.010289   0.010289   0.007281   0.015829    0.006332   \n",
       "4          2   0.004077   0.020384   0.064551   0.023782    0.006795   \n",
       "...      ...        ...        ...        ...        ...         ...   \n",
       "7028       2   0.020289   0.015420   0.006898   0.016231    0.008116   \n",
       "7029       2   0.009960   0.017929   0.018427   0.014941    0.009960   \n",
       "7030       2   0.007617   0.015870   0.019044   0.012696    0.012696   \n",
       "7031       2   0.005271   0.020806   0.035667   0.007926    0.011889   \n",
       "7032       2   0.006541   0.016450   0.020563   0.023501    0.003917   \n",
       "\n",
       "      home-losses  home-goals  home-opposition-goals  home-shots  \\\n",
       "0        0.021398    0.039230               0.057061    0.488587   \n",
       "1        0.022166    0.029555               0.059110    0.495044   \n",
       "2        0.015053    0.037632               0.056448    0.451585   \n",
       "3        0.009497    0.069647               0.037989    0.560339   \n",
       "4        0.003397    0.050961               0.027179    0.546982   \n",
       "...           ...         ...                    ...         ...   \n",
       "7028     0.016231    0.040578               0.048694    0.324626   \n",
       "7029     0.024901    0.044822               0.104584    0.443238   \n",
       "7030     0.016928    0.033855               0.033855    0.516293   \n",
       "7031     0.019815    0.047556               0.055483    0.491416   \n",
       "7032     0.011750    0.039168               0.031334    0.411259   \n",
       "\n",
       "      home-shots_on_target  home-opposition_shots  \\\n",
       "0                 0.238944               0.417260   \n",
       "1                 0.236439               0.557848   \n",
       "2                 0.218266               0.466638   \n",
       "3                 0.259592               0.234266   \n",
       "4                 0.244613               0.251408   \n",
       "...                    ...                    ...   \n",
       "7028              0.174487               0.474766   \n",
       "7029              0.234070               0.458179   \n",
       "7030              0.249683               0.389336   \n",
       "7031              0.245708               0.392341   \n",
       "7032              0.254589               0.493511   \n",
       "\n",
       "      home-opposition_shots_on_target  away-wins  away-draws  away-losses  \\\n",
       "0                            0.189015   0.028531    0.007133     0.000000   \n",
       "1                            0.284465   0.011083    0.011083     0.014777   \n",
       "2                            0.210740   0.007526    0.007526     0.022579   \n",
       "3                            0.117133   0.018995    0.009497     0.003166   \n",
       "4                            0.105320   0.010192    0.006795     0.016987   \n",
       "...                               ...        ...         ...          ...   \n",
       "7028                         0.243470   0.008116    0.016231     0.016231   \n",
       "7029                         0.229089   0.004980    0.019921     0.024901   \n",
       "7030                         0.211596   0.021160    0.008464     0.012696   \n",
       "7031                         0.198152   0.011889    0.011889     0.015852   \n",
       "7032                         0.211505   0.011750    0.007834     0.019584   \n",
       "\n",
       "      away-goals  away-opposition-goals  away-shots  away-shots_on_target  \\\n",
       "0       0.053495               0.021398    0.574178              0.278173   \n",
       "1       0.040638               0.066498    0.384213              0.162552   \n",
       "2       0.041395               0.056448    0.504270              0.222029   \n",
       "3       0.060149               0.025326    0.535013              0.300747   \n",
       "4       0.033974               0.057756    0.485829              0.234421   \n",
       "...          ...                    ...         ...                   ...   \n",
       "7028    0.040578               0.085214    0.482881              0.235354   \n",
       "7029    0.034861               0.104584    0.517941              0.273911   \n",
       "7030    0.063479               0.038087    0.355481              0.181972   \n",
       "7031    0.043593               0.067372    0.408193              0.210041   \n",
       "7032    0.050918               0.074418    0.446510              0.246755   \n",
       "\n",
       "      away-opposition_shots  away-opposition_shots_on_target  \n",
       "0                  0.256775                         0.106990  \n",
       "1                  0.321409                         0.132997  \n",
       "2                  0.376321                         0.173108  \n",
       "3                  0.357730                         0.183614  \n",
       "4                  0.455252                         0.234421  \n",
       "...                     ...                              ...  \n",
       "7028               0.454477                         0.263759  \n",
       "7029               0.313753                         0.129485  \n",
       "7030               0.499366                         0.236987  \n",
       "7031               0.483490                         0.214004  \n",
       "7032               0.415176                         0.180171  \n",
       "\n",
       "[7033 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HtHfSEgO6sUN",
    "outputId": "b7fd6a48-30f1-470e-f92b-118a7046a09a"
   },
   "outputs": [],
   "source": [
    "# Jupyter notebook\n",
    "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "shutil.rmtree(logdir, ignore_errors=True)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 128*8\n",
    "EPOCHS=10000\n",
    "validation_split = 0.2\n",
    "size_histories = {}\n",
    "\n",
    "##### Model01:\n",
    "\n",
    "model01_H1_H = tf.keras.Sequential([\n",
    "    layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "    layers.Dense(13, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02_H1_H = tf.keras.Sequential([\n",
    "    layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "    layers.Dense(21, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H1_H = tf.keras.Sequential([\n",
    "    layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "    layers.Dense(29, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04_H1_H = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H1_H = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "##### Model01:\n",
    "\n",
    "model01_H1_M = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02_H1_M = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H1_M = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04_H1_M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H1_M = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "##### Model01:\n",
    "\n",
    "model01_H1_L = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02_H1_L = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H1_L = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04_H1_L = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H1_L = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "### 2 Hidden Layers:\n",
    "#### High Amount of Neurons (H):\n",
    "##### Model01:\n",
    "\n",
    "model01_H2_H = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02_H2_H = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H2_H = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04_H2_H = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H2_H = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "##### Model01:\n",
    "\n",
    "model01_H2_M = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02_H2_M = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H2_M = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04_H2_M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H2_M = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "##### Model01:\n",
    "\n",
    "model01_H2_L = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02_H2_L = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H2_L = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04_H2_L = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H2_L = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "### 3 Hidden Layers:\n",
    "#### High Amount of Neurons (H):\n",
    "##### Model01:\n",
    "\n",
    "model01_H3_H = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02_H3_H = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H3_H = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04_H3_H = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H3_H = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "##### Model01:\n",
    "\n",
    "model01_H3_M = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02_H3_M = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H3_M = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04_H3_M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H3_M = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "##### Model01:\n",
    "\n",
    "model01_H3_L = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02_H3_L = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H3_L = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04_H3_L = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H3_L = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Funnel Architecture:\n",
    "##### Model01:\n",
    "\n",
    "model01_H3_F = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(10, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02_H3_F = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(18, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H3_F = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(22, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(11, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04_H3_F = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(20, activation='relu'),\n",
    "  layers.Dense(15, activation='relu'),\n",
    "  layers.Dense(11, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H3_F = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(19, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "### 4 Hidden Layers:\n",
    "#### High Amount of Neurons (H):\n",
    "##### Model01:\n",
    "\n",
    "model01_H4_H = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02_H4_H = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H4_H = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04_H4_H = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H4_H = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "##### Model01:\n",
    "\n",
    "model01_H4_M = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02_H4_M = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H4_M = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04_H4_M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H4_M = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "##### Model01:\n",
    "\n",
    "model01_H4_L = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02_H4_L = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H4_L = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04_H4_L = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H4_L = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Funnel Architecture:\n",
    "##### Model01:\n",
    "\n",
    "model01_H4_F = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(10, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02_H4_F = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(18, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H4_F = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(22, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(11, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04_H4_F = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(20, activation='relu'),\n",
    "  layers.Dense(15, activation='relu'),\n",
    "  layers.Dense(11, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H4_F = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(19, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Validate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 21)                462       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 21)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                264       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 39        \n",
      "=================================================================\n",
      "Total params: 1,077\n",
      "Trainable params: 1,077\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.3255,  loss:1.0996,  mae:1.0373,  mape:94739656.0000,  mse:1.4362,  val_accuracy:0.4415,  val_loss:1.0917,  val_mae:1.0061,  val_mape:101369184.0000,  val_mse:1.3717,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5279,  loss:0.9914,  mae:1.0373,  mape:94739656.0000,  mse:1.4600,  val_accuracy:0.5016,  val_loss:1.0088,  val_mae:1.0061,  val_mape:101369184.0000,  val_mse:1.3922,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5364,  loss:0.9810,  mae:1.0373,  mape:94739656.0000,  mse:1.4618,  val_accuracy:0.5024,  val_loss:1.0007,  val_mae:1.0061,  val_mape:101369184.0000,  val_mse:1.3951,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5357,  loss:0.9740,  mae:1.0373,  mape:94739656.0000,  mse:1.4634,  val_accuracy:0.5071,  val_loss:0.9994,  val_mae:1.0061,  val_mape:101369184.0000,  val_mse:1.3966,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5449,  loss:0.9670,  mae:1.0373,  mape:94739656.0000,  mse:1.4639,  val_accuracy:0.5047,  val_loss:0.9964,  val_mae:1.0061,  val_mape:101369184.0000,  val_mse:1.3958,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5481,  loss:0.9662,  mae:1.0373,  mape:94739656.0000,  mse:1.4645,  val_accuracy:0.4984,  val_loss:0.9966,  val_mae:1.0061,  val_mape:101369184.0000,  val_mse:1.3963,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5487,  loss:0.9648,  mae:1.0373,  mape:94739648.0000,  mse:1.4661,  val_accuracy:0.5008,  val_loss:0.9962,  val_mae:1.0061,  val_mape:101369184.0000,  val_mse:1.3983,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5465,  loss:0.9621,  mae:1.0373,  mape:94739656.0000,  mse:1.4664,  val_accuracy:0.5008,  val_loss:0.9973,  val_mae:1.0061,  val_mape:101369184.0000,  val_mse:1.3978,  \n",
      "......................................................"
     ]
    }
   ],
   "source": [
    "# H1_H\n",
    "size_histories['model01_H1_H'] = compile_and_fit(model01_H1_H, 'model01_H1_H', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02_H1_H'] = compile_and_fit(model02_H1_H, 'model02_H1_H', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03_H1_H'] = compile_and_fit(model03_H1_H, 'model03_H1_H', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04_H1_H'] = compile_and_fit(model04_H1_H, 'model04_H1_H', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H1_H'] = compile_and_fit(model05_H1_H, 'model05_H1_H', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H1_M\n",
    "size_histories['model01_H1_M'] = compile_and_fit(model01_H1_M, 'model01_H1_M', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02_H1_M'] = compile_and_fit(model02_H1_M, 'model02_H1_M', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03_H1_M'] = compile_and_fit(model03_H1_M, 'model03_H1_M', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04_H1_M'] = compile_and_fit(model04_H1_M, 'model04_H1_M', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H1_M'] = compile_and_fit(model05_H1_M, 'model05_H1_M', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H1_L\n",
    "size_histories['model01_H1_L'] = compile_and_fit(model01_H1_L, 'model01_H1_L', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02_H1_L'] = compile_and_fit(model02_H1_L, 'model02_H1_L', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03_H1_L'] = compile_and_fit(model03_H1_L, 'model03_H1_L', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04_H1_L'] = compile_and_fit(model04_H1_L, 'model04_H1_L', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H1_L'] = compile_and_fit(model05_H1_L, 'model05_H1_L', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H2_H\n",
    "size_histories['model01_H2_H'] = compile_and_fit(model01_H2_H, 'model01_H2_H', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02_H2_H'] = compile_and_fit(model02_H2_H, 'model02_H2_H', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03_H2_H'] = compile_and_fit(model03_H2_H, 'model03_H2_H', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04_H2_H'] = compile_and_fit(model04_H2_H, 'model04_H2_H', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H2_H'] = compile_and_fit(model05_H2_H, 'model05_H2_H', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H2_M\n",
    "size_histories['model01_H2_M'] = compile_and_fit(model01_H2_M, 'model01_H2_M', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02_H2_M'] = compile_and_fit(model02_H2_M, 'model02_H2_M', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03_H2_M'] = compile_and_fit(model03_H2_M, 'model03_H2_M', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04_H2_M'] = compile_and_fit(model04_H2_M, 'model04_H2_M', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H2_M'] = compile_and_fit(model05_H2_M, 'model05_H2_M', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H2_L\n",
    "size_histories['model01_H2_L'] = compile_and_fit(model01_H2_L, 'model01_H2_L', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02_H2_L'] = compile_and_fit(model02_H2_L, 'model02_H2_L', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03_H2_L'] = compile_and_fit(model03_H2_L, 'model03_H2_L', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04_H2_L'] = compile_and_fit(model04_H2_L, 'model04_H2_L', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H2_L'] = compile_and_fit(model05_H2_L, 'model05_H2_L', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3_H\n",
    "size_histories['model01_H3_H'] = compile_and_fit(model01_H3_H, 'model01_H3_H', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02_H3_H'] = compile_and_fit(model02_H3_H, 'model02_H3_H', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03_H3_H'] = compile_and_fit(model03_H3_H, 'model03_H3_H', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04_H3_H'] = compile_and_fit(model04_H3_H, 'model04_H3_H', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H3_H'] = compile_and_fit(model05_H3_H, 'model05_H3_H', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3_M\n",
    "size_histories['model01_H3_M'] = compile_and_fit(model01_H3_M, 'model01_H3_M', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02_H3_M'] = compile_and_fit(model02_H3_M, 'model02_H3_M', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03_H3_M'] = compile_and_fit(model03_H3_M, 'model03_H3_M', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04_H3_M'] = compile_and_fit(model04_H3_M, 'model04_H3_M', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H3_M'] = compile_and_fit(model05_H3_M, 'model05_H3_M', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3_L\n",
    "size_histories['model01_H3_L'] = compile_and_fit(model01_H3_L, 'model01_H3_L', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02_H3_L'] = compile_and_fit(model02_H3_L, 'model02_H3_L', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03_H3_L'] = compile_and_fit(model03_H3_L, 'model03_H3_L', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04_H3_L'] = compile_and_fit(model04_H3_L, 'model04_H3_L', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H3_L'] = compile_and_fit(model05_H3_L, 'model05_H3_L', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3_F\n",
    "size_histories['model01_H3_F'] = compile_and_fit(model01_H3_F, 'model01_H3_F', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02_H3_F'] = compile_and_fit(model02_H3_F, 'model02_H3_F', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03_H3_F'] = compile_and_fit(model03_H3_F, 'model03_H3_F', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04_H3_F'] = compile_and_fit(model04_H3_F, 'model04_H3_F', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H3_F'] = compile_and_fit(model05_H3_F, 'model05_H3_F', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H4_H\n",
    "size_histories['model01_H4_H'] = compile_and_fit(model01_H4_H, 'model01_H4_H', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02_H4_H'] = compile_and_fit(model02_H4_H, 'model02_H4_H', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03_H4_H'] = compile_and_fit(model03_H4_H, 'model03_H4_H', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04_H4_H'] = compile_and_fit(model04_H4_H, 'model04_H4_H', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H4_H'] = compile_and_fit(model05_H4_H, 'model05_H4_H', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H4_M\n",
    "size_histories['model01_H4_M'] = compile_and_fit(model01_H4_M, 'model01_H4_M', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02_H4_M'] = compile_and_fit(model02_H4_M, 'model02_H4_M', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03_H4_M'] = compile_and_fit(model03_H4_M, 'model03_H4_M', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04_H4_M'] = compile_and_fit(model04_H4_M, 'model04_H4_M', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H4_M'] = compile_and_fit(model05_H4_M, 'model05_H4_M', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H4_L\n",
    "size_histories['model01_H4_L'] = compile_and_fit(model01_H4_L, 'model01_H4_L', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02_H4_L'] = compile_and_fit(model02_H4_L, 'model02_H4_L', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03_H4_L'] = compile_and_fit(model03_H4_L, 'model03_H4_L', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04_H4_L'] = compile_and_fit(model04_H4_L, 'model04_H4_L', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H4_L'] = compile_and_fit(model05_H4_L, 'model05_H4_L', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H4_F\n",
    "size_histories['model01_H4_F'] = compile_and_fit(model01_H4_F, 'model01_H4_F', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02_H4_F'] = compile_and_fit(model02_H4_F, 'model02_H4_F', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03_H4_F'] = compile_and_fit(model03_H4_F, 'model03_H4_F', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04_H4_F'] = compile_and_fit(model04_H4_F, 'model04_H4_F', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H4_F'] = compile_and_fit(model05_H4_F, 'model05_H4_F', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "1DwuhGCJH2yL",
    "outputId": "13ba4f8a-0516-4937-d37a-8b0130fc5a56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model02_H3_M\n",
      "Loss: 0.968027185310017\n",
      "Test Accuracy: 0.5411932\n",
      "Mean Square Error: 1.4485668\n",
      "Mean Absolute Error: 1.0269886\n",
      "Mean Absolute Percentage Error: 99905360.0\n"
     ]
    }
   ],
   "source": [
    "# H1_H\n",
    "score = load_model('../model/model01_H1_H.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model01_H1_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02_H1_H.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02_H1_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03_H1_H.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H1_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04_H1_H.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04_H1_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H1_H.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H1_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H1_M\n",
    "score = load_model('../model/model01_H1_M.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model01_H1_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02_H1_M.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02_H1_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03_H1_M.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H1_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04_H1_M.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04_H1_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H1_M.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H1_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H1_L\n",
    "score = load_model('../model/model01_H1_L.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model01_H1_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02_H1_L.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02_H1_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03_H1_L.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H1_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04_H1_L.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04_H1_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H1_L.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H1_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H2_H\n",
    "score = load_model('../model/model01_H2_H.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model01_H2_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02_H2_H.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02_H2_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03_H2_H.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H2_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04_H2_H.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04_H2_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H2_H.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H2_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H2_M\n",
    "score = load_model('../model/model01_H2_M.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model01_H2_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02_H2_M.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02_H2_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03_H2_M.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H2_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04_H2_M.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04_H2_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H2_M.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H2_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H2_L\n",
    "score = load_model('../model/model01_H2_L.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model01_H2_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02_H2_L.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02_H2_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03_H2_L.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H2_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04_H2_L.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04_H2_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H2_L.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H2_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H3_H\n",
    "score = load_model('../model/model01_H3_H.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model02_H3_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02_H3_H.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02_H3_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03_H3_H.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H3_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04_H3_H.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04_H3_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H3_H.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H3_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H3_M\n",
    "score = load_model('../model/model01_H3_M.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model02_H3_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02_H3_M.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02_H3_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03_H3_M.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H3_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04_H3_M.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04_H3_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H3_M.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H3_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H3_L\n",
    "score = load_model('../model/model01_H3_L.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model02_H3_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02_H3_L.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02_H3_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03_H3_L.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H3_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04_H3_L.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04_H3_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H3_L.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H3_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H3_F\n",
    "score = load_model('../model/model01_H3_F.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model02_H3_F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02_H3_F.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02_H3_F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03_H3_F.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H3_F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04_H3_F.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04_H3_F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H3_F.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H3_F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H4_H\n",
    "score = load_model('../model/model01_H4_H.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model02_H4_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02_H4_H.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02_H4_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03_H4_H.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H4_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04_H4_H.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04_H4_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H4_H.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H4_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H4_M\n",
    "score = load_model('../model/model01_H4_M.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model02_H4_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02_H4_M.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02_H4_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03_H4_M.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H4_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04_H4_M.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04_H4_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H4_M.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H4_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H4_L\n",
    "score = load_model('../model/model01_H4_L.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model02_H4_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02_H4_L.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02_H4_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03_H4_L.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H4_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04_H4_L.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04_H4_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H4_L.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H4_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H4_F\n",
    "score = load_model('../model/model01_H4_F.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model02_H4_F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02_H4_F.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02_H4_F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03_H4_F.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H4_F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04_H4_F.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04_H4_F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H4_F.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H4_F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd3RU1dr48e+elmQyk14ICSGBhFBDbyLNCqioqAgqCtjFdu+rV/29lquv9Xa9eO1iB+sVbIgiAZTee29JCElIQnqbmf37Y0KkJCFAhskkz2etWYtT5uznJGGe2Wc3pbVGCCGEOJHB2wEIIYRoniRBCCGEqJMkCCGEEHWSBCGEEKJOkiCEEELUyeTtAJpKSEiITkpK8nYYp6W0tJTAwEBvh9FovhYv+F7MvhYv+F7MvhYveDbm1atXH9ZaR9Z1rMUkiOjoaFatWuXtME5LWloaI0aM8HYYjeZr8YLvxexr8YLvxexr8YJnY1ZK7a/vmDxiEkIIUSdJEEIIIeokCUIIIUSdWkwbhBCtVXV1NRkZGVRUVHil/ODgYLZu3eqVss+Er8ULTROzv78/cXFxmM3mRr9HEoQQPi4jIwO73U5CQgJKqXNefnFxMXa7/ZyXe6Z8LV44+5i11uTl5ZGRkUFiYmKj3yePmITwcRUVFYSHh3slOQjfoJQiPDz8tGuZkiCEaAEkOYhTOZO/kRaTIAoqNHklld4OQwghWowWkyAKqzS7ckq8HYYQQrQYLSZBABzIL/N2CEK0SkopJk2aVLvtcDiIjIzk8ssvP63rJCQkcPjw4UafM3fuXFJSUkhKSuLFF1+sPefGG28kJSWF7t27M3XqVKqrq+u93nvvvce999573L4RI0bUzswwatQoevbsSbdu3bjrrrtwOp31Xmvy5MlYrVaKi4tr9z3wwAMopU66r4EDB9KrVy/i4+OJjIykV69e9OrVi3379jV4/8f63//9XxYsWNDo80+XJAghxFkLDAxk06ZNlJeXA/DTTz8RGxvr0TKdTifTpk3jhx9+YMuWLcycOZMtW7YA7gSxbds2Nm7cSHl5OW+//fYZl/PZZ5+xfv16Nm3aRG5uLp9//nmD5yclJTF79mwAXC4XCxYsqPNnsXz5ctatW8czzzzD9ddfz7p161i3bh0JCQkn3Wd9nnvuOUaOHHn6N9VILaabq0lJghDi6W82s+VgUZNes2vbIJ66otspzxs9ejTfffcd1157LTNnzmTixIksXrwYgPz8fKZOncqePXuwWq28+eabpKamkpeXx8SJE8nNzWXAgAEcuwTyRx99xCuvvEJVVRUDBw7kP//5D0ajsfb4ihUrSEpKokOHDgBMmDCB2bNn07VrV8aMGVN73oABA8jIyDjj+w8KCgLctaKqqqpTNvZOnDiRTz/9lJtuuom0tDSGDBnCDz/80OjyHA4HERER3HvvvcybN4+XX36Z2bNnM3/+fMrLyzn//PN57bXXUEpx0003ce2113LVVVcRFxfHbbfdxuzZs3E6nXzxxRd06tTpjO8bPFiDUEq9q5TKUUptque4Ukq9opTapZTaoJTqc8yxvyilNiulttacc8rmd5MB9udJghDCWyZMmMCsWbOoqKhgw4YNDBw4sPbYU089Re/evdmwYQPPP/88N998MwBPP/00559/PmvXrmXs2LEcOHAAgK1bt/Lpp5/y22+/sW7dOoxGIx9//PFx5WVmZtKuXbva7bi4ODIzM487p7q6mg8//JBRo0Y1GPunn35a+4inV69eJ038eemllxIVFYXdbufaa69t8FrJycnk5uZSUFDAzJkzmTBhQoPn16WwsJA+ffqwYsUKBg8ezN13383KlSvZuHEjhYWFzJ07t873RUdHs3btWm677Tb+8Y9/nHa5J/JkDeI9YDrwQT3HRwPJNa+BwGvAQKXUecAQILXmvF+B4UBaQ4UZlGJ/XulZBy2EL2vMN31PSU1NZd++fcycOfO4b/AAv/76K19++SUAF1xwAXl5eRQWFrJo0SK++uorAC677DJCQ0MBmD9/PqtXr6Z///4AlJeXExUVddw1j61tHHXid8l77rmHYcOGMXTo0AZjv/7665k+fXrt9okzp/74449UVFRw44038ssvv3DxxRc3eL1x48Yxa9Ysli9fzhtvvNHguXWxWCxcffXVtdsLFy5k+vTpVFRUcPjwYfr27cvo0aPrLBegb9++fP/996dd7ok8liC01ouUUgkNnHIl8IF2/5aXKaVClFIxgAb8AQugADOQfaryyhyagrJqSiod2PxazJMzIXzK2LFjeeihh0hLSyMvL692f0Mf5nU9INBac8stt/DCCy/UW1ZcXBzp6em12xkZGbRt27Z2++mnnyY3N/eMPqDr4u/vz9ixY5k9e/YpE8SECRPo06cPt9xyCwbD6T+oCQgIqP25lJWV8dBDD7F27VpiY2N5/PHH6x3w5ufnB4DRaMThcJx2uSfy5idpLJB+zHYGEKu1XqqUWgBk4U4Q07XWdU5CopS6A7gDwBLdEYCvflxIfJCxrtObnZKSEtLS0rwdRqP5WrzgezGfSbzBwcHH9Zo51442ohYXFzN+/Hj8/PxISEggPT0dh8NBcXExgwYN4t133+WRRx5h8eLFhIWFoZSq3f+nP/2JefPmUVBQQElJCYMGDWLChAncfvvtREZGkp+fT0lJCfHx8WitKSkpoXPnzuzYsYONGzfStm1bPvnkE9555x2Ki4t5//33+f777/nmm28oLS09Kd5jf14VFRVUVVUdt8/pdFJaWkpWVhYlJSW0adMGh8PBnDlzGDx4cL0/7+rqasrLywkNDeWJJ55gxIgRFBcX18Z89AP8WCeWf/SD/eh2Xl4eBoMBPz8/Dh48yOeff8748eMpLi6uLe9oGcXFxRiNRkpLS0+6z6Nlnc7flzcTRF3tCloplQR0AeJq9v2klBqmtV500slavwm8CWCPTdYAUR26MqJ7jIdCblq+tnCJr8ULvhfzmcS7detWr84tdPRDyG6307lzZzp37gyA1WrFZDJht9t5/vnnmTJlCkOGDMFqtfLhhx9it9t57rnnmDhxIsOHD2f48OHEx8djs9lISEjg+eefZ9y4cbhcLsxmM6+++ip2ux2lFDabjdDQUF599VWuueYanE4nU6dOZcCAAQA8+OCDtG/fnksuuQRwP3p58skna+M99ufl7++PxWI5bp/RaCQwMBCDwcANN9xAZWUlTqeTCy64gAcffBCTqe6PTrPZTEBAAHa7nQceeKB2/9GY6/o9nVj+0QRxdNtut3PDDTcwePBg2rdvz+DBg/Hz88Nutx9XnlIKu92O3W4nMDAQo9F4Unn+/v707t27sb9ad1XOUy8gAdhUz7E3gInHbG8HYoCHgSeO2f8k8KdTlRUen6zbP/Kt/s+CndpXLFiwwNshnBZfi1dr34v5TOLdsmVL0wdyGoqKirxa/unytXi1brqY6/pbAVbpej5XvTkOYg5wc01vpkFAodY6CzgADFdKmZRSZtwN1Kec59a/5qnShoxCz0UshBCtiMceMSmlZgIjgAilVAbwFO4GZ7TWrwPfA2OAXUAZMKXmrV8AFwAbcTdYz9Vaf3Oq8gJMithwK8UVZ98wI4RoeWbMmMHLL7+My+WqbTgeMmQIr7766mlfa9q0afz222/H7XvggQeYMmVKPe/wTZ7sxTTxFMc1MK2O/U7gztMtz6Cgc5sgduZ4r7FOCNF8TZkyhSlTpjTJehBnklR8UYuaasNiUuzPK6uzS50QQojT06ISxJGyahwuTbpMuSGEEGetRSWIHnHBAPy2u+HZIIUQQpxai0oQgzuEA7B6/xEvRyKEEL6vRSWIPvHueVy2HWra2SyFEA2T9SDcTmc9iMmTJ580DcjXX3990jxWDd2/p7WoBGH1M2E2KrKOnN7C3EKIsyPrQfyusetBTJw4kVmzZh23b9asWUyc2GAH0HOqxc1q17mNXSbrE63a9W8sPWnf5akxTBqcQHmVk8kzVpx0/Nq+cVzXrx35pVXc/dHq4459eufgRpUr60G4NXY9iIsuuojJkyeTlZVFTEwMZWVl/Pzzz7z11lsAXHXVVaSnp1NRUcGdd97J/ffff8b3cKZaVA0CIDHCRqbUIIQ452Q9CLfGrgdhNBoZN24cn332GQBz5sxh5MiRtWM03n33XVavXs2qVat4/fXXj5sd91xpcV+12wT5kZ5fxvcbshiT6huT9gnRlBr6xh9gMTZ4PCzQ0ugaw4lkPYjfNXY9iIkTJ/Lwww/zwAMPMGvWrNrECfDKK6/w3//+F3Anw507dxIeHt5guU2txSWIhIhANPD9JkkQQpxrsh6EW2PXgxgyZAhZWVmsX7+eJUuW1LZJpKWl8fPPP7N06VKsVitDhw6tdw0IT2pxj5jiwwIBWHtAuroKca5NnTqVJ598kh49ehy3f9iwYbWPiNLS0oiIiCAoKOi4/T/88AMFBQUAXHjhhXzxxRfk5OQA7jaM/fv3H3fN/v37s3PnTvbu3UtVVRWzZs1i7NixALz99tv8+OOPzJw584wW7DmqpKSErKwswN0G8f3339dOZ96Q+Ph4nnvuOe65554Gz1NKMX78eG655RbGjBmDv78/4F5yNDQ0FKvVyrZt21i5cuUZ38PZaHEJon24FYDMI+UcLqn0cjRCtC5xcXHHrYNw1J///GdWrVpFamoqjz76KO+//z7gbptYtGgRffr0Yd68ecTHxwPQtWtXnn32WS655BJSU1O5+OKLaz+ojzKZTEyfPp1LL72ULl26MH78eLp1cy+5etddd5Gdnc3gwYPp1asXzzzzzBndT2lpKWPHjiU1NZWePXsSFRXFXXfd1aj33nnnnXTs2PGU502cOJH169cf11YxatQoHA4HqampPPHEE7WP2s411VLmLUpJSdHbt2/H5dKkPPED1U7N9Bt6c3lq21O/2Utaw2I23uZrMZ/pgkFdunTxTECN0BST351LvhYvNF3Mdf2tKKVWa6371XV+i6tBGAyKjpE2rBYjFdUub4cjhBA+q8U1UgMkR9sprXJwbd+4U58shGgVZD2I09ciE0THyEC+3XCQ8ioHFpMRo6HhgS1C+Dqt9SkHcLV2rX09iDNpTmhxj5gAOkba0BqGvLSA7zZmnfoNQvgwf39/8vLyZB0UUS+tNXl5ebW9pBqrRdYgusS4h8aXVTlYuvswY3s234ZqIc5WXFwcGRkZ5ObmeqX8ioqK0/7g8SZfixeaJmZ/f3/i4k7vsXuLTBCJEYFYLUbCAy0s2X3uh6cLcS6ZzWYSExO9Vn5aWhq9e/f2Wvmny9fiBe/F3CIfMRkNyl2LULA/r4zMI+XeDkkIIXxOi0wQAN3bBnG4yD1QbqnUIoQQ4rS12ATRLTaYcoeL6/rGkRRl83Y4Qgjhc1psguje1r0+9dBOkfRqF+LlaIQQwve02ASRHG3DYjSwIf0ImzILqXLIqGohhDgdHksQSql3lVI5SqlN9RxXSqlXlFK7lFIblFJ9jjkWr5Sap5TaqpTaopRKON3yzUYDnWPsLNqZy+X//pWtWbJOtRBCnA5P1iDeAxpaxmk0kFzzugN47ZhjHwB/1Vp3AQYAOWcSQI/YYDIL3D2Yth2SBCGEEKfDYwlCa70IyG/glCuBD7TbMiBEKRWjlOoKmLTWP9Vcp0RrXXYmMfSIDaa0yomfycDO7JIzuYQQQrRa3hwoFwukH7OdUbMvDjiilPoKSAR+Bh7VWjtPvIBS6g7ctQ8iIyNJS0s77nhlkfstdrNm+bYDpNnOqCLiMSUlJSfF3Jz5WrzgezH7WrzgezH7WrzgvZi9mSDqmllM445pKNAbOAB8CkwG3jnpZK3fBN4E93oQJ86jX+108dyKHwmxW8mvcja7dQFaw1oF3uZrMftavOB7MftavOC9mL3ZiykDaHfMdhxwsGb/Wq31Hq21A/ga6FPH+0/JbDTQJSYIf5OBF6/pceo3CCGEqOXNBDEHuLmmN9MgoFBrnQWsBEKVUpE1510AbDnTQnrEBrE/r4whHSPOPmIhhGhFPNnNdSawFEhRSmUopW5VSt2llDq6oOv3wB5gF/AWcA9ATVvDQ8B8pdRG3I+i3jrTOFJjQyiudPDJiv3szpWGaiGEaCyPtUForSee4rgGptVz7CcgtSni6Bbrnvr78a838/ClKUwbmdQUlxVCiBavRU73fayOkTYMCvzNRg7knVFvWSGEaJVa7FQbR/mbjbQPD8RiMnAgXxKEEEI0VotPEABJUTYcTi0JQgghTkOrSBDJUTZKKx1kFZbLpH1CCNFILb4NAqBTtB0NvHlTX4yGusbnCSGEOFGrqEEcXTCo2qUlQQghRCO1igTRMdKdID5flc769CNejkYIIXxDq0gQARYjcaH+LNiey/xtzWvCPiGEaK5aRYIASIywYTaq2vUhhBBCNKzVJIj4MCsuDZlHpKurEEI0RqtJEO3DrThdmvR8qUEIIURjtJoEER8WCMChogqcLu3laIQQovlrRQnCCsCL43pIV1chhGiE1pMgwt0JIqe40suRCCGEb2g1CcLmZyIs0My36w+yal++t8MRQohmr9UkCIB2oVa2Hipm+V5JEEIIcSqtKkEkRgRiUJAhYyGEEOKUWlWCiA8PxKUhPb/U26EIIUSz16oSRLvQAAD2y7oQQghxSq0rQdR0dS0qd+BeElsIIUR9WmWCePjSTiglYyGEEKIhrSpBtAnyx2xUZBRUeDsUIYRo9lpVgjAaFNFB/sxZn8nS3XneDkcIIZo1jyUIpdS7SqkcpdSmeo4rpdQrSqldSqkNSqk+JxwPUkplKqWmN2VccSEBHDxSwabMwqa8rBBCtDierEG8B4xq4PhoILnmdQfw2gnH/w9Y2NRBJUYGooDMIzIWQgghGuKxBKG1XgQ0NGT5SuAD7bYMCFFKxQAopfoC0cC8po4rLtSKBvbnyVgIIYRoiDfbIGKB9GO2M4BYpZQB+DvwsCcKPdqTaX+ejIUQQoiGmLxYdl39TDVwD/C91jr9VF1RlVJ34H48RWRkJGlpaacsNPeIE4Dy8rJGne9JJSUlXo/hdPhavOB7MftavOB7MftavODFmLXWHnsBCcCmeo69AUw8Zns7EAN8DBwA9gGHgSLgxVOV1alTJ90Yh4srdPtHvtXvLN7TqPM9acGCBd4O4bT4Wrxa+17Mvhav1r4Xs6/Fq7VnYwZW6Xo+V71Zg5gD3KuUmgUMBAq11lnAjUdPUEpNBvpprR9tqkLDAi1YLUbSC+QRkxBCNMRjCUIpNRMYAUQopTKApwAzgNb6deB7YAywCygDpngqlhPiItruz3/XZnJRl2iGJEWci2KFEMLneCxBaK0nnuK4Bqad4pz3cHeXbVJxYf7s3VnKzuxiSRBCCFGPVjWS+qgOETYAMmQshBBC1KtVJoj48EAA9h2WsRBCCFGfVpkgateFkLEQQghRr9aZIGoGywUHmL0ciRBCNF+tOkFc2CXay5EIIUTz1SoThM3PRKjVLGMhhBCiAa0yQQBEB/nz1eoMvl6b6e1QhBCiWWq1CSIxIpAKh4utWUXeDkUIIZqlVpsg4sOtKGDboWJvhyKEEM1Sq00Q7WrWhdh8UFaWE0KIurTeBFHTk+lwSRXZRRVejkYIIZqf1psgagbLDeoQRrXT5eVohBCi+Wm1CSI2NAClYGBiOHGhVm+HI4QQzU6jEoRSqqNSyq/m3yOUUvcrpUI8G5pn+ZmMxIUGsCunWOZkEkKIOjS2BvEl4FRKJQHvAInAJx6L6hzpFGVn+Z58Lvh7GvmlVd4ORwghmpXGJgiX1toBXA38S2v9B9zLg/q05Gg7BeVVuDQs2Jbj7XCEEKJZaWyCqFZKTQRuAb6t2efzM911irbhdLmXIf15a7a3wxFCiGalsQliCjAYeE5rvVcplQh85Lmwzo1O0XYAesQGM39rDgXymEkIIWo1KkForbdore/XWs9USoUCdq31ix6OzeM6RtpQCuJCA6hyupiz/qC3QxJCiGajUWtSK6XSgLE1568DcpVSC7XWf/RgbB4XYDHSPszKkbJqPrx1AAMTw70dkhBCNBuNfcQUrLUuAsYBM7TWfYGLPBfWuZMcbWfboSKGJkdiMbXaYSFCCHGSxn4impRSMcB4fm+kbhG6xgSx93AppZUOPl15gDs+WIXW2tthCSGE1zU2QTwD/Ajs1lqvVEp1AHZ6Lqxzp2e7YFwaNh8sosrhYt6WbH7dddjbYQkhhNc1tpH6c611qtb67prtPVrrazwb2rnRI9Y9IHxDxhHG929Hu7AA/jxnM5UOp5cjE0II72rsVBtxSqn/KqVylFLZSqkvlVJxp3jPuzXnb6rnuFJKvaKU2qWU2qCU6lOzv5dSaqlSanPN/utP/7YaL9LuR9tgf9ZnFOJnMvJ/V3Znd24pbyzc48lihRCi2WvsI6YZwBygLRALfFOzryHvAaMaOD4aSK553QG8VrO/DLhZa92t5v3/8vS8T6lxIWzMOALAiJQoLkuN4dUFu8gtrvRksUII0aw1NkFEaq1naK0dNa/3gMiG3qC1XgTkN3DKlcAH2m0ZEKKUitFa79Ba76y5xkEg51Rlna0eccHsyyujsKwagKeu6MqMKf2JtPt5slghhGjWGjUOAjislLoJmFmzPRHIO8uyY4H0Y7YzavZlHd2hlBoAWIDddV1AKXUH7toHkZGRpKWlnVEgKt/d3vD+dwtJjfz9R5KWDmXVGqtZndF1T6WkpOSMY/YGX4sXfC9mX4sXfC9mX4sXvBiz1vqULyAe9yOmXNzf6L8G4hvxvgRgUz3HvgPOP2Z7PtD3mO0YYDswqDExdurUSZ+p0spq3fGx7/RLP2w9bv8ny/frXk//qHOLK8742g1ZsGCBR67rKb4Wr9a+F7Ovxau178Xsa/Fq7dmYgVW6ns/VxvZiOqC1Hqu1jtRaR2mtr8I9aO5sZADtjtmOAw4CKKWCahLI49r9+MmjrBYTPeKCWb73+Cdi/RPCKKl08OIP2zwdghBCNDtnM3T4bKfZmAPcXNObaRBQqLXOUkpZgP/ibp/4/CzLaLQBiWFsyDhCedXv3VuTomzcen4Hvlidwap9DTWnCCFEy3M2CaLBB/NKqZnAUiBFKZWhlLpVKXWXUuqumlO+B/YAu4C3gHtq9o8HhgGTlVLral69ziLORjk/KYJqp+a3EwbJ3XdBEjHB/jz+9SYcsna1EKIVaWwjdV0anI9Caz3xFMc1MK2O/R/hhanEByaGY/MzMX9bNhd1ja7dH+hn4snLu/LArHVszCykd3zouQ5NCCG8osEEoZQqpu5EoIAAj0TkJRaTgWGdIvh5aw7PujRGw+8VpNE9YugRF0xcqNWLEQohxLnV4CMmrbVdax1Ux8uutT6b2kezdFmPtuQWV7JoZ+5Jx44mh89XpTNfVp8TQrQCMr/1MS7uGk14oIWZyw/UedzhdPHR8gPc9dFq5m46dI6jE0KIc0sSxDEsJgPX9WvH/G05ZB4pP+m4yWjgg6kD6B4bzLRP1sgKdEKIFk0SxAluGhSP1pqPlu2v83hwgJkPbx1I3/ahPDhrLbPXZZ7jCIUQ4tyQBHGCuFArF3eNZtaKA1RU1z3lt83PxPtTBjAgMYz0/LJzHKEQQpwbkiDqcPPgBArKqvm5gcboAIuRD28dyL0XJAOwP69UVqITQrQokiDqMKhDOJF2P77bkNXgeWaj+8d3qLCCy//9K7fMWMm2Q0XnIkQhhPA4SRB1MBoUY7q34ZdtOZRUOk55fpTdjz9e3Il1BwoY/fJi7p+5lj25JecgUiGE8BxJEPUY3SOGSoeLRTtOHhNxIoNBMWVIIgsfHsmdwzry05ZsLvnnIg7W0RNKCCF8hSSIevRrH0pYoIV5mxs/3iE00MKjozuz+JGRPD+uB21D3IPN52/NpqC0ylOhCiGER7S40dBNxWQ0cGHnKOZuPkS101Xb3tAYETY/xvdzz2SeUVDG7R+swmhQ9E8IY2BiOAM7hNGrnUdXURVCiLMmNYgGXNKtDcUVDpbtOfPF8+JCrXx731CmDknkSFk1/5q/gwlvLuOrNe7xE5lHyvlw6T5W7ctvVHuHEEKcK1KDaMDQ5AgCzEbmbc5maPKZL4vdtW0QXdsG8RhQWFbNqv359IgNZsuaPazal88TszcDYDYqLugcxd0jkqSGIYTwOqlBNMDfbGRYp4jax0xNIdhq5sIu0UQF+QMwtmdblj52Ae/c0o9bBiewcl8B172+hOyiiiYpTwghzpTUIE7hur7t+HFzNj9vyWZ0j5gmv75SipjgAGKCA7iwSzQPXJTMsj35RNckkO83ZtE/IYxIu1+Tly2EEA2RBHEKIztHERsSwDu/7mVU9zYo1eBCemfN7m/m4poFi3ZkF3PPx2sA6BAZ6G7gTgxjaHIE4TZJGEIIz5JHTKdgNCimjUxi1f4Cvj7HE/MlR9mYc+8QHh3dmYTwQL7dcJAHP13Hir3u9bFX7cvn9g9W8dhXG/lidQY5xfJYSgjRdKQG0QjX92/H56vTeeSLjRwpq2bigHj8zUaPl6uUIjUuhNS4EO4a3hGnS7PtUBHxYe7Fi4orHaTnl7Fibz4zVxzAoGBU9zY8Pba7PJISQpw1SRCNYDQoZkzuzz0fr+Hpb7bwxsI9vHRtKsM7nXnPpjONo1vb4NrtkSlRjEyJwuXSbD1UxDfrs5i/NZugAPevdc2BAuLDrETI4yghxBmQBNFIIVYLH982kOV783lq9mZue38l79zSn2HnOEnUxVCTOLq1DeZPl6ZgMCi01tz3yVoOFpbTr30o5ydF0jnGTo/Y4NoR3kII0RBpgzgNSikGdQjns7sG0zHSxv2z1pJV2LzmWzIYfm9Ef+vmfjxwYTIllU7+NX8Hd364mlcX7AJAa83cTYcoLKv2VqhCiGZOahBnIDjAzH9u7MPl//6VB2et45PbB2E0eLZ30+lSStUO0Hvwok6UVTnYkV2Czc/ddrL5YBF3fbQapaBzmyAGJoYxqEMYgztGEBxg9nL0QojmQGoQZ6hDpI3/u7I7y/fmM/2XXd4O55SsFhO92oWQFGUHoEtMEF/cNZg/XNSJsEAzs1Ye4K6P1rAu/QgAK/bmc//MtXy3IYvyql120AEAACAASURBVLpX1hNCtGweq0Eopd4FLgdytNbd6ziugJeBMUAZMFlrvabm2C3A4zWnPqu1ft9TcZ6NcX1iWbwzl5fn72Bwx3AGJIZ5O6RGMxoU/RLC6JcQBiRT5XCxMbOQ5GgbAPmlVSzZncec9QexWoyMSIkksLKKIUPdExdWVDvxMxkaHBdSUFrFnPUHySqsIDnKxkVdogm2Su1ECF/hyUdM7wHTgQ/qOT4aSK55DQReAwYqpcKAp4B+gAZWK6XmaK0LPBjrGVFK8ezVPVibfoQ/fraOn/4wnACL57u/eoLFZKBv+9Da7VHd23Bx12iW78nju41ZLNiWQ25xNX+peZT2xNeb+GbDwdo1vCefl1A7+ju3uJKX5m5jzvqDVDlcmAwKh0vz3pT+jEiJYlNmIVsOFmEyKtqFWeneNthnf25CtGQeSxBa60VKqYQGTrkS+EC7F3JeppQKUUrFACOAn7TW+QBKqZ+AUcBMT8V6Nmx+Jl4cl8rEt5bxyi87eWRUZ2+H1GSMBsV5SRGclxQBwNyfF9TWGC7sEk1QgJldOSW8sXA3by3aw40D43n6yu5YLUYW7sjlur5x3Dw4geQoG5sPFtElxv146+et2fzr55215RgUJIQH8stDIwB4e/EeFu7IJcBsJMBixN9kxO5v4n8uSZFEIsQ5pNyfzx66uDtBfFvPI6ZvgRe11r/WbM8HHsGdIPy11s/W7H8CKNda/62Oa9wB3AEQGRnZ97PPPvPMjTTC2xsrWXrQwf8NCaCtrXFNOyUlJdhsNg9H1nTqizenzMUvBxzYLHB5BwsADpfGVE/DfVm1prRa49SQVepiX6GLzBIX9/Z210C+21PF6mwn1S6ocmoqnRBohmeHBKCU4lCpiyirwqAUTpcmu0wTYIJQfwMurSmrBpvF3dU3t7CUSqOVUD+FzaIordbsLXTicIFTg8MFWkNyqIHwAO83yfna3wT4XsznOt5yh8bhArvlzDuyNDbmokpNkJ+7nLT0ag6VanpHGekUWv/j4JEjR67WWver65g3ezHVFa1uYP/JO7V+E3gTICUlRY8YMaLJgjtdPfpVMuJvafyYY+P9ywc06j1paWl4M+bT1VC845uwnLqK0FqjlKKooprzX/wFq8VEUICJ/XnlVDpc/OGiTlw9Ipn9eaUM/2saYYEWyqocVFQroJx/Xt+TEb3jWL4nj2lvLjvp+m/f3I8RXaPZmFHIB0v3ERXkh83PTG5xJQfyy3jpmh6E2/xYc6CANfsL6BRtp1O0HafW7MktqZ0Ofsnuw+SXVtEnPvSk8SZaaw7kl1FW5STQYqJNsD8Wk6H23korHXw1bxHdu/cnKsgPq8VEQWkV/jU1qYpqJ2VVTsICLU340z57aWlpDBs2nPSCMmKCA7CYvJ9oG3Li3/GSXYc5Ul7Npd3aNKo3YqXDicOpCfQzkVVYzvRfdrE/r4yswnKig/zpHR/C1b3jSIqy8e6ve3lu3lacLk2HyEDG9Y5lTI8YOkS6P+yzCssJtVoanJnB6dLM/G4BZYEd2ZVbwtDkiNq/N601Dpfmv2szeWvRHvYcLmPjny/BajGxZt52Plm4h7n7qhmYGMajozvTO/73x8haa3JLKhu8V28miAyg3THbccDBmv0jTtifds6iOkPhNj8euDCZZ7/byoJtOYzsHOXtkFqUo99+rGYjz1zZnQXbcyivcjIsOZIuMUH0T3B3ELBaTDw2ujP78kqxWkyU5GZyfp9ute0rXdq6e2+ZjYaal0IpiAl2f5jvOVzCwh255JVW4XRpAsxG4sOsFJRVE27zY/GOw/zz5x3HxWZQsOHPl2LzM/Hh0v38sOkQSsH5SRHcPDiBgR3CCPI3sy+vjJF/Szvmntz38/jlXZk4IJ69h0t54rdy+M19jp/JQKXDxes39WFU9xh+23WYW99fRYfIQHq3CyU4wIzZqLh1aCJRdn/WpR9h8Y5cQgMtKAUOp8bPZOCy1Bjs/mZ2ZBezNauIIH8zkXY/Imx+hNsstaslVjqcrD1whCW7DrMuoxCtNdFB/vztup4AvPPrXg4VljMwMZz+CWGkF5TVToOfX1bF8L+mYTIoEiMC6REXzIWdoxnWKQK7v5nC8mq2HyqmpLKasionBaVVZBVWMK5PLElRdg4VVrDmQAHrM46QdaSCNsH+dI8N5qIuUVgtv39MVTqcLNpxmG83HMRiNPDXmtgWbMshKMBEgNlEaZWD/NIqwgIttX8Xx3K4NF+tyWBMjxj8zUbmrD/IrJXpJEXZePjSFC7sHIWp5mdSWF7NK/N3suVgEQcLyymtdHCkrJpHRnXm9mEdqKx28d3GLNqHWUmOspN5pJzXF+6hb/tQkqJs9IoP4dbzE4mwWZi/NYe/zdvBu7/tY80TFwPw2FcbWb4nnyFJEVzRM4ZBHcIxGw21X3Amz1jJpsxCyqqcwAb8TO5jQ5Mj2Z9XyoQ3l+FwaXKLK+kaE8T/G9MFp8v9ffqPl6Rw94gkPl15gOkLdnH1f5YwbWRHHr60M5lHyrnslcUcOcU4KG8miDnAvUqpWbgbqQu11llKqR+B55VSR1PdJcBj3grydNw8OIFPlh/gz99spm9CKEH+0mOnqZmMBq7qHctVvWPrPB5p9+PO4R1rt9PSchjRs23tdpC/uabnVt2u7BXLlb1icbk05dVOrBbjcVXzBy5K5qZB8ezILmFnTjFGg6JLTBD+Nd+a/3l9L6aNLOGnLdl8ujKd2z9YxdW9Y/nn9b1ICLfyl2tSCQowUVTuIPNIOUUV1SRFub9NJkYEcm8vPxKTO5NdXEF+SRXRQf50bhMEQHKUnT+NSmH1vgIW78ylrMpJtdPF1X1iibL7s2Z/AX//acdJ9zQ8JRK7v5m5mw7xjzqOr3vyYkKsFh79ciP/XZuJQUFKmyD8TAYsxt/XUl97oIB5W7J5a/He2n39E0KZ1tm9dspfr01l7+FSdmSXsGBbDl+tyeSla3pwff94luw6zN01MxMfZTQorqj53czbcognZ2/GbHRPf39ocwVVDhfrnrwYqwU+XLqPuZsPsTGjkKIKB6FWM2Nr3qu15pEvN5BTfPy34Uu7RdM/IQytNXd+uJouMUEUlFXx3dpy8irWU+10cX3/eJ67ugfDOkXytx+3c+eHq/EzGbhxYHuevKIrAWYjX67JICE8kNS4EOz+JsKsFvoluD+eEiICWffkJceVW1blqK2J9IkPpU/Nt/Y7hnXkQF4ZW7IKa8+9Y2gH2odZ3UsKbM0G4LLUGF69oQ9Wiwm7n4nx/dphLj7IhEsGkxgeWDsYttLhond8CCaDgbE923Jhl6iTHiMFWIxMHpLIdf3a8d6SfXSICAQgyu7HmB4xJEfZmPrSSX8StTzWBqGUmom7JhABZOPumWQG0Fq/XtPNdTruBugyYIrWelXNe6cC/6/mUs9prWecqryUlBS9ffv2pr6N07Zibz4T31rGiE6RvDGpb+03kbq0pEdMzZU3Y652uli0I5eKaheXpTZuLZGzjbfS4az9VmgyKCodLqKD/DEaFPmlVeSXVlFUUU1ucSW5xZUcLqnk/guSMRgUq/fnk1dSxcAO4fUOlqx0OFmz/whr0wsID7QwqlsMa1f8dlLMDqeLNQeOkBxlIzTQQn5pFZsyCwkKMBNoMRIcYCbc5lf7QZpTVEF2USWd2tjwMxmpcrjYc7ikNjm+lrabuZuySGljZ3SPGM5Piqit+WitOVhYwfZDRVQ5XAT6mQi1WogO8ifS7kducSWTZ6xg88EiAsxGkkPg/tG9T/pArXa6mL81hzUHCkgID+SGgfGA+xGPpwfCulyaVfsL2H6oiHZhVkakHP8EwpN/x0qpetsg0Fq3iFenTp10c/HBkr26/SPf6ke/3KBdLle95y1YsODcBdUEfC1erX0vZl+LV2vfibm8yqGdTpfPxHssT8YMrNL1fK7KVBseMGlwAoeKKnh1wW6i7H784eJO3g5JiFbvXEzR39JIgvCQhy5JIaeokpfn7yTCZmHS4ARvhySEEKdFEoSHKKV4flwP8kureGL2Zl5dsBuDgo5RNh4d3fm4dR2EEKI5kgThQWajgdcn9eWjZfvZmOnuubBwey5Xv7qEF6/pge/M3CSEaI0kQXiY2WhgypDE2u2C0iru+XgNf/xsPQlBBs4/spGUaDtX9GxLiLV5DYASQrRuzXvIYwsUGmjhg1sH8OcrumIywJx1B3li9maG/zWNGb/trR3kIoQQ3iY1CC8wGw1MHpJIQvV+hg8fzpasIl78YRtPf7OFL9dk8OK4VLrHShuFEMK7pAbhZUq515P+YOoApt/Qm+yiSq59fQmr9ze72c2FEK2MJIhmQinF5alt+eGBobQJ8ufOD1dz+BQTaQkhhCdJgmhmImx+vD6pL0UV1Tz0+Xpc0iYhhPASSRDNUOc2QTx+WRfStucyY8k+b4cjhGilJEE0U5MGteeiLtG89MM2lu7O83Y4QohWSBJEM6WU4i/XptI2xJ8b3l7G1PdW8sXqDA7klaE9uAqgEEIcJd1cm7GwQAvf3j+U19N289mqdH7ZlgO41zzoGx9KVJAfeaVVFJVXc1WvWK7pG+fliIUQLYkkiGbO5mfioUtT+OPFndiRU8zKfQWs3pfP+oxCluw+TITND5fW/M/n7gVQJgyI93bIQogWQhKEjzAYFJ3bBNG5TRCTBrU/7pjTpZk8YwVPzt5M99hgGWQnhGgS0gbRAhgNipcn9CY00Mz9s9ZSVuU47nh5lZNFO3LJk3EVQojTIDWIFiIs0MI/x/fixneWc/0by7iiZwxB/mb25pXy+aoM8kurCLGamXXHoNplHIUQoiFSg2hBzkuK4JUJvTlSXsXz32/j0a828taiPfSJD+HlCb0wGQw89Pl6mRBQCNEoUoNoYa7o2ZbLU2MornRQUuEg1GohwOJealEpxf0z1zJzxQFuOqEdQwghTiQ1iBZIKUWQv5m2IQG1yQHgitQYBncI56W52zh4pBwArTWbMgtZsuvwSW0XQojWTWoQrYhSihfG9WDMK4u5++M1XNs3ji9WpbM+w73aXaDFyB3DOnL7sESsFvnTEKK1kxpEK5MQEcg/r+/FjkPFPPH1JooqHDx7VXdmTOnP0ORI/vnzDi7420J+2Jh1yhHbTpeWUd1CtGAe/ZqolBoFvAwYgbe11i+ecLw98C4QCeQDN2mtM2qO/QW4DHcS+wl4QMunUZO4tFsblj12IbkllXSMDEQpBcDIlChW78/nia83c/fHaxiZEsl9FybTMy4Eo8F9TlmVg6/WZPLh0v1szy4mKcrG36/rSc92Id68JSGEB3gsQSiljMCrwMVABrBSKTVHa73lmNP+BnygtX5fKXUB8AIwSSl1HjAESK0571dgOJDmqXhbm2CrmWCr+aT9fduHMefeIby3ZB//+GkHC/6zBLufie6xwVSUVLBzwXxKKh10jw1i2siOzF53kJveXs7MOwbJAD0hWhhP1iAGALu01nsAlFKzgCuBYxNEV+APNf9eAHxd828N+AMWQAFmINuDsYpjmIwGbhvagWv7xrFwRy4r9uazMbOQvDIXo7vHMmFAO/rEh6KU4saB7bnu9aVMnrGCNyb1rd0vhPB9ylNPbZRS1wKjtNa31WxPAgZqre895pxPgOVa65eVUuOAL4EIrXWeUupvwG24E8R0rfX/1lHGHcAdAJGRkX0/++wzj9yLp5SUlGCz2bwdRqPVF+/BEhd/X1VBXoUm0Ax2iyLYogjzV1jNCotRYTNDpNVAVIAiIsBAoJlzkkhays+4OfO1mH0tXvBszCNHjlytte5X1zFP1iDq+t9/YjZ6CJiulJoMLAIyAYdSKgnoAhydnvQnpdQwrfWi4y6m9ZvAmwApKSl6xIgRTRf9OZCWloYvxdxQvJdfVM3XazPZkV1MfmkVh4uryCgqp7jQQXmVk0qH67jzlfr9DyTAbCQmJAB/swGz0UCbIH9sfiYKy6sxGhQDE8O4vn/8cV12myLm5sjX4gXfi9nX4gXvxezJBJEBtDtmOw44eOwJWuuDwDgApZQNuEZrXVhTM1imtS6pOfYDMAh3EhHNUJC/mZsHJ9R7vKTSQXp+GQfyy0jPL6OwvLr2WHGFg0OFFVQ7XVQ5XWzPLqas0klwgJlKh5MfNh1ixpJ9vH1zP5Kj7efgboQQ4NkEsRJIVkol4q4ZTABuOPYEpVQEkK+1dgGP4e7RBHAAuF0p9QLuL5rDgX95MFbhYTY/E11igugSc/rzQC3ZfZgHZq3jmteWMGNKf/q2D2vw/OKKavzNRsxG6cUtxNnw2P8grbUDuBf4EdgKfKa13qyUekYpNbbmtBHAdqXUDiAaeK5m/xfAbmAjsB5Yr7X+xlOxiubtvI4RfHX3eYTb/Ljx7eX8J20XS3YfZn9eKVXHPLrKKa5g2sdr6PHnefR/7mfmbjrkxaiF8H0eHQehtf4e+P6EfU8e8+8vcCeDE9/nBO70ZGzCt7QLs/L5XYN5cNY6/jJ3e+3+ALOR0T3aEBJg4YvV6VQ4XNwxrAPL9+Rx10erubW7hRHeC1sInybzKQifEWHz46PbBpJ5pJz9h0vJOFLO6n0FfL8xi7JqJyNTonhsTGc6RtqoqHZy+wereHfTYbqtyWBcn+OXYy0orWL2ukysFhOX94yRqUWEqIP8rxA+JzYkgNiQAADG92vHS9em4nTp2tHeAP5mI2/d3I+r/zmPhz5fT2ZBObcOdc8xtXJfPvd8vIbcYvcCSn+bt51/jO/F+ckRXrkfIZorSRCiRTg2ORzlbzbyYB9/vskJ5u8/7eDNxXvoEhPEqn35tAuz8u1951NW5eSxrzYw6d3l3DGsAw9fkoJJGreFAGSyPtHC+ZkU02/ow5d3D+birtE4nC6mDEnk2/vOp3tsMAMSw/j2vqFM6B/PGwv3MPX9VRRVVB93jfT8Mmavc4/xqI/Tpck8Uk6lw+npWxLinJEahGgV+rYPq7d7bIDFyAvjetAzLpjHv97ENf9Zwls39yPEauZv87Yzc0V67Sp8gzqEcefwjkTa/Nh+qJhth4rYmlXM+vQjFFc6CDAbubpPLBP6t8Pp0hwqrKBvQihRdv9zebtCNAlJEELUmDAgnvhwK3d/tIaRf0/DoBRaayYNas81feNYsTeftxfvZcqMlbXvsZgMpETbubxnW7q1DWJ9+hG+XJ3BJ8sP1J4TaDEy/cY+jEyJ8sZtCXHGJEEIcYzzOkbw3f3n89WaTKocLi7vGUPnNu7BfalxIUwa3J607blorUmKspEQHnhcm8VNg9rz/8Z0IW1HDjY/M2GBZp6cvZk7P1jNe1P6c17S6TeEF5ZXE2gxStuIOOckQQhxgrhQK/dfmFznMT+TkUu7tWnw/aGBFq7u/Xu32k9uG8R1byzhjg9XM+s0pkXPK6nkwU/XsXjnYWKC/Xnqim6M6l532TlFFSzbm0+o1czgDuGSTESTkL8iITws2Grmg6kDCQ4wM+md5Xyz/uApV+IrLK/m+jeXsWJvPvddkES4zcJdH63mHz/twOXSuFyaA3llzNt8iAdnrWXwi79w/8y1THpnBRf+YyEr9+Wfo7sTLZnUIIQ4B9oE+/PxbQO5f9Za7pu5lnd+3cuYHm3ILqqkrMrBzYMTauepcro0989cy/68Uj6YOpDBHcO594Ik/ve/m3hl/k4+Wb6fsionZVXuHlOBFiNTzkvgqt6xZBSU8cIP27jxreW8dlMfLuwS7c3bFj5OEoQQ50hCRCD/vWcIn65M57WFu3j++234mQwYDYqv1x7k9Ul90Vrz7HdbWLgjlxfG9WBwx3DA/Wjrr9emMqxTJGnbcwjyN5PSxk7nNnZS2thrR4J3jw1mcIcIbnpnOXd/vIb3pwxgcMdwnC7ND5uyeGvxXiqqnPzxkk6nfFQmhCQIIc4ho0Fxw8B4Jg5oR3GlA6vZSEFZNTe/u4Lb3l9JlzADG3L3MWVIAhMHxB/3XqUUY3u2ZWzPtg2W4X6kNYDxbyzl1vdXclXvWJbvyWN3bikdIwMxGw1M+3gNn945qM6uv+VVTgrKqgj0MxEccPKytKL1kAQhhBcopQjyd3/4Rtr9mHXHIB6YtZZlu3K5fWgij43uclbXDw208PFtA3n0q418uTqD7rHB/HtiJ8b0iKGk0sHY6b9y/8x1zPvDMAL9TBSUVvHCD1v5aUs2BWW/DxTs1jaIu4Z35PLUmAZXAMwuqmDN/gJW7Mtn6e48wm0Wbhva4ZRde4sqqvlqdQY7c0pIjQvmqt6x+JlOf2Eo4RmSIIRoBoIDzLw3ZUDNymFdm+SaUUH+vDu5f51l/f26nlz3xlKenL2ZS7pF88TXmygoq2Jsz1g6RgUSEmChoMw9oeF9M9fy4bL9/N+V3Ulpc/yCTXkllby8poK1c+cD4Gcy0D8hjH15pUyZsZIrerblzmEd8DcbOHikgswj5WQdKQelyMgvY+7mQ5RVOQnyN/Hx8gO8umA3j4zqTLe2QWw7VMz+vFLahwdyQecoLKam6VPjcGnWHiigbUgA0UEygLEhkiCEaIX6JYRx38gkXvllF1+uySAl2s6MKf3p1vb4Lrh3D+/Ip6vSeWnuNsa8sphJg9pzbd84urUNYvHOwzz8xXryip08cGEyIztH0bmNHX+zkSqHi9fSdjN9wU6+WX/cQpIoBVpDWKCFy3rEcPPgBLrHBrFo52Ge+WYz0z5Zc1K8sSEBPDq6M5enxpBbUsmOQyUEB5jp1jYIQ808XIXl1aTnl9G5jb3ebr6r9uXz+K/lHJq3BIOCq3rH8vhlXQkLtDTRT7ZlkQQhRCv1h4s70S8hjIKyKi7t1gZ/88mPdgwGxcQB8Yzq1oa//LidD5ft570l+/AzGah0uOgQEcg9gxW3XNzpuPdZTAYeuCiZ6/u3Y+W+fFxaExMcQGxoANF2v9rJFY99bDW8UyRzHxzG0t155BRXkhgRSFKUjdX78/nrjzu4b+ZaHv1yA6VVv893FRcawIWdo9idW8qyPXk4XJooux93De/I9f3b4WcyUFThIKuwnDnrDvLW4j2E+Sv+Mb4n2w4VM+O3vaRtz+V/x3RhQGIYJZUOnC5NXGgAJZUOftqSzap9BThdmjbB/sQE+9M+PJB+CaFE2PzYe7iUr9ZksDu3hKt6xXJJHQ3/lQ4nnyw/QHGFgxsHxhNu82uqX6HHSYIQopVSSjGsU2Sjzg0NtPDCuB48fGkKP2/JZkd2MR0ibVzdO5blSxbX+742wf5ccYpG9WOZjYaTYrqgczTDO0XxzfqDrD1QQGxoAD1iQzh4pJwv12TwxeoMYkICuG1oBzpF2/h8VQbPfLuFZ77dcsL9wtW9Y7k4rIDRNeuDXNMnjke+3MD/fL6+3pjiw6xYTAZ+23WY4kpH7f4Imx+HSyoxKAi3+fH9xkP8e2Lv4+7X5dJM+3gNP2/NAeDTlem8N6X/cWurZxSUsSunhEEdwutM0t4kCUII0WhhgRbG9293zss1GhRX9Y7lqt6xx+2/pm/cSeeO6xPHyprGcqdLE2I1E2n3o1e7EOJCraSlpdWem9LGzpd3n8einbnkFlVi8zehgMwj5VhMBs7rGE5S1O8f5sUV1ezILmHlvnx2ZBfTNSaIy1PbEhZoYcKbS3n0yw30jAshPtwKwGsLd/Pz1hyevLwr/RPCmPr+Sq55bQmvTOxNWKCF95bsY/a6gzhdmuQoGx/eOpA2wc2nXUQShBCixemfEEb/hLpn7z2R0aAaPZGi3d9M3/ah9G0fetKxf9/Qh1H/XMRDn69n1h2DWLQzl7/P287Ynm2ZMiQBpRRf3X0ek2esYHLNhI/+ZgOTz3O3wTzx9WZufHsZX909hGBr/d2L9x0u5ePl+2kbEsCkQe09Oq2KJAghhGgCsSEBPDW2Gw99vp5bZqxg5b58OrcJ4oVxPWrbWtqFWZl97/nM3XQIk8H9iO9oA3nb4AAmvbOCqe+v5LWb+tQ5RfyaAwVMfW8lxRXutpKlu/OYfkOfRvXwyi6qYFdOCe3DrcSFWht1T5IghBCiiVzTJ5YDeaW8v3Q//RPC+Of1vQj0O/5j1uZn4to6Ho0N7BDOvyb04g+frmPwC7+QEG4lwuZH99hggssd5KxM56k5m4kK8mPOtPP5ZVs2f/5mC9M+WcOdwzqwNauInTklxIdZGZESRcfIQKqcLn7deZiZKw7wy7YcapY1YWhyBHcO60hsaECD9yMJQgghmohSij9eksIfL0k5o/eP6RFDShs7/12TyZ7DJWQXVfLhsv1UOVywegN924fW1i4mD0kE4Jlvt/DTlmzAPS9XaZWTZ7/bSnSQH8UVDsqqnETYLNw9oiNDOkaw5kAB7y3Zx03vLD9lPJIghBCiGekYaeOhS39PMBXVTt6evYBu3VMZ3imydtwHwOQhiQzrFMm+vFI6RtqID7NysLCCX7blsGZ/AcEBZoZ1iuD8pMjax1DnJUVw29AOpG3PpaTSwXUv1R+LJAghhGjG/M1GukeYGNG57ob0DpE2OkTaardjaxqvJw1q3+A161tb5FgeXQ9CKTVKKbVdKbVLKfVoHcfbK6XmK6U2KKXSlFJxxxyLV0rNU0ptVUptUUoleDJWIYQQx/NYglBKGfn/7Z17jBV3Fcc/X1mg2G1ZCoSgVB4RmmKChRJarDYFH1E0mFRMIU1tDKQRbdrG+IA0MbHRmKpRixJrW2kk9oV9YENiW9yuJj4CQnlbaWklKRFK0QCumrauxz9+58JwmeUGytyZWc4nubm/OfO7cz9zM7u/O7+5cw6sBD4GTAUWSWpOMvNdYLWZTQPuAL6VWbca+I6ZXQrMAg4W5RoEQRCcTJFnELOAPWb2spm9ATwMfLKpz1Sg29s9jfU+kHSY2XoAM+s1s38X6BoEQRA0oValD894w9IC4KNmtsSXbwCuMLObM30eBDaY2V2SrgUeA0YBHwCWAG8AE4FfA8vMrK/pPW4CbgIYPXr05WvW2pH30QAAB0JJREFUrClkX4qit7eXzs7O1h0rQt18oX7OdfOF+jnXzReKdZ4zZ85mM5uZu9LMCnkAnwbuyyzfAPywqc87gMeBLcBdwD5gOLAAOAJMIl1IfwxYfKr3mzJlitWNnp6eshVOi7r5mtXPuW6+ZvVzrpuvWbHOwCbr5/9qkVNM+4Bs0pZxwAl5f83sb2Z2rZlNB2732BF/7RZL01P/BdYCMwp0DYIgCJoocoD4EzBZ0kRJQ4CFwJPZDpJGSWo4LAdWZV47QlIjreNc4MTUjEEQBEGhFDZA+Df/m4GngeeBNWa2S9IdkuZ7t2uA3ZJeAMYA3/TX9gFfArol7QAE3FuUaxAEQXAyhV2kbjeS/gnsLtvjNBkFHCpb4jSomy/Uz7luvlA/57r5QrHO480stzDIQLqTerf1dyW+okjaVCfnuvlC/Zzr5gv1c66bL5TnXOid1EEQBEF9iQEiCIIgyGUgDRD3lC1wBtTNuW6+UD/nuvlC/Zzr5gslOQ+Yi9RBEATB2WUgnUEEQRAEZ5EYIIIgCIJcBsQA0aruRFlIWiXpoKSdmdhFktZLetGfR3hcklb4PmyX1PbUIpIultTjNTh2Sbq1ys6SzpO0UdI29/26xydK2uC+j/id/Ega6st7fP2EdvpmvAdJ2iJpXU1890raIWmrpE0eq+QxkXHukvSopL/48Ty7qs6SLvHPtvE4Kum2Svj2l6SpLg9gEPASKbHfEGAbMLVsL3e7mpRDamcm9m1SZlqAZcCd3p4H/Ip01/iVpCy37fYdC8zw9gXAC6SU7JV09vft9PZgYIN7rAEWevxuYKm3Pw/c7e2FwCMlHRdfBB4E1vly1X33AqOaYpU8JjJ+PwOWeHsI0FV1Z3cZBBwAxlfBt5QP4Sx/oLOBpzPLy4HlZXtlfCY0DRC7gbHeHku6wQ/gJ8CivH4luv8S+HAdnIG3A88BV5DuOO1oPj5IaV9me7vD+6nNnuNINVDmAuv8j7yyvv7eeQNEZY8J4ELgr82fVZWdM+/9EeD3VfEdCFNM7wReySzv81hVGWNm+wH8uVFotlL74dMZ00nfyivr7NM1W0kVB9eTziYPW8oF1ux0zNfXHwFGttMX+AHwFeB/vjySavsCGPCMpM1KNVigwscEaTbhNeB+n8q7T9L5VNu5wULgIW+X7jsQBgjlxOr4293K7IekTlINjtvM7OipuubE2upsZn1mdhnpm/ks4NJTOJXqK+kTwEEz25wN53SthG+Gq8xsBql88BckXX2KvlVw7iBN7f7YUimBf5GmaPqjCs74taf5wC9adc2JFeI7EAaIlnUnKsarksYC+HOj1nYl9kPSYNLg8ICZPe7hSjsDmNlh4DekOdkuSY08Y1mnY76+fjjwjzZqXgXMl7SXVIJ3LumMoqq+QKrb4s8HgSdIA3GVj4l9wD4z2+DLj5IGjCo7QxqAnzOzV325dN+BMEC0rDtRMZ4EbvT2jaR5/kb8M/4LhSuBI43Ty3YhScBPgefN7HuZVZV0ljRaUpe3hwEfIqWW7yFVJczzbezHAuBZ80ncdmBmy81snJlNIB2nz5rZ9VX1BZB0vqQLGm3SHPlOKnpMAJjZAeAVSZd46IOkejKVdXYWcXx6qeFVrm8ZF2IKuLAzj/SLm5eA28v2yXg9BOwH3iSN+otJc8jdwIv+fJH3FbDS92EHMLME3/eTTlW3A1v9Ma+qzsA0Urna7aR/Wl/z+CRgI7CHdLo+1OPn+fIeXz+pxGPjGo7/iqmyvu62zR+7Gn9fVT0mMt6XAZv82FgLjKiyM+lHFn8HhmdipftGqo0gCIIgl4EwxRQEQRAUQAwQQRAEQS4xQARBEAS5xAARBEEQ5BIDRBAEQZBLDBBB0AJJfU3ZNs9axmBJE5TJ9hsEVaKjdZcgOOf5j6V0HkFwThFnEEFwhnidhDuValJslPRuj4+X1O25+rslvcvjYyQ9oVS/Ypuk9/mmBkm6V6mmxTN+VziSbpH0Z9/OwyXtZnAOEwNEELRmWNMU03WZdUfNbBbwI1JeJby92symAQ8AKzy+Avitmb2XlBtol8cnAyvN7D3AYeBTHl8GTPftfK6onQuC/og7qYOgBZJ6zawzJ74XmGtmL3uSwwNmNlLSIVJ+/jc9vt/MRkl6DRhnZq9ntjEBWG9mk335q8BgM/uGpKeAXlKqiLVm1lvwrgbBCcQZRBC8Nayfdn998ng90+7j+LXBj5Ny7lwObM5kfA2CthADRBC8Na7LPP/R238gZWsFuB74nbe7gaVwrNDRhf1tVNLbgIvNrIdUYKgLOOksJgiKJL6RBEFrhnnVugZPmVnjp65DJW0gfdla5LFbgFWSvkyqbPZZj98K3CNpMelMYSkp228eg4CfSxpOyt75fUs1L4KgbcQ1iCA4Q/waxEwzO1S2SxAUQUwxBUEQBLnEGUQQBEGQS5xBBEEQBLnEABEEQRDkEgNEEARBkEsMEEEQBEEuMUAEQRAEufwfJDqTxLxJzY4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'loss', smoothing_std=10)\n",
    "plotter.plot(size_histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "colab-nn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
