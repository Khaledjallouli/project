{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Sequantial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 999)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow_core.estimator import inputs\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "\n",
    "from  IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_try(dataframe):\n",
    "    highestValue = 0;\n",
    "    ds = np.full((dataframe.shape[0], dataframe.shape[1]), 0)\n",
    "    for i in range(dataframe.shape[0]):\n",
    "        for j in range(dataframe.shape[1]):\n",
    "            if highestValue < dataframe[i][j]:\n",
    "                highestValue = dataframe[i][j]\n",
    "    \n",
    "    for i in range(dataframe.shape[0]):\n",
    "        for j in range(dataframe.shape[1]):\n",
    "                dataframe[i][j] = (dataframe[i][j]/highestValue)\n",
    "    \n",
    "    return dataframe\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "def encode(i):\n",
    "    switcher = {\n",
    "        \"H\": 2,\n",
    "        \"D\": 1,\n",
    "        \"A\": 0,\n",
    "        }\n",
    "    # 1 be assigned as default value of passed argument (if goals > 5)\n",
    "    return switcher.get(i, 1)\n",
    "\n",
    "def normalize_and_encode(dataframe):\n",
    "    column_names_to_not_normalize = ['result']\n",
    "    column_names_to_normalize = [x for x in list(dataframe) if x not in column_names_to_not_normalize ]\n",
    "    x = dataframe[column_names_to_normalize].values\n",
    "    x_scaled = preprocessing.normalize(x) #vom alten\n",
    "    std_scale = preprocessing.MinMaxScaler().fit(x)\n",
    "    #x_train_norm = std_scale.transform(x)\n",
    "    x_train_norm = normalize_try(x)\n",
    "    df_temp = pd.DataFrame(x_train_norm, columns=column_names_to_normalize, index = dataframe.index)\n",
    "    dataframe[column_names_to_normalize] = df_temp\n",
    "\n",
    "    #dataframe['result'] = dataframe.apply(lambda row: encode(row['result']), axis=1)\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit([ \"H\", \"D\", \"A\"])\n",
    "    dataframe.loc[:,['result']]=le.transform(dataframe['result'])\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "def get_X_and_y(dataframe):\n",
    "    X = dataframe.drop(columns=['result']).values\n",
    "    y = dataframe[['result']].values\n",
    "    return X,y\n",
    "\n",
    "\n",
    "#def get_lr_schedule(train, batch_size):\n",
    "    #lr_schedule = tf.keras.optimizers.SGD(lr=0.001, clipvalue=0.5)\n",
    "    #tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "    #0.0001, # lr??\n",
    "    #decay_steps=(len(train)//batch_size)*1000,\n",
    "    #decay_rate=1,\n",
    "    #staircase=False)\n",
    "    #return lr_schedule\n",
    "\n",
    "def get_optimizer(train, batch_size):\n",
    "    return tf.keras.optimizers.SGD(lr=0.01, momentum=0.9) \n",
    "            #tf.keras.optimizers.Adam(get_lr_schedule(train, batch_size))\n",
    "\n",
    "\n",
    "def get_callbacks(name):\n",
    "    return [\n",
    "        tfdocs.modeling.EpochDots(),\n",
    "        #tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200),\n",
    "        #tf.keras.callbacks.TensorBoard(logdir/name), # Jupyter Notebook\n",
    "        #tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1) # Google Colab\n",
    "      ]\n",
    "\n",
    "def compile_and_fit(model, name, X, y, validation_split, batch_size, optimizer=None, max_epochs=1000):\n",
    "    if optimizer is None:\n",
    "        optimizer = get_optimizer(X, batch_size)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "     \n",
    "    history = model.fit(\n",
    "        X,\n",
    "        y,\n",
    "        validation_split=validation_split,\n",
    "        batch_size=batch_size,\n",
    "        epochs=max_epochs,\n",
    "        callbacks=get_callbacks(name),\n",
    "        verbose=0)\n",
    "    \n",
    "    model.save(\"../model/%s.h5\" %name) \n",
    "    \n",
    "    return history\n",
    "\n",
    "def plot_history(model_history):\n",
    "\tplt.plot(model_history.history['accuracy'])\n",
    "\tplt.plot(model_history.history['val_accuracy'])\n",
    "\tplt.title(\"%s accuracy\" %model_history)\n",
    "\tplt.ylabel('accuracy')\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.legend(['train', 'val'], loc='upper left')\n",
    "\tplt.show()\n",
    "\t\n",
    "\tplt.plot(model_history.history['loss'])\n",
    "\tplt.plot(model_history.history['val_loss'])\n",
    "\tplt.title(\"%s loss\" %model_history)\n",
    "\tplt.ylabel('loss')\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.legend(['train', 'val'], loc='upper left')\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the sliding window + Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>137</td>\n",
       "      <td>67</td>\n",
       "      <td>117</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>161</td>\n",
       "      <td>78</td>\n",
       "      <td>72</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>134</td>\n",
       "      <td>64</td>\n",
       "      <td>151</td>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>104</td>\n",
       "      <td>44</td>\n",
       "      <td>87</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>120</td>\n",
       "      <td>58</td>\n",
       "      <td>124</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>134</td>\n",
       "      <td>59</td>\n",
       "      <td>100</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.30</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>177</td>\n",
       "      <td>82</td>\n",
       "      <td>74</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>169</td>\n",
       "      <td>95</td>\n",
       "      <td>113</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H</td>\n",
       "      <td>1.20</td>\n",
       "      <td>6.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>161</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>143</td>\n",
       "      <td>69</td>\n",
       "      <td>134</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7028</th>\n",
       "      <td>H</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.70</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>80</td>\n",
       "      <td>43</td>\n",
       "      <td>117</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>119</td>\n",
       "      <td>58</td>\n",
       "      <td>112</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>H</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>89</td>\n",
       "      <td>47</td>\n",
       "      <td>92</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>104</td>\n",
       "      <td>55</td>\n",
       "      <td>63</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7030</th>\n",
       "      <td>H</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.50</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>122</td>\n",
       "      <td>59</td>\n",
       "      <td>92</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>84</td>\n",
       "      <td>43</td>\n",
       "      <td>118</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031</th>\n",
       "      <td>H</td>\n",
       "      <td>1.33</td>\n",
       "      <td>5.25</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>124</td>\n",
       "      <td>62</td>\n",
       "      <td>99</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>103</td>\n",
       "      <td>53</td>\n",
       "      <td>122</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>H</td>\n",
       "      <td>1.67</td>\n",
       "      <td>4.20</td>\n",
       "      <td>5.25</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>105</td>\n",
       "      <td>65</td>\n",
       "      <td>126</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>114</td>\n",
       "      <td>63</td>\n",
       "      <td>106</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7033 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     result  odds-home  odds-draw  odds-away  home-wins  home-draws  \\\n",
       "0         H       3.50       3.30       2.10          1           3   \n",
       "1         D       2.50       3.30       2.88          3           1   \n",
       "2         A       1.91       3.40       4.20          4           2   \n",
       "3         H       3.25       3.25       2.30          5           2   \n",
       "4         H       1.20       6.00      19.00          7           2   \n",
       "...     ...        ...        ...        ...        ...         ...   \n",
       "7028      H       5.00       3.80       1.70          4           2   \n",
       "7029      H       2.00       3.60       3.70          3           2   \n",
       "7030      H       1.80       3.75       4.50          3           3   \n",
       "7031      H       1.33       5.25       9.00          2           3   \n",
       "7032      H       1.67       4.20       5.25          6           1   \n",
       "\n",
       "      home-losses  home-goals  home-opposition-goals  home-shots  \\\n",
       "0               6          11                     16         137   \n",
       "1               6           8                     16         134   \n",
       "2               4          10                     15         120   \n",
       "3               3          22                     12         177   \n",
       "4               1          15                      8         161   \n",
       "...           ...         ...                    ...         ...   \n",
       "7028            4          10                     12          80   \n",
       "7029            5           9                     21          89   \n",
       "7030            4           8                      8         122   \n",
       "7031            5          12                     14         124   \n",
       "7032            3          10                      8         105   \n",
       "\n",
       "      home-shots_on_target  home-opposition_shots  \\\n",
       "0                       67                    117   \n",
       "1                       64                    151   \n",
       "2                       58                    124   \n",
       "3                       82                     74   \n",
       "4                       72                     74   \n",
       "...                    ...                    ...   \n",
       "7028                    43                    117   \n",
       "7029                    47                     92   \n",
       "7030                    59                     92   \n",
       "7031                    62                     99   \n",
       "7032                    65                    126   \n",
       "\n",
       "      home-opposition_shots_on_target  away-wins  away-draws  away-losses  \\\n",
       "0                                  53          8           2            0   \n",
       "1                                  77          3           3            4   \n",
       "2                                  56          2           2            6   \n",
       "3                                  37          6           3            1   \n",
       "4                                  31          3           2            5   \n",
       "...                               ...        ...         ...          ...   \n",
       "7028                               60          2           4            4   \n",
       "7029                               46          1           4            5   \n",
       "7030                               50          5           2            3   \n",
       "7031                               50          3           3            4   \n",
       "7032                               54          3           2            5   \n",
       "\n",
       "      away-goals  away-opposition-goals  away-shots  away-shots_on_target  \\\n",
       "0             15                      6         161                    78   \n",
       "1             11                     18         104                    44   \n",
       "2             11                     15         134                    59   \n",
       "3             19                      8         169                    95   \n",
       "4             10                     17         143                    69   \n",
       "...          ...                    ...         ...                   ...   \n",
       "7028          10                     21         119                    58   \n",
       "7029           7                     21         104                    55   \n",
       "7030          15                      9          84                    43   \n",
       "7031          11                     17         103                    53   \n",
       "7032          13                     19         114                    63   \n",
       "\n",
       "      away-opposition_shots  away-opposition_shots_on_target  \n",
       "0                        72                               30  \n",
       "1                        87                               36  \n",
       "2                       100                               46  \n",
       "3                       113                               58  \n",
       "4                       134                               69  \n",
       "...                     ...                              ...  \n",
       "7028                    112                               65  \n",
       "7029                     63                               26  \n",
       "7030                    118                               56  \n",
       "7031                    122                               54  \n",
       "7032                    106                               46  \n",
       "\n",
       "[7033 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df02 = pd.read_csv('../data/data_classification_results/sliding02_shots.csv', sep=',', index_col=0)\n",
    "df02\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329 train examples\n",
      "704 test examples\n"
     ]
    }
   ],
   "source": [
    "n02 = normalize_and_encode(df02)\n",
    "\n",
    "\n",
    "train02, test02 = train_test_split(n02, test_size=0.1, shuffle=False)\n",
    "print(len(train02), 'train examples')\n",
    "print(len(test02), 'test examples')\n",
    "\n",
    "\n",
    "train_X02,train_y02 = get_X_and_y(train02)\n",
    "\n",
    "test_X02,test_y02 = get_X_and_y(test02)\n",
    "\n",
    "train_y02 = to_categorical(train_y02)\n",
    "test_y02 = to_categorical(test_y02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.015837</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>0.009502</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.072398</td>\n",
       "      <td>0.619910</td>\n",
       "      <td>0.303167</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.239819</td>\n",
       "      <td>0.036199</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067873</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.728507</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.325792</td>\n",
       "      <td>0.135747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.011312</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>0.013032</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.036199</td>\n",
       "      <td>0.072398</td>\n",
       "      <td>0.606335</td>\n",
       "      <td>0.289593</td>\n",
       "      <td>0.683258</td>\n",
       "      <td>0.348416</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.081448</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.199095</td>\n",
       "      <td>0.393665</td>\n",
       "      <td>0.162896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.008643</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.019005</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.045249</td>\n",
       "      <td>0.067873</td>\n",
       "      <td>0.542986</td>\n",
       "      <td>0.262443</td>\n",
       "      <td>0.561086</td>\n",
       "      <td>0.253394</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.067873</td>\n",
       "      <td>0.606335</td>\n",
       "      <td>0.266968</td>\n",
       "      <td>0.452489</td>\n",
       "      <td>0.208145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.010407</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.054299</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.371041</td>\n",
       "      <td>0.334842</td>\n",
       "      <td>0.167421</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.085973</td>\n",
       "      <td>0.036199</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.429864</td>\n",
       "      <td>0.511312</td>\n",
       "      <td>0.262443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.005430</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.085973</td>\n",
       "      <td>0.031674</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.067873</td>\n",
       "      <td>0.036199</td>\n",
       "      <td>0.728507</td>\n",
       "      <td>0.325792</td>\n",
       "      <td>0.334842</td>\n",
       "      <td>0.140271</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.045249</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.312217</td>\n",
       "      <td>0.606335</td>\n",
       "      <td>0.312217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7028</th>\n",
       "      <td>2</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.017195</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.045249</td>\n",
       "      <td>0.054299</td>\n",
       "      <td>0.361991</td>\n",
       "      <td>0.194570</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.271493</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.045249</td>\n",
       "      <td>0.095023</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.262443</td>\n",
       "      <td>0.506787</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>2</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.016290</td>\n",
       "      <td>0.016742</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.040724</td>\n",
       "      <td>0.095023</td>\n",
       "      <td>0.402715</td>\n",
       "      <td>0.212670</td>\n",
       "      <td>0.416290</td>\n",
       "      <td>0.208145</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.031674</td>\n",
       "      <td>0.095023</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.248869</td>\n",
       "      <td>0.285068</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7030</th>\n",
       "      <td>2</td>\n",
       "      <td>0.008145</td>\n",
       "      <td>0.016968</td>\n",
       "      <td>0.020362</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.036199</td>\n",
       "      <td>0.036199</td>\n",
       "      <td>0.552036</td>\n",
       "      <td>0.266968</td>\n",
       "      <td>0.416290</td>\n",
       "      <td>0.226244</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.067873</td>\n",
       "      <td>0.040724</td>\n",
       "      <td>0.380090</td>\n",
       "      <td>0.194570</td>\n",
       "      <td>0.533937</td>\n",
       "      <td>0.253394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031</th>\n",
       "      <td>2</td>\n",
       "      <td>0.006018</td>\n",
       "      <td>0.023756</td>\n",
       "      <td>0.040724</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.054299</td>\n",
       "      <td>0.063348</td>\n",
       "      <td>0.561086</td>\n",
       "      <td>0.280543</td>\n",
       "      <td>0.447964</td>\n",
       "      <td>0.226244</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.466063</td>\n",
       "      <td>0.239819</td>\n",
       "      <td>0.552036</td>\n",
       "      <td>0.244344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>2</td>\n",
       "      <td>0.007557</td>\n",
       "      <td>0.019005</td>\n",
       "      <td>0.023756</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.045249</td>\n",
       "      <td>0.036199</td>\n",
       "      <td>0.475113</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.570136</td>\n",
       "      <td>0.244344</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.085973</td>\n",
       "      <td>0.515837</td>\n",
       "      <td>0.285068</td>\n",
       "      <td>0.479638</td>\n",
       "      <td>0.208145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7033 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result  odds-home  odds-draw  odds-away  home-wins  home-draws  \\\n",
       "0          2   0.015837   0.014932   0.009502   0.004525    0.013575   \n",
       "1          1   0.011312   0.014932   0.013032   0.013575    0.004525   \n",
       "2          0   0.008643   0.015385   0.019005   0.018100    0.009050   \n",
       "3          2   0.014706   0.014706   0.010407   0.022624    0.009050   \n",
       "4          2   0.005430   0.027149   0.085973   0.031674    0.009050   \n",
       "...      ...        ...        ...        ...        ...         ...   \n",
       "7028       2   0.022624   0.017195   0.007692   0.018100    0.009050   \n",
       "7029       2   0.009050   0.016290   0.016742   0.013575    0.009050   \n",
       "7030       2   0.008145   0.016968   0.020362   0.013575    0.013575   \n",
       "7031       2   0.006018   0.023756   0.040724   0.009050    0.013575   \n",
       "7032       2   0.007557   0.019005   0.023756   0.027149    0.004525   \n",
       "\n",
       "      home-losses  home-goals  home-opposition-goals  home-shots  \\\n",
       "0        0.027149    0.049774               0.072398    0.619910   \n",
       "1        0.027149    0.036199               0.072398    0.606335   \n",
       "2        0.018100    0.045249               0.067873    0.542986   \n",
       "3        0.013575    0.099548               0.054299    0.800905   \n",
       "4        0.004525    0.067873               0.036199    0.728507   \n",
       "...           ...         ...                    ...         ...   \n",
       "7028     0.018100    0.045249               0.054299    0.361991   \n",
       "7029     0.022624    0.040724               0.095023    0.402715   \n",
       "7030     0.018100    0.036199               0.036199    0.552036   \n",
       "7031     0.022624    0.054299               0.063348    0.561086   \n",
       "7032     0.013575    0.045249               0.036199    0.475113   \n",
       "\n",
       "      home-shots_on_target  home-opposition_shots  \\\n",
       "0                 0.303167               0.529412   \n",
       "1                 0.289593               0.683258   \n",
       "2                 0.262443               0.561086   \n",
       "3                 0.371041               0.334842   \n",
       "4                 0.325792               0.334842   \n",
       "...                    ...                    ...   \n",
       "7028              0.194570               0.529412   \n",
       "7029              0.212670               0.416290   \n",
       "7030              0.266968               0.416290   \n",
       "7031              0.280543               0.447964   \n",
       "7032              0.294118               0.570136   \n",
       "\n",
       "      home-opposition_shots_on_target  away-wins  away-draws  away-losses  \\\n",
       "0                            0.239819   0.036199    0.009050     0.000000   \n",
       "1                            0.348416   0.013575    0.013575     0.018100   \n",
       "2                            0.253394   0.009050    0.009050     0.027149   \n",
       "3                            0.167421   0.027149    0.013575     0.004525   \n",
       "4                            0.140271   0.013575    0.009050     0.022624   \n",
       "...                               ...        ...         ...          ...   \n",
       "7028                         0.271493   0.009050    0.018100     0.018100   \n",
       "7029                         0.208145   0.004525    0.018100     0.022624   \n",
       "7030                         0.226244   0.022624    0.009050     0.013575   \n",
       "7031                         0.226244   0.013575    0.013575     0.018100   \n",
       "7032                         0.244344   0.013575    0.009050     0.022624   \n",
       "\n",
       "      away-goals  away-opposition-goals  away-shots  away-shots_on_target  \\\n",
       "0       0.067873               0.027149    0.728507              0.352941   \n",
       "1       0.049774               0.081448    0.470588              0.199095   \n",
       "2       0.049774               0.067873    0.606335              0.266968   \n",
       "3       0.085973               0.036199    0.764706              0.429864   \n",
       "4       0.045249               0.076923    0.647059              0.312217   \n",
       "...          ...                    ...         ...                   ...   \n",
       "7028    0.045249               0.095023    0.538462              0.262443   \n",
       "7029    0.031674               0.095023    0.470588              0.248869   \n",
       "7030    0.067873               0.040724    0.380090              0.194570   \n",
       "7031    0.049774               0.076923    0.466063              0.239819   \n",
       "7032    0.058824               0.085973    0.515837              0.285068   \n",
       "\n",
       "      away-opposition_shots  away-opposition_shots_on_target  \n",
       "0                  0.325792                         0.135747  \n",
       "1                  0.393665                         0.162896  \n",
       "2                  0.452489                         0.208145  \n",
       "3                  0.511312                         0.262443  \n",
       "4                  0.606335                         0.312217  \n",
       "...                     ...                              ...  \n",
       "7028               0.506787                         0.294118  \n",
       "7029               0.285068                         0.117647  \n",
       "7030               0.533937                         0.253394  \n",
       "7031               0.552036                         0.244344  \n",
       "7032               0.479638                         0.208145  \n",
       "\n",
       "[7033 rows x 22 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "result\n",
       "2    3238\n",
       "0    2035\n",
       "1    1760\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byhomegoal = df02.groupby('result')\n",
    "byhomegoal.size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.008643</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.019005</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.045249</td>\n",
       "      <td>0.067873</td>\n",
       "      <td>0.542986</td>\n",
       "      <td>0.262443</td>\n",
       "      <td>0.561086</td>\n",
       "      <td>0.253394</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.067873</td>\n",
       "      <td>0.606335</td>\n",
       "      <td>0.266968</td>\n",
       "      <td>0.452489</td>\n",
       "      <td>0.208145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.010769</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.040724</td>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.212670</td>\n",
       "      <td>0.601810</td>\n",
       "      <td>0.348416</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.570136</td>\n",
       "      <td>0.266968</td>\n",
       "      <td>0.552036</td>\n",
       "      <td>0.266968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.012670</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.067873</td>\n",
       "      <td>0.072398</td>\n",
       "      <td>0.565611</td>\n",
       "      <td>0.285068</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.330317</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.072398</td>\n",
       "      <td>0.466063</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.624434</td>\n",
       "      <td>0.343891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.010181</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.067873</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.402715</td>\n",
       "      <td>0.167421</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.330317</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.031674</td>\n",
       "      <td>0.054299</td>\n",
       "      <td>0.579186</td>\n",
       "      <td>0.289593</td>\n",
       "      <td>0.669683</td>\n",
       "      <td>0.334842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.017195</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.429864</td>\n",
       "      <td>0.190045</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.330317</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.040724</td>\n",
       "      <td>0.067873</td>\n",
       "      <td>0.475113</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.723982</td>\n",
       "      <td>0.357466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3747</th>\n",
       "      <td>2</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.017195</td>\n",
       "      <td>0.021493</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.067873</td>\n",
       "      <td>0.072398</td>\n",
       "      <td>0.547511</td>\n",
       "      <td>0.289593</td>\n",
       "      <td>0.443439</td>\n",
       "      <td>0.276018</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.045249</td>\n",
       "      <td>0.054299</td>\n",
       "      <td>0.447964</td>\n",
       "      <td>0.190045</td>\n",
       "      <td>0.506787</td>\n",
       "      <td>0.285068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749</th>\n",
       "      <td>2</td>\n",
       "      <td>0.010769</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>0.013122</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.031674</td>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.583710</td>\n",
       "      <td>0.303167</td>\n",
       "      <td>0.565611</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.108597</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.556561</td>\n",
       "      <td>0.248869</td>\n",
       "      <td>0.583710</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3750</th>\n",
       "      <td>2</td>\n",
       "      <td>0.008145</td>\n",
       "      <td>0.015837</td>\n",
       "      <td>0.020362</td>\n",
       "      <td>0.045249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.104072</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.375566</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.144796</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.063348</td>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.592760</td>\n",
       "      <td>0.248869</td>\n",
       "      <td>0.452489</td>\n",
       "      <td>0.217195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>2</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.031674</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.072398</td>\n",
       "      <td>0.040724</td>\n",
       "      <td>0.642534</td>\n",
       "      <td>0.343891</td>\n",
       "      <td>0.393665</td>\n",
       "      <td>0.194570</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.031674</td>\n",
       "      <td>0.072398</td>\n",
       "      <td>0.506787</td>\n",
       "      <td>0.244344</td>\n",
       "      <td>0.524887</td>\n",
       "      <td>0.244344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3753</th>\n",
       "      <td>2</td>\n",
       "      <td>0.008281</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.020362</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.054299</td>\n",
       "      <td>0.067873</td>\n",
       "      <td>0.438914</td>\n",
       "      <td>0.199095</td>\n",
       "      <td>0.407240</td>\n",
       "      <td>0.144796</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.497738</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.642534</td>\n",
       "      <td>0.312217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5280 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result  odds-home  odds-draw  odds-away  home-wins  home-draws  \\\n",
       "2          0   0.008643   0.015385   0.019005   0.018100    0.009050   \n",
       "5          0   0.010769   0.014932   0.013575   0.013575    0.013575   \n",
       "6          0   0.011765   0.014706   0.012670   0.018100    0.004525   \n",
       "7          0   0.010181   0.014706   0.015385   0.022624    0.009050   \n",
       "9          0   0.007692   0.017195   0.022624   0.027149    0.009050   \n",
       "...      ...        ...        ...        ...        ...         ...   \n",
       "3747       2   0.007692   0.017195   0.021493   0.013575    0.013575   \n",
       "3749       2   0.010769   0.014932   0.013122   0.018100    0.013575   \n",
       "3750       2   0.008145   0.015837   0.020362   0.045249    0.000000   \n",
       "3751       2   0.006787   0.018100   0.031674   0.027149    0.009050   \n",
       "3753       2   0.008281   0.015385   0.020362   0.013575    0.013575   \n",
       "\n",
       "      home-losses  home-goals  home-opposition-goals  home-shots  \\\n",
       "2        0.018100    0.045249               0.067873    0.542986   \n",
       "5        0.018100    0.040724               0.049774    0.461538   \n",
       "6        0.022624    0.067873               0.072398    0.565611   \n",
       "7        0.013575    0.067873               0.076923    0.402715   \n",
       "9        0.009050    0.076923               0.049774    0.429864   \n",
       "...           ...         ...                    ...         ...   \n",
       "3747     0.018100    0.067873               0.072398    0.547511   \n",
       "3749     0.013575    0.031674               0.049774    0.583710   \n",
       "3750     0.000000    0.104072               0.004525    0.823529   \n",
       "3751     0.009050    0.072398               0.040724    0.642534   \n",
       "3753     0.018100    0.054299               0.067873    0.438914   \n",
       "\n",
       "      home-shots_on_target  home-opposition_shots  \\\n",
       "2                 0.262443               0.561086   \n",
       "5                 0.212670               0.601810   \n",
       "6                 0.285068               0.692308   \n",
       "7                 0.167421               0.782805   \n",
       "9                 0.190045               0.647059   \n",
       "...                    ...                    ...   \n",
       "3747              0.289593               0.443439   \n",
       "3749              0.303167               0.565611   \n",
       "3750              0.375566               0.307692   \n",
       "3751              0.343891               0.393665   \n",
       "3753              0.199095               0.407240   \n",
       "\n",
       "      home-opposition_shots_on_target  away-wins  away-draws  away-losses  \\\n",
       "2                            0.253394   0.009050    0.009050     0.027149   \n",
       "5                            0.348416   0.018100    0.009050     0.018100   \n",
       "6                            0.330317   0.018100    0.013575     0.013575   \n",
       "7                            0.330317   0.009050    0.009050     0.027149   \n",
       "9                            0.330317   0.013575    0.009050     0.022624   \n",
       "...                               ...        ...         ...          ...   \n",
       "3747                         0.276018   0.013575    0.013575     0.018100   \n",
       "3749                         0.235294   0.022624    0.009050     0.013575   \n",
       "3750                         0.144796   0.022624    0.013575     0.009050   \n",
       "3751                         0.194570   0.004525    0.013575     0.027149   \n",
       "3753                         0.144796   0.013575    0.009050     0.022624   \n",
       "\n",
       "      away-goals  away-opposition-goals  away-shots  away-shots_on_target  \\\n",
       "2       0.049774               0.067873    0.606335              0.266968   \n",
       "5       0.049774               0.058824    0.570136              0.266968   \n",
       "6       0.058824               0.072398    0.466063              0.230769   \n",
       "7       0.031674               0.054299    0.579186              0.289593   \n",
       "9       0.040724               0.067873    0.475113              0.230769   \n",
       "...          ...                    ...         ...                   ...   \n",
       "3747    0.045249               0.054299    0.447964              0.190045   \n",
       "3749    0.108597               0.076923    0.556561              0.248869   \n",
       "3750    0.063348               0.049774    0.592760              0.248869   \n",
       "3751    0.031674               0.072398    0.506787              0.244344   \n",
       "3753    0.022624               0.049774    0.497738              0.230769   \n",
       "\n",
       "      away-opposition_shots  away-opposition_shots_on_target  \n",
       "2                  0.452489                         0.208145  \n",
       "5                  0.552036                         0.266968  \n",
       "6                  0.624434                         0.343891  \n",
       "7                  0.669683                         0.334842  \n",
       "9                  0.723982                         0.357466  \n",
       "...                     ...                              ...  \n",
       "3747               0.506787                         0.285068  \n",
       "3749               0.583710                         0.294118  \n",
       "3750               0.452489                         0.217195  \n",
       "3751               0.524887                         0.244344  \n",
       "3753               0.642534                         0.312217  \n",
       "\n",
       "[5280 rows x 22 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdA = df02[df02.result == 0].head(1760)\n",
    "fdD = df02[df02.result == 1].head(1760)\n",
    "fdH = df02[df02.result == 2].head(1760)\n",
    "df02 = pd.concat([fdA, fdD])\n",
    "df02 = pd.concat([df02, fdH])\n",
    "\n",
    "df02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "result\n",
       "2    1760\n",
       "1    1760\n",
       "0    1760\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byhomegoal = df02.groupby('result')\n",
    "byhomegoal.size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train02, test02 = train_test_split(df02, test_size=0.1, shuffle=False)\n",
    "print(len(train02), 'train examples')\n",
    "print(len(test02), 'test examples')\n",
    "\n",
    "\n",
    "train_X02,train_y02 = get_X_and_y(train02)\n",
    "\n",
    "test_X02,test_y02 = get_X_and_y(test02)\n",
    "\n",
    "train_y02 = to_categorical(train_y02)\n",
    "test_y02 = to_categorical(test_y02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "shutil.rmtree(logdir, ignore_errors=True)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 20\n",
    "EPOCHS=10000\n",
    "validation_split = 0.2\n",
    "size_histories = {}\n",
    "\n",
    "model02_H3_M = tf.keras.Sequential([\n",
    "  layers.Dense(35, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(20, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(10, activation='relu'),\n",
    "  #layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax'),\n",
    "  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "shutil.rmtree(logdir, ignore_errors=True)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 120\n",
    "EPOCHS=10000\n",
    "validation_split = 0.2\n",
    "size_histories = {}\n",
    "\n",
    "model02_H3_M = tf.keras.Sequential([\n",
    "  layers.Dense(35, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(20, activation='relu',kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "  bias_initializer=initializers.Zeros()),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(10, activation='relu',kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "  bias_initializer=initializers.Zeros()),\n",
    "  #layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax', kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "  bias_initializer=initializers.Zeros()),\n",
    "  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model02_H3_M.compile(optimizer=\"Adam\", loss='categorical_crossentropy', metrics=[ \"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33333334, 0.3333346 , 0.33333203],\n",
       "       [0.33333325, 0.33333454, 0.33333218],\n",
       "       [0.33333337, 0.33333445, 0.33333218],\n",
       "       ...,\n",
       "       [0.33333334, 0.3333346 , 0.33333206],\n",
       "       [0.3333333 , 0.33333468, 0.333332  ],\n",
       "       [0.33333334, 0.33333454, 0.33333212]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedResult = model02_H3_M.predict(test_X02, batch_size=BATCH_SIZE)\n",
    "predictedResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynew = model02_H3_M.predict_classes(test_X02)\n",
    "ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 35)                770       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 35)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                720       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 1,733\n",
      "Trainable params: 1,733\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.4594,  loss:1.0775,  val_accuracy:0.4408,  val_loss:1.0722,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.4653,  loss:1.0605,  val_accuracy:0.4408,  val_loss:1.0728,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.4653,  loss:1.0605,  val_accuracy:0.4408,  val_loss:1.0726,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.4653,  loss:1.0603,  val_accuracy:0.4408,  val_loss:1.0727,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.4653,  loss:1.0604,  val_accuracy:0.4408,  val_loss:1.0730,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.4653,  loss:1.0604,  val_accuracy:0.4408,  val_loss:1.0727,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.4653,  loss:1.0605,  val_accuracy:0.4408,  val_loss:1.0731,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.4653,  loss:1.0604,  val_accuracy:0.4408,  val_loss:1.0729,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.4653,  loss:1.0604,  val_accuracy:0.4408,  val_loss:1.0730,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.4653,  loss:1.0603,  val_accuracy:0.4408,  val_loss:1.0729,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5157,  loss:1.0053,  val_accuracy:0.4976,  val_loss:1.0258,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5325,  loss:0.9862,  val_accuracy:0.4984,  val_loss:1.0134,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5291,  loss:0.9847,  val_accuracy:0.4945,  val_loss:1.0091,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5283,  loss:0.9762,  val_accuracy:0.4968,  val_loss:1.0163,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5319,  loss:0.9728,  val_accuracy:0.4976,  val_loss:1.0085,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5341,  loss:0.9752,  val_accuracy:0.4945,  val_loss:1.0041,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5353,  loss:0.9754,  val_accuracy:0.4953,  val_loss:1.0050,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5358,  loss:0.9727,  val_accuracy:0.4984,  val_loss:1.0058,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5382,  loss:0.9700,  val_accuracy:0.4953,  val_loss:1.0042,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5392,  loss:0.9679,  val_accuracy:0.4984,  val_loss:1.0035,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5380,  loss:0.9690,  val_accuracy:0.4929,  val_loss:1.0056,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5313,  loss:0.9712,  val_accuracy:0.4968,  val_loss:1.0047,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5374,  loss:0.9626,  val_accuracy:0.4961,  val_loss:1.0099,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, accuracy:0.5390,  loss:0.9700,  val_accuracy:0.4984,  val_loss:1.0054,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, accuracy:0.5374,  loss:0.9610,  val_accuracy:0.4992,  val_loss:1.0062,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, accuracy:0.5418,  loss:0.9656,  val_accuracy:0.4945,  val_loss:1.0174,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, accuracy:0.5439,  loss:0.9624,  val_accuracy:0.5008,  val_loss:1.0047,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, accuracy:0.5408,  loss:0.9642,  val_accuracy:0.4968,  val_loss:1.0065,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, accuracy:0.5453,  loss:0.9588,  val_accuracy:0.5008,  val_loss:1.0173,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, accuracy:0.5402,  loss:0.9578,  val_accuracy:0.4984,  val_loss:1.0090,  \n",
      "....................................................................................................\n",
      "Epoch: 3000, accuracy:0.5434,  loss:0.9591,  val_accuracy:0.4905,  val_loss:1.0085,  \n",
      "....................................................................................................\n",
      "Epoch: 3100, accuracy:0.5424,  loss:0.9622,  val_accuracy:0.4945,  val_loss:1.0047,  \n",
      "....................................................................................................\n",
      "Epoch: 3200, accuracy:0.5408,  loss:0.9608,  val_accuracy:0.4874,  val_loss:1.0078,  \n",
      "....................................................................................................\n",
      "Epoch: 3300, accuracy:0.5398,  loss:0.9597,  val_accuracy:0.4937,  val_loss:1.0058,  \n",
      "....................................................................................................\n",
      "Epoch: 3400, accuracy:0.5432,  loss:0.9608,  val_accuracy:0.4716,  val_loss:1.0135,  \n",
      "....................................................................................................\n",
      "Epoch: 3500, accuracy:0.5416,  loss:0.9580,  val_accuracy:0.4834,  val_loss:1.0074,  \n",
      "....................................................................................................\n",
      "Epoch: 3600, accuracy:0.5520,  loss:0.9574,  val_accuracy:0.4905,  val_loss:1.0095,  \n",
      "....................................................................................................\n",
      "Epoch: 3700, accuracy:0.5436,  loss:0.9577,  val_accuracy:0.4968,  val_loss:1.0123,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 3800, accuracy:0.5453,  loss:0.9582,  val_accuracy:0.4937,  val_loss:1.0116,  \n",
      "....................................................................................................\n",
      "Epoch: 3900, accuracy:0.5465,  loss:0.9564,  val_accuracy:0.4889,  val_loss:1.0249,  \n",
      "....................................................................................................\n",
      "Epoch: 4000, accuracy:0.5465,  loss:0.9570,  val_accuracy:0.4889,  val_loss:1.0149,  \n",
      "....................................................................................................\n",
      "Epoch: 4100, accuracy:0.5505,  loss:0.9534,  val_accuracy:0.4882,  val_loss:1.0092,  \n",
      "....................................................................................................\n",
      "Epoch: 4200, accuracy:0.5489,  loss:0.9518,  val_accuracy:0.4882,  val_loss:1.0118,  \n",
      "....................................................................................................\n",
      "Epoch: 4300, accuracy:0.5483,  loss:0.9544,  val_accuracy:0.4866,  val_loss:1.0095,  \n",
      "....................................................................................................\n",
      "Epoch: 4400, accuracy:0.5465,  loss:0.9567,  val_accuracy:0.4882,  val_loss:1.0146,  \n",
      "....................................................................................................\n",
      "Epoch: 4500, accuracy:0.5493,  loss:0.9530,  val_accuracy:0.4921,  val_loss:1.0178,  \n",
      "....................................................................................................\n",
      "Epoch: 4600, accuracy:0.5487,  loss:0.9534,  val_accuracy:0.4921,  val_loss:1.0169,  \n",
      "....................................................................................................\n",
      "Epoch: 4700, accuracy:0.5465,  loss:0.9538,  val_accuracy:0.4889,  val_loss:1.0149,  \n",
      "....................................................................................................\n",
      "Epoch: 4800, accuracy:0.5436,  loss:0.9528,  val_accuracy:0.4850,  val_loss:1.0175,  \n",
      "....................................................................................................\n",
      "Epoch: 4900, accuracy:0.5471,  loss:0.9555,  val_accuracy:0.4961,  val_loss:1.0273,  \n",
      "....................................................................................................\n",
      "Epoch: 5000, accuracy:0.5426,  loss:0.9576,  val_accuracy:0.4882,  val_loss:1.0152,  \n",
      "....................................................................................................\n",
      "Epoch: 5100, accuracy:0.5477,  loss:0.9515,  val_accuracy:0.4921,  val_loss:1.0137,  \n",
      "....................................................................................................\n",
      "Epoch: 5200, accuracy:0.5489,  loss:0.9520,  val_accuracy:0.4921,  val_loss:1.0141,  \n",
      "....................................................................................................\n",
      "Epoch: 5300, accuracy:0.5491,  loss:0.9513,  val_accuracy:0.4905,  val_loss:1.0162,  \n",
      "....................................................................................................\n",
      "Epoch: 5400, accuracy:0.5485,  loss:0.9527,  val_accuracy:0.4874,  val_loss:1.0162,  \n",
      "....................................................................................................\n",
      "Epoch: 5500, accuracy:0.5489,  loss:0.9533,  val_accuracy:0.4921,  val_loss:1.0145,  \n",
      "....................................................................................................\n",
      "Epoch: 5600, accuracy:0.5493,  loss:0.9519,  val_accuracy:0.5032,  val_loss:1.0101,  \n",
      "....................................................................................................\n",
      "Epoch: 5700, accuracy:0.5515,  loss:0.9519,  val_accuracy:0.4882,  val_loss:1.0170,  \n",
      "....................................................................................................\n",
      "Epoch: 5800, accuracy:0.5518,  loss:0.9503,  val_accuracy:0.4976,  val_loss:1.0254,  \n",
      "....................................................................................................\n",
      "Epoch: 5900, accuracy:0.5503,  loss:0.9513,  val_accuracy:0.4921,  val_loss:1.0163,  \n",
      "....................................................................................................\n",
      "Epoch: 6000, accuracy:0.5457,  loss:0.9533,  val_accuracy:0.4874,  val_loss:1.0136,  \n",
      "....................................................................................................\n",
      "Epoch: 6100, accuracy:0.5451,  loss:0.9487,  val_accuracy:0.4889,  val_loss:1.0130,  \n",
      "....................................................................................................\n",
      "Epoch: 6200, accuracy:0.5526,  loss:0.9502,  val_accuracy:0.4913,  val_loss:1.0161,  \n",
      "....................................................................................................\n",
      "Epoch: 6300, accuracy:0.5534,  loss:0.9459,  val_accuracy:0.4810,  val_loss:1.0186,  \n",
      "....................................................................................................\n",
      "Epoch: 6400, accuracy:0.5437,  loss:0.9568,  val_accuracy:0.4755,  val_loss:1.0143,  \n",
      "....................................................................................................\n",
      "Epoch: 6500, accuracy:0.5467,  loss:0.9489,  val_accuracy:0.4913,  val_loss:1.0217,  \n",
      "....................................................................................................\n",
      "Epoch: 6600, accuracy:0.5501,  loss:0.9487,  val_accuracy:0.4961,  val_loss:1.0199,  \n",
      "....................................................................................................\n",
      "Epoch: 6700, accuracy:0.5526,  loss:0.9478,  val_accuracy:0.4889,  val_loss:1.0168,  \n",
      "....................................................................................................\n",
      "Epoch: 6800, accuracy:0.5520,  loss:0.9498,  val_accuracy:0.4850,  val_loss:1.0169,  \n",
      "....................................................................................................\n",
      "Epoch: 6900, accuracy:0.5499,  loss:0.9489,  val_accuracy:0.4945,  val_loss:1.0133,  \n",
      "....................................................................................................\n",
      "Epoch: 7000, accuracy:0.5509,  loss:0.9499,  val_accuracy:0.4905,  val_loss:1.0161,  \n",
      "....................................................................................................\n",
      "Epoch: 7100, accuracy:0.5542,  loss:0.9466,  val_accuracy:0.4850,  val_loss:1.0149,  \n",
      "....................................................................................................\n",
      "Epoch: 7200, accuracy:0.5516,  loss:0.9463,  val_accuracy:0.4937,  val_loss:1.0220,  \n",
      "....................................................................................................\n",
      "Epoch: 7300, accuracy:0.5556,  loss:0.9493,  val_accuracy:0.4842,  val_loss:1.0236,  \n",
      "....................................................................................................\n",
      "Epoch: 7400, accuracy:0.5536,  loss:0.9462,  val_accuracy:0.4929,  val_loss:1.0241,  \n",
      "....................................................................................................\n",
      "Epoch: 7500, accuracy:0.5554,  loss:0.9451,  val_accuracy:0.4866,  val_loss:1.0181,  \n",
      "....................................................................................................\n",
      "Epoch: 7600, accuracy:0.5532,  loss:0.9471,  val_accuracy:0.4897,  val_loss:1.0292,  \n",
      "....................................................................................................\n",
      "Epoch: 7700, accuracy:0.5560,  loss:0.9466,  val_accuracy:0.4961,  val_loss:1.0204,  \n",
      "....................................................................................................\n",
      "Epoch: 7800, accuracy:0.5548,  loss:0.9449,  val_accuracy:0.4866,  val_loss:1.0189,  \n",
      "....................................................................................................\n",
      "Epoch: 7900, accuracy:0.5609,  loss:0.9419,  val_accuracy:0.4937,  val_loss:1.0161,  \n",
      "....................................................................................................\n",
      "Epoch: 8000, accuracy:0.5554,  loss:0.9433,  val_accuracy:0.4850,  val_loss:1.0191,  \n",
      "....................................................................................................\n",
      "Epoch: 8100, accuracy:0.5530,  loss:0.9442,  val_accuracy:0.4897,  val_loss:1.0227,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 8200, accuracy:0.5611,  loss:0.9420,  val_accuracy:0.4882,  val_loss:1.0171,  \n",
      "....................................................................................................\n",
      "Epoch: 8300, accuracy:0.5538,  loss:0.9443,  val_accuracy:0.4945,  val_loss:1.0234,  \n",
      "....................................................................................................\n",
      "Epoch: 8400, accuracy:0.5570,  loss:0.9419,  val_accuracy:0.4882,  val_loss:1.0205,  \n",
      "....................................................................................................\n",
      "Epoch: 8500, accuracy:0.5552,  loss:0.9455,  val_accuracy:0.4905,  val_loss:1.0276,  \n",
      "....................................................................................................\n",
      "Epoch: 8600, accuracy:0.5538,  loss:0.9451,  val_accuracy:0.4850,  val_loss:1.0223,  \n",
      "....................................................................................................\n",
      "Epoch: 8700, accuracy:0.5592,  loss:0.9417,  val_accuracy:0.4929,  val_loss:1.0212,  \n",
      "....................................................................................................\n",
      "Epoch: 8800, accuracy:0.5597,  loss:0.9430,  val_accuracy:0.4889,  val_loss:1.0227,  \n",
      "....................................................................................................\n",
      "Epoch: 8900, accuracy:0.5601,  loss:0.9435,  val_accuracy:0.4921,  val_loss:1.0230,  \n",
      "....................................................................................................\n",
      "Epoch: 9000, accuracy:0.5582,  loss:0.9403,  val_accuracy:0.4968,  val_loss:1.0264,  \n",
      "....................................................................................................\n",
      "Epoch: 9100, accuracy:0.5560,  loss:0.9429,  val_accuracy:0.4850,  val_loss:1.0246,  \n",
      "....................................................................................................\n",
      "Epoch: 9200, accuracy:0.5597,  loss:0.9424,  val_accuracy:0.4747,  val_loss:1.0205,  \n",
      "....................................................................................................\n",
      "Epoch: 9300, accuracy:0.5590,  loss:0.9434,  val_accuracy:0.4905,  val_loss:1.0304,  \n",
      "....................................................................................................\n",
      "Epoch: 9400, accuracy:0.5546,  loss:0.9408,  val_accuracy:0.4945,  val_loss:1.0295,  \n",
      "....................................................................................................\n",
      "Epoch: 9500, accuracy:0.5564,  loss:0.9444,  val_accuracy:0.4850,  val_loss:1.0157,  \n",
      "....................................................................................................\n",
      "Epoch: 9600, accuracy:0.5516,  loss:0.9460,  val_accuracy:0.4905,  val_loss:1.0193,  \n",
      "....................................................................................................\n",
      "Epoch: 9700, accuracy:0.5520,  loss:0.9419,  val_accuracy:0.4953,  val_loss:1.0204,  \n",
      "....................................................................................................\n",
      "Epoch: 9800, accuracy:0.5637,  loss:0.9366,  val_accuracy:0.4882,  val_loss:1.0299,  \n",
      "....................................................................................................\n",
      "Epoch: 9900, accuracy:0.5582,  loss:0.9392,  val_accuracy:0.4842,  val_loss:1.0154,  \n",
      "...................................................................................................."
     ]
    }
   ],
   "source": [
    "size_histories['model02_H3_M'] = compile_and_fit(model02_H3_M, 'model02_H3_M', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE, max_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model02_H3_M\n",
      "Loss: 0.9696509675546126\n",
      "Test Accuracy: 0.53409094\n"
     ]
    }
   ],
   "source": [
    "model = load_model('../model/model02_H3_M.h5')\n",
    "score = model.evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02_H3_M\")\n",
    "print(\"Loss:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'loss', smoothing_std=10)\n",
    "plotter.plot(size_histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedResult = model.predict(test_X02, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03222584, 0.02137494, 0.9463992 ],\n",
       "       [0.18969478, 0.28162023, 0.528685  ],\n",
       "       [0.5734929 , 0.2396584 , 0.18684871],\n",
       "       ...,\n",
       "       [0.19696744, 0.2706721 , 0.53236043],\n",
       "       [0.09398375, 0.2387523 , 0.66726387],\n",
       "       [0.18388881, 0.25853828, 0.5575729 ]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, ..., 0, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynewtrin = model.predict_classes(train_X02)\n",
    "ynewtrin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prob: Predicting only two classes instead of 3!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 0, 2, 2,\n",
       "       2, 2, 2, 0, 2, 2, 2, 1, 2, 1, 2, 0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2,\n",
       "       0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2, 2, 0, 2, 2, 0, 2, 2,\n",
       "       2, 0, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, 0, 2,\n",
       "       0, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 2, 0, 0, 2, 2,\n",
       "       2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 1, 0, 2, 2, 0, 2, 0, 2, 1,\n",
       "       2, 2, 2, 1, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 1, 2,\n",
       "       0, 2, 0, 0, 0, 2, 2, 0, 0, 2, 2, 2, 1, 2, 2, 2, 0, 0, 0, 2, 2, 2,\n",
       "       2, 0, 1, 2, 0, 2, 0, 0, 2, 2, 0, 2, 2, 1, 2, 0, 2, 2, 2, 1, 2, 2,\n",
       "       2, 1, 1, 2, 0, 0, 0, 1, 2, 0, 0, 2, 2, 1, 2, 2, 2, 2, 0, 0, 2, 0,\n",
       "       2, 2, 0, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "       0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2,\n",
       "       0, 2, 0, 1, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 0, 1, 2, 0,\n",
       "       0, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 1, 0, 1, 2,\n",
       "       2, 2, 2, 0, 2, 0, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2,\n",
       "       2, 2, 2, 0, 0, 2, 0, 2, 2, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2,\n",
       "       1, 2, 2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 2, 1, 2, 0, 2, 0, 2, 2, 2, 0,\n",
       "       0, 0, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0, 0, 2, 0, 2, 0, 2, 0,\n",
       "       2, 2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 0, 0, 2, 1, 1, 2, 1, 2, 0, 2, 0,\n",
       "       0, 2, 0, 2, 2, 1, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 1,\n",
       "       2, 2, 2, 2, 2, 1, 2, 0, 0, 2, 0, 2, 2, 1, 2, 0, 2, 2, 2, 2, 1, 0,\n",
       "       0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 1, 2, 2, 2, 2, 2, 0, 2, 0, 2,\n",
       "       2, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 0, 2, 0,\n",
       "       2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 1, 2,\n",
       "       2, 2, 0, 2, 0, 2, 2, 0, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2,\n",
       "       0, 0, 0, 2, 2, 2, 2, 2, 0, 2, 2, 1, 0, 2, 0, 0, 2, 2, 2, 0, 0, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 1, 2, 2, 1, 2, 2, 2, 0, 2, 2,\n",
       "       0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
       "       0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 1, 2, 0,\n",
       "       0, 1, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0, 2, 1,\n",
       "       0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 1, 2, 1, 2, 0, 2, 2, 0, 2, 0, 0,\n",
       "       2, 2, 2, 1, 2, 0, 2, 0, 0, 1, 0, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynew = model.predict_classes(test_X02)\n",
    "ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y02 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
