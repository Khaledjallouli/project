{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/thu-soccer/project/blob/master/colab/colab_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 999)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow_core.estimator import inputs\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "\n",
    "from  IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "FtJth4hT577a",
    "outputId": "ce296e87-fcd1-4261-8057-6daacd747370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19781 train examples\n",
      "1042 test examples\n",
      "6681 train examples\n",
      "352 test examples\n",
      "6681 train examples\n",
      "352 test examples\n",
      "6646 train examples\n",
      "350 test examples\n",
      "6646 train examples\n",
      "350 test examples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def normalize_and_encode(dataframe):\n",
    "    column_names_to_not_normalize = ['result']\n",
    "    column_names_to_normalize = [x for x in list(dataframe) if x not in column_names_to_not_normalize ]\n",
    "    x = dataframe[column_names_to_normalize].values\n",
    "    x_scaled = preprocessing.normalize(x)\n",
    "    df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = dataframe.index)\n",
    "    dataframe[column_names_to_normalize] = df_temp\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit([ \"H\", \"A\", \"D\"])\n",
    "    dataframe.loc[:,['result']]=le.transform(dataframe['result'])\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "def get_X_and_y(dataframe):\n",
    "    X = dataframe.drop(columns=['result']).values\n",
    "    y = dataframe[['result']].values\n",
    "    return X,y\n",
    "\n",
    "df01 = pd.read_csv('../data/sliding01.csv', sep=',', index_col=0)\n",
    "df02 = pd.read_csv('../data/sliding02_shots.csv', sep=',', index_col=0)\n",
    "df03 = pd.read_csv('../data/sliding03_shots_extra.csv', sep=',', index_col=0)\n",
    "df04 = pd.read_csv('../data/sliding04_shots_and_possession.csv', sep=',', index_col=0)\n",
    "df05 = pd.read_csv('../data/sliding05_shots_and_possession_extra.csv', sep=',', index_col=0)\n",
    "\n",
    "n01 = normalize_and_encode(df01)\n",
    "n02 = normalize_and_encode(df02)\n",
    "n03 = normalize_and_encode(df03)\n",
    "n04 = normalize_and_encode(df04)\n",
    "n05 = normalize_and_encode(df05)\n",
    "\n",
    "train01, test01 = train_test_split(n01, test_size=0.05)\n",
    "print(len(train01), 'train examples')\n",
    "print(len(test01), 'test examples')\n",
    "\n",
    "train02, test02 = train_test_split(n02, test_size=0.05)\n",
    "print(len(train02), 'train examples')\n",
    "print(len(test02), 'test examples')\n",
    "\n",
    "train03, test03 = train_test_split(n03, test_size=0.05)\n",
    "print(len(train03), 'train examples')\n",
    "print(len(test03), 'test examples')\n",
    "\n",
    "train04, test04 = train_test_split(n04, test_size=0.05)\n",
    "print(len(train04), 'train examples')\n",
    "print(len(test04), 'test examples')\n",
    "\n",
    "train05, test05 = train_test_split(n05, test_size=0.05)\n",
    "print(len(train04), 'train examples')\n",
    "print(len(test04), 'test examples')\n",
    "\n",
    "train_X01,train_y01 = get_X_and_y(train01)\n",
    "train_X02,train_y02 = get_X_and_y(train02)\n",
    "train_X03,train_y03 = get_X_and_y(train03)\n",
    "train_X04,train_y04 = get_X_and_y(train04)\n",
    "train_X05,train_y05 = get_X_and_y(train05)\n",
    "\n",
    "test_X01,test_y01 = get_X_and_y(test01)\n",
    "test_X02,test_y02 = get_X_and_y(test02)\n",
    "test_X03,test_y03 = get_X_and_y(test03)\n",
    "test_X04,test_y04 = get_X_and_y(test04)\n",
    "test_X05,test_y05 = get_X_and_y(test05)\n",
    "\n",
    "\n",
    "#Many models train better if you gradually reduce the learning rate during training. Use optimizers.schedules to reduce the learning rate over time:\n",
    "#The code sets a schedules.InverseTimeDecay to hyperbolically decrease the learning rate to 1/2 of the base rate at 1000 epochs, 1/3 at 2000 epochs and so on.\n",
    "\n",
    "def get_lr_schedule(train, batch_size):\n",
    "    lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "    0.001,\n",
    "    decay_steps=(len(train)//batch_size)*1000,\n",
    "    decay_rate=1,\n",
    "    staircase=False)\n",
    "    return lr_schedule\n",
    "\n",
    "def get_optimizer(train, batch_size):\n",
    "    return tf.keras.optimizers.Adam(get_lr_schedule(train, batch_size))\n",
    "\n",
    "\n",
    "#Each model in this tutorial will use the same training configuration. So set these up in a reusable way, starting with the list of callbacks.\n",
    "#The training for this tutorial runs for many short epochs. To reduce the logging noise use the tfdocs.EpochDots which simply a . for each epoch and, and a full set of metrics every 100 epochs.\n",
    "\n",
    "def get_callbacks(name):\n",
    "    return [\n",
    "        tfdocs.modeling.EpochDots(),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200),\n",
    "        #tf.keras.callbacks.TensorBoard(logdir/name), # Jupyter Notebook\n",
    "        #tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1) # Google Colab\n",
    "      ]\n",
    "\n",
    "def compile_and_fit(model, name, X, y, validation_split, batch_size, optimizer=None, max_epochs=1000):\n",
    "    if optimizer is None:\n",
    "        optimizer = get_optimizer(X, batch_size)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "     \n",
    "    history = model.fit(\n",
    "        X,\n",
    "        y,\n",
    "        validation_split=validation_split,\n",
    "        batch_size=batch_size,\n",
    "#        steps_per_epoch = 50, # (len(train_X01)//batch_size,\n",
    "        epochs=max_epochs,\n",
    "        callbacks=get_callbacks(name),\n",
    "        verbose=0)\n",
    "    \n",
    "    model.save(\"../model/%s.h5\" %name) \n",
    "    \n",
    "    return history\n",
    "\n",
    "def plot_history(model_history):\n",
    "\tplt.plot(model_history.history['accuracy'])\n",
    "\tplt.plot(model_history.history['val_accuracy'])\n",
    "\tplt.title(\"%s accuracy\" %model_history)\n",
    "\tplt.ylabel('accuracy')\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.legend(['train', 'val'], loc='upper left')\n",
    "\tplt.show()\n",
    "\t\n",
    "\tplt.plot(model_history.history['loss'])\n",
    "\tplt.plot(model_history.history['val_loss'])\n",
    "\tplt.title(\"%s loss\" %model_history)\n",
    "\tplt.ylabel('loss')\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.legend(['train', 'val'], loc='upper left')\n",
    "\tplt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "C5oCSP7gaQ9y",
    "outputId": "6e0a4bc2-e646-4474-bad8-bd213594e680"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.049957</td>\n",
       "      <td>0.165301</td>\n",
       "      <td>0.330601</td>\n",
       "      <td>0.183667</td>\n",
       "      <td>0.110200</td>\n",
       "      <td>0.073467</td>\n",
       "      <td>0.514268</td>\n",
       "      <td>0.367334</td>\n",
       "      <td>0.073467</td>\n",
       "      <td>0.073467</td>\n",
       "      <td>0.220401</td>\n",
       "      <td>0.293868</td>\n",
       "      <td>0.514268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.077897</td>\n",
       "      <td>0.103862</td>\n",
       "      <td>0.121172</td>\n",
       "      <td>0.103862</td>\n",
       "      <td>0.138483</td>\n",
       "      <td>0.103862</td>\n",
       "      <td>0.553931</td>\n",
       "      <td>0.415448</td>\n",
       "      <td>0.138483</td>\n",
       "      <td>0.103862</td>\n",
       "      <td>0.103862</td>\n",
       "      <td>0.484690</td>\n",
       "      <td>0.415448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.109311</td>\n",
       "      <td>0.117119</td>\n",
       "      <td>0.105407</td>\n",
       "      <td>0.195198</td>\n",
       "      <td>0.078079</td>\n",
       "      <td>0.117119</td>\n",
       "      <td>0.390396</td>\n",
       "      <td>0.312317</td>\n",
       "      <td>0.156158</td>\n",
       "      <td>0.156158</td>\n",
       "      <td>0.078079</td>\n",
       "      <td>0.585594</td>\n",
       "      <td>0.507514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.068789</td>\n",
       "      <td>0.117049</td>\n",
       "      <td>0.155945</td>\n",
       "      <td>0.180075</td>\n",
       "      <td>0.108045</td>\n",
       "      <td>0.072030</td>\n",
       "      <td>0.648271</td>\n",
       "      <td>0.396166</td>\n",
       "      <td>0.108045</td>\n",
       "      <td>0.108045</td>\n",
       "      <td>0.144060</td>\n",
       "      <td>0.360151</td>\n",
       "      <td>0.396166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.108097</td>\n",
       "      <td>0.154424</td>\n",
       "      <td>0.205899</td>\n",
       "      <td>0.102949</td>\n",
       "      <td>0.205899</td>\n",
       "      <td>0.205899</td>\n",
       "      <td>0.308848</td>\n",
       "      <td>0.463272</td>\n",
       "      <td>0.051475</td>\n",
       "      <td>0.308848</td>\n",
       "      <td>0.154424</td>\n",
       "      <td>0.360322</td>\n",
       "      <td>0.514746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20818</td>\n",
       "      <td>2</td>\n",
       "      <td>0.162536</td>\n",
       "      <td>0.123527</td>\n",
       "      <td>0.055262</td>\n",
       "      <td>0.097521</td>\n",
       "      <td>0.065014</td>\n",
       "      <td>0.162536</td>\n",
       "      <td>0.260057</td>\n",
       "      <td>0.487607</td>\n",
       "      <td>0.065014</td>\n",
       "      <td>0.130029</td>\n",
       "      <td>0.130029</td>\n",
       "      <td>0.325071</td>\n",
       "      <td>0.682650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20819</td>\n",
       "      <td>2</td>\n",
       "      <td>0.061498</td>\n",
       "      <td>0.110696</td>\n",
       "      <td>0.113771</td>\n",
       "      <td>0.092247</td>\n",
       "      <td>0.092247</td>\n",
       "      <td>0.122995</td>\n",
       "      <td>0.307489</td>\n",
       "      <td>0.584228</td>\n",
       "      <td>0.030749</td>\n",
       "      <td>0.122995</td>\n",
       "      <td>0.153744</td>\n",
       "      <td>0.215242</td>\n",
       "      <td>0.645726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20820</td>\n",
       "      <td>2</td>\n",
       "      <td>0.073697</td>\n",
       "      <td>0.153535</td>\n",
       "      <td>0.184242</td>\n",
       "      <td>0.122828</td>\n",
       "      <td>0.163770</td>\n",
       "      <td>0.122828</td>\n",
       "      <td>0.409426</td>\n",
       "      <td>0.368484</td>\n",
       "      <td>0.204713</td>\n",
       "      <td>0.081885</td>\n",
       "      <td>0.122828</td>\n",
       "      <td>0.614139</td>\n",
       "      <td>0.368484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20821</td>\n",
       "      <td>2</td>\n",
       "      <td>0.044350</td>\n",
       "      <td>0.175065</td>\n",
       "      <td>0.300111</td>\n",
       "      <td>0.066691</td>\n",
       "      <td>0.100037</td>\n",
       "      <td>0.166729</td>\n",
       "      <td>0.400149</td>\n",
       "      <td>0.466840</td>\n",
       "      <td>0.100037</td>\n",
       "      <td>0.100037</td>\n",
       "      <td>0.133383</td>\n",
       "      <td>0.366803</td>\n",
       "      <td>0.533532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20822</td>\n",
       "      <td>2</td>\n",
       "      <td>0.055791</td>\n",
       "      <td>0.140313</td>\n",
       "      <td>0.175391</td>\n",
       "      <td>0.200447</td>\n",
       "      <td>0.033408</td>\n",
       "      <td>0.100223</td>\n",
       "      <td>0.334078</td>\n",
       "      <td>0.267263</td>\n",
       "      <td>0.133631</td>\n",
       "      <td>0.033408</td>\n",
       "      <td>0.167039</td>\n",
       "      <td>0.467709</td>\n",
       "      <td>0.668156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20823 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       result  odds-home  odds-draw  odds-away  home-wins  home-draws  \\\n",
       "0           2   0.049957   0.165301   0.330601   0.183667    0.110200   \n",
       "1           1   0.077897   0.103862   0.121172   0.103862    0.138483   \n",
       "2           1   0.109311   0.117119   0.105407   0.195198    0.078079   \n",
       "3           0   0.068789   0.117049   0.155945   0.180075    0.108045   \n",
       "4           2   0.108097   0.154424   0.205899   0.102949    0.205899   \n",
       "...       ...        ...        ...        ...        ...         ...   \n",
       "20818       2   0.162536   0.123527   0.055262   0.097521    0.065014   \n",
       "20819       2   0.061498   0.110696   0.113771   0.092247    0.092247   \n",
       "20820       2   0.073697   0.153535   0.184242   0.122828    0.163770   \n",
       "20821       2   0.044350   0.175065   0.300111   0.066691    0.100037   \n",
       "20822       2   0.055791   0.140313   0.175391   0.200447    0.033408   \n",
       "\n",
       "       home-losses  home-goals  home-opposition-goals  away-wins  away-draws  \\\n",
       "0         0.073467    0.514268               0.367334   0.073467    0.073467   \n",
       "1         0.103862    0.553931               0.415448   0.138483    0.103862   \n",
       "2         0.117119    0.390396               0.312317   0.156158    0.156158   \n",
       "3         0.072030    0.648271               0.396166   0.108045    0.108045   \n",
       "4         0.205899    0.308848               0.463272   0.051475    0.308848   \n",
       "...            ...         ...                    ...        ...         ...   \n",
       "20818     0.162536    0.260057               0.487607   0.065014    0.130029   \n",
       "20819     0.122995    0.307489               0.584228   0.030749    0.122995   \n",
       "20820     0.122828    0.409426               0.368484   0.204713    0.081885   \n",
       "20821     0.166729    0.400149               0.466840   0.100037    0.100037   \n",
       "20822     0.100223    0.334078               0.267263   0.133631    0.033408   \n",
       "\n",
       "       away-losses  away-goals  away-opposition-goals  \n",
       "0         0.220401    0.293868               0.514268  \n",
       "1         0.103862    0.484690               0.415448  \n",
       "2         0.078079    0.585594               0.507514  \n",
       "3         0.144060    0.360151               0.396166  \n",
       "4         0.154424    0.360322               0.514746  \n",
       "...            ...         ...                    ...  \n",
       "20818     0.130029    0.325071               0.682650  \n",
       "20819     0.153744    0.215242               0.645726  \n",
       "20820     0.122828    0.614139               0.368484  \n",
       "20821     0.133383    0.366803               0.533532  \n",
       "20822     0.167039    0.467709               0.668156  \n",
       "\n",
       "[20823 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "colab_type": "code",
    "id": "UCnuh-duaSip",
    "outputId": "9ec7f29c-b38b-46c6-a6bb-d1904d8dfb17"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.012482</td>\n",
       "      <td>0.011769</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.010699</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.039230</td>\n",
       "      <td>0.057061</td>\n",
       "      <td>0.488587</td>\n",
       "      <td>0.238944</td>\n",
       "      <td>0.417260</td>\n",
       "      <td>0.189015</td>\n",
       "      <td>0.028531</td>\n",
       "      <td>0.007133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053495</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.574178</td>\n",
       "      <td>0.278173</td>\n",
       "      <td>0.256775</td>\n",
       "      <td>0.106990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.010640</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.022166</td>\n",
       "      <td>0.029555</td>\n",
       "      <td>0.059110</td>\n",
       "      <td>0.495044</td>\n",
       "      <td>0.236439</td>\n",
       "      <td>0.557848</td>\n",
       "      <td>0.284465</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.014777</td>\n",
       "      <td>0.040638</td>\n",
       "      <td>0.066498</td>\n",
       "      <td>0.384213</td>\n",
       "      <td>0.162552</td>\n",
       "      <td>0.321409</td>\n",
       "      <td>0.132997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007188</td>\n",
       "      <td>0.012795</td>\n",
       "      <td>0.015805</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.037632</td>\n",
       "      <td>0.056448</td>\n",
       "      <td>0.451585</td>\n",
       "      <td>0.218266</td>\n",
       "      <td>0.466638</td>\n",
       "      <td>0.210740</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.022579</td>\n",
       "      <td>0.041395</td>\n",
       "      <td>0.056448</td>\n",
       "      <td>0.504270</td>\n",
       "      <td>0.222029</td>\n",
       "      <td>0.376321</td>\n",
       "      <td>0.173108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010289</td>\n",
       "      <td>0.010289</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.015829</td>\n",
       "      <td>0.006332</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.069647</td>\n",
       "      <td>0.037989</td>\n",
       "      <td>0.560339</td>\n",
       "      <td>0.259592</td>\n",
       "      <td>0.234266</td>\n",
       "      <td>0.117133</td>\n",
       "      <td>0.018995</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.060149</td>\n",
       "      <td>0.025326</td>\n",
       "      <td>0.535013</td>\n",
       "      <td>0.300747</td>\n",
       "      <td>0.357730</td>\n",
       "      <td>0.183614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>0.020384</td>\n",
       "      <td>0.064551</td>\n",
       "      <td>0.023782</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.050961</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.546982</td>\n",
       "      <td>0.244613</td>\n",
       "      <td>0.251408</td>\n",
       "      <td>0.105320</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.016987</td>\n",
       "      <td>0.033974</td>\n",
       "      <td>0.057756</td>\n",
       "      <td>0.485829</td>\n",
       "      <td>0.234421</td>\n",
       "      <td>0.455252</td>\n",
       "      <td>0.234421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7028</td>\n",
       "      <td>2</td>\n",
       "      <td>0.020289</td>\n",
       "      <td>0.015420</td>\n",
       "      <td>0.006898</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.040578</td>\n",
       "      <td>0.048694</td>\n",
       "      <td>0.324626</td>\n",
       "      <td>0.174487</td>\n",
       "      <td>0.474766</td>\n",
       "      <td>0.243470</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.040578</td>\n",
       "      <td>0.085214</td>\n",
       "      <td>0.482881</td>\n",
       "      <td>0.235354</td>\n",
       "      <td>0.454477</td>\n",
       "      <td>0.263759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7029</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.017929</td>\n",
       "      <td>0.018427</td>\n",
       "      <td>0.014941</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.024901</td>\n",
       "      <td>0.044822</td>\n",
       "      <td>0.104584</td>\n",
       "      <td>0.443238</td>\n",
       "      <td>0.234070</td>\n",
       "      <td>0.458179</td>\n",
       "      <td>0.229089</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.019921</td>\n",
       "      <td>0.024901</td>\n",
       "      <td>0.034861</td>\n",
       "      <td>0.104584</td>\n",
       "      <td>0.517941</td>\n",
       "      <td>0.273911</td>\n",
       "      <td>0.313753</td>\n",
       "      <td>0.129485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7030</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007617</td>\n",
       "      <td>0.015870</td>\n",
       "      <td>0.019044</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.016928</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.516293</td>\n",
       "      <td>0.249683</td>\n",
       "      <td>0.389336</td>\n",
       "      <td>0.211596</td>\n",
       "      <td>0.021160</td>\n",
       "      <td>0.008464</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.063479</td>\n",
       "      <td>0.038087</td>\n",
       "      <td>0.355481</td>\n",
       "      <td>0.181972</td>\n",
       "      <td>0.499366</td>\n",
       "      <td>0.236987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7031</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.020806</td>\n",
       "      <td>0.035667</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.019815</td>\n",
       "      <td>0.047556</td>\n",
       "      <td>0.055483</td>\n",
       "      <td>0.491416</td>\n",
       "      <td>0.245708</td>\n",
       "      <td>0.392341</td>\n",
       "      <td>0.198152</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.015852</td>\n",
       "      <td>0.043593</td>\n",
       "      <td>0.067372</td>\n",
       "      <td>0.408193</td>\n",
       "      <td>0.210041</td>\n",
       "      <td>0.483490</td>\n",
       "      <td>0.214004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7032</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006541</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.020563</td>\n",
       "      <td>0.023501</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.039168</td>\n",
       "      <td>0.031334</td>\n",
       "      <td>0.411259</td>\n",
       "      <td>0.254589</td>\n",
       "      <td>0.493511</td>\n",
       "      <td>0.211505</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.007834</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.050918</td>\n",
       "      <td>0.074418</td>\n",
       "      <td>0.446510</td>\n",
       "      <td>0.246755</td>\n",
       "      <td>0.415176</td>\n",
       "      <td>0.180171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7033 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result  odds-home  odds-draw  odds-away  home-wins  home-draws  \\\n",
       "0          2   0.012482   0.011769   0.007489   0.003566    0.010699   \n",
       "1          1   0.009236   0.012191   0.010640   0.011083    0.003694   \n",
       "2          0   0.007188   0.012795   0.015805   0.015053    0.007526   \n",
       "3          2   0.010289   0.010289   0.007281   0.015829    0.006332   \n",
       "4          2   0.004077   0.020384   0.064551   0.023782    0.006795   \n",
       "...      ...        ...        ...        ...        ...         ...   \n",
       "7028       2   0.020289   0.015420   0.006898   0.016231    0.008116   \n",
       "7029       2   0.009960   0.017929   0.018427   0.014941    0.009960   \n",
       "7030       2   0.007617   0.015870   0.019044   0.012696    0.012696   \n",
       "7031       2   0.005271   0.020806   0.035667   0.007926    0.011889   \n",
       "7032       2   0.006541   0.016450   0.020563   0.023501    0.003917   \n",
       "\n",
       "      home-losses  home-goals  home-opposition-goals  home-shots  \\\n",
       "0        0.021398    0.039230               0.057061    0.488587   \n",
       "1        0.022166    0.029555               0.059110    0.495044   \n",
       "2        0.015053    0.037632               0.056448    0.451585   \n",
       "3        0.009497    0.069647               0.037989    0.560339   \n",
       "4        0.003397    0.050961               0.027179    0.546982   \n",
       "...           ...         ...                    ...         ...   \n",
       "7028     0.016231    0.040578               0.048694    0.324626   \n",
       "7029     0.024901    0.044822               0.104584    0.443238   \n",
       "7030     0.016928    0.033855               0.033855    0.516293   \n",
       "7031     0.019815    0.047556               0.055483    0.491416   \n",
       "7032     0.011750    0.039168               0.031334    0.411259   \n",
       "\n",
       "      home-shots_on_target  home-opposition_shots  \\\n",
       "0                 0.238944               0.417260   \n",
       "1                 0.236439               0.557848   \n",
       "2                 0.218266               0.466638   \n",
       "3                 0.259592               0.234266   \n",
       "4                 0.244613               0.251408   \n",
       "...                    ...                    ...   \n",
       "7028              0.174487               0.474766   \n",
       "7029              0.234070               0.458179   \n",
       "7030              0.249683               0.389336   \n",
       "7031              0.245708               0.392341   \n",
       "7032              0.254589               0.493511   \n",
       "\n",
       "      home-opposition_shots_on_target  away-wins  away-draws  away-losses  \\\n",
       "0                            0.189015   0.028531    0.007133     0.000000   \n",
       "1                            0.284465   0.011083    0.011083     0.014777   \n",
       "2                            0.210740   0.007526    0.007526     0.022579   \n",
       "3                            0.117133   0.018995    0.009497     0.003166   \n",
       "4                            0.105320   0.010192    0.006795     0.016987   \n",
       "...                               ...        ...         ...          ...   \n",
       "7028                         0.243470   0.008116    0.016231     0.016231   \n",
       "7029                         0.229089   0.004980    0.019921     0.024901   \n",
       "7030                         0.211596   0.021160    0.008464     0.012696   \n",
       "7031                         0.198152   0.011889    0.011889     0.015852   \n",
       "7032                         0.211505   0.011750    0.007834     0.019584   \n",
       "\n",
       "      away-goals  away-opposition-goals  away-shots  away-shots_on_target  \\\n",
       "0       0.053495               0.021398    0.574178              0.278173   \n",
       "1       0.040638               0.066498    0.384213              0.162552   \n",
       "2       0.041395               0.056448    0.504270              0.222029   \n",
       "3       0.060149               0.025326    0.535013              0.300747   \n",
       "4       0.033974               0.057756    0.485829              0.234421   \n",
       "...          ...                    ...         ...                   ...   \n",
       "7028    0.040578               0.085214    0.482881              0.235354   \n",
       "7029    0.034861               0.104584    0.517941              0.273911   \n",
       "7030    0.063479               0.038087    0.355481              0.181972   \n",
       "7031    0.043593               0.067372    0.408193              0.210041   \n",
       "7032    0.050918               0.074418    0.446510              0.246755   \n",
       "\n",
       "      away-opposition_shots  away-opposition_shots_on_target  \n",
       "0                  0.256775                         0.106990  \n",
       "1                  0.321409                         0.132997  \n",
       "2                  0.376321                         0.173108  \n",
       "3                  0.357730                         0.183614  \n",
       "4                  0.455252                         0.234421  \n",
       "...                     ...                              ...  \n",
       "7028               0.454477                         0.263759  \n",
       "7029               0.313753                         0.129485  \n",
       "7030               0.499366                         0.236987  \n",
       "7031               0.483490                         0.214004  \n",
       "7032               0.415176                         0.180171  \n",
       "\n",
       "[7033 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "colab_type": "code",
    "id": "iUgEWCcJaTKx",
    "outputId": "a30e80e8-8b13-43cf-988d-0fa22e73fd94"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "      <th>home_shot_accuracy</th>\n",
       "      <th>home_shot_efficiency</th>\n",
       "      <th>home_opposition_shot_accuracy</th>\n",
       "      <th>home_opposition_shot_efficiency</th>\n",
       "      <th>away_shot_accuracy</th>\n",
       "      <th>away_shot_efficiency</th>\n",
       "      <th>away_opposition_shot_accuracy</th>\n",
       "      <th>away_opposition_shot_efficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.012482</td>\n",
       "      <td>0.011769</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.010699</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.039229</td>\n",
       "      <td>0.057061</td>\n",
       "      <td>0.488583</td>\n",
       "      <td>0.238942</td>\n",
       "      <td>0.417257</td>\n",
       "      <td>0.189014</td>\n",
       "      <td>0.028530</td>\n",
       "      <td>0.007133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053495</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.574174</td>\n",
       "      <td>0.278171</td>\n",
       "      <td>0.256774</td>\n",
       "      <td>0.106989</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.001616</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.000713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.010640</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.022166</td>\n",
       "      <td>0.029555</td>\n",
       "      <td>0.059109</td>\n",
       "      <td>0.495039</td>\n",
       "      <td>0.236437</td>\n",
       "      <td>0.557843</td>\n",
       "      <td>0.284463</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.014777</td>\n",
       "      <td>0.040638</td>\n",
       "      <td>0.066498</td>\n",
       "      <td>0.384210</td>\n",
       "      <td>0.162550</td>\n",
       "      <td>0.321406</td>\n",
       "      <td>0.132996</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.001884</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.001847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007188</td>\n",
       "      <td>0.012795</td>\n",
       "      <td>0.015805</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.037632</td>\n",
       "      <td>0.056448</td>\n",
       "      <td>0.451581</td>\n",
       "      <td>0.218264</td>\n",
       "      <td>0.466634</td>\n",
       "      <td>0.210738</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.022579</td>\n",
       "      <td>0.041395</td>\n",
       "      <td>0.056448</td>\n",
       "      <td>0.504266</td>\n",
       "      <td>0.222028</td>\n",
       "      <td>0.376318</td>\n",
       "      <td>0.173106</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.001731</td>\n",
       "      <td>0.001227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010289</td>\n",
       "      <td>0.010289</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.015829</td>\n",
       "      <td>0.006331</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.069646</td>\n",
       "      <td>0.037989</td>\n",
       "      <td>0.560335</td>\n",
       "      <td>0.259590</td>\n",
       "      <td>0.234264</td>\n",
       "      <td>0.117132</td>\n",
       "      <td>0.018994</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.060149</td>\n",
       "      <td>0.025326</td>\n",
       "      <td>0.535009</td>\n",
       "      <td>0.300745</td>\n",
       "      <td>0.357728</td>\n",
       "      <td>0.183613</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.000437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>0.020384</td>\n",
       "      <td>0.064550</td>\n",
       "      <td>0.023782</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.050961</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.546979</td>\n",
       "      <td>0.244612</td>\n",
       "      <td>0.251406</td>\n",
       "      <td>0.105319</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.016987</td>\n",
       "      <td>0.033974</td>\n",
       "      <td>0.057756</td>\n",
       "      <td>0.485826</td>\n",
       "      <td>0.234419</td>\n",
       "      <td>0.455249</td>\n",
       "      <td>0.234419</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.000837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7028</td>\n",
       "      <td>2</td>\n",
       "      <td>0.020289</td>\n",
       "      <td>0.015420</td>\n",
       "      <td>0.006898</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.040578</td>\n",
       "      <td>0.048693</td>\n",
       "      <td>0.324623</td>\n",
       "      <td>0.174485</td>\n",
       "      <td>0.474761</td>\n",
       "      <td>0.243467</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.040578</td>\n",
       "      <td>0.085213</td>\n",
       "      <td>0.482876</td>\n",
       "      <td>0.235351</td>\n",
       "      <td>0.454472</td>\n",
       "      <td>0.263756</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.001311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7029</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.017928</td>\n",
       "      <td>0.018426</td>\n",
       "      <td>0.014940</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.044821</td>\n",
       "      <td>0.104582</td>\n",
       "      <td>0.443228</td>\n",
       "      <td>0.234064</td>\n",
       "      <td>0.458168</td>\n",
       "      <td>0.229084</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.019920</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.034861</td>\n",
       "      <td>0.104582</td>\n",
       "      <td>0.517929</td>\n",
       "      <td>0.273905</td>\n",
       "      <td>0.313745</td>\n",
       "      <td>0.129482</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.004022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7030</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007617</td>\n",
       "      <td>0.015870</td>\n",
       "      <td>0.019043</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.016927</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.516288</td>\n",
       "      <td>0.249680</td>\n",
       "      <td>0.389332</td>\n",
       "      <td>0.211593</td>\n",
       "      <td>0.021159</td>\n",
       "      <td>0.008464</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.063478</td>\n",
       "      <td>0.038087</td>\n",
       "      <td>0.355477</td>\n",
       "      <td>0.181970</td>\n",
       "      <td>0.499360</td>\n",
       "      <td>0.236985</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.000680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7031</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.020806</td>\n",
       "      <td>0.035667</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.019815</td>\n",
       "      <td>0.047556</td>\n",
       "      <td>0.055482</td>\n",
       "      <td>0.491412</td>\n",
       "      <td>0.245706</td>\n",
       "      <td>0.392337</td>\n",
       "      <td>0.198150</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.015852</td>\n",
       "      <td>0.043593</td>\n",
       "      <td>0.067371</td>\n",
       "      <td>0.408189</td>\n",
       "      <td>0.210039</td>\n",
       "      <td>0.483486</td>\n",
       "      <td>0.214002</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7032</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006541</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.020563</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.039167</td>\n",
       "      <td>0.031334</td>\n",
       "      <td>0.411255</td>\n",
       "      <td>0.254586</td>\n",
       "      <td>0.493506</td>\n",
       "      <td>0.211503</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.007833</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.050917</td>\n",
       "      <td>0.074418</td>\n",
       "      <td>0.446505</td>\n",
       "      <td>0.246753</td>\n",
       "      <td>0.415172</td>\n",
       "      <td>0.180169</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.001618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7033 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result  odds-home  odds-draw  odds-away  home-wins  home-draws  \\\n",
       "0          2   0.012482   0.011769   0.007489   0.003566    0.010699   \n",
       "1          1   0.009236   0.012191   0.010640   0.011083    0.003694   \n",
       "2          0   0.007188   0.012795   0.015805   0.015053    0.007526   \n",
       "3          2   0.010289   0.010289   0.007281   0.015829    0.006331   \n",
       "4          2   0.004077   0.020384   0.064550   0.023782    0.006795   \n",
       "...      ...        ...        ...        ...        ...         ...   \n",
       "7028       2   0.020289   0.015420   0.006898   0.016231    0.008116   \n",
       "7029       2   0.009960   0.017928   0.018426   0.014940    0.009960   \n",
       "7030       2   0.007617   0.015870   0.019043   0.012696    0.012696   \n",
       "7031       2   0.005271   0.020806   0.035667   0.007926    0.011889   \n",
       "7032       2   0.006541   0.016450   0.020563   0.023500    0.003917   \n",
       "\n",
       "      home-losses  home-goals  home-opposition-goals  home-shots  \\\n",
       "0        0.021398    0.039229               0.057061    0.488583   \n",
       "1        0.022166    0.029555               0.059109    0.495039   \n",
       "2        0.015053    0.037632               0.056448    0.451581   \n",
       "3        0.009497    0.069646               0.037989    0.560335   \n",
       "4        0.003397    0.050961               0.027179    0.546979   \n",
       "...           ...         ...                    ...         ...   \n",
       "7028     0.016231    0.040578               0.048693    0.324623   \n",
       "7029     0.024900    0.044821               0.104582    0.443228   \n",
       "7030     0.016927    0.033855               0.033855    0.516288   \n",
       "7031     0.019815    0.047556               0.055482    0.491412   \n",
       "7032     0.011750    0.039167               0.031334    0.411255   \n",
       "\n",
       "      home-shots_on_target  home-opposition_shots  \\\n",
       "0                 0.238942               0.417257   \n",
       "1                 0.236437               0.557843   \n",
       "2                 0.218264               0.466634   \n",
       "3                 0.259590               0.234264   \n",
       "4                 0.244612               0.251406   \n",
       "...                    ...                    ...   \n",
       "7028              0.174485               0.474761   \n",
       "7029              0.234064               0.458168   \n",
       "7030              0.249680               0.389332   \n",
       "7031              0.245706               0.392337   \n",
       "7032              0.254586               0.493506   \n",
       "\n",
       "      home-opposition_shots_on_target  away-wins  away-draws  away-losses  \\\n",
       "0                            0.189014   0.028530    0.007133     0.000000   \n",
       "1                            0.284463   0.011083    0.011083     0.014777   \n",
       "2                            0.210738   0.007526    0.007526     0.022579   \n",
       "3                            0.117132   0.018994    0.009497     0.003166   \n",
       "4                            0.105319   0.010192    0.006795     0.016987   \n",
       "...                               ...        ...         ...          ...   \n",
       "7028                         0.243467   0.008116    0.016231     0.016231   \n",
       "7029                         0.229084   0.004980    0.019920     0.024900   \n",
       "7030                         0.211593   0.021159    0.008464     0.012696   \n",
       "7031                         0.198150   0.011889    0.011889     0.015852   \n",
       "7032                         0.211503   0.011750    0.007833     0.019584   \n",
       "\n",
       "      away-goals  away-opposition-goals  away-shots  away-shots_on_target  \\\n",
       "0       0.053495               0.021398    0.574174              0.278171   \n",
       "1       0.040638               0.066498    0.384210              0.162550   \n",
       "2       0.041395               0.056448    0.504266              0.222028   \n",
       "3       0.060149               0.025326    0.535009              0.300745   \n",
       "4       0.033974               0.057756    0.485826              0.234419   \n",
       "...          ...                    ...         ...                   ...   \n",
       "7028    0.040578               0.085213    0.482876              0.235351   \n",
       "7029    0.034861               0.104582    0.517929              0.273905   \n",
       "7030    0.063478               0.038087    0.355477              0.181970   \n",
       "7031    0.043593               0.067371    0.408189              0.210039   \n",
       "7032    0.050917               0.074418    0.446505              0.246753   \n",
       "\n",
       "      away-opposition_shots  away-opposition_shots_on_target  \\\n",
       "0                  0.256774                         0.106989   \n",
       "1                  0.321406                         0.132996   \n",
       "2                  0.376318                         0.173106   \n",
       "3                  0.357728                         0.183613   \n",
       "4                  0.455249                         0.234419   \n",
       "...                     ...                              ...   \n",
       "7028               0.454472                         0.263756   \n",
       "7029               0.313745                         0.129482   \n",
       "7030               0.499360                         0.236985   \n",
       "7031               0.483486                         0.214002   \n",
       "7032               0.415172                         0.180169   \n",
       "\n",
       "      home_shot_accuracy  home_shot_efficiency  home_opposition_shot_accuracy  \\\n",
       "0               0.001744              0.000586                       0.001616   \n",
       "1               0.001764              0.000462                       0.001884   \n",
       "2               0.001819              0.000649                       0.001699   \n",
       "3               0.001467              0.000849                       0.001583   \n",
       "4               0.001519              0.000708                       0.001423   \n",
       "...                  ...                   ...                            ...   \n",
       "7028            0.002181              0.000944                       0.002081   \n",
       "7029            0.002630              0.000954                       0.002490   \n",
       "7030            0.002047              0.000574                       0.002300   \n",
       "7031            0.001981              0.000767                       0.002002   \n",
       "7032            0.002425              0.000603                       0.001679   \n",
       "\n",
       "      home_opposition_shot_efficiency  away_shot_accuracy  \\\n",
       "0                            0.001077            0.001728   \n",
       "1                            0.000768            0.001563   \n",
       "2                            0.001008            0.001657   \n",
       "3                            0.001027            0.001780   \n",
       "4                            0.000877            0.001639   \n",
       "...                               ...                 ...   \n",
       "7028                         0.000812            0.001978   \n",
       "7029                         0.002274            0.002634   \n",
       "7030                         0.000677            0.002166   \n",
       "7031                         0.001110            0.002039   \n",
       "7032                         0.000580            0.002164   \n",
       "\n",
       "      away_shot_efficiency  away_opposition_shot_accuracy  \\\n",
       "0                 0.000686                       0.001486   \n",
       "1                 0.000924                       0.001529   \n",
       "2                 0.000702                       0.001731   \n",
       "3                 0.000633                       0.001625   \n",
       "4                 0.000492                       0.001749   \n",
       "...                    ...                            ...   \n",
       "7028              0.000700                       0.002355   \n",
       "7029              0.000634                       0.002055   \n",
       "7030              0.001476                       0.002008   \n",
       "7031              0.000823                       0.001754   \n",
       "7032              0.000808                       0.001700   \n",
       "\n",
       "      away_opposition_shot_efficiency  \n",
       "0                            0.000713  \n",
       "1                            0.001847  \n",
       "2                            0.001227  \n",
       "3                            0.000437  \n",
       "4                            0.000837  \n",
       "...                               ...  \n",
       "7028                         0.001311  \n",
       "7029                         0.004022  \n",
       "7030                         0.000680  \n",
       "7031                         0.001248  \n",
       "7032                         0.001618  \n",
       "\n",
       "[7033 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "colab_type": "code",
    "id": "tPTv1eKnaTy6",
    "outputId": "a438f9c7-fdce-4e67-a4fc-8af1bf8e89e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-possession</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>home-opposition_possession</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-possession</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "      <th>away-opposition_possession</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.003146</td>\n",
       "      <td>0.006291</td>\n",
       "      <td>0.011534</td>\n",
       "      <td>0.016777</td>\n",
       "      <td>0.143652</td>\n",
       "      <td>0.070253</td>\n",
       "      <td>0.504354</td>\n",
       "      <td>0.122681</td>\n",
       "      <td>0.055573</td>\n",
       "      <td>0.449829</td>\n",
       "      <td>0.008388</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015728</td>\n",
       "      <td>0.006291</td>\n",
       "      <td>0.168817</td>\n",
       "      <td>0.081787</td>\n",
       "      <td>0.505403</td>\n",
       "      <td>0.075496</td>\n",
       "      <td>0.031457</td>\n",
       "      <td>0.448781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.002343</td>\n",
       "      <td>0.005094</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.019356</td>\n",
       "      <td>0.012225</td>\n",
       "      <td>0.192540</td>\n",
       "      <td>0.090667</td>\n",
       "      <td>0.550114</td>\n",
       "      <td>0.070292</td>\n",
       "      <td>0.036674</td>\n",
       "      <td>0.375911</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.019356</td>\n",
       "      <td>0.008150</td>\n",
       "      <td>0.172165</td>\n",
       "      <td>0.096779</td>\n",
       "      <td>0.558264</td>\n",
       "      <td>0.115116</td>\n",
       "      <td>0.059086</td>\n",
       "      <td>0.368780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>0.019859</td>\n",
       "      <td>0.007317</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.015678</td>\n",
       "      <td>0.008362</td>\n",
       "      <td>0.168280</td>\n",
       "      <td>0.075256</td>\n",
       "      <td>0.498568</td>\n",
       "      <td>0.077346</td>\n",
       "      <td>0.032402</td>\n",
       "      <td>0.452578</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>0.009407</td>\n",
       "      <td>0.018814</td>\n",
       "      <td>0.137968</td>\n",
       "      <td>0.064803</td>\n",
       "      <td>0.443171</td>\n",
       "      <td>0.145285</td>\n",
       "      <td>0.074210</td>\n",
       "      <td>0.507975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>0.011549</td>\n",
       "      <td>0.107092</td>\n",
       "      <td>0.049346</td>\n",
       "      <td>0.460917</td>\n",
       "      <td>0.139640</td>\n",
       "      <td>0.080844</td>\n",
       "      <td>0.494515</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.005250</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>0.016799</td>\n",
       "      <td>0.121791</td>\n",
       "      <td>0.056696</td>\n",
       "      <td>0.430469</td>\n",
       "      <td>0.137540</td>\n",
       "      <td>0.067195</td>\n",
       "      <td>0.524963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002715</td>\n",
       "      <td>0.003394</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>0.015665</td>\n",
       "      <td>0.016709</td>\n",
       "      <td>0.130540</td>\n",
       "      <td>0.065792</td>\n",
       "      <td>0.454281</td>\n",
       "      <td>0.159781</td>\n",
       "      <td>0.076236</td>\n",
       "      <td>0.496054</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.013576</td>\n",
       "      <td>0.016709</td>\n",
       "      <td>0.107565</td>\n",
       "      <td>0.053260</td>\n",
       "      <td>0.456369</td>\n",
       "      <td>0.144117</td>\n",
       "      <td>0.079369</td>\n",
       "      <td>0.493965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6991</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>0.012650</td>\n",
       "      <td>0.084331</td>\n",
       "      <td>0.045328</td>\n",
       "      <td>0.436415</td>\n",
       "      <td>0.123335</td>\n",
       "      <td>0.063249</td>\n",
       "      <td>0.521801</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>0.022137</td>\n",
       "      <td>0.125443</td>\n",
       "      <td>0.061140</td>\n",
       "      <td>0.410062</td>\n",
       "      <td>0.118064</td>\n",
       "      <td>0.068519</td>\n",
       "      <td>0.549208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6992</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.022398</td>\n",
       "      <td>0.094925</td>\n",
       "      <td>0.050129</td>\n",
       "      <td>0.417030</td>\n",
       "      <td>0.098125</td>\n",
       "      <td>0.049062</td>\n",
       "      <td>0.553551</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.007466</td>\n",
       "      <td>0.022398</td>\n",
       "      <td>0.110924</td>\n",
       "      <td>0.058662</td>\n",
       "      <td>0.447961</td>\n",
       "      <td>0.067194</td>\n",
       "      <td>0.027731</td>\n",
       "      <td>0.522621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6993</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.004780</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.004249</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.129584</td>\n",
       "      <td>0.062667</td>\n",
       "      <td>0.476910</td>\n",
       "      <td>0.097719</td>\n",
       "      <td>0.053108</td>\n",
       "      <td>0.489656</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.015932</td>\n",
       "      <td>0.009559</td>\n",
       "      <td>0.089221</td>\n",
       "      <td>0.045673</td>\n",
       "      <td>0.525769</td>\n",
       "      <td>0.125335</td>\n",
       "      <td>0.059481</td>\n",
       "      <td>0.439734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6994</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.005523</td>\n",
       "      <td>0.009468</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.005260</td>\n",
       "      <td>0.012624</td>\n",
       "      <td>0.014728</td>\n",
       "      <td>0.130447</td>\n",
       "      <td>0.065223</td>\n",
       "      <td>0.557555</td>\n",
       "      <td>0.104147</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.399757</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.004208</td>\n",
       "      <td>0.011572</td>\n",
       "      <td>0.017884</td>\n",
       "      <td>0.108355</td>\n",
       "      <td>0.055756</td>\n",
       "      <td>0.460772</td>\n",
       "      <td>0.128343</td>\n",
       "      <td>0.056808</td>\n",
       "      <td>0.496540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6995</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>0.004406</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.006294</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.010491</td>\n",
       "      <td>0.008393</td>\n",
       "      <td>0.110153</td>\n",
       "      <td>0.068190</td>\n",
       "      <td>0.568601</td>\n",
       "      <td>0.132184</td>\n",
       "      <td>0.056650</td>\n",
       "      <td>0.386061</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>0.013638</td>\n",
       "      <td>0.019932</td>\n",
       "      <td>0.119595</td>\n",
       "      <td>0.066092</td>\n",
       "      <td>0.487822</td>\n",
       "      <td>0.111202</td>\n",
       "      <td>0.048258</td>\n",
       "      <td>0.466840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6996 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result  odds-home  odds-draw  odds-away  home-wins  home-draws  \\\n",
       "0          2   0.003670   0.003460   0.002202   0.001049    0.003146   \n",
       "1          2   0.003311   0.003311   0.002343   0.005094    0.002037   \n",
       "2          2   0.001254   0.006271   0.019859   0.007317    0.002090   \n",
       "3          0   0.002499   0.003465   0.003150   0.003150    0.003150   \n",
       "4          0   0.002715   0.003394   0.002924   0.004177    0.001044   \n",
       "...      ...        ...        ...        ...        ...         ...   \n",
       "6991       2   0.005271   0.004006   0.001792   0.004217    0.002108   \n",
       "6992       2   0.002133   0.003840   0.003946   0.003200    0.002133   \n",
       "6993       2   0.001912   0.003983   0.004780   0.003186    0.003186   \n",
       "6994       2   0.001399   0.005523   0.009468   0.002104    0.003156   \n",
       "6995       2   0.001752   0.004406   0.005508   0.006294    0.001049   \n",
       "\n",
       "      home-losses  home-goals  home-opposition-goals  home-shots  \\\n",
       "0        0.006291    0.011534               0.016777    0.143652   \n",
       "1        0.003056    0.019356               0.012225    0.192540   \n",
       "2        0.001045    0.015678               0.008362    0.168280   \n",
       "3        0.004200    0.009449               0.011549    0.107092   \n",
       "4        0.005222    0.015665               0.016709    0.130540   \n",
       "...           ...         ...                    ...         ...   \n",
       "6991     0.004217    0.010541               0.012650    0.084331   \n",
       "6992     0.005333    0.009599               0.022398    0.094925   \n",
       "6993     0.004249    0.008497               0.008497    0.129584   \n",
       "6994     0.005260    0.012624               0.014728    0.130447   \n",
       "6995     0.003147    0.010491               0.008393    0.110153   \n",
       "\n",
       "      home-shots_on_target  home-possession  home-opposition_shots  \\\n",
       "0                 0.070253         0.504354               0.122681   \n",
       "1                 0.090667         0.550114               0.070292   \n",
       "2                 0.075256         0.498568               0.077346   \n",
       "3                 0.049346         0.460917               0.139640   \n",
       "4                 0.065792         0.454281               0.159781   \n",
       "...                    ...              ...                    ...   \n",
       "6991              0.045328         0.436415               0.123335   \n",
       "6992              0.050129         0.417030               0.098125   \n",
       "6993              0.062667         0.476910               0.097719   \n",
       "6994              0.065223         0.557555               0.104147   \n",
       "6995              0.068190         0.568601               0.132184   \n",
       "\n",
       "      home-opposition_shots_on_target  home-opposition_possession  away-wins  \\\n",
       "0                            0.055573                    0.449829   0.008388   \n",
       "1                            0.036674                    0.375911   0.006112   \n",
       "2                            0.032402                    0.452578   0.002090   \n",
       "3                            0.080844                    0.494515   0.003150   \n",
       "4                            0.076236                    0.496054   0.004177   \n",
       "...                               ...                         ...        ...   \n",
       "6991                         0.063249                    0.521801   0.002108   \n",
       "6992                         0.049062                    0.553551   0.001067   \n",
       "6993                         0.053108                    0.489656   0.005311   \n",
       "6994                         0.052600                    0.399757   0.003156   \n",
       "6995                         0.056650                    0.386061   0.003147   \n",
       "\n",
       "      away-draws  away-losses  away-goals  away-opposition-goals  away-shots  \\\n",
       "0       0.002097     0.000000    0.015728               0.006291    0.168817   \n",
       "1       0.003056     0.001019    0.019356               0.008150    0.172165   \n",
       "2       0.002090     0.006271    0.009407               0.018814    0.137968   \n",
       "3       0.002100     0.005250    0.009449               0.016799    0.121791   \n",
       "4       0.003133     0.003133    0.013576               0.016709    0.107565   \n",
       "...          ...          ...         ...                    ...         ...   \n",
       "6991    0.004217     0.004217    0.010541               0.022137    0.125443   \n",
       "6992    0.004266     0.005333    0.007466               0.022398    0.110924   \n",
       "6993    0.002124     0.003186    0.015932               0.009559    0.089221   \n",
       "6994    0.003156     0.004208    0.011572               0.017884    0.108355   \n",
       "6995    0.002098     0.005245    0.013638               0.019932    0.119595   \n",
       "\n",
       "      away-shots_on_target  away-possession  away-opposition_shots  \\\n",
       "0                 0.081787         0.505403               0.075496   \n",
       "1                 0.096779         0.558264               0.115116   \n",
       "2                 0.064803         0.443171               0.145285   \n",
       "3                 0.056696         0.430469               0.137540   \n",
       "4                 0.053260         0.456369               0.144117   \n",
       "...                    ...              ...                    ...   \n",
       "6991              0.061140         0.410062               0.118064   \n",
       "6992              0.058662         0.447961               0.067194   \n",
       "6993              0.045673         0.525769               0.125335   \n",
       "6994              0.055756         0.460772               0.128343   \n",
       "6995              0.066092         0.487822               0.111202   \n",
       "\n",
       "      away-opposition_shots_on_target  away-opposition_possession  \n",
       "0                            0.031457                    0.448781  \n",
       "1                            0.059086                    0.368780  \n",
       "2                            0.074210                    0.507975  \n",
       "3                            0.067195                    0.524963  \n",
       "4                            0.079369                    0.493965  \n",
       "...                               ...                         ...  \n",
       "6991                         0.068519                    0.549208  \n",
       "6992                         0.027731                    0.522621  \n",
       "6993                         0.059481                    0.439734  \n",
       "6994                         0.056808                    0.496540  \n",
       "6995                         0.048258                    0.466840  \n",
       "\n",
       "[6996 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "colab_type": "code",
    "id": "wHXHdefzaUcP",
    "outputId": "55ce72c7-6329-4541-c391-a10303b02d3c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-possession</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>home-opposition_possession</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-possession</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "      <th>away-opposition_possession</th>\n",
       "      <th>home_shot_accuracy</th>\n",
       "      <th>home_shot_efficiency</th>\n",
       "      <th>home_opposition_shot_accuracy</th>\n",
       "      <th>home_opposition_shot_efficiency</th>\n",
       "      <th>away_shot_accuracy</th>\n",
       "      <th>away_shot_efficiency</th>\n",
       "      <th>away_opposition_shot_accuracy</th>\n",
       "      <th>away_opposition_shot_efficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.003146</td>\n",
       "      <td>0.006291</td>\n",
       "      <td>0.011534</td>\n",
       "      <td>0.016777</td>\n",
       "      <td>0.143652</td>\n",
       "      <td>0.070253</td>\n",
       "      <td>0.504354</td>\n",
       "      <td>0.122681</td>\n",
       "      <td>0.055573</td>\n",
       "      <td>0.449829</td>\n",
       "      <td>0.008388</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015728</td>\n",
       "      <td>0.006291</td>\n",
       "      <td>0.168817</td>\n",
       "      <td>0.081787</td>\n",
       "      <td>0.505402</td>\n",
       "      <td>0.075496</td>\n",
       "      <td>0.031457</td>\n",
       "      <td>0.448780</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.002343</td>\n",
       "      <td>0.005094</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.019356</td>\n",
       "      <td>0.012225</td>\n",
       "      <td>0.192540</td>\n",
       "      <td>0.090667</td>\n",
       "      <td>0.550114</td>\n",
       "      <td>0.070292</td>\n",
       "      <td>0.036674</td>\n",
       "      <td>0.375911</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.019356</td>\n",
       "      <td>0.008150</td>\n",
       "      <td>0.172165</td>\n",
       "      <td>0.096779</td>\n",
       "      <td>0.558263</td>\n",
       "      <td>0.115116</td>\n",
       "      <td>0.059086</td>\n",
       "      <td>0.368780</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.000141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>0.019859</td>\n",
       "      <td>0.007317</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.015678</td>\n",
       "      <td>0.008362</td>\n",
       "      <td>0.168280</td>\n",
       "      <td>0.075255</td>\n",
       "      <td>0.498567</td>\n",
       "      <td>0.077346</td>\n",
       "      <td>0.032402</td>\n",
       "      <td>0.452578</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>0.009407</td>\n",
       "      <td>0.018814</td>\n",
       "      <td>0.137968</td>\n",
       "      <td>0.064803</td>\n",
       "      <td>0.443171</td>\n",
       "      <td>0.145285</td>\n",
       "      <td>0.074210</td>\n",
       "      <td>0.507974</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.000265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>0.011549</td>\n",
       "      <td>0.107092</td>\n",
       "      <td>0.049346</td>\n",
       "      <td>0.460917</td>\n",
       "      <td>0.139640</td>\n",
       "      <td>0.080844</td>\n",
       "      <td>0.494515</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.005250</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>0.016799</td>\n",
       "      <td>0.121791</td>\n",
       "      <td>0.056696</td>\n",
       "      <td>0.430469</td>\n",
       "      <td>0.137540</td>\n",
       "      <td>0.067195</td>\n",
       "      <td>0.524962</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002715</td>\n",
       "      <td>0.003394</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>0.015665</td>\n",
       "      <td>0.016709</td>\n",
       "      <td>0.130540</td>\n",
       "      <td>0.065792</td>\n",
       "      <td>0.454280</td>\n",
       "      <td>0.159781</td>\n",
       "      <td>0.076236</td>\n",
       "      <td>0.496053</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.013576</td>\n",
       "      <td>0.016709</td>\n",
       "      <td>0.107565</td>\n",
       "      <td>0.053260</td>\n",
       "      <td>0.456369</td>\n",
       "      <td>0.144117</td>\n",
       "      <td>0.079369</td>\n",
       "      <td>0.493965</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6991</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>0.012650</td>\n",
       "      <td>0.084331</td>\n",
       "      <td>0.045328</td>\n",
       "      <td>0.436415</td>\n",
       "      <td>0.123335</td>\n",
       "      <td>0.063249</td>\n",
       "      <td>0.521800</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>0.022137</td>\n",
       "      <td>0.125443</td>\n",
       "      <td>0.061140</td>\n",
       "      <td>0.410061</td>\n",
       "      <td>0.118064</td>\n",
       "      <td>0.068519</td>\n",
       "      <td>0.549208</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.000341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6992</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.022398</td>\n",
       "      <td>0.094925</td>\n",
       "      <td>0.050129</td>\n",
       "      <td>0.417030</td>\n",
       "      <td>0.098125</td>\n",
       "      <td>0.049062</td>\n",
       "      <td>0.553551</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.007466</td>\n",
       "      <td>0.022398</td>\n",
       "      <td>0.110923</td>\n",
       "      <td>0.058661</td>\n",
       "      <td>0.447960</td>\n",
       "      <td>0.067194</td>\n",
       "      <td>0.027731</td>\n",
       "      <td>0.522620</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6993</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.004780</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.004249</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.129583</td>\n",
       "      <td>0.062667</td>\n",
       "      <td>0.476909</td>\n",
       "      <td>0.097719</td>\n",
       "      <td>0.053108</td>\n",
       "      <td>0.489655</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.015932</td>\n",
       "      <td>0.009559</td>\n",
       "      <td>0.089221</td>\n",
       "      <td>0.045673</td>\n",
       "      <td>0.525769</td>\n",
       "      <td>0.125335</td>\n",
       "      <td>0.059481</td>\n",
       "      <td>0.439734</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.000171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6994</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.005523</td>\n",
       "      <td>0.009468</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.005260</td>\n",
       "      <td>0.012624</td>\n",
       "      <td>0.014728</td>\n",
       "      <td>0.130447</td>\n",
       "      <td>0.065223</td>\n",
       "      <td>0.557555</td>\n",
       "      <td>0.104147</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.399756</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.004208</td>\n",
       "      <td>0.011572</td>\n",
       "      <td>0.017884</td>\n",
       "      <td>0.108355</td>\n",
       "      <td>0.055755</td>\n",
       "      <td>0.460772</td>\n",
       "      <td>0.128343</td>\n",
       "      <td>0.056807</td>\n",
       "      <td>0.496539</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6995</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>0.004406</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.006294</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.010491</td>\n",
       "      <td>0.008393</td>\n",
       "      <td>0.110153</td>\n",
       "      <td>0.068190</td>\n",
       "      <td>0.568600</td>\n",
       "      <td>0.132184</td>\n",
       "      <td>0.056650</td>\n",
       "      <td>0.386061</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>0.013638</td>\n",
       "      <td>0.019932</td>\n",
       "      <td>0.119595</td>\n",
       "      <td>0.066092</td>\n",
       "      <td>0.487821</td>\n",
       "      <td>0.111202</td>\n",
       "      <td>0.048258</td>\n",
       "      <td>0.466840</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6996 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result  odds-home  odds-draw  odds-away  home-wins  home-draws  \\\n",
       "0          2   0.003670   0.003460   0.002202   0.001049    0.003146   \n",
       "1          2   0.003311   0.003311   0.002343   0.005094    0.002037   \n",
       "2          2   0.001254   0.006271   0.019859   0.007317    0.002090   \n",
       "3          0   0.002499   0.003465   0.003150   0.003150    0.003150   \n",
       "4          0   0.002715   0.003394   0.002924   0.004177    0.001044   \n",
       "...      ...        ...        ...        ...        ...         ...   \n",
       "6991       2   0.005271   0.004006   0.001792   0.004217    0.002108   \n",
       "6992       2   0.002133   0.003840   0.003946   0.003200    0.002133   \n",
       "6993       2   0.001912   0.003983   0.004780   0.003186    0.003186   \n",
       "6994       2   0.001399   0.005523   0.009468   0.002104    0.003156   \n",
       "6995       2   0.001752   0.004406   0.005508   0.006294    0.001049   \n",
       "\n",
       "      home-losses  home-goals  home-opposition-goals  home-shots  \\\n",
       "0        0.006291    0.011534               0.016777    0.143652   \n",
       "1        0.003056    0.019356               0.012225    0.192540   \n",
       "2        0.001045    0.015678               0.008362    0.168280   \n",
       "3        0.004200    0.009449               0.011549    0.107092   \n",
       "4        0.005222    0.015665               0.016709    0.130540   \n",
       "...           ...         ...                    ...         ...   \n",
       "6991     0.004217    0.010541               0.012650    0.084331   \n",
       "6992     0.005333    0.009599               0.022398    0.094925   \n",
       "6993     0.004249    0.008497               0.008497    0.129583   \n",
       "6994     0.005260    0.012624               0.014728    0.130447   \n",
       "6995     0.003147    0.010491               0.008393    0.110153   \n",
       "\n",
       "      home-shots_on_target  home-possession  home-opposition_shots  \\\n",
       "0                 0.070253         0.504354               0.122681   \n",
       "1                 0.090667         0.550114               0.070292   \n",
       "2                 0.075255         0.498567               0.077346   \n",
       "3                 0.049346         0.460917               0.139640   \n",
       "4                 0.065792         0.454280               0.159781   \n",
       "...                    ...              ...                    ...   \n",
       "6991              0.045328         0.436415               0.123335   \n",
       "6992              0.050129         0.417030               0.098125   \n",
       "6993              0.062667         0.476909               0.097719   \n",
       "6994              0.065223         0.557555               0.104147   \n",
       "6995              0.068190         0.568600               0.132184   \n",
       "\n",
       "      home-opposition_shots_on_target  home-opposition_possession  away-wins  \\\n",
       "0                            0.055573                    0.449829   0.008388   \n",
       "1                            0.036674                    0.375911   0.006112   \n",
       "2                            0.032402                    0.452578   0.002090   \n",
       "3                            0.080844                    0.494515   0.003150   \n",
       "4                            0.076236                    0.496053   0.004177   \n",
       "...                               ...                         ...        ...   \n",
       "6991                         0.063249                    0.521800   0.002108   \n",
       "6992                         0.049062                    0.553551   0.001067   \n",
       "6993                         0.053108                    0.489655   0.005311   \n",
       "6994                         0.052600                    0.399756   0.003156   \n",
       "6995                         0.056650                    0.386061   0.003147   \n",
       "\n",
       "      away-draws  away-losses  away-goals  away-opposition-goals  away-shots  \\\n",
       "0       0.002097     0.000000    0.015728               0.006291    0.168817   \n",
       "1       0.003056     0.001019    0.019356               0.008150    0.172165   \n",
       "2       0.002090     0.006271    0.009407               0.018814    0.137968   \n",
       "3       0.002100     0.005250    0.009449               0.016799    0.121791   \n",
       "4       0.003133     0.003133    0.013576               0.016709    0.107565   \n",
       "...          ...          ...         ...                    ...         ...   \n",
       "6991    0.004217     0.004217    0.010541               0.022137    0.125443   \n",
       "6992    0.004266     0.005333    0.007466               0.022398    0.110923   \n",
       "6993    0.002124     0.003186    0.015932               0.009559    0.089221   \n",
       "6994    0.003156     0.004208    0.011572               0.017884    0.108355   \n",
       "6995    0.002098     0.005245    0.013638               0.019932    0.119595   \n",
       "\n",
       "      away-shots_on_target  away-possession  away-opposition_shots  \\\n",
       "0                 0.081787         0.505402               0.075496   \n",
       "1                 0.096779         0.558263               0.115116   \n",
       "2                 0.064803         0.443171               0.145285   \n",
       "3                 0.056696         0.430469               0.137540   \n",
       "4                 0.053260         0.456369               0.144117   \n",
       "...                    ...              ...                    ...   \n",
       "6991              0.061140         0.410061               0.118064   \n",
       "6992              0.058661         0.447960               0.067194   \n",
       "6993              0.045673         0.525769               0.125335   \n",
       "6994              0.055755         0.460772               0.128343   \n",
       "6995              0.066092         0.487821               0.111202   \n",
       "\n",
       "      away-opposition_shots_on_target  away-opposition_possession  \\\n",
       "0                            0.031457                    0.448780   \n",
       "1                            0.059086                    0.368780   \n",
       "2                            0.074210                    0.507974   \n",
       "3                            0.067195                    0.524962   \n",
       "4                            0.079369                    0.493965   \n",
       "...                               ...                         ...   \n",
       "6991                         0.068519                    0.549208   \n",
       "6992                         0.027731                    0.522620   \n",
       "6993                         0.059481                    0.439734   \n",
       "6994                         0.056807                    0.496539   \n",
       "6995                         0.048258                    0.466840   \n",
       "\n",
       "      home_shot_accuracy  home_shot_efficiency  home_opposition_shot_accuracy  \\\n",
       "0               0.000513              0.000172                       0.000475   \n",
       "1               0.000480              0.000217                       0.000532   \n",
       "2               0.000467              0.000218                       0.000438   \n",
       "3               0.000484              0.000201                       0.000608   \n",
       "4               0.000526              0.000249                       0.000498   \n",
       "...                  ...                   ...                            ...   \n",
       "6991            0.000567              0.000245                       0.000541   \n",
       "6992            0.000563              0.000204                       0.000533   \n",
       "6993            0.000514              0.000144                       0.000577   \n",
       "6994            0.000526              0.000204                       0.000531   \n",
       "6995            0.000649              0.000161                       0.000450   \n",
       "\n",
       "      home_opposition_shot_efficiency  away_shot_accuracy  \\\n",
       "0                            0.000317            0.000508   \n",
       "1                            0.000340            0.000573   \n",
       "2                            0.000270            0.000491   \n",
       "3                            0.000150            0.000489   \n",
       "4                            0.000229            0.000517   \n",
       "...                               ...                 ...   \n",
       "6991                         0.000211            0.000514   \n",
       "6992                         0.000487            0.000564   \n",
       "6993                         0.000170            0.000544   \n",
       "6994                         0.000295            0.000541   \n",
       "6995                         0.000155            0.000580   \n",
       "\n",
       "      away_shot_efficiency  away_opposition_shot_accuracy  \\\n",
       "0                 0.000202                       0.000437   \n",
       "1                 0.000204                       0.000523   \n",
       "2                 0.000152                       0.000534   \n",
       "3                 0.000175                       0.000513   \n",
       "4                 0.000266                       0.000575   \n",
       "...                    ...                            ...   \n",
       "6991              0.000182                       0.000612   \n",
       "6992              0.000136                       0.000440   \n",
       "6993              0.000371                       0.000504   \n",
       "6994              0.000218                       0.000466   \n",
       "6995              0.000216                       0.000455   \n",
       "\n",
       "      away_opposition_shot_efficiency  \n",
       "0                            0.000210  \n",
       "1                            0.000141  \n",
       "2                            0.000265  \n",
       "3                            0.000262  \n",
       "4                            0.000220  \n",
       "...                               ...  \n",
       "6991                         0.000341  \n",
       "6992                         0.000861  \n",
       "6993                         0.000171  \n",
       "6994                         0.000331  \n",
       "6995                         0.000433  \n",
       "\n",
       "[6996 rows x 34 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter notebook\n",
    "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "shutil.rmtree(logdir, ignore_errors=True)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 128*8\n",
    "EPOCHS=10000\n",
    "validation_split = 0.2\n",
    "size_histories = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HtHfSEgO6sUN",
    "outputId": "b7fd6a48-30f1-470e-f92b-118a7046a09a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 78        \n",
      "=================================================================\n",
      "Total params: 1,378\n",
      "Trainable params: 1,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.4614,  loss:1.0771,  val_accuracy:0.4571,  val_loss:1.0747,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5199,  loss:0.9886,  val_accuracy:0.5128,  val_loss:0.9944,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5286,  loss:0.9809,  val_accuracy:0.5143,  val_loss:0.9870,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5309,  loss:0.9760,  val_accuracy:0.5180,  val_loss:0.9822,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5348,  loss:0.9732,  val_accuracy:0.5195,  val_loss:0.9801,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5361,  loss:0.9709,  val_accuracy:0.5233,  val_loss:0.9784,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5372,  loss:0.9694,  val_accuracy:0.5233,  val_loss:0.9776,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5348,  loss:0.9686,  val_accuracy:0.5263,  val_loss:0.9769,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5371,  loss:0.9667,  val_accuracy:0.5233,  val_loss:0.9764,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5395,  loss:0.9661,  val_accuracy:0.5286,  val_loss:0.9757,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5372,  loss:0.9655,  val_accuracy:0.5218,  val_loss:0.9752,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5397,  loss:0.9643,  val_accuracy:0.5308,  val_loss:0.9746,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5393,  loss:0.9640,  val_accuracy:0.5278,  val_loss:0.9743,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5388,  loss:0.9634,  val_accuracy:0.5308,  val_loss:0.9737,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5388,  loss:0.9627,  val_accuracy:0.5286,  val_loss:0.9740,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5382,  loss:0.9626,  val_accuracy:0.5301,  val_loss:0.9734,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5393,  loss:0.9623,  val_accuracy:0.5293,  val_loss:0.9733,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5401,  loss:0.9618,  val_accuracy:0.5293,  val_loss:0.9731,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5410,  loss:0.9615,  val_accuracy:0.5293,  val_loss:0.9738,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5380,  loss:0.9614,  val_accuracy:0.5248,  val_loss:0.9733,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5397,  loss:0.9607,  val_accuracy:0.5271,  val_loss:0.9729,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5380,  loss:0.9611,  val_accuracy:0.5241,  val_loss:0.9728,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5414,  loss:0.9604,  val_accuracy:0.5233,  val_loss:0.9728,  \n",
      "....................................................................Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 102       \n",
      "=================================================================\n",
      "Total params: 2,346\n",
      "Trainable params: 2,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.2972,  loss:1.0992,  val_accuracy:0.4947,  val_loss:1.0825,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5156,  loss:0.9922,  val_accuracy:0.5346,  val_loss:0.9853,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5181,  loss:0.9857,  val_accuracy:0.5391,  val_loss:0.9827,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5261,  loss:0.9810,  val_accuracy:0.5444,  val_loss:0.9738,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5256,  loss:0.9790,  val_accuracy:0.5489,  val_loss:0.9666,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5290,  loss:0.9750,  val_accuracy:0.5451,  val_loss:0.9673,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5292,  loss:0.9737,  val_accuracy:0.5459,  val_loss:0.9642,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5286,  loss:0.9726,  val_accuracy:0.5496,  val_loss:0.9614,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5305,  loss:0.9714,  val_accuracy:0.5526,  val_loss:0.9588,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5307,  loss:0.9701,  val_accuracy:0.5534,  val_loss:0.9590,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5303,  loss:0.9694,  val_accuracy:0.5549,  val_loss:0.9562,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5305,  loss:0.9687,  val_accuracy:0.5579,  val_loss:0.9576,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5322,  loss:0.9680,  val_accuracy:0.5586,  val_loss:0.9576,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5312,  loss:0.9682,  val_accuracy:0.5564,  val_loss:0.9553,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5324,  loss:0.9671,  val_accuracy:0.5571,  val_loss:0.9553,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5337,  loss:0.9669,  val_accuracy:0.5571,  val_loss:0.9569,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5320,  loss:0.9665,  val_accuracy:0.5541,  val_loss:0.9554,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5320,  loss:0.9665,  val_accuracy:0.5571,  val_loss:0.9563,  \n",
      "..........................................................Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 21)                462       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 12)                264       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 39        \n",
      "=================================================================\n",
      "Total params: 765\n",
      "Trainable params: 765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.3737,  loss:1.0886,  val_accuracy:0.4787,  val_loss:1.0808,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5228,  loss:0.9839,  val_accuracy:0.5228,  val_loss:0.9787,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5346,  loss:0.9759,  val_accuracy:0.5280,  val_loss:0.9706,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5352,  loss:0.9712,  val_accuracy:0.5288,  val_loss:0.9673,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5400,  loss:0.9684,  val_accuracy:0.5288,  val_loss:0.9656,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5419,  loss:0.9668,  val_accuracy:0.5280,  val_loss:0.9646,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5410,  loss:0.9657,  val_accuracy:0.5266,  val_loss:0.9638,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5415,  loss:0.9653,  val_accuracy:0.5243,  val_loss:0.9640,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5395,  loss:0.9657,  val_accuracy:0.5280,  val_loss:0.9647,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5414,  loss:0.9646,  val_accuracy:0.5243,  val_loss:0.9641,  \n",
      "...............Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4)                 56        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 253\n",
      "Trainable params: 253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.4178,  loss:1.0978,  val_accuracy:0.4658,  val_loss:1.0948,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5330,  loss:0.9717,  val_accuracy:0.5272,  val_loss:0.9744,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5328,  loss:0.9709,  val_accuracy:0.5274,  val_loss:0.9740,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5332,  loss:0.9708,  val_accuracy:0.5246,  val_loss:0.9740,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5323,  loss:0.9706,  val_accuracy:0.5257,  val_loss:0.9739,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5319,  loss:0.9704,  val_accuracy:0.5269,  val_loss:0.9741,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5326,  loss:0.9702,  val_accuracy:0.5259,  val_loss:0.9738,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5324,  loss:0.9700,  val_accuracy:0.5277,  val_loss:0.9741,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5329,  loss:0.9700,  val_accuracy:0.5269,  val_loss:0.9739,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5313,  loss:0.9702,  val_accuracy:0.5282,  val_loss:0.9743,  \n",
      "......................................................Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 90        \n",
      "=================================================================\n",
      "Total params: 2,700\n",
      "Trainable params: 2,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.3436,  loss:1.0986,  val_accuracy:0.4690,  val_loss:1.0862,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5266,  loss:0.9787,  val_accuracy:0.5415,  val_loss:0.9684,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5314,  loss:0.9702,  val_accuracy:0.5453,  val_loss:0.9617,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5348,  loss:0.9659,  val_accuracy:0.5482,  val_loss:0.9584,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5348,  loss:0.9630,  val_accuracy:0.5438,  val_loss:0.9583,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5344,  loss:0.9609,  val_accuracy:0.5482,  val_loss:0.9569,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5357,  loss:0.9600,  val_accuracy:0.5482,  val_loss:0.9576,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5365,  loss:0.9610,  val_accuracy:0.5453,  val_loss:0.9574,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5399,  loss:0.9572,  val_accuracy:0.5423,  val_loss:0.9577,  \n",
      "............................Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 13)                338       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 1,212\n",
      "Trainable params: 1,212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.4614,  loss:1.0921,  val_accuracy:0.4571,  val_loss:1.0891,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5222,  loss:0.9904,  val_accuracy:0.5143,  val_loss:0.9954,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5265,  loss:0.9858,  val_accuracy:0.5128,  val_loss:0.9899,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5284,  loss:0.9825,  val_accuracy:0.5173,  val_loss:0.9861,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5318,  loss:0.9801,  val_accuracy:0.5165,  val_loss:0.9832,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5320,  loss:0.9775,  val_accuracy:0.5158,  val_loss:0.9807,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5322,  loss:0.9761,  val_accuracy:0.5188,  val_loss:0.9786,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5337,  loss:0.9745,  val_accuracy:0.5173,  val_loss:0.9776,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5348,  loss:0.9745,  val_accuracy:0.5241,  val_loss:0.9775,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5344,  loss:0.9726,  val_accuracy:0.5195,  val_loss:0.9754,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5357,  loss:0.9719,  val_accuracy:0.5188,  val_loss:0.9748,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5344,  loss:0.9711,  val_accuracy:0.5211,  val_loss:0.9741,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5344,  loss:0.9710,  val_accuracy:0.5263,  val_loss:0.9749,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5357,  loss:0.9699,  val_accuracy:0.5278,  val_loss:0.9732,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5354,  loss:0.9696,  val_accuracy:0.5271,  val_loss:0.9731,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5357,  loss:0.9691,  val_accuracy:0.5256,  val_loss:0.9729,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5340,  loss:0.9687,  val_accuracy:0.5271,  val_loss:0.9724,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5363,  loss:0.9681,  val_accuracy:0.5271,  val_loss:0.9719,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5357,  loss:0.9684,  val_accuracy:0.5301,  val_loss:0.9716,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5357,  loss:0.9674,  val_accuracy:0.5301,  val_loss:0.9711,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5363,  loss:0.9669,  val_accuracy:0.5226,  val_loss:0.9710,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5371,  loss:0.9668,  val_accuracy:0.5248,  val_loss:0.9712,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5382,  loss:0.9664,  val_accuracy:0.5308,  val_loss:0.9710,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, accuracy:0.5369,  loss:0.9665,  val_accuracy:0.5368,  val_loss:0.9714,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, accuracy:0.5380,  loss:0.9659,  val_accuracy:0.5218,  val_loss:0.9709,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, accuracy:0.5389,  loss:0.9659,  val_accuracy:0.5218,  val_loss:0.9711,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, accuracy:0.5393,  loss:0.9659,  val_accuracy:0.5241,  val_loss:0.9708,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, accuracy:0.5389,  loss:0.9659,  val_accuracy:0.5241,  val_loss:0.9709,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, accuracy:0.5367,  loss:0.9655,  val_accuracy:0.5368,  val_loss:0.9708,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, accuracy:0.5408,  loss:0.9655,  val_accuracy:0.5248,  val_loss:0.9707,  \n",
      "....................................................................................................\n",
      "Epoch: 3000, accuracy:0.5397,  loss:0.9650,  val_accuracy:0.5241,  val_loss:0.9707,  \n",
      "....................................................................................................\n",
      "Epoch: 3100, accuracy:0.5403,  loss:0.9650,  val_accuracy:0.5256,  val_loss:0.9704,  \n",
      "....................................................................................................\n",
      "Epoch: 3200, accuracy:0.5399,  loss:0.9653,  val_accuracy:0.5346,  val_loss:0.9707,  \n",
      "............................................................Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 8)                 272       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 1,493\n",
      "Trainable params: 1,493\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.4511,  loss:1.0834,  val_accuracy:0.4947,  val_loss:1.0716,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5167,  loss:0.9905,  val_accuracy:0.5376,  val_loss:0.9800,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5243,  loss:0.9834,  val_accuracy:0.5459,  val_loss:0.9728,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5275,  loss:0.9785,  val_accuracy:0.5466,  val_loss:0.9688,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5265,  loss:0.9773,  val_accuracy:0.5519,  val_loss:0.9627,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5305,  loss:0.9735,  val_accuracy:0.5466,  val_loss:0.9649,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5309,  loss:0.9710,  val_accuracy:0.5571,  val_loss:0.9577,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5301,  loss:0.9704,  val_accuracy:0.5541,  val_loss:0.9582,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5324,  loss:0.9683,  val_accuracy:0.5564,  val_loss:0.9582,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5295,  loss:0.9682,  val_accuracy:0.5564,  val_loss:0.9576,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5329,  loss:0.9667,  val_accuracy:0.5526,  val_loss:0.9581,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5325,  loss:0.9666,  val_accuracy:0.5556,  val_loss:0.9547,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5333,  loss:0.9661,  val_accuracy:0.5549,  val_loss:0.9517,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5297,  loss:0.9660,  val_accuracy:0.5556,  val_loss:0.9535,  \n",
      "...................................................................................................Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 770\n",
      "Trainable params: 770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.4594,  loss:1.0781,  val_accuracy:0.4655,  val_loss:1.0680,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5328,  loss:0.9702,  val_accuracy:0.5267,  val_loss:0.9723,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5336,  loss:0.9693,  val_accuracy:0.5269,  val_loss:0.9733,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5303,  loss:0.9699,  val_accuracy:0.5294,  val_loss:0.9738,  \n",
      ".......................Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_29 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 13)                338       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 1,394\n",
      "Trainable params: 1,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.3845,  loss:1.0944,  val_accuracy:0.4571,  val_loss:1.0881,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5250,  loss:0.9847,  val_accuracy:0.5158,  val_loss:0.9895,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5337,  loss:0.9762,  val_accuracy:0.5203,  val_loss:0.9808,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5322,  loss:0.9725,  val_accuracy:0.5233,  val_loss:0.9780,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5363,  loss:0.9700,  val_accuracy:0.5233,  val_loss:0.9762,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5342,  loss:0.9680,  val_accuracy:0.5271,  val_loss:0.9751,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5335,  loss:0.9665,  val_accuracy:0.5271,  val_loss:0.9740,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5337,  loss:0.9653,  val_accuracy:0.5241,  val_loss:0.9736,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5352,  loss:0.9646,  val_accuracy:0.5316,  val_loss:0.9721,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5363,  loss:0.9711,  val_accuracy:0.5256,  val_loss:0.9720,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5363,  loss:0.9668,  val_accuracy:0.5301,  val_loss:0.9721,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5382,  loss:0.9632,  val_accuracy:0.5263,  val_loss:0.9717,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5386,  loss:0.9617,  val_accuracy:0.5241,  val_loss:0.9719,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5367,  loss:0.9616,  val_accuracy:0.5263,  val_loss:0.9723,  \n",
      "....................................................................Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 21)                462       \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 5)                 110       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 650\n",
      "Trainable params: 650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, accuracy:0.4603,  loss:1.0869,  val_accuracy:0.4622,  val_loss:1.0836,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5290,  loss:0.9837,  val_accuracy:0.5191,  val_loss:0.9799,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5339,  loss:0.9736,  val_accuracy:0.5258,  val_loss:0.9710,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5378,  loss:0.9677,  val_accuracy:0.5266,  val_loss:0.9676,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5421,  loss:0.9635,  val_accuracy:0.5258,  val_loss:0.9674,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5453,  loss:0.9609,  val_accuracy:0.5310,  val_loss:0.9680,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5442,  loss:0.9608,  val_accuracy:0.5251,  val_loss:0.9675,  \n",
      "............................Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 7)                 210       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 3)                 24        \n",
      "=================================================================\n",
      "Total params: 1,216\n",
      "Trainable params: 1,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.2820,  loss:1.1003,  val_accuracy:0.4705,  val_loss:1.0972,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.4579,  loss:1.0643,  val_accuracy:0.4690,  val_loss:1.0583,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.4579,  loss:1.0642,  val_accuracy:0.4690,  val_loss:1.0580,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.4579,  loss:1.0642,  val_accuracy:0.4690,  val_loss:1.0581,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.4579,  loss:1.0642,  val_accuracy:0.4690,  val_loss:1.0581,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.4579,  loss:1.0642,  val_accuracy:0.4690,  val_loss:1.0580,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.4579,  loss:1.0642,  val_accuracy:0.4690,  val_loss:1.0580,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.4579,  loss:1.0642,  val_accuracy:0.4690,  val_loss:1.0580,  \n",
      "................................................................................Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 25)                850       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 19)                494       \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 12)                240       \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 2,805\n",
      "Trainable params: 2,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.2835,  loss:1.1018,  val_accuracy:0.3947,  val_loss:1.0950,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5166,  loss:0.9901,  val_accuracy:0.5361,  val_loss:0.9822,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5256,  loss:0.9788,  val_accuracy:0.5459,  val_loss:0.9684,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5278,  loss:0.9755,  val_accuracy:0.5511,  val_loss:0.9638,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5307,  loss:0.9728,  val_accuracy:0.5474,  val_loss:0.9620,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5295,  loss:0.9718,  val_accuracy:0.5519,  val_loss:0.9602,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5305,  loss:0.9689,  val_accuracy:0.5466,  val_loss:0.9608,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5297,  loss:0.9688,  val_accuracy:0.5511,  val_loss:0.9575,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5305,  loss:0.9695,  val_accuracy:0.5444,  val_loss:0.9655,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5344,  loss:0.9659,  val_accuracy:0.5556,  val_loss:0.9574,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5320,  loss:0.9667,  val_accuracy:0.5586,  val_loss:0.9565,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5324,  loss:0.9668,  val_accuracy:0.5504,  val_loss:0.9589,  \n",
      "............Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 952\n",
      "Trainable params: 952\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.4582,  loss:1.0885,  val_accuracy:0.4658,  val_loss:1.0780,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5314,  loss:0.9703,  val_accuracy:0.5297,  val_loss:0.9731,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5339,  loss:0.9693,  val_accuracy:0.5264,  val_loss:0.9726,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5340,  loss:0.9690,  val_accuracy:0.5269,  val_loss:0.9728,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5331,  loss:0.9685,  val_accuracy:0.5272,  val_loss:0.9746,  \n",
      ".......Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_56 (Dense)             (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 3)                 90        \n",
      "=================================================================\n",
      "Total params: 4,440\n",
      "Trainable params: 4,440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.4289,  loss:1.0924,  val_accuracy:0.4690,  val_loss:1.0819,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5277,  loss:0.9794,  val_accuracy:0.5423,  val_loss:0.9685,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5326,  loss:0.9723,  val_accuracy:0.5467,  val_loss:0.9631,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5359,  loss:0.9664,  val_accuracy:0.5475,  val_loss:0.9569,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5365,  loss:0.9643,  val_accuracy:0.5490,  val_loss:0.9553,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5380,  loss:0.9645,  val_accuracy:0.5527,  val_loss:0.9553,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5346,  loss:0.9642,  val_accuracy:0.5438,  val_loss:0.9589,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5400,  loss:0.9608,  val_accuracy:0.5520,  val_loss:0.9547,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5385,  loss:0.9605,  val_accuracy:0.5542,  val_loss:0.9546,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5400,  loss:0.9595,  val_accuracy:0.5550,  val_loss:0.9547,  \n",
      ".......Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_62 (Dense)             (None, 21)                462       \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 5)                 110       \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 680\n",
      "Trainable params: 680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.4268,  loss:1.0976,  val_accuracy:0.4622,  val_loss:1.0954,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5256,  loss:0.9909,  val_accuracy:0.5213,  val_loss:0.9898,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5307,  loss:0.9784,  val_accuracy:0.5221,  val_loss:0.9762,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5354,  loss:0.9736,  val_accuracy:0.5228,  val_loss:0.9701,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5374,  loss:0.9702,  val_accuracy:0.5266,  val_loss:0.9667,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5380,  loss:0.9683,  val_accuracy:0.5273,  val_loss:0.9650,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5427,  loss:0.9669,  val_accuracy:0.5258,  val_loss:0.9656,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5427,  loss:0.9658,  val_accuracy:0.5228,  val_loss:0.9636,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5425,  loss:0.9655,  val_accuracy:0.5221,  val_loss:0.9630,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5427,  loss:0.9651,  val_accuracy:0.5221,  val_loss:0.9628,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5417,  loss:0.9651,  val_accuracy:0.5221,  val_loss:0.9628,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5432,  loss:0.9650,  val_accuracy:0.5243,  val_loss:0.9627,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5414,  loss:0.9643,  val_accuracy:0.5236,  val_loss:0.9628,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5442,  loss:0.9642,  val_accuracy:0.5280,  val_loss:0.9632,  \n",
      ".................................................................."
     ]
    }
   ],
   "source": [
    "##### Model04:\n",
    "\n",
    "model04_H1_H = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H1_H = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02_H1_M = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "##### Model01:\n",
    "\n",
    "model01_H1_L = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "### 2 Hidden Layers:\n",
    "#### High Amount of Neurons (H):\n",
    "\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H2_H = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04_H2_M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H2_L = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "### 3 Hidden Layers:\n",
    "#### High Amount of Neurons (H):\n",
    "##### Model01:\n",
    "\n",
    "model01_H3_H = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04_H3_M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02_H3_L = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H3_L = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "#### Funnel Architecture:\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05_H3_F = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(19, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "### 4 Hidden Layers:\n",
    "#### High Amount of Neurons (H):\n",
    "##### Model01:\n",
    "\n",
    "model01_H4_H = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03_H4_H = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02_H4_L = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# H1_H\n",
    "size_histories['model04_H1_H'] = compile_and_fit(model04_H1_H, 'model04_H1_H', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05_H1_H'] = compile_and_fit(model05_H1_H, 'model05_H1_H', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H1_M\n",
    "size_histories['model02_H1_M'] = compile_and_fit(model02_H1_M, 'model02_H1_M', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H1_L\n",
    "size_histories['model01_H1_L'] = compile_and_fit(model01_H1_L, 'model01_H1_L', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H2_H\n",
    "size_histories['model03_H2_H'] = compile_and_fit(model03_H2_H, 'model03_H2_H', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H2_M\n",
    "size_histories['model04_H2_M'] = compile_and_fit(model04_H2_M, 'model04_H2_M', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H2_L\n",
    "size_histories['model05_H2_L'] = compile_and_fit(model05_H2_L, 'model05_H2_L', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3_H\n",
    "size_histories['model01_H3_H'] = compile_and_fit(model01_H3_H, 'model01_H3_H', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3_M\n",
    "size_histories['model04_H3_M'] = compile_and_fit(model04_H3_M, 'model04_H3_M', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3_L\n",
    "size_histories['model02_H3_L'] = compile_and_fit(model02_H3_L, 'model02_H3_L', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03_H3_L'] = compile_and_fit(model03_H3_L, 'model03_H3_L', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3_F\n",
    "size_histories['model05_H3_F'] = compile_and_fit(model05_H3_F, 'model05_H3_F', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H4_H\n",
    "size_histories['model01_H4_H'] = compile_and_fit(model01_H4_H, 'model01_H4_H', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03_H4_H'] = compile_and_fit(model03_H4_H, 'model03_H4_H', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H4_L\n",
    "size_histories['model02_H4_L'] = compile_and_fit(model02_H4_L, 'model02_H4_L', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "1DwuhGCJH2yL",
    "outputId": "13ba4f8a-0516-4937-d37a-8b0130fc5a56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model04_H1_H\n",
      "Test Score: 0.9267910296576364\n",
      "Test Accuracy: 0.5714286\n",
      "#####\n",
      "model05_H1_H\n",
      "Test Score: 0.948808195250375\n",
      "Test Accuracy: 0.55142856\n",
      "#####\n",
      "model02_H1_M\n",
      "Test Score: 0.9566391381350431\n",
      "Test Accuracy: 0.5255682\n",
      "#####\n",
      "model01_H1_L\n",
      "Test Score: 0.9768726762791742\n",
      "Test Accuracy: 0.5268714\n",
      "#####\n",
      "model03_H2_H\n",
      "Test Score: 0.9630814303051342\n",
      "Test Accuracy: 0.54829544\n",
      "#####\n",
      "model04_H2_M\n",
      "Test Score: 0.9227963055883135\n",
      "Test Accuracy: 0.56285715\n",
      "#####\n",
      "model05_H2_L\n",
      "Test Score: 0.949548671586173\n",
      "Test Accuracy: 0.5371429\n",
      "#####\n",
      "model02_H3_H\n",
      "Test Score: 0.9746278024451975\n",
      "Test Accuracy: 0.5287908\n",
      "#####\n",
      "model04_H3_M\n",
      "Test Score: 0.9245155463899885\n",
      "Test Accuracy: 0.5714286\n",
      "#####\n",
      "model02_H3_L\n",
      "Test Score: 0.9613407308405096\n",
      "Test Accuracy: 0.51420456\n",
      "#####\n",
      "model03_H3_L\n",
      "Test Score: 1.056014429439198\n",
      "Test Accuracy: 0.4659091\n",
      "#####\n",
      "model05_H3_F\n",
      "Test Score: 0.9461135513441903\n",
      "Test Accuracy: 0.55142856\n",
      "#####\n",
      "model02_H4_H\n",
      "Test Score: 0.9729569659580882\n",
      "Test Accuracy: 0.53550863\n",
      "#####\n",
      "model03_H4_H\n",
      "Test Score: 0.9635824669491161\n",
      "Test Accuracy: 0.55397725\n",
      "#####\n",
      "model02_H4_L\n",
      "Test Score: 0.9568331241607666\n",
      "Test Accuracy: 0.52840906\n",
      "#####\n"
     ]
    }
   ],
   "source": [
    "# H1_H\n",
    "score = load_model('../model/model04_H1_H.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04_H1_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05_H1_H.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H1_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H1_M\n",
    "\n",
    "score = load_model('../model/model02_H1_M.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02_H1_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "\n",
    "# H1_L\n",
    "score = load_model('../model/model01_H1_L.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model01_H1_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "\n",
    "# H2_H\n",
    "\n",
    "\n",
    "score = load_model('../model/model03_H2_H.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H2_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "\n",
    "# H2_M\n",
    "\n",
    "\n",
    "score = load_model('../model/model04_H2_M.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04_H2_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H2_L\n",
    "\n",
    "score = load_model('../model/model05_H2_L.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H2_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H3_H\n",
    "score = load_model('../model/model01_H3_H.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model02_H3_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "\n",
    "# H3_M\n",
    "\n",
    "score = load_model('../model/model04_H3_M.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04_H3_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H3_L\n",
    "\n",
    "score = load_model('../model/model02_H3_L.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02_H3_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03_H3_L.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H3_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H3_F\n",
    "score = load_model('../model/model05_H3_F.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05_H3_F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H4_H\n",
    "score = load_model('../model/model01_H4_H.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model02_H4_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "\n",
    "score = load_model('../model/model03_H4_H.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03_H4_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H4_L\n",
    "\n",
    "score = load_model('../model/model02_H4_L.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02_H4_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add weight regularization: L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HtHfSEgO6sUN",
    "outputId": "b7fd6a48-30f1-470e-f92b-118a7046a09a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_68 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 3)                 78        \n",
      "=================================================================\n",
      "Total params: 1,378\n",
      "Trainable params: 1,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.2910,  loss:1.1607,  val_accuracy:0.2789,  val_loss:1.1524,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5182,  loss:1.0110,  val_accuracy:0.5075,  val_loss:1.0173,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5188,  loss:1.0063,  val_accuracy:0.5068,  val_loss:1.0135,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5199,  loss:1.0040,  val_accuracy:0.5120,  val_loss:1.0114,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5190,  loss:1.0024,  val_accuracy:0.5098,  val_loss:1.0101,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5179,  loss:1.0019,  val_accuracy:0.5090,  val_loss:1.0092,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5196,  loss:0.9999,  val_accuracy:0.5105,  val_loss:1.0080,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5198,  loss:0.9989,  val_accuracy:0.5098,  val_loss:1.0071,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5198,  loss:0.9981,  val_accuracy:0.5135,  val_loss:1.0066,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5201,  loss:0.9986,  val_accuracy:0.5128,  val_loss:1.0061,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5201,  loss:0.9968,  val_accuracy:0.5143,  val_loss:1.0054,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5205,  loss:0.9962,  val_accuracy:0.5150,  val_loss:1.0047,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5216,  loss:0.9959,  val_accuracy:0.5158,  val_loss:1.0040,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5224,  loss:0.9951,  val_accuracy:0.5143,  val_loss:1.0034,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5220,  loss:0.9953,  val_accuracy:0.5158,  val_loss:1.0038,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5220,  loss:0.9950,  val_accuracy:0.5105,  val_loss:1.0031,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5248,  loss:0.9937,  val_accuracy:0.5165,  val_loss:1.0022,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5228,  loss:0.9934,  val_accuracy:0.5120,  val_loss:1.0021,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5260,  loss:0.9948,  val_accuracy:0.5180,  val_loss:1.0024,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5220,  loss:0.9936,  val_accuracy:0.5120,  val_loss:1.0011,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5256,  loss:0.9922,  val_accuracy:0.5135,  val_loss:1.0006,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5271,  loss:0.9922,  val_accuracy:0.5165,  val_loss:1.0003,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5261,  loss:0.9916,  val_accuracy:0.5173,  val_loss:0.9995,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, accuracy:0.5254,  loss:0.9917,  val_accuracy:0.5165,  val_loss:0.9993,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, accuracy:0.5273,  loss:0.9913,  val_accuracy:0.5150,  val_loss:0.9990,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, accuracy:0.5260,  loss:0.9914,  val_accuracy:0.5150,  val_loss:0.9988,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, accuracy:0.5295,  loss:0.9906,  val_accuracy:0.5158,  val_loss:0.9984,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, accuracy:0.5288,  loss:0.9903,  val_accuracy:0.5150,  val_loss:0.9982,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, accuracy:0.5282,  loss:0.9902,  val_accuracy:0.5150,  val_loss:0.9979,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, accuracy:0.5273,  loss:0.9901,  val_accuracy:0.5158,  val_loss:0.9979,  \n",
      "....................................................................................................\n",
      "Epoch: 3000, accuracy:0.5295,  loss:0.9899,  val_accuracy:0.5165,  val_loss:0.9976,  \n",
      "....................................................................................................\n",
      "Epoch: 3100, accuracy:0.5258,  loss:0.9901,  val_accuracy:0.5165,  val_loss:0.9975,  \n",
      "....................................................................................................\n",
      "Epoch: 3200, accuracy:0.5292,  loss:0.9894,  val_accuracy:0.5150,  val_loss:0.9969,  \n",
      "....................................................................................................\n",
      "Epoch: 3300, accuracy:0.5275,  loss:0.9898,  val_accuracy:0.5135,  val_loss:0.9975,  \n",
      "....................................................................................................\n",
      "Epoch: 3400, accuracy:0.5265,  loss:0.9889,  val_accuracy:0.5180,  val_loss:0.9967,  \n",
      "....................................................................................................\n",
      "Epoch: 3500, accuracy:0.5297,  loss:0.9888,  val_accuracy:0.5135,  val_loss:0.9963,  \n",
      "....................................................................................................\n",
      "Epoch: 3600, accuracy:0.5290,  loss:0.9886,  val_accuracy:0.5173,  val_loss:0.9961,  \n",
      "....................................................................................................\n",
      "Epoch: 3700, accuracy:0.5299,  loss:0.9888,  val_accuracy:0.5203,  val_loss:0.9964,  \n",
      "....................................................................................................\n",
      "Epoch: 3800, accuracy:0.5307,  loss:0.9882,  val_accuracy:0.5195,  val_loss:0.9959,  \n",
      "....................................................................................................\n",
      "Epoch: 3900, accuracy:0.5299,  loss:0.9881,  val_accuracy:0.5203,  val_loss:0.9959,  \n",
      "....................................................................................................\n",
      "Epoch: 4000, accuracy:0.5290,  loss:0.9879,  val_accuracy:0.5188,  val_loss:0.9960,  \n",
      "....................................................................................................\n",
      "Epoch: 4100, accuracy:0.5292,  loss:0.9879,  val_accuracy:0.5188,  val_loss:0.9950,  \n",
      "....................................................................................................\n",
      "Epoch: 4200, accuracy:0.5310,  loss:0.9879,  val_accuracy:0.5195,  val_loss:0.9949,  \n",
      "....................................................................................................\n",
      "Epoch: 4300, accuracy:0.5305,  loss:0.9876,  val_accuracy:0.5203,  val_loss:0.9946,  \n",
      "....................................................................................................\n",
      "Epoch: 4400, accuracy:0.5292,  loss:0.9873,  val_accuracy:0.5173,  val_loss:0.9941,  \n",
      "....................................................................................................\n",
      "Epoch: 4500, accuracy:0.5286,  loss:0.9875,  val_accuracy:0.5203,  val_loss:0.9941,  \n",
      "....................................................................................................\n",
      "Epoch: 4600, accuracy:0.5278,  loss:0.9874,  val_accuracy:0.5158,  val_loss:0.9941,  \n",
      "....................................................................................................\n",
      "Epoch: 4700, accuracy:0.5305,  loss:0.9870,  val_accuracy:0.5165,  val_loss:0.9942,  \n",
      "....................................................................................................\n",
      "Epoch: 4800, accuracy:0.5290,  loss:0.9868,  val_accuracy:0.5180,  val_loss:0.9938,  \n",
      "....................................................................................................\n",
      "Epoch: 4900, accuracy:0.5305,  loss:0.9867,  val_accuracy:0.5165,  val_loss:0.9936,  \n",
      "....................................................................................................\n",
      "Epoch: 5000, accuracy:0.5301,  loss:0.9865,  val_accuracy:0.5203,  val_loss:0.9938,  \n",
      "....................................................................................................\n",
      "Epoch: 5100, accuracy:0.5310,  loss:0.9865,  val_accuracy:0.5173,  val_loss:0.9934,  \n",
      "....................................................................................................\n",
      "Epoch: 5200, accuracy:0.5307,  loss:0.9866,  val_accuracy:0.5188,  val_loss:0.9934,  \n",
      "....................................................................................................\n",
      "Epoch: 5300, accuracy:0.5293,  loss:0.9864,  val_accuracy:0.5180,  val_loss:0.9933,  \n",
      "....................................................................................................\n",
      "Epoch: 5400, accuracy:0.5303,  loss:0.9862,  val_accuracy:0.5248,  val_loss:0.9939,  \n",
      "....................................................................................................\n",
      "Epoch: 5500, accuracy:0.5292,  loss:0.9870,  val_accuracy:0.5165,  val_loss:0.9942,  \n",
      "....................................................................................................\n",
      "Epoch: 5600, accuracy:0.5324,  loss:0.9867,  val_accuracy:0.5218,  val_loss:0.9933,  \n",
      "....................................................................................................\n",
      "Epoch: 5700, accuracy:0.5324,  loss:0.9858,  val_accuracy:0.5158,  val_loss:0.9929,  \n",
      "....................................................................................................\n",
      "Epoch: 5800, accuracy:0.5318,  loss:0.9860,  val_accuracy:0.5188,  val_loss:0.9929,  \n",
      "....................................................................................................\n",
      "Epoch: 5900, accuracy:0.5301,  loss:0.9858,  val_accuracy:0.5180,  val_loss:0.9926,  \n",
      "....................................................................................................\n",
      "Epoch: 6000, accuracy:0.5312,  loss:0.9855,  val_accuracy:0.5158,  val_loss:0.9928,  \n",
      "....................................................................................................\n",
      "Epoch: 6100, accuracy:0.5322,  loss:0.9857,  val_accuracy:0.5188,  val_loss:0.9926,  \n",
      "....................................................................................................\n",
      "Epoch: 6200, accuracy:0.5320,  loss:0.9858,  val_accuracy:0.5180,  val_loss:0.9926,  \n",
      "................Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_71 (Dense)             (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 3)                 102       \n",
      "=================================================================\n",
      "Total params: 2,346\n",
      "Trainable params: 2,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.3503,  loss:1.1624,  val_accuracy:0.4947,  val_loss:1.1421,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5107,  loss:1.0145,  val_accuracy:0.5308,  val_loss:1.0040,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5150,  loss:1.0112,  val_accuracy:0.5316,  val_loss:1.0052,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5126,  loss:1.0098,  val_accuracy:0.5323,  val_loss:1.0044,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5124,  loss:1.0087,  val_accuracy:0.5301,  val_loss:0.9999,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5124,  loss:1.0067,  val_accuracy:0.5323,  val_loss:0.9969,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5128,  loss:1.0057,  val_accuracy:0.5293,  val_loss:0.9985,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5132,  loss:1.0049,  val_accuracy:0.5301,  val_loss:0.9966,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5130,  loss:1.0040,  val_accuracy:0.5338,  val_loss:0.9985,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5128,  loss:1.0037,  val_accuracy:0.5301,  val_loss:0.9957,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5149,  loss:1.0031,  val_accuracy:0.5376,  val_loss:0.9981,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5149,  loss:1.0023,  val_accuracy:0.5331,  val_loss:0.9947,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5149,  loss:1.0016,  val_accuracy:0.5346,  val_loss:0.9929,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5160,  loss:1.0009,  val_accuracy:0.5368,  val_loss:0.9939,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5164,  loss:1.0004,  val_accuracy:0.5376,  val_loss:0.9934,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5156,  loss:1.0000,  val_accuracy:0.5376,  val_loss:0.9926,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5188,  loss:1.0002,  val_accuracy:0.5391,  val_loss:0.9945,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5169,  loss:0.9991,  val_accuracy:0.5421,  val_loss:0.9905,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5158,  loss:0.9986,  val_accuracy:0.5391,  val_loss:0.9922,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5182,  loss:0.9989,  val_accuracy:0.5414,  val_loss:0.9926,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5182,  loss:0.9981,  val_accuracy:0.5444,  val_loss:0.9917,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5184,  loss:0.9975,  val_accuracy:0.5414,  val_loss:0.9896,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5188,  loss:0.9971,  val_accuracy:0.5429,  val_loss:0.9897,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, accuracy:0.5192,  loss:0.9971,  val_accuracy:0.5414,  val_loss:0.9874,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, accuracy:0.5198,  loss:0.9964,  val_accuracy:0.5436,  val_loss:0.9870,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, accuracy:0.5184,  loss:0.9962,  val_accuracy:0.5429,  val_loss:0.9897,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, accuracy:0.5190,  loss:0.9964,  val_accuracy:0.5451,  val_loss:0.9870,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, accuracy:0.5209,  loss:0.9957,  val_accuracy:0.5466,  val_loss:0.9897,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, accuracy:0.5190,  loss:0.9961,  val_accuracy:0.5451,  val_loss:0.9860,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, accuracy:0.5207,  loss:0.9953,  val_accuracy:0.5429,  val_loss:0.9862,  \n",
      "....................................................................................................\n",
      "Epoch: 3000, accuracy:0.5218,  loss:0.9950,  val_accuracy:0.5436,  val_loss:0.9873,  \n",
      "....................................................................................................\n",
      "Epoch: 3100, accuracy:0.5228,  loss:0.9949,  val_accuracy:0.5421,  val_loss:0.9869,  \n",
      "....................................................................................................\n",
      "Epoch: 3200, accuracy:0.5205,  loss:0.9946,  val_accuracy:0.5451,  val_loss:0.9855,  \n",
      "....................................................................................................\n",
      "Epoch: 3300, accuracy:0.5228,  loss:0.9947,  val_accuracy:0.5459,  val_loss:0.9875,  \n",
      "....................................................................................................\n",
      "Epoch: 3400, accuracy:0.5207,  loss:0.9941,  val_accuracy:0.5444,  val_loss:0.9856,  \n",
      "....................................................................................................\n",
      "Epoch: 3500, accuracy:0.5224,  loss:0.9940,  val_accuracy:0.5459,  val_loss:0.9857,  \n",
      "....................................................................................................\n",
      "Epoch: 3600, accuracy:0.5265,  loss:0.9945,  val_accuracy:0.5466,  val_loss:0.9871,  \n",
      "....................................................................................................\n",
      "Epoch: 3700, accuracy:0.5237,  loss:0.9935,  val_accuracy:0.5444,  val_loss:0.9862,  \n",
      "....................................................................................................\n",
      "Epoch: 3800, accuracy:0.5233,  loss:0.9935,  val_accuracy:0.5481,  val_loss:0.9853,  \n",
      "....................................................................................................\n",
      "Epoch: 3900, accuracy:0.5224,  loss:0.9934,  val_accuracy:0.5459,  val_loss:0.9861,  \n",
      "....................................................................................................\n",
      "Epoch: 4000, accuracy:0.5222,  loss:0.9932,  val_accuracy:0.5496,  val_loss:0.9847,  \n",
      "....................................................................................................\n",
      "Epoch: 4100, accuracy:0.5243,  loss:0.9933,  val_accuracy:0.5459,  val_loss:0.9866,  \n",
      "....................................................................................................\n",
      "Epoch: 4200, accuracy:0.5224,  loss:0.9928,  val_accuracy:0.5511,  val_loss:0.9845,  \n",
      "....................................................................................................\n",
      "Epoch: 4300, accuracy:0.5233,  loss:0.9930,  val_accuracy:0.5444,  val_loss:0.9828,  \n",
      "....................................................................................................\n",
      "Epoch: 4400, accuracy:0.5229,  loss:0.9925,  val_accuracy:0.5489,  val_loss:0.9852,  \n",
      "....................................................................................................\n",
      "Epoch: 4500, accuracy:0.5241,  loss:0.9929,  val_accuracy:0.5496,  val_loss:0.9856,  \n",
      "....................................................................................................\n",
      "Epoch: 4600, accuracy:0.5233,  loss:0.9923,  val_accuracy:0.5511,  val_loss:0.9834,  \n",
      "....................................................................................................\n",
      "Epoch: 4700, accuracy:0.5241,  loss:0.9921,  val_accuracy:0.5519,  val_loss:0.9838,  \n",
      "....................................................................................................\n",
      "Epoch: 4800, accuracy:0.5233,  loss:0.9922,  val_accuracy:0.5444,  val_loss:0.9821,  \n",
      "....................................................................................................\n",
      "Epoch: 4900, accuracy:0.5216,  loss:0.9923,  val_accuracy:0.5444,  val_loss:0.9814,  \n",
      "....................................................................................................\n",
      "Epoch: 5000, accuracy:0.5231,  loss:0.9919,  val_accuracy:0.5451,  val_loss:0.9817,  \n",
      "..................................Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_74 (Dense)             (None, 21)                462       \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 12)                264       \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 3)                 39        \n",
      "=================================================================\n",
      "Total params: 765\n",
      "Trainable params: 765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.2483,  loss:1.1473,  val_accuracy:0.2640,  val_loss:1.1372,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5217,  loss:1.0069,  val_accuracy:0.5153,  val_loss:1.0032,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5284,  loss:1.0000,  val_accuracy:0.5236,  val_loss:0.9953,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5292,  loss:0.9963,  val_accuracy:0.5243,  val_loss:0.9920,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5298,  loss:0.9943,  val_accuracy:0.5228,  val_loss:0.9897,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5294,  loss:0.9925,  val_accuracy:0.5236,  val_loss:0.9879,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5316,  loss:0.9912,  val_accuracy:0.5243,  val_loss:0.9868,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5327,  loss:0.9906,  val_accuracy:0.5228,  val_loss:0.9860,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5327,  loss:0.9893,  val_accuracy:0.5243,  val_loss:0.9858,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5335,  loss:0.9886,  val_accuracy:0.5251,  val_loss:0.9844,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5348,  loss:0.9881,  val_accuracy:0.5221,  val_loss:0.9836,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5346,  loss:0.9875,  val_accuracy:0.5236,  val_loss:0.9839,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5344,  loss:0.9873,  val_accuracy:0.5251,  val_loss:0.9827,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5339,  loss:0.9875,  val_accuracy:0.5251,  val_loss:0.9830,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5346,  loss:0.9862,  val_accuracy:0.5251,  val_loss:0.9820,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5337,  loss:0.9859,  val_accuracy:0.5251,  val_loss:0.9817,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5376,  loss:0.9853,  val_accuracy:0.5258,  val_loss:0.9812,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5327,  loss:0.9850,  val_accuracy:0.5258,  val_loss:0.9815,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5357,  loss:0.9848,  val_accuracy:0.5258,  val_loss:0.9809,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5357,  loss:0.9844,  val_accuracy:0.5266,  val_loss:0.9804,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5337,  loss:0.9845,  val_accuracy:0.5273,  val_loss:0.9803,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5348,  loss:0.9839,  val_accuracy:0.5280,  val_loss:0.9804,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5378,  loss:0.9837,  val_accuracy:0.5280,  val_loss:0.9797,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, accuracy:0.5371,  loss:0.9836,  val_accuracy:0.5288,  val_loss:0.9795,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, accuracy:0.5382,  loss:0.9834,  val_accuracy:0.5273,  val_loss:0.9796,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, accuracy:0.5350,  loss:0.9834,  val_accuracy:0.5303,  val_loss:0.9790,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, accuracy:0.5376,  loss:0.9827,  val_accuracy:0.5266,  val_loss:0.9797,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, accuracy:0.5387,  loss:0.9829,  val_accuracy:0.5295,  val_loss:0.9788,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, accuracy:0.5382,  loss:0.9827,  val_accuracy:0.5303,  val_loss:0.9786,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, accuracy:0.5363,  loss:0.9829,  val_accuracy:0.5280,  val_loss:0.9784,  \n",
      "....................................................................................................\n",
      "Epoch: 3000, accuracy:0.5376,  loss:0.9821,  val_accuracy:0.5280,  val_loss:0.9783,  \n",
      "....................................................................................................\n",
      "Epoch: 3100, accuracy:0.5378,  loss:0.9821,  val_accuracy:0.5280,  val_loss:0.9781,  \n",
      "....................................................................................................\n",
      "Epoch: 3200, accuracy:0.5387,  loss:0.9819,  val_accuracy:0.5266,  val_loss:0.9780,  \n",
      "....................................................................................................\n",
      "Epoch: 3300, accuracy:0.5359,  loss:0.9821,  val_accuracy:0.5295,  val_loss:0.9779,  \n",
      "....................................................................................................\n",
      "Epoch: 3400, accuracy:0.5376,  loss:0.9819,  val_accuracy:0.5273,  val_loss:0.9781,  \n",
      "....................................................................................................\n",
      "Epoch: 3500, accuracy:0.5372,  loss:0.9817,  val_accuracy:0.5295,  val_loss:0.9776,  \n",
      "....................................................................................................\n",
      "Epoch: 3600, accuracy:0.5376,  loss:0.9816,  val_accuracy:0.5288,  val_loss:0.9776,  \n",
      "....................................................................................................\n",
      "Epoch: 3700, accuracy:0.5389,  loss:0.9814,  val_accuracy:0.5280,  val_loss:0.9775,  \n",
      "....................................................................................................\n",
      "Epoch: 3800, accuracy:0.5357,  loss:0.9820,  val_accuracy:0.5266,  val_loss:0.9779,  \n",
      "....................................................................................................\n",
      "Epoch: 3900, accuracy:0.5367,  loss:0.9812,  val_accuracy:0.5288,  val_loss:0.9774,  \n",
      "....................................................................................................\n",
      "Epoch: 4000, accuracy:0.5380,  loss:0.9810,  val_accuracy:0.5288,  val_loss:0.9772,  \n",
      "....................................................................................................\n",
      "Epoch: 4100, accuracy:0.5372,  loss:0.9811,  val_accuracy:0.5288,  val_loss:0.9770,  \n",
      "....................................................................................................\n",
      "Epoch: 4200, accuracy:0.5393,  loss:0.9807,  val_accuracy:0.5295,  val_loss:0.9772,  \n",
      "....................................................................................................\n",
      "Epoch: 4300, accuracy:0.5397,  loss:0.9807,  val_accuracy:0.5288,  val_loss:0.9770,  \n",
      "....................................................................................................\n",
      "Epoch: 4400, accuracy:0.5406,  loss:0.9806,  val_accuracy:0.5273,  val_loss:0.9771,  \n",
      "....................................................................................................\n",
      "Epoch: 4500, accuracy:0.5384,  loss:0.9804,  val_accuracy:0.5318,  val_loss:0.9768,  \n",
      "....................................................................................................\n",
      "Epoch: 4600, accuracy:0.5397,  loss:0.9804,  val_accuracy:0.5236,  val_loss:0.9772,  \n",
      "....................................................................................................\n",
      "Epoch: 4700, accuracy:0.5391,  loss:0.9804,  val_accuracy:0.5258,  val_loss:0.9772,  \n",
      "....................................................................................................\n",
      "Epoch: 4800, accuracy:0.5400,  loss:0.9803,  val_accuracy:0.5251,  val_loss:0.9774,  \n",
      "....................................................................................................\n",
      "Epoch: 4900, accuracy:0.5400,  loss:0.9802,  val_accuracy:0.5295,  val_loss:0.9766,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 5000, accuracy:0.5384,  loss:0.9802,  val_accuracy:0.5295,  val_loss:0.9765,  \n",
      "....................................................................................................\n",
      "Epoch: 5100, accuracy:0.5408,  loss:0.9802,  val_accuracy:0.5266,  val_loss:0.9768,  \n",
      "....................................................................................................\n",
      "Epoch: 5200, accuracy:0.5391,  loss:0.9801,  val_accuracy:0.5303,  val_loss:0.9762,  \n",
      "....................................................................................................\n",
      "Epoch: 5300, accuracy:0.5389,  loss:0.9799,  val_accuracy:0.5280,  val_loss:0.9764,  \n",
      "....................................................................................................\n",
      "Epoch: 5400, accuracy:0.5399,  loss:0.9800,  val_accuracy:0.5266,  val_loss:0.9766,  \n",
      "....................................................................................................\n",
      "Epoch: 5500, accuracy:0.5382,  loss:0.9799,  val_accuracy:0.5303,  val_loss:0.9762,  \n",
      "....................................................................................................\n",
      "Epoch: 5600, accuracy:0.5389,  loss:0.9802,  val_accuracy:0.5273,  val_loss:0.9764,  \n",
      "....................................................................................................\n",
      "Epoch: 5700, accuracy:0.5376,  loss:0.9799,  val_accuracy:0.5280,  val_loss:0.9761,  \n",
      "....................................................................................................\n",
      "Epoch: 5800, accuracy:0.5380,  loss:0.9796,  val_accuracy:0.5288,  val_loss:0.9762,  \n",
      "....................................................................................................\n",
      "Epoch: 5900, accuracy:0.5378,  loss:0.9802,  val_accuracy:0.5318,  val_loss:0.9760,  \n",
      "....................................................................................................\n",
      "Epoch: 6000, accuracy:0.5378,  loss:0.9795,  val_accuracy:0.5280,  val_loss:0.9759,  \n",
      "....................................................................................................\n",
      "Epoch: 6100, accuracy:0.5400,  loss:0.9797,  val_accuracy:0.5273,  val_loss:0.9763,  \n",
      "................................................................Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_77 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 4)                 56        \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 253\n",
      "Trainable params: 253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.2526,  loss:1.2138,  val_accuracy:0.2497,  val_loss:1.1717,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5316,  loss:0.9877,  val_accuracy:0.5289,  val_loss:0.9887,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5325,  loss:0.9805,  val_accuracy:0.5274,  val_loss:0.9824,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5327,  loss:0.9786,  val_accuracy:0.5287,  val_loss:0.9804,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5338,  loss:0.9777,  val_accuracy:0.5282,  val_loss:0.9793,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5322,  loss:0.9770,  val_accuracy:0.5279,  val_loss:0.9790,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5325,  loss:0.9767,  val_accuracy:0.5264,  val_loss:0.9782,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5328,  loss:0.9763,  val_accuracy:0.5284,  val_loss:0.9780,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5331,  loss:0.9762,  val_accuracy:0.5277,  val_loss:0.9777,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5325,  loss:0.9762,  val_accuracy:0.5297,  val_loss:0.9776,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5336,  loss:0.9756,  val_accuracy:0.5272,  val_loss:0.9774,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5329,  loss:0.9756,  val_accuracy:0.5264,  val_loss:0.9772,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5327,  loss:0.9754,  val_accuracy:0.5277,  val_loss:0.9770,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5335,  loss:0.9751,  val_accuracy:0.5279,  val_loss:0.9769,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5336,  loss:0.9750,  val_accuracy:0.5282,  val_loss:0.9768,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5332,  loss:0.9750,  val_accuracy:0.5305,  val_loss:0.9770,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5329,  loss:0.9749,  val_accuracy:0.5269,  val_loss:0.9767,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5336,  loss:0.9748,  val_accuracy:0.5279,  val_loss:0.9766,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5332,  loss:0.9748,  val_accuracy:0.5277,  val_loss:0.9765,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5335,  loss:0.9746,  val_accuracy:0.5272,  val_loss:0.9765,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5331,  loss:0.9744,  val_accuracy:0.5279,  val_loss:0.9764,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5324,  loss:0.9747,  val_accuracy:0.5282,  val_loss:0.9767,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5327,  loss:0.9743,  val_accuracy:0.5277,  val_loss:0.9764,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, accuracy:0.5331,  loss:0.9744,  val_accuracy:0.5284,  val_loss:0.9765,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, accuracy:0.5339,  loss:0.9741,  val_accuracy:0.5282,  val_loss:0.9765,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, accuracy:0.5330,  loss:0.9742,  val_accuracy:0.5274,  val_loss:0.9764,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, accuracy:0.5334,  loss:0.9742,  val_accuracy:0.5264,  val_loss:0.9762,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, accuracy:0.5336,  loss:0.9740,  val_accuracy:0.5264,  val_loss:0.9762,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, accuracy:0.5336,  loss:0.9739,  val_accuracy:0.5284,  val_loss:0.9764,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, accuracy:0.5332,  loss:0.9740,  val_accuracy:0.5274,  val_loss:0.9761,  \n",
      "....................................................................................................\n",
      "Epoch: 3000, accuracy:0.5326,  loss:0.9739,  val_accuracy:0.5262,  val_loss:0.9761,  \n",
      "....................................................................................................\n",
      "Epoch: 3100, accuracy:0.5331,  loss:0.9737,  val_accuracy:0.5264,  val_loss:0.9764,  \n",
      "....................................................................................................\n",
      "Epoch: 3200, accuracy:0.5331,  loss:0.9738,  val_accuracy:0.5269,  val_loss:0.9764,  \n",
      "....................................................................................................\n",
      "Epoch: 3300, accuracy:0.5332,  loss:0.9739,  val_accuracy:0.5264,  val_loss:0.9760,  \n",
      "....................................................................................................\n",
      "Epoch: 3400, accuracy:0.5328,  loss:0.9737,  val_accuracy:0.5282,  val_loss:0.9761,  \n",
      "....................................................................................................\n",
      "Epoch: 3500, accuracy:0.5330,  loss:0.9737,  val_accuracy:0.5277,  val_loss:0.9762,  \n",
      "....................................................................................................\n",
      "Epoch: 3600, accuracy:0.5331,  loss:0.9737,  val_accuracy:0.5277,  val_loss:0.9761,  \n",
      "....................................................................................................\n",
      "Epoch: 3700, accuracy:0.5339,  loss:0.9736,  val_accuracy:0.5277,  val_loss:0.9760,  \n",
      "....................................................................................................\n",
      "Epoch: 3800, accuracy:0.5337,  loss:0.9737,  val_accuracy:0.5282,  val_loss:0.9760,  \n",
      "....................................................................................................\n",
      "Epoch: 3900, accuracy:0.5339,  loss:0.9735,  val_accuracy:0.5277,  val_loss:0.9760,  \n",
      "....................................................................................................\n",
      "Epoch: 4000, accuracy:0.5331,  loss:0.9736,  val_accuracy:0.5284,  val_loss:0.9761,  \n",
      "....................................................................................................\n",
      "Epoch: 4100, accuracy:0.5335,  loss:0.9735,  val_accuracy:0.5284,  val_loss:0.9761,  \n",
      "....................................................................................................\n",
      "Epoch: 4200, accuracy:0.5334,  loss:0.9735,  val_accuracy:0.5284,  val_loss:0.9760,  \n",
      "....................................................................................................\n",
      "Epoch: 4300, accuracy:0.5328,  loss:0.9736,  val_accuracy:0.5282,  val_loss:0.9758,  \n",
      "....................................................................................................\n",
      "Epoch: 4400, accuracy:0.5335,  loss:0.9734,  val_accuracy:0.5279,  val_loss:0.9759,  \n",
      "....................................................................................................\n",
      "Epoch: 4500, accuracy:0.5332,  loss:0.9734,  val_accuracy:0.5279,  val_loss:0.9759,  \n",
      "....................................................................................................\n",
      "Epoch: 4600, accuracy:0.5336,  loss:0.9734,  val_accuracy:0.5277,  val_loss:0.9758,  \n",
      "....................................................................................................\n",
      "Epoch: 4700, accuracy:0.5332,  loss:0.9733,  val_accuracy:0.5282,  val_loss:0.9758,  \n",
      "....................................................................................................\n",
      "Epoch: 4800, accuracy:0.5333,  loss:0.9737,  val_accuracy:0.5287,  val_loss:0.9760,  \n",
      "....................................................................................................\n",
      "Epoch: 4900, accuracy:0.5334,  loss:0.9733,  val_accuracy:0.5287,  val_loss:0.9758,  \n",
      "....................................................................................................\n",
      "Epoch: 5000, accuracy:0.5334,  loss:0.9734,  val_accuracy:0.5274,  val_loss:0.9758,  \n",
      "....................................................................................................\n",
      "Epoch: 5100, accuracy:0.5324,  loss:0.9734,  val_accuracy:0.5287,  val_loss:0.9758,  \n",
      "....................................................................................................\n",
      "Epoch: 5200, accuracy:0.5340,  loss:0.9733,  val_accuracy:0.5287,  val_loss:0.9757,  \n",
      "....................................................................................................\n",
      "Epoch: 5300, accuracy:0.5331,  loss:0.9733,  val_accuracy:0.5282,  val_loss:0.9759,  \n",
      "....................................................................................................\n",
      "Epoch: 5400, accuracy:0.5339,  loss:0.9733,  val_accuracy:0.5282,  val_loss:0.9757,  \n",
      "....................................................................................................\n",
      "Epoch: 5500, accuracy:0.5331,  loss:0.9734,  val_accuracy:0.5282,  val_loss:0.9759,  \n",
      "....................................................................................................\n",
      "Epoch: 5600, accuracy:0.5338,  loss:0.9732,  val_accuracy:0.5287,  val_loss:0.9757,  \n",
      "....................................................................................................\n",
      "Epoch: 5700, accuracy:0.5330,  loss:0.9732,  val_accuracy:0.5284,  val_loss:0.9757,  \n",
      "....................................................................................................\n",
      "Epoch: 5800, accuracy:0.5336,  loss:0.9731,  val_accuracy:0.5284,  val_loss:0.9757,  \n",
      "....................................................................................................\n",
      "Epoch: 5900, accuracy:0.5331,  loss:0.9732,  val_accuracy:0.5287,  val_loss:0.9757,  \n",
      "....................................................................................................\n",
      "Epoch: 6000, accuracy:0.5333,  loss:0.9731,  val_accuracy:0.5282,  val_loss:0.9757,  \n",
      "....................................................................................................\n",
      "Epoch: 6100, accuracy:0.5324,  loss:0.9732,  val_accuracy:0.5279,  val_loss:0.9756,  \n",
      "....................................................................................................Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_80 (Dense)             (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 3)                 90        \n",
      "=================================================================\n",
      "Total params: 2,700\n",
      "Trainable params: 2,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.3859,  loss:1.1793,  val_accuracy:0.4690,  val_loss:1.1658,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5230,  loss:1.0081,  val_accuracy:0.5348,  val_loss:0.9953,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5277,  loss:0.9980,  val_accuracy:0.5370,  val_loss:0.9881,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5269,  loss:0.9942,  val_accuracy:0.5423,  val_loss:0.9847,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5299,  loss:0.9923,  val_accuracy:0.5408,  val_loss:0.9821,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5309,  loss:0.9914,  val_accuracy:0.5393,  val_loss:0.9831,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5281,  loss:0.9885,  val_accuracy:0.5423,  val_loss:0.9815,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5339,  loss:0.9874,  val_accuracy:0.5438,  val_loss:0.9779,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5309,  loss:0.9869,  val_accuracy:0.5408,  val_loss:0.9776,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5339,  loss:0.9859,  val_accuracy:0.5438,  val_loss:0.9763,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5339,  loss:0.9855,  val_accuracy:0.5430,  val_loss:0.9765,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5348,  loss:0.9848,  val_accuracy:0.5445,  val_loss:0.9754,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5309,  loss:0.9852,  val_accuracy:0.5445,  val_loss:0.9750,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5324,  loss:0.9853,  val_accuracy:0.5423,  val_loss:0.9755,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5298,  loss:0.9849,  val_accuracy:0.5415,  val_loss:0.9749,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5299,  loss:0.9841,  val_accuracy:0.5445,  val_loss:0.9768,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5356,  loss:0.9827,  val_accuracy:0.5430,  val_loss:0.9737,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5337,  loss:0.9828,  val_accuracy:0.5445,  val_loss:0.9733,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5348,  loss:0.9822,  val_accuracy:0.5453,  val_loss:0.9730,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5357,  loss:0.9819,  val_accuracy:0.5475,  val_loss:0.9726,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5337,  loss:0.9841,  val_accuracy:0.5460,  val_loss:0.9725,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5326,  loss:0.9816,  val_accuracy:0.5453,  val_loss:0.9723,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5320,  loss:0.9820,  val_accuracy:0.5467,  val_loss:0.9721,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, accuracy:0.5318,  loss:0.9819,  val_accuracy:0.5482,  val_loss:0.9719,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, accuracy:0.5352,  loss:0.9810,  val_accuracy:0.5460,  val_loss:0.9719,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, accuracy:0.5339,  loss:0.9809,  val_accuracy:0.5482,  val_loss:0.9717,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, accuracy:0.5356,  loss:0.9806,  val_accuracy:0.5430,  val_loss:0.9719,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, accuracy:0.5371,  loss:0.9810,  val_accuracy:0.5475,  val_loss:0.9714,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, accuracy:0.5327,  loss:0.9809,  val_accuracy:0.5467,  val_loss:0.9712,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, accuracy:0.5344,  loss:0.9802,  val_accuracy:0.5475,  val_loss:0.9712,  \n",
      "....................................................................................................\n",
      "Epoch: 3000, accuracy:0.5335,  loss:0.9808,  val_accuracy:0.5497,  val_loss:0.9711,  \n",
      "....................................................................................................\n",
      "Epoch: 3100, accuracy:0.5344,  loss:0.9802,  val_accuracy:0.5497,  val_loss:0.9709,  \n",
      "....................................................................................................\n",
      "Epoch: 3200, accuracy:0.5339,  loss:0.9800,  val_accuracy:0.5490,  val_loss:0.9708,  \n",
      "....................................................................................................\n",
      "Epoch: 3300, accuracy:0.5369,  loss:0.9808,  val_accuracy:0.5475,  val_loss:0.9707,  \n",
      "....................................................................................................\n",
      "Epoch: 3400, accuracy:0.5371,  loss:0.9798,  val_accuracy:0.5415,  val_loss:0.9707,  \n",
      "....................................................................................................\n",
      "Epoch: 3500, accuracy:0.5314,  loss:0.9804,  val_accuracy:0.5430,  val_loss:0.9720,  \n",
      "....................................................................................................\n",
      "Epoch: 3600, accuracy:0.5344,  loss:0.9796,  val_accuracy:0.5475,  val_loss:0.9705,  \n",
      "..Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_84 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 13)                338       \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 1,212\n",
      "Trainable params: 1,212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.2910,  loss:1.1609,  val_accuracy:0.2789,  val_loss:1.1519,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5150,  loss:1.0125,  val_accuracy:0.5060,  val_loss:1.0192,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5162,  loss:1.0087,  val_accuracy:0.5105,  val_loss:1.0149,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5179,  loss:1.0058,  val_accuracy:0.5150,  val_loss:1.0126,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5196,  loss:1.0050,  val_accuracy:0.5158,  val_loss:1.0110,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5186,  loss:1.0028,  val_accuracy:0.5105,  val_loss:1.0101,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5207,  loss:1.0025,  val_accuracy:0.5113,  val_loss:1.0088,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5205,  loss:1.0015,  val_accuracy:0.5135,  val_loss:1.0083,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5228,  loss:1.0000,  val_accuracy:0.5105,  val_loss:1.0074,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5214,  loss:0.9990,  val_accuracy:0.5135,  val_loss:1.0063,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5203,  loss:0.9991,  val_accuracy:0.5083,  val_loss:1.0066,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5250,  loss:0.9978,  val_accuracy:0.5173,  val_loss:1.0046,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5258,  loss:0.9972,  val_accuracy:0.5173,  val_loss:1.0041,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5282,  loss:0.9967,  val_accuracy:0.5165,  val_loss:1.0036,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5261,  loss:0.9964,  val_accuracy:0.5135,  val_loss:1.0031,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5263,  loss:0.9955,  val_accuracy:0.5165,  val_loss:1.0019,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5293,  loss:0.9957,  val_accuracy:0.5165,  val_loss:1.0016,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5271,  loss:0.9948,  val_accuracy:0.5188,  val_loss:1.0012,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5299,  loss:0.9941,  val_accuracy:0.5165,  val_loss:1.0012,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5286,  loss:0.9944,  val_accuracy:0.5173,  val_loss:1.0007,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5286,  loss:0.9938,  val_accuracy:0.5158,  val_loss:1.0003,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5303,  loss:0.9935,  val_accuracy:0.5158,  val_loss:0.9999,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5303,  loss:0.9931,  val_accuracy:0.5158,  val_loss:0.9996,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, accuracy:0.5271,  loss:0.9935,  val_accuracy:0.5158,  val_loss:0.9992,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, accuracy:0.5310,  loss:0.9927,  val_accuracy:0.5158,  val_loss:0.9988,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, accuracy:0.5320,  loss:0.9927,  val_accuracy:0.5211,  val_loss:0.9992,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, accuracy:0.5299,  loss:0.9919,  val_accuracy:0.5165,  val_loss:0.9984,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, accuracy:0.5314,  loss:0.9916,  val_accuracy:0.5165,  val_loss:0.9980,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, accuracy:0.5309,  loss:0.9916,  val_accuracy:0.5173,  val_loss:0.9980,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, accuracy:0.5301,  loss:0.9917,  val_accuracy:0.5180,  val_loss:0.9976,  \n",
      "....................................................................................................\n",
      "Epoch: 3000, accuracy:0.5282,  loss:0.9918,  val_accuracy:0.5173,  val_loss:0.9975,  \n",
      "....................................................................................................\n",
      "Epoch: 3100, accuracy:0.5312,  loss:0.9912,  val_accuracy:0.5158,  val_loss:0.9972,  \n",
      "....................................................................................................\n",
      "Epoch: 3200, accuracy:0.5284,  loss:0.9917,  val_accuracy:0.5165,  val_loss:0.9971,  \n",
      "....................................................................................................\n",
      "Epoch: 3300, accuracy:0.5324,  loss:0.9905,  val_accuracy:0.5218,  val_loss:0.9977,  \n",
      "....................................................................................................\n",
      "Epoch: 3400, accuracy:0.5309,  loss:0.9909,  val_accuracy:0.5158,  val_loss:0.9972,  \n",
      "....................................................................................................\n",
      "Epoch: 3500, accuracy:0.5340,  loss:0.9906,  val_accuracy:0.5211,  val_loss:0.9971,  \n",
      "....................................................................................................\n",
      "Epoch: 3600, accuracy:0.5310,  loss:0.9901,  val_accuracy:0.5150,  val_loss:0.9964,  \n",
      "....................................................................................................\n",
      "Epoch: 3700, accuracy:0.5320,  loss:0.9901,  val_accuracy:0.5188,  val_loss:0.9963,  \n",
      "....................................................................................................\n",
      "Epoch: 3800, accuracy:0.5337,  loss:0.9900,  val_accuracy:0.5150,  val_loss:0.9962,  \n",
      "....................................................................................................\n",
      "Epoch: 3900, accuracy:0.5322,  loss:0.9899,  val_accuracy:0.5203,  val_loss:0.9964,  \n",
      "....................................................................................................\n",
      "Epoch: 4000, accuracy:0.5307,  loss:0.9902,  val_accuracy:0.5180,  val_loss:0.9959,  \n",
      "....................................................................................................\n",
      "Epoch: 4100, accuracy:0.5344,  loss:0.9891,  val_accuracy:0.5158,  val_loss:0.9965,  \n",
      "....................................................................................................\n",
      "Epoch: 4200, accuracy:0.5309,  loss:0.9909,  val_accuracy:0.5158,  val_loss:0.9964,  \n",
      "....................................................................................................\n",
      "Epoch: 4300, accuracy:0.5342,  loss:0.9894,  val_accuracy:0.5226,  val_loss:0.9960,  \n",
      "....................................................................................................\n",
      "Epoch: 4400, accuracy:0.5337,  loss:0.9896,  val_accuracy:0.5226,  val_loss:0.9957,  \n",
      "....................................................................................................\n",
      "Epoch: 4500, accuracy:0.5340,  loss:0.9899,  val_accuracy:0.5241,  val_loss:0.9960,  \n",
      "....................................................................................................\n",
      "Epoch: 4600, accuracy:0.5335,  loss:0.9891,  val_accuracy:0.5218,  val_loss:0.9956,  \n",
      "....................................................................................................\n",
      "Epoch: 4700, accuracy:0.5352,  loss:0.9888,  val_accuracy:0.5203,  val_loss:0.9954,  \n",
      "....................................................................................................\n",
      "Epoch: 4800, accuracy:0.5325,  loss:0.9887,  val_accuracy:0.5256,  val_loss:0.9955,  \n",
      "....................................................................................................\n",
      "Epoch: 4900, accuracy:0.5337,  loss:0.9887,  val_accuracy:0.5165,  val_loss:0.9949,  \n",
      "....................................................................................................\n",
      "Epoch: 5000, accuracy:0.5344,  loss:0.9885,  val_accuracy:0.5203,  val_loss:0.9949,  \n",
      "....................................................................................................\n",
      "Epoch: 5100, accuracy:0.5342,  loss:0.9884,  val_accuracy:0.5173,  val_loss:0.9948,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 5200, accuracy:0.5324,  loss:0.9885,  val_accuracy:0.5173,  val_loss:0.9947,  \n",
      "....................................................................................................\n",
      "Epoch: 5300, accuracy:0.5359,  loss:0.9883,  val_accuracy:0.5165,  val_loss:0.9946,  \n",
      "....................................................................................................\n",
      "Epoch: 5400, accuracy:0.5324,  loss:0.9886,  val_accuracy:0.5180,  val_loss:0.9945,  \n",
      "....................................................................................................\n",
      "Epoch: 5500, accuracy:0.5352,  loss:0.9881,  val_accuracy:0.5180,  val_loss:0.9944,  \n",
      "....................................................................................................\n",
      "Epoch: 5600, accuracy:0.5350,  loss:0.9881,  val_accuracy:0.5173,  val_loss:0.9944,  \n",
      "....................................................................................................\n",
      "Epoch: 5700, accuracy:0.5331,  loss:0.9884,  val_accuracy:0.5150,  val_loss:0.9944,  \n",
      ".........................................................Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_88 (Dense)             (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 8)                 272       \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 1,493\n",
      "Trainable params: 1,493\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.4511,  loss:1.0810,  val_accuracy:0.4947,  val_loss:1.0654,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5207,  loss:0.9942,  val_accuracy:0.5361,  val_loss:0.9833,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5245,  loss:0.9837,  val_accuracy:0.5489,  val_loss:0.9733,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5233,  loss:0.9807,  val_accuracy:0.5466,  val_loss:0.9683,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5288,  loss:0.9754,  val_accuracy:0.5436,  val_loss:0.9668,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5301,  loss:0.9728,  val_accuracy:0.5436,  val_loss:0.9644,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5314,  loss:0.9712,  val_accuracy:0.5496,  val_loss:0.9611,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5292,  loss:0.9726,  val_accuracy:0.5511,  val_loss:0.9583,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5339,  loss:0.9693,  val_accuracy:0.5519,  val_loss:0.9599,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5305,  loss:0.9682,  val_accuracy:0.5571,  val_loss:0.9566,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5335,  loss:0.9671,  val_accuracy:0.5586,  val_loss:0.9561,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5340,  loss:0.9666,  val_accuracy:0.5541,  val_loss:0.9557,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5352,  loss:0.9663,  val_accuracy:0.5549,  val_loss:0.9554,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5329,  loss:0.9662,  val_accuracy:0.5571,  val_loss:0.9543,  \n",
      "..............................................Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_92 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 770\n",
      "Trainable params: 770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.3620,  loss:1.1470,  val_accuracy:0.4655,  val_loss:1.1333,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5322,  loss:0.9868,  val_accuracy:0.5302,  val_loss:0.9889,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5317,  loss:0.9834,  val_accuracy:0.5269,  val_loss:0.9853,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5320,  loss:0.9816,  val_accuracy:0.5269,  val_loss:0.9841,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5330,  loss:0.9803,  val_accuracy:0.5279,  val_loss:0.9825,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5322,  loss:0.9794,  val_accuracy:0.5267,  val_loss:0.9822,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5327,  loss:0.9792,  val_accuracy:0.5257,  val_loss:0.9811,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5322,  loss:0.9795,  val_accuracy:0.5282,  val_loss:0.9807,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5337,  loss:0.9779,  val_accuracy:0.5259,  val_loss:0.9805,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5327,  loss:0.9776,  val_accuracy:0.5277,  val_loss:0.9800,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5332,  loss:0.9773,  val_accuracy:0.5287,  val_loss:0.9797,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5337,  loss:0.9772,  val_accuracy:0.5269,  val_loss:0.9799,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5332,  loss:0.9773,  val_accuracy:0.5284,  val_loss:0.9794,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5323,  loss:0.9770,  val_accuracy:0.5264,  val_loss:0.9800,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5329,  loss:0.9767,  val_accuracy:0.5279,  val_loss:0.9791,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5333,  loss:0.9766,  val_accuracy:0.5272,  val_loss:0.9791,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5333,  loss:0.9765,  val_accuracy:0.5282,  val_loss:0.9789,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5337,  loss:0.9765,  val_accuracy:0.5267,  val_loss:0.9790,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5315,  loss:0.9775,  val_accuracy:0.5267,  val_loss:0.9788,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5322,  loss:0.9762,  val_accuracy:0.5274,  val_loss:0.9789,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5324,  loss:0.9761,  val_accuracy:0.5269,  val_loss:0.9786,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5328,  loss:0.9762,  val_accuracy:0.5272,  val_loss:0.9785,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5324,  loss:0.9758,  val_accuracy:0.5274,  val_loss:0.9785,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, accuracy:0.5325,  loss:0.9760,  val_accuracy:0.5277,  val_loss:0.9785,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, accuracy:0.5325,  loss:0.9757,  val_accuracy:0.5262,  val_loss:0.9786,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, accuracy:0.5339,  loss:0.9756,  val_accuracy:0.5277,  val_loss:0.9784,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, accuracy:0.5327,  loss:0.9756,  val_accuracy:0.5262,  val_loss:0.9785,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, accuracy:0.5334,  loss:0.9755,  val_accuracy:0.5274,  val_loss:0.9782,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, accuracy:0.5327,  loss:0.9757,  val_accuracy:0.5264,  val_loss:0.9786,  \n",
      "......................................................................................Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_97 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 13)                338       \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 1,394\n",
      "Trainable params: 1,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.4569,  loss:1.1585,  val_accuracy:0.4571,  val_loss:1.1527,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5137,  loss:1.0149,  val_accuracy:0.5098,  val_loss:1.0203,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5182,  loss:1.0084,  val_accuracy:0.5090,  val_loss:1.0165,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5167,  loss:1.0070,  val_accuracy:0.5120,  val_loss:1.0152,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5182,  loss:1.0061,  val_accuracy:0.5150,  val_loss:1.0128,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5192,  loss:1.0041,  val_accuracy:0.5120,  val_loss:1.0117,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5196,  loss:1.0032,  val_accuracy:0.5135,  val_loss:1.0111,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5213,  loss:1.0025,  val_accuracy:0.5128,  val_loss:1.0098,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5196,  loss:1.0013,  val_accuracy:0.5135,  val_loss:1.0090,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5214,  loss:1.0006,  val_accuracy:0.5165,  val_loss:1.0083,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5233,  loss:0.9994,  val_accuracy:0.5150,  val_loss:1.0072,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5231,  loss:0.9992,  val_accuracy:0.5150,  val_loss:1.0061,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5250,  loss:0.9983,  val_accuracy:0.5173,  val_loss:1.0056,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5254,  loss:0.9972,  val_accuracy:0.5165,  val_loss:1.0046,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5269,  loss:0.9964,  val_accuracy:0.5165,  val_loss:1.0039,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5288,  loss:0.9958,  val_accuracy:0.5150,  val_loss:1.0032,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5284,  loss:0.9956,  val_accuracy:0.5173,  val_loss:1.0024,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5278,  loss:0.9943,  val_accuracy:0.5180,  val_loss:1.0019,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5301,  loss:0.9939,  val_accuracy:0.5150,  val_loss:1.0015,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5325,  loss:0.9938,  val_accuracy:0.5180,  val_loss:1.0012,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5280,  loss:0.9935,  val_accuracy:0.5165,  val_loss:1.0005,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5293,  loss:0.9929,  val_accuracy:0.5203,  val_loss:1.0003,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5303,  loss:0.9925,  val_accuracy:0.5173,  val_loss:0.9998,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, accuracy:0.5309,  loss:0.9926,  val_accuracy:0.5188,  val_loss:0.9994,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 2400, accuracy:0.5303,  loss:0.9919,  val_accuracy:0.5241,  val_loss:0.9998,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, accuracy:0.5314,  loss:0.9921,  val_accuracy:0.5211,  val_loss:0.9989,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, accuracy:0.5316,  loss:0.9921,  val_accuracy:0.5271,  val_loss:0.9994,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, accuracy:0.5320,  loss:0.9919,  val_accuracy:0.5203,  val_loss:0.9982,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, accuracy:0.5307,  loss:0.9913,  val_accuracy:0.5203,  val_loss:0.9980,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, accuracy:0.5320,  loss:0.9909,  val_accuracy:0.5226,  val_loss:0.9976,  \n",
      "....................................................................................................\n",
      "Epoch: 3000, accuracy:0.5295,  loss:0.9913,  val_accuracy:0.5226,  val_loss:0.9973,  \n",
      "....................................................................................................\n",
      "Epoch: 3100, accuracy:0.5327,  loss:0.9910,  val_accuracy:0.5271,  val_loss:0.9980,  \n",
      "....................................................................................................\n",
      "Epoch: 3200, accuracy:0.5310,  loss:0.9907,  val_accuracy:0.5218,  val_loss:0.9969,  \n",
      "....................................................................................................\n",
      "Epoch: 3300, accuracy:0.5322,  loss:0.9903,  val_accuracy:0.5218,  val_loss:0.9967,  \n",
      "....................................................................................................\n",
      "Epoch: 3400, accuracy:0.5309,  loss:0.9901,  val_accuracy:0.5211,  val_loss:0.9964,  \n",
      "....................................................................................................\n",
      "Epoch: 3500, accuracy:0.5322,  loss:0.9898,  val_accuracy:0.5173,  val_loss:0.9972,  \n",
      "....................................................................................................\n",
      "Epoch: 3600, accuracy:0.5324,  loss:0.9900,  val_accuracy:0.5233,  val_loss:0.9966,  \n",
      "....................................................................................................\n",
      "Epoch: 3700, accuracy:0.5288,  loss:0.9903,  val_accuracy:0.5218,  val_loss:0.9964,  \n",
      "....................................................................................................\n",
      "Epoch: 3800, accuracy:0.5307,  loss:0.9896,  val_accuracy:0.5195,  val_loss:0.9958,  \n",
      "....................................................................................................\n",
      "Epoch: 3900, accuracy:0.5312,  loss:0.9900,  val_accuracy:0.5218,  val_loss:0.9958,  \n",
      "....................................................................................................\n",
      "Epoch: 4000, accuracy:0.5331,  loss:0.9893,  val_accuracy:0.5218,  val_loss:0.9956,  \n",
      "....................................................................................................\n",
      "Epoch: 4100, accuracy:0.5320,  loss:0.9890,  val_accuracy:0.5278,  val_loss:0.9961,  \n",
      "....................................................................................................\n",
      "Epoch: 4200, accuracy:0.5312,  loss:0.9889,  val_accuracy:0.5211,  val_loss:0.9953,  \n",
      "....................................................................................................\n",
      "Epoch: 4300, accuracy:0.5324,  loss:0.9892,  val_accuracy:0.5218,  val_loss:0.9953,  \n",
      "....................................................................................................\n",
      "Epoch: 4400, accuracy:0.5325,  loss:0.9888,  val_accuracy:0.5203,  val_loss:0.9951,  \n",
      "....................................................................................................\n",
      "Epoch: 4500, accuracy:0.5325,  loss:0.9890,  val_accuracy:0.5323,  val_loss:0.9960,  \n",
      "....................................................................................................\n",
      "Epoch: 4600, accuracy:0.5339,  loss:0.9893,  val_accuracy:0.5323,  val_loss:0.9959,  \n",
      "....................................................................................................\n",
      "Epoch: 4700, accuracy:0.5337,  loss:0.9886,  val_accuracy:0.5211,  val_loss:0.9946,  \n",
      "....................................................................................................\n",
      "Epoch: 4800, accuracy:0.5327,  loss:0.9892,  val_accuracy:0.5308,  val_loss:0.9952,  \n",
      "....................................................................................................\n",
      "Epoch: 4900, accuracy:0.5327,  loss:0.9892,  val_accuracy:0.5203,  val_loss:0.9943,  \n",
      "....................................................................................................\n",
      "Epoch: 5000, accuracy:0.5325,  loss:0.9882,  val_accuracy:0.5241,  val_loss:0.9947,  \n",
      "....................................................................................................\n",
      "Epoch: 5100, accuracy:0.5335,  loss:0.9890,  val_accuracy:0.5188,  val_loss:0.9943,  \n",
      "....................................................................................................\n",
      "Epoch: 5200, accuracy:0.5337,  loss:0.9880,  val_accuracy:0.5226,  val_loss:0.9941,  \n",
      "....................................................................................................\n",
      "Epoch: 5300, accuracy:0.5340,  loss:0.9884,  val_accuracy:0.5248,  val_loss:0.9942,  \n",
      "..............Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_102 (Dense)            (None, 21)                462       \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 5)                 110       \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 650\n",
      "Trainable params: 650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.4603,  loss:1.1339,  val_accuracy:0.4622,  val_loss:1.1287,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5178,  loss:1.0118,  val_accuracy:0.5161,  val_loss:1.0089,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5271,  loss:1.0017,  val_accuracy:0.5198,  val_loss:0.9967,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5296,  loss:0.9963,  val_accuracy:0.5236,  val_loss:0.9913,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5286,  loss:0.9949,  val_accuracy:0.5236,  val_loss:0.9887,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5311,  loss:0.9921,  val_accuracy:0.5258,  val_loss:0.9863,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5342,  loss:0.9902,  val_accuracy:0.5243,  val_loss:0.9850,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5378,  loss:0.9891,  val_accuracy:0.5288,  val_loss:0.9838,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5363,  loss:0.9882,  val_accuracy:0.5258,  val_loss:0.9839,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5380,  loss:0.9878,  val_accuracy:0.5280,  val_loss:0.9828,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5339,  loss:0.9894,  val_accuracy:0.5258,  val_loss:0.9831,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5372,  loss:0.9870,  val_accuracy:0.5273,  val_loss:0.9820,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5395,  loss:0.9862,  val_accuracy:0.5273,  val_loss:0.9818,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5380,  loss:0.9860,  val_accuracy:0.5280,  val_loss:0.9808,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5397,  loss:0.9857,  val_accuracy:0.5288,  val_loss:0.9805,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5397,  loss:0.9857,  val_accuracy:0.5266,  val_loss:0.9809,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5391,  loss:0.9853,  val_accuracy:0.5273,  val_loss:0.9803,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5374,  loss:0.9852,  val_accuracy:0.5280,  val_loss:0.9803,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5393,  loss:0.9845,  val_accuracy:0.5303,  val_loss:0.9796,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5382,  loss:0.9848,  val_accuracy:0.5273,  val_loss:0.9794,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5387,  loss:0.9842,  val_accuracy:0.5266,  val_loss:0.9792,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5382,  loss:0.9846,  val_accuracy:0.5258,  val_loss:0.9793,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5397,  loss:0.9840,  val_accuracy:0.5266,  val_loss:0.9789,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, accuracy:0.5378,  loss:0.9845,  val_accuracy:0.5266,  val_loss:0.9790,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, accuracy:0.5382,  loss:0.9838,  val_accuracy:0.5243,  val_loss:0.9788,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, accuracy:0.5404,  loss:0.9836,  val_accuracy:0.5258,  val_loss:0.9787,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, accuracy:0.5400,  loss:0.9837,  val_accuracy:0.5273,  val_loss:0.9786,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, accuracy:0.5384,  loss:0.9837,  val_accuracy:0.5273,  val_loss:0.9786,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, accuracy:0.5402,  loss:0.9832,  val_accuracy:0.5258,  val_loss:0.9783,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, accuracy:0.5385,  loss:0.9833,  val_accuracy:0.5273,  val_loss:0.9796,  \n",
      "....................................................................................................\n",
      "Epoch: 3000, accuracy:0.5404,  loss:0.9831,  val_accuracy:0.5266,  val_loss:0.9782,  \n",
      "....................................................................................................\n",
      "Epoch: 3100, accuracy:0.5384,  loss:0.9841,  val_accuracy:0.5273,  val_loss:0.9781,  \n",
      "....................................................................................................\n",
      "Epoch: 3200, accuracy:0.5399,  loss:0.9829,  val_accuracy:0.5266,  val_loss:0.9780,  \n",
      "....................................................................................................\n",
      "Epoch: 3300, accuracy:0.5361,  loss:0.9834,  val_accuracy:0.5251,  val_loss:0.9785,  \n",
      "....................................................................................................\n",
      "Epoch: 3400, accuracy:0.5395,  loss:0.9828,  val_accuracy:0.5266,  val_loss:0.9779,  \n",
      "....................................................................................................\n",
      "Epoch: 3500, accuracy:0.5391,  loss:0.9829,  val_accuracy:0.5288,  val_loss:0.9777,  \n",
      "....................................................................................................\n",
      "Epoch: 3600, accuracy:0.5395,  loss:0.9829,  val_accuracy:0.5243,  val_loss:0.9781,  \n",
      "....................................................................................................\n",
      "Epoch: 3700, accuracy:0.5406,  loss:0.9825,  val_accuracy:0.5266,  val_loss:0.9777,  \n",
      "....................................................................................................\n",
      "Epoch: 3800, accuracy:0.5406,  loss:0.9827,  val_accuracy:0.5258,  val_loss:0.9777,  \n",
      "....................................................................................................\n",
      "Epoch: 3900, accuracy:0.5393,  loss:0.9828,  val_accuracy:0.5295,  val_loss:0.9786,  \n",
      "....................................................................................................\n",
      "Epoch: 4000, accuracy:0.5406,  loss:0.9826,  val_accuracy:0.5288,  val_loss:0.9774,  \n",
      "....................................................................................................\n",
      "Epoch: 4100, accuracy:0.5402,  loss:0.9829,  val_accuracy:0.5273,  val_loss:0.9780,  \n",
      "....................................................................................................\n",
      "Epoch: 4200, accuracy:0.5397,  loss:0.9822,  val_accuracy:0.5266,  val_loss:0.9780,  \n",
      "....................................................................................................\n",
      "Epoch: 4300, accuracy:0.5395,  loss:0.9826,  val_accuracy:0.5258,  val_loss:0.9775,  \n",
      "................................Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_107 (Dense)            (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 7)                 210       \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 3)                 24        \n",
      "=================================================================\n",
      "Total params: 1,216\n",
      "Trainable params: 1,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.4579,  loss:1.1447,  val_accuracy:0.4690,  val_loss:1.1355,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5208,  loss:1.0103,  val_accuracy:0.5340,  val_loss:0.9984,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5271,  loss:1.0008,  val_accuracy:0.5355,  val_loss:0.9919,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5260,  loss:0.9974,  val_accuracy:0.5438,  val_loss:0.9879,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5286,  loss:0.9952,  val_accuracy:0.5370,  val_loss:0.9868,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5296,  loss:0.9932,  val_accuracy:0.5497,  val_loss:0.9842,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5305,  loss:0.9926,  val_accuracy:0.5438,  val_loss:0.9831,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5318,  loss:0.9907,  val_accuracy:0.5438,  val_loss:0.9821,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5316,  loss:0.9901,  val_accuracy:0.5453,  val_loss:0.9815,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5331,  loss:0.9892,  val_accuracy:0.5460,  val_loss:0.9807,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5320,  loss:0.9913,  val_accuracy:0.5460,  val_loss:0.9803,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5337,  loss:0.9886,  val_accuracy:0.5460,  val_loss:0.9800,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5324,  loss:0.9881,  val_accuracy:0.5453,  val_loss:0.9795,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5316,  loss:0.9883,  val_accuracy:0.5453,  val_loss:0.9800,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5320,  loss:0.9871,  val_accuracy:0.5423,  val_loss:0.9792,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5311,  loss:0.9874,  val_accuracy:0.5475,  val_loss:0.9785,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5316,  loss:0.9870,  val_accuracy:0.5460,  val_loss:0.9781,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5327,  loss:0.9866,  val_accuracy:0.5393,  val_loss:0.9786,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5331,  loss:0.9863,  val_accuracy:0.5423,  val_loss:0.9780,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5339,  loss:0.9859,  val_accuracy:0.5460,  val_loss:0.9774,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5333,  loss:0.9861,  val_accuracy:0.5475,  val_loss:0.9773,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5326,  loss:0.9854,  val_accuracy:0.5408,  val_loss:0.9777,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5305,  loss:0.9864,  val_accuracy:0.5460,  val_loss:0.9771,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, accuracy:0.5333,  loss:0.9853,  val_accuracy:0.5482,  val_loss:0.9769,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, accuracy:0.5339,  loss:0.9853,  val_accuracy:0.5482,  val_loss:0.9767,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, accuracy:0.5294,  loss:0.9856,  val_accuracy:0.5393,  val_loss:0.9771,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, accuracy:0.5356,  loss:0.9850,  val_accuracy:0.5393,  val_loss:0.9770,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, accuracy:0.5346,  loss:0.9855,  val_accuracy:0.5453,  val_loss:0.9764,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, accuracy:0.5335,  loss:0.9845,  val_accuracy:0.5497,  val_loss:0.9762,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, accuracy:0.5314,  loss:0.9843,  val_accuracy:0.5467,  val_loss:0.9762,  \n",
      "....................................................................................................\n",
      "Epoch: 3000, accuracy:0.5331,  loss:0.9841,  val_accuracy:0.5497,  val_loss:0.9759,  \n",
      "....................................................................................................\n",
      "Epoch: 3100, accuracy:0.5316,  loss:0.9859,  val_accuracy:0.5482,  val_loss:0.9757,  \n",
      "....................................................................................................\n",
      "Epoch: 3200, accuracy:0.5311,  loss:0.9841,  val_accuracy:0.5438,  val_loss:0.9760,  \n",
      "....................................................................................................\n",
      "Epoch: 3300, accuracy:0.5312,  loss:0.9840,  val_accuracy:0.5415,  val_loss:0.9758,  \n",
      "....................................................................................................\n",
      "Epoch: 3400, accuracy:0.5350,  loss:0.9836,  val_accuracy:0.5400,  val_loss:0.9758,  \n",
      "....................................................................................................\n",
      "Epoch: 3500, accuracy:0.5322,  loss:0.9843,  val_accuracy:0.5520,  val_loss:0.9754,  \n",
      "....................................................................................................\n",
      "Epoch: 3600, accuracy:0.5352,  loss:0.9837,  val_accuracy:0.5393,  val_loss:0.9769,  \n",
      "....................................................................................................\n",
      "Epoch: 3700, accuracy:0.5331,  loss:0.9835,  val_accuracy:0.5400,  val_loss:0.9759,  \n",
      "....................................................................................................\n",
      "Epoch: 3800, accuracy:0.5354,  loss:0.9835,  val_accuracy:0.5423,  val_loss:0.9763,  \n",
      "....................................................................................................\n",
      "Epoch: 3900, accuracy:0.5339,  loss:0.9832,  val_accuracy:0.5415,  val_loss:0.9763,  \n",
      "....................................................................................................\n",
      "Epoch: 4000, accuracy:0.5350,  loss:0.9832,  val_accuracy:0.5520,  val_loss:0.9749,  \n",
      "....................................................................................................\n",
      "Epoch: 4100, accuracy:0.5342,  loss:0.9830,  val_accuracy:0.5512,  val_loss:0.9746,  \n",
      "....................................................................................................\n",
      "Epoch: 4200, accuracy:0.5342,  loss:0.9830,  val_accuracy:0.5445,  val_loss:0.9748,  \n",
      "....................................................................................................\n",
      "Epoch: 4300, accuracy:0.5320,  loss:0.9830,  val_accuracy:0.5535,  val_loss:0.9746,  \n",
      "....................................................................................................\n",
      "Epoch: 4400, accuracy:0.5337,  loss:0.9834,  val_accuracy:0.5423,  val_loss:0.9754,  \n",
      "....................................................................................................\n",
      "Epoch: 4500, accuracy:0.5352,  loss:0.9830,  val_accuracy:0.5423,  val_loss:0.9756,  \n",
      "....................................................................................................\n",
      "Epoch: 4600, accuracy:0.5326,  loss:0.9836,  val_accuracy:0.5475,  val_loss:0.9744,  \n",
      "....................................................................................................\n",
      "Epoch: 4700, accuracy:0.5341,  loss:0.9826,  val_accuracy:0.5475,  val_loss:0.9744,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 4800, accuracy:0.5326,  loss:0.9824,  val_accuracy:0.5445,  val_loss:0.9744,  \n",
      "......................................................Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_112 (Dense)            (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 25)                850       \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 19)                494       \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 12)                240       \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 2,805\n",
      "Trainable params: 2,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.4073,  loss:1.2023,  val_accuracy:0.4947,  val_loss:1.1962,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5135,  loss:1.0260,  val_accuracy:0.5271,  val_loss:1.0130,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5141,  loss:1.0168,  val_accuracy:0.5331,  val_loss:1.0091,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5152,  loss:1.0131,  val_accuracy:0.5331,  val_loss:1.0039,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5166,  loss:1.0104,  val_accuracy:0.5383,  val_loss:1.0000,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5169,  loss:1.0081,  val_accuracy:0.5406,  val_loss:0.9982,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5169,  loss:1.0068,  val_accuracy:0.5444,  val_loss:0.9972,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5245,  loss:1.0054,  val_accuracy:0.5429,  val_loss:0.9963,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5252,  loss:1.0052,  val_accuracy:0.5436,  val_loss:0.9939,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5239,  loss:1.0025,  val_accuracy:0.5459,  val_loss:0.9912,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5220,  loss:1.0016,  val_accuracy:0.5459,  val_loss:0.9929,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5250,  loss:1.0000,  val_accuracy:0.5496,  val_loss:0.9902,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5235,  loss:1.0001,  val_accuracy:0.5466,  val_loss:0.9908,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5254,  loss:0.9984,  val_accuracy:0.5526,  val_loss:0.9885,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5286,  loss:0.9989,  val_accuracy:0.5549,  val_loss:0.9874,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5261,  loss:0.9974,  val_accuracy:0.5534,  val_loss:0.9871,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5248,  loss:0.9984,  val_accuracy:0.5489,  val_loss:0.9910,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5263,  loss:0.9966,  val_accuracy:0.5489,  val_loss:0.9870,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5271,  loss:0.9961,  val_accuracy:0.5519,  val_loss:0.9886,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5280,  loss:0.9956,  val_accuracy:0.5504,  val_loss:0.9856,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5284,  loss:0.9954,  val_accuracy:0.5526,  val_loss:0.9863,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5271,  loss:0.9969,  val_accuracy:0.5489,  val_loss:0.9839,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5280,  loss:0.9946,  val_accuracy:0.5489,  val_loss:0.9838,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, accuracy:0.5288,  loss:0.9945,  val_accuracy:0.5526,  val_loss:0.9854,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, accuracy:0.5286,  loss:0.9941,  val_accuracy:0.5511,  val_loss:0.9839,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, accuracy:0.5275,  loss:0.9951,  val_accuracy:0.5511,  val_loss:0.9836,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, accuracy:0.5269,  loss:0.9937,  val_accuracy:0.5504,  val_loss:0.9825,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, accuracy:0.5260,  loss:0.9959,  val_accuracy:0.5496,  val_loss:0.9845,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, accuracy:0.5301,  loss:0.9935,  val_accuracy:0.5489,  val_loss:0.9857,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, accuracy:0.5301,  loss:0.9930,  val_accuracy:0.5519,  val_loss:0.9819,  \n",
      "....................................................................................................\n",
      "Epoch: 3000, accuracy:0.5286,  loss:0.9932,  val_accuracy:0.5504,  val_loss:0.9811,  \n",
      "....................................................................................................\n",
      "Epoch: 3100, accuracy:0.5288,  loss:0.9931,  val_accuracy:0.5504,  val_loss:0.9829,  \n",
      "....................................................................................................\n",
      "Epoch: 3200, accuracy:0.5284,  loss:0.9926,  val_accuracy:0.5504,  val_loss:0.9825,  \n",
      "....................................................................................................\n",
      "Epoch: 3300, accuracy:0.5295,  loss:0.9925,  val_accuracy:0.5511,  val_loss:0.9822,  \n",
      "....................................................................................................\n",
      "Epoch: 3400, accuracy:0.5282,  loss:0.9946,  val_accuracy:0.5534,  val_loss:0.9831,  \n",
      "....................................................................................................\n",
      "Epoch: 3500, accuracy:0.5290,  loss:0.9932,  val_accuracy:0.5519,  val_loss:0.9846,  \n",
      "....................................................................................................\n",
      "Epoch: 3600, accuracy:0.5293,  loss:0.9922,  val_accuracy:0.5504,  val_loss:0.9808,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 3700, accuracy:0.5293,  loss:0.9920,  val_accuracy:0.5519,  val_loss:0.9800,  \n",
      "....................................................................................................\n",
      "Epoch: 3800, accuracy:0.5267,  loss:0.9928,  val_accuracy:0.5504,  val_loss:0.9816,  \n",
      "....................................................................................................\n",
      "Epoch: 3900, accuracy:0.5277,  loss:0.9916,  val_accuracy:0.5466,  val_loss:0.9859,  \n",
      "....................................................................................................\n",
      "Epoch: 4000, accuracy:0.5292,  loss:0.9918,  val_accuracy:0.5504,  val_loss:0.9836,  \n",
      "....................................................................................................\n",
      "Epoch: 4100, accuracy:0.5295,  loss:0.9921,  val_accuracy:0.5481,  val_loss:0.9836,  \n",
      "....................................................................................................\n",
      "Epoch: 4200, accuracy:0.5307,  loss:0.9916,  val_accuracy:0.5511,  val_loss:0.9820,  \n",
      "....................................................................................................\n",
      "Epoch: 4300, accuracy:0.5299,  loss:0.9911,  val_accuracy:0.5511,  val_loss:0.9809,  \n",
      "....................................................................................................\n",
      "Epoch: 4400, accuracy:0.5288,  loss:0.9915,  val_accuracy:0.5534,  val_loss:0.9822,  \n",
      ".....................Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_118 (Dense)            (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 952\n",
      "Trainable params: 952\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.4557,  loss:1.1435,  val_accuracy:0.4655,  val_loss:1.1294,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5337,  loss:0.9894,  val_accuracy:0.5277,  val_loss:0.9914,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5331,  loss:0.9851,  val_accuracy:0.5264,  val_loss:0.9871,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5333,  loss:0.9833,  val_accuracy:0.5251,  val_loss:0.9847,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5319,  loss:0.9815,  val_accuracy:0.5262,  val_loss:0.9835,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5322,  loss:0.9807,  val_accuracy:0.5262,  val_loss:0.9825,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5308,  loss:0.9803,  val_accuracy:0.5267,  val_loss:0.9817,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5323,  loss:0.9797,  val_accuracy:0.5254,  val_loss:0.9813,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5327,  loss:0.9792,  val_accuracy:0.5277,  val_loss:0.9821,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5331,  loss:0.9788,  val_accuracy:0.5257,  val_loss:0.9808,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5313,  loss:0.9795,  val_accuracy:0.5289,  val_loss:0.9813,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5321,  loss:0.9788,  val_accuracy:0.5244,  val_loss:0.9804,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5348,  loss:0.9783,  val_accuracy:0.5251,  val_loss:0.9802,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5325,  loss:0.9778,  val_accuracy:0.5279,  val_loss:0.9803,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5332,  loss:0.9776,  val_accuracy:0.5272,  val_loss:0.9801,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5331,  loss:0.9775,  val_accuracy:0.5294,  val_loss:0.9803,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5322,  loss:0.9782,  val_accuracy:0.5239,  val_loss:0.9797,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5325,  loss:0.9775,  val_accuracy:0.5254,  val_loss:0.9797,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5334,  loss:0.9771,  val_accuracy:0.5297,  val_loss:0.9800,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5336,  loss:0.9769,  val_accuracy:0.5244,  val_loss:0.9795,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5313,  loss:0.9775,  val_accuracy:0.5244,  val_loss:0.9794,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5339,  loss:0.9767,  val_accuracy:0.5282,  val_loss:0.9795,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5327,  loss:0.9767,  val_accuracy:0.5259,  val_loss:0.9792,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, accuracy:0.5332,  loss:0.9767,  val_accuracy:0.5249,  val_loss:0.9792,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, accuracy:0.5336,  loss:0.9765,  val_accuracy:0.5272,  val_loss:0.9792,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, accuracy:0.5339,  loss:0.9764,  val_accuracy:0.5262,  val_loss:0.9791,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, accuracy:0.5340,  loss:0.9763,  val_accuracy:0.5246,  val_loss:0.9791,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, accuracy:0.5332,  loss:0.9765,  val_accuracy:0.5246,  val_loss:0.9795,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, accuracy:0.5340,  loss:0.9761,  val_accuracy:0.5264,  val_loss:0.9790,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, accuracy:0.5343,  loss:0.9763,  val_accuracy:0.5246,  val_loss:0.9794,  \n",
      "....................................................................................................\n",
      "Epoch: 3000, accuracy:0.5341,  loss:0.9765,  val_accuracy:0.5206,  val_loss:0.9821,  \n",
      "....................................................................................................\n",
      "Epoch: 3100, accuracy:0.5341,  loss:0.9765,  val_accuracy:0.5259,  val_loss:0.9803,  \n",
      "....................................................................................................\n",
      "Epoch: 3200, accuracy:0.5336,  loss:0.9759,  val_accuracy:0.5259,  val_loss:0.9792,  \n",
      "....................................................................................................\n",
      "Epoch: 3300, accuracy:0.5331,  loss:0.9764,  val_accuracy:0.5272,  val_loss:0.9790,  \n",
      "....................................................................................................\n",
      "Epoch: 3400, accuracy:0.5338,  loss:0.9759,  val_accuracy:0.5264,  val_loss:0.9792,  \n",
      "....................................................................................................\n",
      "Epoch: 3500, accuracy:0.5337,  loss:0.9765,  val_accuracy:0.5264,  val_loss:0.9791,  \n",
      "....................................................................................................\n",
      "Epoch: 3600, accuracy:0.5324,  loss:0.9760,  val_accuracy:0.5254,  val_loss:0.9795,  \n",
      "....................................................................................................\n",
      "Epoch: 3700, accuracy:0.5343,  loss:0.9757,  val_accuracy:0.5259,  val_loss:0.9789,  \n",
      "....................................................................................................\n",
      "Epoch: 3800, accuracy:0.5325,  loss:0.9760,  val_accuracy:0.5264,  val_loss:0.9789,  \n",
      "....................................................................................................\n",
      "Epoch: 3900, accuracy:0.5337,  loss:0.9756,  val_accuracy:0.5264,  val_loss:0.9790,  \n",
      "....................................................................................................\n",
      "Epoch: 4000, accuracy:0.5333,  loss:0.9756,  val_accuracy:0.5249,  val_loss:0.9800,  \n",
      "....................................................................................................\n",
      "Epoch: 4100, accuracy:0.5331,  loss:0.9757,  val_accuracy:0.5259,  val_loss:0.9790,  \n",
      "....................................................................................................\n",
      "Epoch: 4200, accuracy:0.5334,  loss:0.9755,  val_accuracy:0.5254,  val_loss:0.9792,  \n",
      "....................................................................................................\n",
      "Epoch: 4300, accuracy:0.5316,  loss:0.9758,  val_accuracy:0.5254,  val_loss:0.9795,  \n",
      "....................................................................................................\n",
      "Epoch: 4400, accuracy:0.5337,  loss:0.9758,  val_accuracy:0.5274,  val_loss:0.9789,  \n",
      "....................................................................................................\n",
      "Epoch: 4500, accuracy:0.5331,  loss:0.9756,  val_accuracy:0.5254,  val_loss:0.9795,  \n",
      "....................................................................................................\n",
      "Epoch: 4600, accuracy:0.5340,  loss:0.9756,  val_accuracy:0.5262,  val_loss:0.9796,  \n",
      "....................................................................................................\n",
      "Epoch: 4700, accuracy:0.5316,  loss:0.9757,  val_accuracy:0.5257,  val_loss:0.9792,  \n",
      "....................................................................................................\n",
      "Epoch: 4800, accuracy:0.5331,  loss:0.9755,  val_accuracy:0.5249,  val_loss:0.9789,  \n",
      "....................................................................................................\n",
      "Epoch: 4900, accuracy:0.5354,  loss:0.9754,  val_accuracy:0.5274,  val_loss:0.9788,  \n",
      "....................................................................................................\n",
      "Epoch: 5000, accuracy:0.5342,  loss:0.9754,  val_accuracy:0.5249,  val_loss:0.9788,  \n",
      "....................................................................................................\n",
      "Epoch: 5100, accuracy:0.5332,  loss:0.9754,  val_accuracy:0.5259,  val_loss:0.9788,  \n",
      "....................................................................................................\n",
      "Epoch: 5200, accuracy:0.5334,  loss:0.9754,  val_accuracy:0.5251,  val_loss:0.9788,  \n",
      "....................................................................................................\n",
      "Epoch: 5300, accuracy:0.5321,  loss:0.9758,  val_accuracy:0.5267,  val_loss:0.9793,  \n",
      "....................................................................................................\n",
      "Epoch: 5400, accuracy:0.5325,  loss:0.9763,  val_accuracy:0.5224,  val_loss:0.9816,  \n",
      "....................................................................................................\n",
      "Epoch: 5500, accuracy:0.5332,  loss:0.9752,  val_accuracy:0.5254,  val_loss:0.9787,  \n",
      "....................................................................................................\n",
      "Epoch: 5600, accuracy:0.5337,  loss:0.9752,  val_accuracy:0.5257,  val_loss:0.9789,  \n",
      "..................Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_124 (Dense)            (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 3)                 90        \n",
      "=================================================================\n",
      "Total params: 4,440\n",
      "Trainable params: 4,440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.4177,  loss:1.2364,  val_accuracy:0.4690,  val_loss:1.2233,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5269,  loss:1.0122,  val_accuracy:0.5415,  val_loss:1.0037,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5339,  loss:1.0011,  val_accuracy:0.5340,  val_loss:0.9940,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5299,  loss:0.9966,  val_accuracy:0.5475,  val_loss:0.9879,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5356,  loss:0.9935,  val_accuracy:0.5482,  val_loss:0.9840,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5346,  loss:0.9924,  val_accuracy:0.5527,  val_loss:0.9832,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5365,  loss:0.9907,  val_accuracy:0.5482,  val_loss:0.9809,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5378,  loss:0.9906,  val_accuracy:0.5482,  val_loss:0.9800,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5346,  loss:0.9889,  val_accuracy:0.5482,  val_loss:0.9795,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5356,  loss:0.9871,  val_accuracy:0.5438,  val_loss:0.9791,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5361,  loss:0.9863,  val_accuracy:0.5512,  val_loss:0.9778,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5384,  loss:0.9866,  val_accuracy:0.5460,  val_loss:0.9789,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5387,  loss:0.9853,  val_accuracy:0.5475,  val_loss:0.9770,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5346,  loss:0.9848,  val_accuracy:0.5438,  val_loss:0.9773,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5326,  loss:0.9873,  val_accuracy:0.5400,  val_loss:0.9826,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5361,  loss:0.9863,  val_accuracy:0.5482,  val_loss:0.9763,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5387,  loss:0.9841,  val_accuracy:0.5482,  val_loss:0.9764,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5352,  loss:0.9855,  val_accuracy:0.5467,  val_loss:0.9776,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5382,  loss:0.9846,  val_accuracy:0.5467,  val_loss:0.9770,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5367,  loss:0.9836,  val_accuracy:0.5467,  val_loss:0.9752,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5372,  loss:0.9829,  val_accuracy:0.5512,  val_loss:0.9751,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5382,  loss:0.9826,  val_accuracy:0.5475,  val_loss:0.9748,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5369,  loss:0.9831,  val_accuracy:0.5490,  val_loss:0.9748,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, accuracy:0.5363,  loss:0.9828,  val_accuracy:0.5467,  val_loss:0.9747,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, accuracy:0.5374,  loss:0.9819,  val_accuracy:0.5467,  val_loss:0.9744,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, accuracy:0.5361,  loss:0.9822,  val_accuracy:0.5460,  val_loss:0.9757,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, accuracy:0.5361,  loss:0.9821,  val_accuracy:0.5475,  val_loss:0.9750,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, accuracy:0.5374,  loss:0.9824,  val_accuracy:0.5475,  val_loss:0.9744,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, accuracy:0.5350,  loss:0.9819,  val_accuracy:0.5482,  val_loss:0.9739,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, accuracy:0.5378,  loss:0.9812,  val_accuracy:0.5482,  val_loss:0.9740,  \n",
      "....................................................................................................\n",
      "Epoch: 3000, accuracy:0.5393,  loss:0.9812,  val_accuracy:0.5467,  val_loss:0.9741,  \n",
      "....................................................................................................\n",
      "Epoch: 3100, accuracy:0.5384,  loss:0.9841,  val_accuracy:0.5475,  val_loss:0.9746,  \n",
      "....................................................................................................\n",
      "Epoch: 3200, accuracy:0.5365,  loss:0.9809,  val_accuracy:0.5460,  val_loss:0.9735,  \n",
      "....................................................................................................\n",
      "Epoch: 3300, accuracy:0.5354,  loss:0.9823,  val_accuracy:0.5497,  val_loss:0.9740,  \n",
      "....................................................................................................\n",
      "Epoch: 3400, accuracy:0.5348,  loss:0.9830,  val_accuracy:0.5490,  val_loss:0.9738,  \n",
      "....................................................................................................\n",
      "Epoch: 3500, accuracy:0.5376,  loss:0.9808,  val_accuracy:0.5482,  val_loss:0.9737,  \n",
      "....................................................................................................\n",
      "Epoch: 3600, accuracy:0.5363,  loss:0.9822,  val_accuracy:0.5512,  val_loss:0.9737,  \n",
      "....................................................................................................\n",
      "Epoch: 3700, accuracy:0.5382,  loss:0.9803,  val_accuracy:0.5475,  val_loss:0.9733,  \n",
      "....................................................................................................\n",
      "Epoch: 3800, accuracy:0.5387,  loss:0.9802,  val_accuracy:0.5490,  val_loss:0.9734,  \n",
      "....................................................................................................\n",
      "Epoch: 3900, accuracy:0.5376,  loss:0.9804,  val_accuracy:0.5490,  val_loss:0.9737,  \n",
      "....................................................................................................\n",
      "Epoch: 4000, accuracy:0.5387,  loss:0.9801,  val_accuracy:0.5482,  val_loss:0.9730,  \n",
      "....................................................................................................\n",
      "Epoch: 4100, accuracy:0.5380,  loss:0.9800,  val_accuracy:0.5460,  val_loss:0.9729,  \n",
      "....................................................................................................\n",
      "Epoch: 4200, accuracy:0.5406,  loss:0.9813,  val_accuracy:0.5475,  val_loss:0.9731,  \n",
      "....................................................................................................\n",
      "Epoch: 4300, accuracy:0.5389,  loss:0.9797,  val_accuracy:0.5482,  val_loss:0.9730,  \n",
      "....................................................................................................\n",
      "Epoch: 4400, accuracy:0.5399,  loss:0.9797,  val_accuracy:0.5497,  val_loss:0.9732,  \n",
      "....................................................................................................\n",
      "Epoch: 4500, accuracy:0.5380,  loss:0.9796,  val_accuracy:0.5490,  val_loss:0.9732,  \n",
      "....................................................................................................\n",
      "Epoch: 4600, accuracy:0.5359,  loss:0.9799,  val_accuracy:0.5490,  val_loss:0.9741,  \n",
      "....................................................................................................\n",
      "Epoch: 4700, accuracy:0.5393,  loss:0.9798,  val_accuracy:0.5482,  val_loss:0.9727,  \n",
      "....................................................................................................\n",
      "Epoch: 4800, accuracy:0.5412,  loss:0.9794,  val_accuracy:0.5475,  val_loss:0.9737,  \n",
      "....................................................................................................\n",
      "Epoch: 4900, accuracy:0.5354,  loss:0.9801,  val_accuracy:0.5475,  val_loss:0.9727,  \n",
      "....................................................................................................\n",
      "Epoch: 5000, accuracy:0.5380,  loss:0.9795,  val_accuracy:0.5482,  val_loss:0.9724,  \n",
      "....................................................................................................\n",
      "Epoch: 5100, accuracy:0.5380,  loss:0.9790,  val_accuracy:0.5467,  val_loss:0.9726,  \n",
      "....................................................................................................\n",
      "Epoch: 5200, accuracy:0.5397,  loss:0.9790,  val_accuracy:0.5512,  val_loss:0.9728,  \n",
      "....................................................................................................\n",
      "Epoch: 5300, accuracy:0.5376,  loss:0.9798,  val_accuracy:0.5453,  val_loss:0.9723,  \n",
      "....................................................................................................\n",
      "Epoch: 5400, accuracy:0.5387,  loss:0.9789,  val_accuracy:0.5467,  val_loss:0.9723,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 5500, accuracy:0.5374,  loss:0.9795,  val_accuracy:0.5527,  val_loss:0.9727,  \n",
      "....................................................................................................\n",
      "Epoch: 5600, accuracy:0.5369,  loss:0.9793,  val_accuracy:0.5467,  val_loss:0.9732,  \n",
      "...........................................................Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_130 (Dense)            (None, 21)                462       \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 5)                 110       \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 680\n",
      "Trainable params: 680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.4139,  loss:1.1416,  val_accuracy:0.4622,  val_loss:1.1392,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5198,  loss:1.0176,  val_accuracy:0.5108,  val_loss:1.0190,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5264,  loss:1.0046,  val_accuracy:0.5168,  val_loss:1.0020,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5298,  loss:0.9976,  val_accuracy:0.5213,  val_loss:0.9937,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5337,  loss:0.9944,  val_accuracy:0.5236,  val_loss:0.9897,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5324,  loss:0.9924,  val_accuracy:0.5251,  val_loss:0.9875,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5329,  loss:0.9910,  val_accuracy:0.5251,  val_loss:0.9860,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5350,  loss:0.9894,  val_accuracy:0.5273,  val_loss:0.9848,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5363,  loss:0.9885,  val_accuracy:0.5273,  val_loss:0.9845,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5350,  loss:0.9892,  val_accuracy:0.5280,  val_loss:0.9837,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5397,  loss:0.9875,  val_accuracy:0.5273,  val_loss:0.9831,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5384,  loss:0.9871,  val_accuracy:0.5273,  val_loss:0.9826,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5387,  loss:0.9863,  val_accuracy:0.5280,  val_loss:0.9824,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5402,  loss:0.9859,  val_accuracy:0.5266,  val_loss:0.9823,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5348,  loss:0.9862,  val_accuracy:0.5280,  val_loss:0.9831,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5376,  loss:0.9865,  val_accuracy:0.5251,  val_loss:0.9819,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5382,  loss:0.9855,  val_accuracy:0.5288,  val_loss:0.9830,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5389,  loss:0.9853,  val_accuracy:0.5266,  val_loss:0.9822,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5399,  loss:0.9849,  val_accuracy:0.5221,  val_loss:0.9817,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5402,  loss:0.9847,  val_accuracy:0.5288,  val_loss:0.9824,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5385,  loss:0.9854,  val_accuracy:0.5243,  val_loss:0.9816,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5404,  loss:0.9845,  val_accuracy:0.5221,  val_loss:0.9814,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5352,  loss:0.9858,  val_accuracy:0.5243,  val_loss:0.9813,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, accuracy:0.5391,  loss:0.9840,  val_accuracy:0.5228,  val_loss:0.9813,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, accuracy:0.5399,  loss:0.9841,  val_accuracy:0.5243,  val_loss:0.9810,  \n",
      ".........."
     ]
    }
   ],
   "source": [
    "##### Model04:\n",
    "\n",
    "l2_model04_H1_H = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(25, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "l2_model05_H1_H = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(33, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "l2_model02_H1_M = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(12, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "##### Model01:\n",
    "\n",
    "l2_model01_H1_L = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(4, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "### 2 Hidden Layers:\n",
    "#### High Amount of Neurons (H):\n",
    "\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "l2_model03_H2_H = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(29, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(29, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "l2_model04_H2_M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "l2_model05_H2_L = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(8, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(8, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "### 3 Hidden Layers:\n",
    "#### High Amount of Neurons (H):\n",
    "##### Model01:\n",
    "\n",
    "l2_model01_H3_H = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "l2_model04_H3_M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "l2_model02_H3_L = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(5, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(5, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(5, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "l2_model03_H3_L = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(7, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(7, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(7, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "#### Funnel Architecture:\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "l2_model05_H3_F = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(25, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(19, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(12, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(6, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "### 4 Hidden Layers:\n",
    "#### High Amount of Neurons (H):\n",
    "##### Model01:\n",
    "\n",
    "l2_model01_H4_H = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "l2_model03_H4_H = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(29, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(29, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(29, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(29, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "l2_model02_H4_L = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(5, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(5, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(5, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(5, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# H1_H\n",
    "size_histories['l2_model04_H1_H'] = compile_and_fit(l2_model04_H1_H, 'l2_model04_H1_H', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['l2_model05_H1_H'] = compile_and_fit(l2_model05_H1_H, 'l2_model05_H1_H', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H1_M\n",
    "size_histories['l2_model02_H1_M'] = compile_and_fit(l2_model02_H1_M, 'l2_model02_H1_M', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H1_L\n",
    "size_histories['l2_model01_H1_L'] = compile_and_fit(l2_model01_H1_L, 'l2_model01_H1_L', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H2_H\n",
    "size_histories['l2_model03_H2_H'] = compile_and_fit(l2_model03_H2_H, 'l2_model03_H2_H', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H2_M\n",
    "size_histories['l2_model04_H2_M'] = compile_and_fit(l2_model04_H2_M, 'l2_model04_H2_M', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H2_L\n",
    "size_histories['l2_model05_H2_L'] = compile_and_fit(l2_model05_H2_L, 'l2_model05_H2_L', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3_H\n",
    "size_histories['l2_model01_H3_H'] = compile_and_fit(l2_model01_H3_H, 'l2_model01_H3_H', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3_M\n",
    "size_histories['l2_model04_H3_M'] = compile_and_fit(l2_model04_H3_M, 'l2_model04_H3_M', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3_L\n",
    "size_histories['l2_model02_H3_L'] = compile_and_fit(l2_model02_H3_L, 'l2_model02_H3_L', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['l2_model03_H3_L'] = compile_and_fit(l2_model03_H3_L, 'l2_model03_H3_L', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3_F\n",
    "size_histories['l2_model05_H3_F'] = compile_and_fit(l2_model05_H3_F, 'l2_model05_H3_F', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H4_H\n",
    "size_histories['l2_model01_H4_H'] = compile_and_fit(l2_model01_H4_H, 'l2_model01_H4_H', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['l2_model03_H4_H'] = compile_and_fit(l2_model03_H4_H, 'l2_model03_H4_H', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H4_L\n",
    "size_histories['l2_model02_H4_L'] = compile_and_fit(l2_model02_H4_L, 'l2_model02_H4_L', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "1DwuhGCJH2yL",
    "outputId": "13ba4f8a-0516-4937-d37a-8b0130fc5a56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2_model04_H1_H\n",
      "Test Score: 0.9507763855797904\n",
      "Test Accuracy: 0.5542857\n",
      "#####\n",
      "l2_model05_H1_H\n",
      "Test Score: 0.9714918368203299\n",
      "Test Accuracy: 0.5485714\n",
      "#####\n",
      "l2_model02_H1_M\n",
      "Test Score: 0.9723828868432478\n",
      "Test Accuracy: 0.53125\n",
      "#####\n",
      "l2_model01_H1_L\n",
      "Test Score: 0.9782900750751459\n",
      "Test Accuracy: 0.53071016\n",
      "#####\n",
      "l2_model03_H2_H\n",
      "Test Score: 0.9759981415488503\n",
      "Test Accuracy: 0.5511364\n",
      "#####\n",
      "l2_model04_H2_M\n",
      "Test Score: 0.9522068973949978\n",
      "Test Accuracy: 0.5485714\n",
      "#####\n",
      "l2_model05_H2_L\n",
      "Test Score: 0.9532836730139597\n",
      "Test Accuracy: 0.5485714\n",
      "#####\n",
      "l2_model02_H3_H\n",
      "Test Score: 0.9804608708608631\n",
      "Test Accuracy: 0.53358924\n",
      "#####\n",
      "l2_model04_H3_M\n",
      "Test Score: 0.950789190360478\n",
      "Test Accuracy: 0.56\n",
      "#####\n",
      "l2_model02_H3_L\n",
      "Test Score: 0.9777267358519814\n",
      "Test Accuracy: 0.52840906\n",
      "#####\n",
      "l2_model03_H3_L\n",
      "Test Score: 0.9800749583677812\n",
      "Test Accuracy: 0.5511364\n",
      "#####\n",
      "l2_model05_H3_F\n",
      "Test Score: 0.9735877329962594\n",
      "Test Accuracy: 0.54285717\n",
      "#####\n",
      "model02_H4_H\n",
      "Test Score: 0.980573253874129\n",
      "Test Accuracy: 0.53071016\n",
      "#####\n",
      "l2_model03_H4_H\n",
      "Test Score: 0.9820105487650092\n",
      "Test Accuracy: 0.54829544\n",
      "#####\n",
      "l2_model02_H4_L\n",
      "Test Score: 0.9806894172321666\n",
      "Test Accuracy: 0.5255682\n",
      "#####\n"
     ]
    }
   ],
   "source": [
    "# H1_H\n",
    "score = load_model('../model/l2_model04_H1_H.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"l2_model04_H1_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/l2_model05_H1_H.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"l2_model05_H1_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H1_M\n",
    "\n",
    "score = load_model('../model/l2_model02_H1_M.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"l2_model02_H1_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "\n",
    "# H1_L\n",
    "score = load_model('../model/l2_model01_H1_L.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"l2_model01_H1_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "\n",
    "# H2_H\n",
    "\n",
    "\n",
    "score = load_model('../model/l2_model03_H2_H.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"l2_model03_H2_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "\n",
    "# H2_M\n",
    "\n",
    "\n",
    "score = load_model('../model/l2_model04_H2_M.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"l2_model04_H2_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H2_L\n",
    "\n",
    "score = load_model('../model/l2_model05_H2_L.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"l2_model05_H2_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H3_H\n",
    "score = load_model('../model/l2_model01_H3_H.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"l2_model02_H3_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "\n",
    "# H3_M\n",
    "\n",
    "score = load_model('../model/l2_model04_H3_M.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"l2_model04_H3_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H3_L\n",
    "\n",
    "score = load_model('../model/l2_model02_H3_L.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"l2_model02_H3_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/l2_model03_H3_L.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"l2_model03_H3_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H3_F\n",
    "score = load_model('../model/l2_model05_H3_F.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"l2_model05_H3_F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H4_H\n",
    "score = load_model('../model/l2_model01_H4_H.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"l2_model02_H4_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "\n",
    "score = load_model('../model/l2_model03_H4_H.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"l2_model03_H4_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H4_L\n",
    "\n",
    "score = load_model('../model/l2_model02_H4_L.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"l2_model02_H4_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HtHfSEgO6sUN",
    "outputId": "b7fd6a48-30f1-470e-f92b-118a7046a09a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_204 (Dense)            (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_205 (Dense)            (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 3)                 78        \n",
      "=================================================================\n",
      "Total params: 1,378\n",
      "Trainable params: 1,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.3292,  loss:1.1033,  val_accuracy:0.4496,  val_loss:1.0890,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5190,  loss:0.9987,  val_accuracy:0.5083,  val_loss:0.9997,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5241,  loss:0.9897,  val_accuracy:0.5120,  val_loss:0.9927,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5248,  loss:0.9856,  val_accuracy:0.5158,  val_loss:0.9873,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5278,  loss:0.9817,  val_accuracy:0.5195,  val_loss:0.9837,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5316,  loss:0.9800,  val_accuracy:0.5248,  val_loss:0.9813,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5320,  loss:0.9778,  val_accuracy:0.5226,  val_loss:0.9794,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5331,  loss:0.9763,  val_accuracy:0.5203,  val_loss:0.9782,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5352,  loss:0.9737,  val_accuracy:0.5203,  val_loss:0.9770,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5348,  loss:0.9702,  val_accuracy:0.5226,  val_loss:0.9762,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5333,  loss:0.9713,  val_accuracy:0.5248,  val_loss:0.9758,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5339,  loss:0.9742,  val_accuracy:0.5263,  val_loss:0.9752,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5404,  loss:0.9698,  val_accuracy:0.5256,  val_loss:0.9744,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5335,  loss:0.9712,  val_accuracy:0.5293,  val_loss:0.9740,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5350,  loss:0.9686,  val_accuracy:0.5286,  val_loss:0.9741,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5356,  loss:0.9673,  val_accuracy:0.5256,  val_loss:0.9741,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5380,  loss:0.9679,  val_accuracy:0.5301,  val_loss:0.9729,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5371,  loss:0.9679,  val_accuracy:0.5256,  val_loss:0.9729,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5365,  loss:0.9645,  val_accuracy:0.5346,  val_loss:0.9725,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5354,  loss:0.9664,  val_accuracy:0.5271,  val_loss:0.9726,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5372,  loss:0.9669,  val_accuracy:0.5248,  val_loss:0.9731,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5408,  loss:0.9615,  val_accuracy:0.5301,  val_loss:0.9721,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5406,  loss:0.9666,  val_accuracy:0.5293,  val_loss:0.9723,  \n",
      "...................................................................Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_207 (Dense)            (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_208 (Dense)            (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 3)                 102       \n",
      "=================================================================\n",
      "Total params: 2,346\n",
      "Trainable params: 2,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.2940,  loss:1.1157,  val_accuracy:0.4947,  val_loss:1.0864,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5122,  loss:0.9976,  val_accuracy:0.5353,  val_loss:0.9797,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5175,  loss:0.9917,  val_accuracy:0.5444,  val_loss:0.9749,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5239,  loss:0.9875,  val_accuracy:0.5436,  val_loss:0.9705,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5209,  loss:0.9817,  val_accuracy:0.5474,  val_loss:0.9696,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5248,  loss:0.9821,  val_accuracy:0.5511,  val_loss:0.9652,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5267,  loss:0.9800,  val_accuracy:0.5481,  val_loss:0.9637,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5292,  loss:0.9774,  val_accuracy:0.5481,  val_loss:0.9639,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5335,  loss:0.9758,  val_accuracy:0.5511,  val_loss:0.9622,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5299,  loss:0.9702,  val_accuracy:0.5504,  val_loss:0.9618,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5303,  loss:0.9739,  val_accuracy:0.5504,  val_loss:0.9607,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5357,  loss:0.9705,  val_accuracy:0.5504,  val_loss:0.9596,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5295,  loss:0.9732,  val_accuracy:0.5511,  val_loss:0.9592,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5314,  loss:0.9706,  val_accuracy:0.5489,  val_loss:0.9613,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5314,  loss:0.9679,  val_accuracy:0.5519,  val_loss:0.9598,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5305,  loss:0.9715,  val_accuracy:0.5526,  val_loss:0.9611,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5325,  loss:0.9700,  val_accuracy:0.5519,  val_loss:0.9601,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5357,  loss:0.9679,  val_accuracy:0.5496,  val_loss:0.9585,  \n",
      "......................................................................Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_210 (Dense)            (None, 21)                462       \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 21)                0         \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, 12)                264       \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 3)                 39        \n",
      "=================================================================\n",
      "Total params: 765\n",
      "Trainable params: 765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.2949,  loss:1.1131,  val_accuracy:0.2827,  val_loss:1.1033,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5161,  loss:0.9988,  val_accuracy:0.5288,  val_loss:0.9860,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5311,  loss:0.9870,  val_accuracy:0.5280,  val_loss:0.9783,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5339,  loss:0.9831,  val_accuracy:0.5266,  val_loss:0.9739,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5337,  loss:0.9767,  val_accuracy:0.5251,  val_loss:0.9705,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5371,  loss:0.9764,  val_accuracy:0.5251,  val_loss:0.9699,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5393,  loss:0.9729,  val_accuracy:0.5288,  val_loss:0.9682,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5410,  loss:0.9744,  val_accuracy:0.5273,  val_loss:0.9678,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5432,  loss:0.9699,  val_accuracy:0.5303,  val_loss:0.9670,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5391,  loss:0.9708,  val_accuracy:0.5333,  val_loss:0.9665,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5415,  loss:0.9656,  val_accuracy:0.5333,  val_loss:0.9662,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5397,  loss:0.9651,  val_accuracy:0.5378,  val_loss:0.9655,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5445,  loss:0.9640,  val_accuracy:0.5303,  val_loss:0.9659,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5395,  loss:0.9677,  val_accuracy:0.5355,  val_loss:0.9655,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5468,  loss:0.9624,  val_accuracy:0.5325,  val_loss:0.9658,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5430,  loss:0.9696,  val_accuracy:0.5325,  val_loss:0.9659,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5483,  loss:0.9628,  val_accuracy:0.5325,  val_loss:0.9657,  \n",
      ".................................................................Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_213 (Dense)            (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_214 (Dense)            (None, 4)                 56        \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 253\n",
      "Trainable params: 253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.3773,  loss:1.1057,  val_accuracy:0.4455,  val_loss:1.0958,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5133,  loss:0.9923,  val_accuracy:0.5267,  val_loss:0.9760,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5202,  loss:0.9863,  val_accuracy:0.5274,  val_loss:0.9742,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5171,  loss:0.9865,  val_accuracy:0.5277,  val_loss:0.9741,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5215,  loss:0.9848,  val_accuracy:0.5274,  val_loss:0.9741,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5161,  loss:0.9855,  val_accuracy:0.5277,  val_loss:0.9742,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5149,  loss:0.9873,  val_accuracy:0.5279,  val_loss:0.9740,  \n",
      ".............................................Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_216 (Dense)            (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_217 (Dense)            (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_218 (Dense)            (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_219 (Dense)            (None, 3)                 90        \n",
      "=================================================================\n",
      "Total params: 2,700\n",
      "Trainable params: 2,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, accuracy:0.3277,  loss:1.1014,  val_accuracy:0.4690,  val_loss:1.0885,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5210,  loss:0.9885,  val_accuracy:0.5348,  val_loss:0.9700,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5275,  loss:0.9803,  val_accuracy:0.5378,  val_loss:0.9642,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5286,  loss:0.9746,  val_accuracy:0.5438,  val_loss:0.9614,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5318,  loss:0.9717,  val_accuracy:0.5415,  val_loss:0.9615,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5318,  loss:0.9708,  val_accuracy:0.5400,  val_loss:0.9606,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5367,  loss:0.9682,  val_accuracy:0.5423,  val_loss:0.9605,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5389,  loss:0.9668,  val_accuracy:0.5355,  val_loss:0.9594,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5378,  loss:0.9620,  val_accuracy:0.5363,  val_loss:0.9586,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5395,  loss:0.9640,  val_accuracy:0.5355,  val_loss:0.9587,  \n",
      "..................................................Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_220 (Dense)            (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, 13)                338       \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 1,212\n",
      "Trainable params: 1,212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.4142,  loss:1.0887,  val_accuracy:0.4571,  val_loss:1.0821,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5201,  loss:1.0025,  val_accuracy:0.5165,  val_loss:0.9987,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5211,  loss:0.9954,  val_accuracy:0.5165,  val_loss:0.9917,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5286,  loss:0.9883,  val_accuracy:0.5180,  val_loss:0.9880,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5284,  loss:0.9862,  val_accuracy:0.5203,  val_loss:0.9844,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5324,  loss:0.9810,  val_accuracy:0.5256,  val_loss:0.9827,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5271,  loss:0.9809,  val_accuracy:0.5248,  val_loss:0.9798,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5339,  loss:0.9755,  val_accuracy:0.5241,  val_loss:0.9781,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5325,  loss:0.9757,  val_accuracy:0.5203,  val_loss:0.9765,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5348,  loss:0.9757,  val_accuracy:0.5301,  val_loss:0.9760,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5388,  loss:0.9734,  val_accuracy:0.5308,  val_loss:0.9748,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5301,  loss:0.9782,  val_accuracy:0.5301,  val_loss:0.9732,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5299,  loss:0.9747,  val_accuracy:0.5286,  val_loss:0.9725,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5322,  loss:0.9744,  val_accuracy:0.5301,  val_loss:0.9715,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5382,  loss:0.9684,  val_accuracy:0.5308,  val_loss:0.9712,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5356,  loss:0.9679,  val_accuracy:0.5308,  val_loss:0.9716,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5376,  loss:0.9704,  val_accuracy:0.5316,  val_loss:0.9713,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5389,  loss:0.9674,  val_accuracy:0.5278,  val_loss:0.9704,  \n",
      "...................Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_224 (Dense)            (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_225 (Dense)            (None, 8)                 272       \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_226 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_227 (Dense)            (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 1,493\n",
      "Trainable params: 1,493\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.3213,  loss:1.1103,  val_accuracy:0.3932,  val_loss:1.0960,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5062,  loss:1.0083,  val_accuracy:0.5316,  val_loss:0.9848,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5149,  loss:0.9964,  val_accuracy:0.5398,  val_loss:0.9751,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5186,  loss:0.9936,  val_accuracy:0.5489,  val_loss:0.9707,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5209,  loss:0.9888,  val_accuracy:0.5504,  val_loss:0.9690,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5222,  loss:0.9878,  val_accuracy:0.5406,  val_loss:0.9699,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5271,  loss:0.9832,  val_accuracy:0.5459,  val_loss:0.9687,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5297,  loss:0.9799,  val_accuracy:0.5481,  val_loss:0.9649,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5203,  loss:0.9829,  val_accuracy:0.5444,  val_loss:0.9649,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5280,  loss:0.9766,  val_accuracy:0.5451,  val_loss:0.9640,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5265,  loss:0.9793,  val_accuracy:0.5489,  val_loss:0.9636,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5320,  loss:0.9780,  val_accuracy:0.5481,  val_loss:0.9626,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5322,  loss:0.9737,  val_accuracy:0.5459,  val_loss:0.9622,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5344,  loss:0.9725,  val_accuracy:0.5474,  val_loss:0.9618,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5340,  loss:0.9764,  val_accuracy:0.5429,  val_loss:0.9625,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5369,  loss:0.9707,  val_accuracy:0.5481,  val_loss:0.9619,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5352,  loss:0.9723,  val_accuracy:0.5519,  val_loss:0.9601,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5318,  loss:0.9716,  val_accuracy:0.5481,  val_loss:0.9607,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5386,  loss:0.9752,  val_accuracy:0.5504,  val_loss:0.9597,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5416,  loss:0.9710,  val_accuracy:0.5489,  val_loss:0.9602,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5365,  loss:0.9718,  val_accuracy:0.5451,  val_loss:0.9593,  \n",
      ".........................Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_228 (Dense)            (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_229 (Dense)            (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_230 (Dense)            (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_231 (Dense)            (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_232 (Dense)            (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 770\n",
      "Trainable params: 770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.3597,  loss:1.1008,  val_accuracy:0.4655,  val_loss:1.0845,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5270,  loss:0.9837,  val_accuracy:0.5297,  val_loss:0.9759,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5330,  loss:0.9791,  val_accuracy:0.5297,  val_loss:0.9747,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5312,  loss:0.9795,  val_accuracy:0.5208,  val_loss:0.9766,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5348,  loss:0.9778,  val_accuracy:0.5249,  val_loss:0.9767,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5319,  loss:0.9778,  val_accuracy:0.5274,  val_loss:0.9757,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5341,  loss:0.9765,  val_accuracy:0.5262,  val_loss:0.9759,  \n",
      "...............................Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_233 (Dense)            (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_234 (Dense)            (None, 13)                338       \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_235 (Dense)            (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_236 (Dense)            (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_237 (Dense)            (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 1,394\n",
      "Trainable params: 1,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.2827,  loss:1.1068,  val_accuracy:0.2940,  val_loss:1.0976,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5214,  loss:1.0095,  val_accuracy:0.5113,  val_loss:1.0034,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5207,  loss:1.0024,  val_accuracy:0.5150,  val_loss:0.9980,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5237,  loss:0.9967,  val_accuracy:0.5165,  val_loss:0.9918,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5293,  loss:0.9930,  val_accuracy:0.5143,  val_loss:0.9880,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5265,  loss:0.9908,  val_accuracy:0.5233,  val_loss:0.9896,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5290,  loss:0.9885,  val_accuracy:0.5195,  val_loss:0.9869,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5254,  loss:0.9897,  val_accuracy:0.5173,  val_loss:0.9847,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5331,  loss:0.9888,  val_accuracy:0.5286,  val_loss:0.9844,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5286,  loss:0.9872,  val_accuracy:0.5203,  val_loss:0.9846,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5350,  loss:0.9838,  val_accuracy:0.5233,  val_loss:0.9847,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5305,  loss:0.9842,  val_accuracy:0.5218,  val_loss:0.9845,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5312,  loss:0.9839,  val_accuracy:0.5218,  val_loss:0.9829,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5322,  loss:0.9797,  val_accuracy:0.5256,  val_loss:0.9835,  \n",
      ".............................Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_238 (Dense)            (None, 21)                462       \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 21)                0         \n",
      "_________________________________________________________________\n",
      "dense_239 (Dense)            (None, 5)                 110       \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_240 (Dense)            (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_241 (Dense)            (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_242 (Dense)            (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 650\n",
      "Trainable params: 650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.3741,  loss:1.0963,  val_accuracy:0.3493,  val_loss:1.0958,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.4869,  loss:1.0261,  val_accuracy:0.5198,  val_loss:1.0060,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5125,  loss:1.0141,  val_accuracy:0.5198,  val_loss:0.9928,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5112,  loss:1.0064,  val_accuracy:0.5228,  val_loss:0.9887,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5124,  loss:1.0048,  val_accuracy:0.5198,  val_loss:0.9877,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5114,  loss:1.0035,  val_accuracy:0.5221,  val_loss:0.9846,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5225,  loss:1.0035,  val_accuracy:0.5213,  val_loss:0.9831,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5290,  loss:1.0016,  val_accuracy:0.5243,  val_loss:0.9824,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5271,  loss:0.9959,  val_accuracy:0.5258,  val_loss:0.9818,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5357,  loss:0.9953,  val_accuracy:0.5228,  val_loss:0.9822,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5273,  loss:1.0010,  val_accuracy:0.5236,  val_loss:0.9821,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5238,  loss:0.9969,  val_accuracy:0.5206,  val_loss:0.9822,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5254,  loss:0.9995,  val_accuracy:0.5198,  val_loss:0.9831,  \n",
      "...........................................Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_243 (Dense)            (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_244 (Dense)            (None, 7)                 210       \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "dense_245 (Dense)            (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "dense_246 (Dense)            (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "dense_247 (Dense)            (None, 3)                 24        \n",
      "=================================================================\n",
      "Total params: 1,216\n",
      "Trainable params: 1,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.3391,  loss:1.0969,  val_accuracy:0.4690,  val_loss:1.0921,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.4579,  loss:1.0232,  val_accuracy:0.4690,  val_loss:0.9999,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5075,  loss:1.0060,  val_accuracy:0.5295,  val_loss:0.9856,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5172,  loss:0.9969,  val_accuracy:0.5355,  val_loss:0.9790,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5155,  loss:0.9992,  val_accuracy:0.5370,  val_loss:0.9769,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5148,  loss:0.9968,  val_accuracy:0.5370,  val_loss:0.9748,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5253,  loss:0.9904,  val_accuracy:0.5400,  val_loss:0.9676,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5333,  loss:0.9894,  val_accuracy:0.5393,  val_loss:0.9658,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5329,  loss:0.9858,  val_accuracy:0.5385,  val_loss:0.9657,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5356,  loss:0.9841,  val_accuracy:0.5408,  val_loss:0.9661,  \n",
      "................Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_248 (Dense)            (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_249 (Dense)            (None, 25)                850       \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_250 (Dense)            (None, 19)                494       \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 19)                0         \n",
      "_________________________________________________________________\n",
      "dense_251 (Dense)            (None, 12)                240       \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_252 (Dense)            (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_253 (Dense)            (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 2,805\n",
      "Trainable params: 2,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.3117,  loss:1.1010,  val_accuracy:0.4947,  val_loss:1.0908,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.4998,  loss:1.0067,  val_accuracy:0.5383,  val_loss:0.9809,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5134,  loss:0.9962,  val_accuracy:0.5496,  val_loss:0.9769,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5113,  loss:0.9995,  val_accuracy:0.5504,  val_loss:0.9701,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5098,  loss:0.9907,  val_accuracy:0.5414,  val_loss:0.9700,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5119,  loss:0.9868,  val_accuracy:0.5414,  val_loss:0.9707,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5070,  loss:0.9856,  val_accuracy:0.5436,  val_loss:0.9689,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5246,  loss:0.9848,  val_accuracy:0.5353,  val_loss:0.9700,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5318,  loss:0.9811,  val_accuracy:0.5489,  val_loss:0.9658,  \n",
      "..........Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_254 (Dense)            (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_255 (Dense)            (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_256 (Dense)            (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_257 (Dense)            (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_258 (Dense)            (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_259 (Dense)            (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 952\n",
      "Trainable params: 952\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.4336,  loss:1.0911,  val_accuracy:0.4655,  val_loss:1.0810,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5239,  loss:0.9834,  val_accuracy:0.5198,  val_loss:0.9804,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5305,  loss:0.9802,  val_accuracy:0.5221,  val_loss:0.9823,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5333,  loss:0.9798,  val_accuracy:0.5244,  val_loss:0.9808,  \n",
      "...............................Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_260 (Dense)            (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_261 (Dense)            (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_262 (Dense)            (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dropout_98 (Dropout)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_263 (Dense)            (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_264 (Dense)            (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dropout_100 (Dropout)        (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_265 (Dense)            (None, 3)                 90        \n",
      "=================================================================\n",
      "Total params: 4,440\n",
      "Trainable params: 4,440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, accuracy:0.2764,  loss:1.1111,  val_accuracy:0.4667,  val_loss:1.0962,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5290,  loss:0.9866,  val_accuracy:0.5363,  val_loss:0.9736,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5361,  loss:0.9791,  val_accuracy:0.5378,  val_loss:0.9685,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5350,  loss:0.9767,  val_accuracy:0.5333,  val_loss:0.9679,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5399,  loss:0.9730,  val_accuracy:0.5318,  val_loss:0.9659,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5399,  loss:0.9711,  val_accuracy:0.5385,  val_loss:0.9644,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5393,  loss:0.9676,  val_accuracy:0.5295,  val_loss:0.9657,  \n",
      "....................................Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_266 (Dense)            (None, 21)                462       \n",
      "_________________________________________________________________\n",
      "dropout_101 (Dropout)        (None, 21)                0         \n",
      "_________________________________________________________________\n",
      "dense_267 (Dense)            (None, 5)                 110       \n",
      "_________________________________________________________________\n",
      "dropout_102 (Dropout)        (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_268 (Dense)            (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dropout_103 (Dropout)        (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_269 (Dense)            (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dropout_104 (Dropout)        (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_270 (Dense)            (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dropout_105 (Dropout)        (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_271 (Dense)            (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 680\n",
      "Trainable params: 680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.3413,  loss:1.1011,  val_accuracy:0.2842,  val_loss:1.0972,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.4601,  loss:1.0315,  val_accuracy:0.4622,  val_loss:1.0170,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.4946,  loss:1.0213,  val_accuracy:0.5161,  val_loss:0.9992,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5037,  loss:1.0110,  val_accuracy:0.5191,  val_loss:0.9916,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5107,  loss:1.0067,  val_accuracy:0.5236,  val_loss:0.9882,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5110,  loss:1.0029,  val_accuracy:0.5295,  val_loss:0.9835,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5129,  loss:1.0056,  val_accuracy:0.5295,  val_loss:0.9821,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5182,  loss:0.9977,  val_accuracy:0.5303,  val_loss:0.9807,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5187,  loss:1.0001,  val_accuracy:0.5266,  val_loss:0.9810,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5219,  loss:0.9934,  val_accuracy:0.5236,  val_loss:0.9819,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5172,  loss:0.9939,  val_accuracy:0.5243,  val_loss:0.9811,  \n",
      "..............................................................................."
     ]
    }
   ],
   "source": [
    "##### Model04:\n",
    "\n",
    "drop_model04_H1_H = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 feature\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "drop_model05_H1_H = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "drop_model02_H1_M = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "##### Model01:\n",
    "\n",
    "drop_model01_H1_L = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(4, activation='relu'), \n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "### 2 Hidden Layers:\n",
    "#### High Amount of Neurons (H):\n",
    "\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "drop_model03_H2_H = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "drop_model04_H2_M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "drop_model05_H2_L = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "### 3 Hidden Layers:\n",
    "#### High Amount of Neurons (H):\n",
    "##### Model01:\n",
    "\n",
    "drop_model01_H3_H = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "drop_model04_H3_M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "drop_model02_H3_L = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "drop_model03_H3_L = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "#### Funnel Architecture:\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "drop_model05_H3_F = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(19, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "### 4 Hidden Layers:\n",
    "#### High Amount of Neurons (H):\n",
    "##### Model01:\n",
    "\n",
    "drop_model01_H4_H = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "drop_model03_H4_H = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "drop_model02_H4_L = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# H1_H\n",
    "size_histories['drop_model04_H1_H'] = compile_and_fit(drop_model04_H1_H, 'drop_model04_H1_H', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['drop_model05_H1_H'] = compile_and_fit(drop_model05_H1_H, 'drop_model05_H1_H', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H1_M\n",
    "size_histories['drop_model02_H1_M'] = compile_and_fit(drop_model02_H1_M, 'drop_model02_H1_M', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H1_L\n",
    "size_histories['drop_model01_H1_L'] = compile_and_fit(drop_model01_H1_L, 'drop_model01_H1_L', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H2_H\n",
    "size_histories['drop_model03_H2_H'] = compile_and_fit(drop_model03_H2_H, 'drop_model03_H2_H', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H2_M\n",
    "size_histories['drop_model04_H2_M'] = compile_and_fit(drop_model04_H2_M, 'drop_model04_H2_M', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H2_L\n",
    "size_histories['drop_model05_H2_L'] = compile_and_fit(drop_model05_H2_L, 'drop_model05_H2_L', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3_H\n",
    "size_histories['drop_model01_H3_H'] = compile_and_fit(drop_model01_H3_H, 'drop_model01_H3_H', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3_M\n",
    "size_histories['drop_model04_H3_M'] = compile_and_fit(drop_model04_H3_M, 'drop_model04_H3_M', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3_L\n",
    "size_histories['drop_model02_H3_L'] = compile_and_fit(drop_model02_H3_L, 'drop_model02_H3_L', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['drop_model03_H3_L'] = compile_and_fit(drop_model03_H3_L, 'drop_model03_H3_L', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3_F\n",
    "size_histories['drop_model05_H3_F'] = compile_and_fit(drop_model05_H3_F, 'drop_model05_H3_F', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H4_H\n",
    "size_histories['drop_model01_H4_H'] = compile_and_fit(drop_model01_H4_H, 'drop_model01_H4_H', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['drop_model03_H4_H'] = compile_and_fit(drop_model03_H4_H, 'drop_model03_H4_H', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H4_L\n",
    "size_histories['drop_model02_H4_L'] = compile_and_fit(drop_model02_H4_L, 'drop_model02_H4_L', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "1DwuhGCJH2yL",
    "outputId": "13ba4f8a-0516-4937-d37a-8b0130fc5a56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop_model04_H1_H\n",
      "Test Score: 0.9297366493088859\n",
      "Test Accuracy: 0.55142856\n",
      "#####\n",
      "drop_model05_H1_H\n",
      "Test Score: 0.9520663247789656\n",
      "Test Accuracy: 0.54571426\n",
      "#####\n",
      "drop_model02_H1_M\n",
      "Test Score: 0.9659043225375089\n",
      "Test Accuracy: 0.51704544\n",
      "#####\n",
      "drop_model01_H1_L\n",
      "Test Score: 0.9774055418034662\n",
      "Test Accuracy: 0.5239923\n",
      "#####\n",
      "drop_model03_H2_H\n",
      "Test Score: 0.9661700508811257\n",
      "Test Accuracy: 0.5511364\n",
      "#####\n",
      "drop_model04_H2_M\n",
      "Test Score: 0.929811326435634\n",
      "Test Accuracy: 0.57714283\n",
      "#####\n",
      "drop_model05_H2_L\n",
      "Test Score: 0.9545187609536308\n",
      "Test Accuracy: 0.5342857\n",
      "#####\n",
      "drop_model02_H3_H\n",
      "Test Score: 0.9740686600816914\n",
      "Test Accuracy: 0.53454894\n",
      "#####\n",
      "drop_model04_H3_M\n",
      "Test Score: 0.9557076978683472\n",
      "Test Accuracy: 0.5657143\n",
      "#####\n",
      "model02_H3_L\n",
      "Test Score: 0.9850913828069513\n",
      "Test Accuracy: 0.5113636\n",
      "#####\n",
      "drop_model03_H3_L\n",
      "Test Score: 0.9724155014211481\n",
      "Test Accuracy: 0.53409094\n",
      "#####\n",
      "drop_model05_H3_F\n",
      "Test Score: 0.9699322707312448\n",
      "Test Accuracy: 0.5371429\n",
      "#####\n",
      "model02_H4_H\n",
      "Test Score: 0.9796521824975847\n",
      "Test Accuracy: 0.53166986\n",
      "#####\n",
      "drop_model03_H4_H\n",
      "Test Score: 0.9714847098697316\n",
      "Test Accuracy: 0.53409094\n",
      "#####\n",
      "drop_model02_H4_L\n",
      "Test Score: 0.9802783077413385\n",
      "Test Accuracy: 0.53125\n",
      "#####\n"
     ]
    }
   ],
   "source": [
    "# H1_H\n",
    "score = load_model('../model/drop_model04_H1_H.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"drop_model04_H1_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/drop_model05_H1_H.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"drop_model05_H1_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H1_M\n",
    "\n",
    "score = load_model('../model/drop_model02_H1_M.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"drop_model02_H1_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "\n",
    "# H1_L\n",
    "score = load_model('../model/drop_model01_H1_L.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"drop_model01_H1_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "\n",
    "# H2_H\n",
    "\n",
    "\n",
    "score = load_model('../model/drop_model03_H2_H.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"drop_model03_H2_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "\n",
    "# H2_M\n",
    "\n",
    "\n",
    "score = load_model('../model/drop_model04_H2_M.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"drop_model04_H2_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H2_L\n",
    "\n",
    "score = load_model('../model/drop_model05_H2_L.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"drop_model05_H2_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H3_H\n",
    "score = load_model('../model/drop_model01_H3_H.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"drop_model02_H3_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "\n",
    "# H3_M\n",
    "\n",
    "score = load_model('../model/drop_model04_H3_M.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"drop_model04_H3_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H3_L\n",
    "\n",
    "score = load_model('../model/drop_model02_H3_L.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02_H3_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/drop_model03_H3_L.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"drop_model03_H3_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H3_F\n",
    "score = load_model('../model/drop_model05_H3_F.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"drop_model05_H3_F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H4_H\n",
    "score = load_model('../model/drop_model01_H4_H.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model02_H4_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "\n",
    "score = load_model('../model/drop_model03_H4_H.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"drop_model03_H4_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H4_L\n",
    "\n",
    "score = load_model('../model/drop_model02_H4_L.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"drop_model02_H4_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dropout and regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HtHfSEgO6sUN",
    "outputId": "b7fd6a48-30f1-470e-f92b-118a7046a09a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_68 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 3)                 78        \n",
      "=================================================================\n",
      "Total params: 1,378\n",
      "Trainable params: 1,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.3318,  loss:1.1508,  val_accuracy:0.4714,  val_loss:1.1366,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5132,  loss:1.0187,  val_accuracy:0.5308,  val_loss:1.0004,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5135,  loss:1.0125,  val_accuracy:0.5323,  val_loss:0.9937,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5124,  loss:1.0130,  val_accuracy:0.5316,  val_loss:0.9922,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5150,  loss:1.0103,  val_accuracy:0.5308,  val_loss:0.9906,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5128,  loss:1.0088,  val_accuracy:0.5338,  val_loss:0.9895,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5137,  loss:1.0074,  val_accuracy:0.5338,  val_loss:0.9884,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5177,  loss:1.0085,  val_accuracy:0.5323,  val_loss:0.9891,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5152,  loss:1.0075,  val_accuracy:0.5323,  val_loss:0.9877,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5179,  loss:1.0037,  val_accuracy:0.5368,  val_loss:0.9867,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5152,  loss:1.0054,  val_accuracy:0.5346,  val_loss:0.9867,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5188,  loss:1.0067,  val_accuracy:0.5361,  val_loss:0.9866,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5173,  loss:1.0036,  val_accuracy:0.5331,  val_loss:0.9850,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5198,  loss:1.0030,  val_accuracy:0.5338,  val_loss:0.9845,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5152,  loss:1.0034,  val_accuracy:0.5353,  val_loss:0.9844,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5231,  loss:1.0038,  val_accuracy:0.5353,  val_loss:0.9836,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5188,  loss:1.0030,  val_accuracy:0.5346,  val_loss:0.9828,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5218,  loss:1.0043,  val_accuracy:0.5361,  val_loss:0.9833,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5192,  loss:1.0017,  val_accuracy:0.5331,  val_loss:0.9824,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5194,  loss:1.0009,  val_accuracy:0.5361,  val_loss:0.9837,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5209,  loss:1.0022,  val_accuracy:0.5346,  val_loss:0.9825,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5181,  loss:1.0018,  val_accuracy:0.5346,  val_loss:0.9820,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5199,  loss:1.0019,  val_accuracy:0.5368,  val_loss:0.9811,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, accuracy:0.5196,  loss:1.0026,  val_accuracy:0.5338,  val_loss:0.9818,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, accuracy:0.5226,  loss:1.0004,  val_accuracy:0.5383,  val_loss:0.9805,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, accuracy:0.5181,  loss:1.0003,  val_accuracy:0.5346,  val_loss:0.9800,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, accuracy:0.5166,  loss:0.9998,  val_accuracy:0.5368,  val_loss:0.9804,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, accuracy:0.5186,  loss:0.9975,  val_accuracy:0.5398,  val_loss:0.9802,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, accuracy:0.5226,  loss:0.9976,  val_accuracy:0.5353,  val_loss:0.9792,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, accuracy:0.5250,  loss:0.9994,  val_accuracy:0.5368,  val_loss:0.9793,  \n",
      "....................................................................................................\n",
      "Epoch: 3000, accuracy:0.5243,  loss:0.9981,  val_accuracy:0.5368,  val_loss:0.9791,  \n",
      "....................................................................................................\n",
      "Epoch: 3100, accuracy:0.5237,  loss:0.9954,  val_accuracy:0.5361,  val_loss:0.9791,  \n",
      "....................................................................................................\n",
      "Epoch: 3200, accuracy:0.5213,  loss:1.0002,  val_accuracy:0.5376,  val_loss:0.9787,  \n",
      "....................................................................................................\n",
      "Epoch: 3300, accuracy:0.5198,  loss:0.9964,  val_accuracy:0.5361,  val_loss:0.9782,  \n",
      "....................................................................................................\n",
      "Epoch: 3400, accuracy:0.5241,  loss:0.9950,  val_accuracy:0.5421,  val_loss:0.9794,  \n",
      "....................................................................................................\n",
      "Epoch: 3500, accuracy:0.5241,  loss:0.9963,  val_accuracy:0.5398,  val_loss:0.9779,  \n",
      "..........Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_71 (Dense)             (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 3)                 102       \n",
      "=================================================================\n",
      "Total params: 2,346\n",
      "Trainable params: 2,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, accuracy:0.4575,  loss:1.1382,  val_accuracy:0.4759,  val_loss:1.1207,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5152,  loss:1.0173,  val_accuracy:0.5323,  val_loss:1.0027,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5169,  loss:1.0121,  val_accuracy:0.5241,  val_loss:1.0015,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5190,  loss:1.0096,  val_accuracy:0.5308,  val_loss:0.9968,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5164,  loss:1.0067,  val_accuracy:0.5301,  val_loss:0.9961,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5175,  loss:1.0049,  val_accuracy:0.5316,  val_loss:0.9944,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5179,  loss:1.0084,  val_accuracy:0.5308,  val_loss:0.9948,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5207,  loss:1.0049,  val_accuracy:0.5301,  val_loss:0.9932,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5190,  loss:1.0035,  val_accuracy:0.5308,  val_loss:0.9924,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5184,  loss:1.0025,  val_accuracy:0.5323,  val_loss:0.9930,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5190,  loss:1.0036,  val_accuracy:0.5308,  val_loss:0.9912,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5216,  loss:1.0020,  val_accuracy:0.5316,  val_loss:0.9903,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5231,  loss:1.0010,  val_accuracy:0.5331,  val_loss:0.9904,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5220,  loss:1.0014,  val_accuracy:0.5331,  val_loss:0.9891,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5218,  loss:0.9994,  val_accuracy:0.5316,  val_loss:0.9886,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5214,  loss:0.9991,  val_accuracy:0.5293,  val_loss:0.9881,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5184,  loss:0.9991,  val_accuracy:0.5301,  val_loss:0.9874,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5201,  loss:1.0011,  val_accuracy:0.5316,  val_loss:0.9874,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5252,  loss:0.9988,  val_accuracy:0.5346,  val_loss:0.9887,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5261,  loss:0.9958,  val_accuracy:0.5293,  val_loss:0.9865,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5211,  loss:0.9972,  val_accuracy:0.5308,  val_loss:0.9857,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5245,  loss:0.9976,  val_accuracy:0.5353,  val_loss:0.9863,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5299,  loss:0.9947,  val_accuracy:0.5346,  val_loss:0.9848,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, accuracy:0.5231,  loss:0.9977,  val_accuracy:0.5323,  val_loss:0.9846,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, accuracy:0.5273,  loss:0.9951,  val_accuracy:0.5383,  val_loss:0.9846,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, accuracy:0.5292,  loss:0.9961,  val_accuracy:0.5376,  val_loss:0.9844,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, accuracy:0.5265,  loss:0.9951,  val_accuracy:0.5316,  val_loss:0.9836,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, accuracy:0.5301,  loss:0.9931,  val_accuracy:0.5376,  val_loss:0.9841,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, accuracy:0.5307,  loss:0.9915,  val_accuracy:0.5368,  val_loss:0.9834,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, accuracy:0.5260,  loss:0.9947,  val_accuracy:0.5338,  val_loss:0.9830,  \n",
      "....................................................................................................\n",
      "Epoch: 3000, accuracy:0.5271,  loss:0.9959,  val_accuracy:0.5398,  val_loss:0.9829,  \n",
      "....................................................................................................\n",
      "Epoch: 3100, accuracy:0.5246,  loss:0.9932,  val_accuracy:0.5361,  val_loss:0.9825,  \n",
      "....................................................................................................\n",
      "Epoch: 3200, accuracy:0.5267,  loss:0.9928,  val_accuracy:0.5383,  val_loss:0.9822,  \n",
      "....................................................................................................\n",
      "Epoch: 3300, accuracy:0.5278,  loss:0.9915,  val_accuracy:0.5391,  val_loss:0.9821,  \n",
      "....................................................................................................\n",
      "Epoch: 3400, accuracy:0.5307,  loss:0.9916,  val_accuracy:0.5398,  val_loss:0.9822,  \n",
      "....................................................................................................\n",
      "Epoch: 3500, accuracy:0.5318,  loss:0.9952,  val_accuracy:0.5391,  val_loss:0.9834,  \n",
      "....................................................................................................\n",
      "Epoch: 3600, accuracy:0.5275,  loss:0.9949,  val_accuracy:0.5331,  val_loss:0.9820,  \n",
      "....................................................................................................\n",
      "Epoch: 3700, accuracy:0.5263,  loss:0.9950,  val_accuracy:0.5406,  val_loss:0.9817,  \n",
      "....................................................................................................\n",
      "Epoch: 3800, accuracy:0.5275,  loss:0.9918,  val_accuracy:0.5406,  val_loss:0.9817,  \n",
      "....................................................................................................\n",
      "Epoch: 3900, accuracy:0.5290,  loss:0.9915,  val_accuracy:0.5406,  val_loss:0.9808,  \n",
      "....................................................................................................\n",
      "Epoch: 4000, accuracy:0.5301,  loss:0.9915,  val_accuracy:0.5391,  val_loss:0.9810,  \n",
      "....................................................................................................\n",
      "Epoch: 4100, accuracy:0.5278,  loss:0.9928,  val_accuracy:0.5398,  val_loss:0.9804,  \n",
      "....................................................................................................\n",
      "Epoch: 4200, accuracy:0.5312,  loss:0.9884,  val_accuracy:0.5414,  val_loss:0.9806,  \n",
      "....................................................................................................\n",
      "Epoch: 4300, accuracy:0.5340,  loss:0.9906,  val_accuracy:0.5398,  val_loss:0.9809,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 4400, accuracy:0.5350,  loss:0.9879,  val_accuracy:0.5429,  val_loss:0.9806,  \n",
      "....................................................................................................\n",
      "Epoch: 4500, accuracy:0.5310,  loss:0.9910,  val_accuracy:0.5398,  val_loss:0.9805,  \n",
      "....................................................................................................\n",
      "Epoch: 4600, accuracy:0.5290,  loss:0.9910,  val_accuracy:0.5414,  val_loss:0.9805,  \n",
      "....................................................................................................\n",
      "Epoch: 4700, accuracy:0.5282,  loss:0.9901,  val_accuracy:0.5361,  val_loss:0.9801,  \n",
      "....................................................................................................\n",
      "Epoch: 4800, accuracy:0.5265,  loss:0.9899,  val_accuracy:0.5406,  val_loss:0.9795,  \n",
      "....................................................................................................\n",
      "Epoch: 4900, accuracy:0.5290,  loss:0.9914,  val_accuracy:0.5414,  val_loss:0.9805,  \n",
      "....................................................................................................\n",
      "Epoch: 5000, accuracy:0.5312,  loss:0.9900,  val_accuracy:0.5361,  val_loss:0.9796,  \n",
      "....................................................................................................\n",
      "Epoch: 5100, accuracy:0.5301,  loss:0.9886,  val_accuracy:0.5368,  val_loss:0.9792,  \n",
      "....................................................................................................\n",
      "Epoch: 5200, accuracy:0.5284,  loss:0.9888,  val_accuracy:0.5421,  val_loss:0.9792,  \n",
      "....................................................................................................\n",
      "Epoch: 5300, accuracy:0.5350,  loss:0.9897,  val_accuracy:0.5421,  val_loss:0.9791,  \n",
      "....................................................................................................\n",
      "Epoch: 5400, accuracy:0.5314,  loss:0.9878,  val_accuracy:0.5421,  val_loss:0.9795,  \n",
      "....................................................................................................\n",
      "Epoch: 5500, accuracy:0.5318,  loss:0.9877,  val_accuracy:0.5451,  val_loss:0.9795,  \n",
      "....................................................................................................\n",
      "Epoch: 5600, accuracy:0.5325,  loss:0.9886,  val_accuracy:0.5436,  val_loss:0.9791,  \n",
      "....................................................................................................\n",
      "Epoch: 5700, accuracy:0.5290,  loss:0.9895,  val_accuracy:0.5361,  val_loss:0.9786,  \n",
      "....................................................................................................\n",
      "Epoch: 5800, accuracy:0.5329,  loss:0.9893,  val_accuracy:0.5398,  val_loss:0.9787,  \n",
      "....................................................................................................\n",
      "Epoch: 5900, accuracy:0.5293,  loss:0.9882,  val_accuracy:0.5383,  val_loss:0.9785,  \n",
      "....................................................................................................\n",
      "Epoch: 6000, accuracy:0.5309,  loss:0.9889,  val_accuracy:0.5383,  val_loss:0.9784,  \n",
      "....................................................................................................\n",
      "Epoch: 6100, accuracy:0.5325,  loss:0.9860,  val_accuracy:0.5429,  val_loss:0.9791,  \n",
      "....................................................................................................\n",
      "Epoch: 6200, accuracy:0.5280,  loss:0.9878,  val_accuracy:0.5391,  val_loss:0.9782,  \n",
      "....................................................................................................\n",
      "Epoch: 6300, accuracy:0.5344,  loss:0.9865,  val_accuracy:0.5414,  val_loss:0.9782,  \n",
      "....................................................................................................\n",
      "Epoch: 6400, accuracy:0.5314,  loss:0.9880,  val_accuracy:0.5406,  val_loss:0.9778,  \n",
      "....................................................................................................\n",
      "Epoch: 6500, accuracy:0.5342,  loss:0.9844,  val_accuracy:0.5353,  val_loss:0.9784,  \n",
      "....................................................................................................\n",
      "Epoch: 6600, accuracy:0.5314,  loss:0.9875,  val_accuracy:0.5376,  val_loss:0.9778,  \n",
      "....................................................................................................\n",
      "Epoch: 6700, accuracy:0.5350,  loss:0.9880,  val_accuracy:0.5361,  val_loss:0.9777,  \n",
      "....................................................................................................\n",
      "Epoch: 6800, accuracy:0.5318,  loss:0.9880,  val_accuracy:0.5444,  val_loss:0.9782,  \n",
      ".............................................Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_74 (Dense)             (None, 21)                462       \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 21)                0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 12)                264       \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 3)                 39        \n",
      "=================================================================\n",
      "Total params: 765\n",
      "Trainable params: 765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.3346,  loss:1.1382,  val_accuracy:0.4144,  val_loss:1.1342,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5135,  loss:1.0171,  val_accuracy:0.5153,  val_loss:1.0174,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5215,  loss:1.0112,  val_accuracy:0.5123,  val_loss:1.0099,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5251,  loss:1.0053,  val_accuracy:0.5138,  val_loss:1.0048,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5213,  loss:0.9997,  val_accuracy:0.5183,  val_loss:1.0012,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5202,  loss:0.9986,  val_accuracy:0.5213,  val_loss:0.9994,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5279,  loss:0.9954,  val_accuracy:0.5206,  val_loss:0.9976,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5298,  loss:0.9949,  val_accuracy:0.5198,  val_loss:0.9960,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5271,  loss:0.9926,  val_accuracy:0.5206,  val_loss:0.9946,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5277,  loss:0.9926,  val_accuracy:0.5228,  val_loss:0.9933,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5277,  loss:0.9921,  val_accuracy:0.5228,  val_loss:0.9927,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5339,  loss:0.9907,  val_accuracy:0.5206,  val_loss:0.9916,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5311,  loss:0.9895,  val_accuracy:0.5236,  val_loss:0.9910,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5305,  loss:0.9890,  val_accuracy:0.5221,  val_loss:0.9902,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5350,  loss:0.9900,  val_accuracy:0.5228,  val_loss:0.9889,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5309,  loss:0.9897,  val_accuracy:0.5266,  val_loss:0.9897,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5329,  loss:0.9899,  val_accuracy:0.5243,  val_loss:0.9883,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5333,  loss:0.9883,  val_accuracy:0.5251,  val_loss:0.9882,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5279,  loss:0.9878,  val_accuracy:0.5213,  val_loss:0.9868,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5311,  loss:0.9875,  val_accuracy:0.5198,  val_loss:0.9866,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5344,  loss:0.9891,  val_accuracy:0.5251,  val_loss:0.9864,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5324,  loss:0.9854,  val_accuracy:0.5221,  val_loss:0.9857,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5299,  loss:0.9870,  val_accuracy:0.5221,  val_loss:0.9853,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, accuracy:0.5357,  loss:0.9856,  val_accuracy:0.5243,  val_loss:0.9850,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, accuracy:0.5337,  loss:0.9885,  val_accuracy:0.5266,  val_loss:0.9849,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, accuracy:0.5327,  loss:0.9894,  val_accuracy:0.5198,  val_loss:0.9846,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, accuracy:0.5363,  loss:0.9853,  val_accuracy:0.5266,  val_loss:0.9840,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, accuracy:0.5369,  loss:0.9848,  val_accuracy:0.5228,  val_loss:0.9837,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, accuracy:0.5356,  loss:0.9864,  val_accuracy:0.5251,  val_loss:0.9841,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, accuracy:0.5339,  loss:0.9847,  val_accuracy:0.5251,  val_loss:0.9833,  \n",
      "....................................................................................................\n",
      "Epoch: 3000, accuracy:0.5326,  loss:0.9836,  val_accuracy:0.5266,  val_loss:0.9828,  \n",
      "....................................................................................................\n",
      "Epoch: 3100, accuracy:0.5327,  loss:0.9865,  val_accuracy:0.5198,  val_loss:0.9830,  \n",
      "....................................................................................................\n",
      "Epoch: 3200, accuracy:0.5342,  loss:0.9855,  val_accuracy:0.5206,  val_loss:0.9829,  \n",
      "....................................................................................................\n",
      "Epoch: 3300, accuracy:0.5320,  loss:0.9844,  val_accuracy:0.5266,  val_loss:0.9828,  \n",
      "....................................................................................................\n",
      "Epoch: 3400, accuracy:0.5309,  loss:0.9858,  val_accuracy:0.5251,  val_loss:0.9824,  \n",
      "....................................................................................................\n",
      "Epoch: 3500, accuracy:0.5335,  loss:0.9842,  val_accuracy:0.5280,  val_loss:0.9821,  \n",
      "....................................................................................................\n",
      "Epoch: 3600, accuracy:0.5378,  loss:0.9814,  val_accuracy:0.5258,  val_loss:0.9820,  \n",
      "....................................................................................................\n",
      "Epoch: 3700, accuracy:0.5367,  loss:0.9824,  val_accuracy:0.5266,  val_loss:0.9820,  \n",
      "....................................................................................................\n",
      "Epoch: 3800, accuracy:0.5359,  loss:0.9822,  val_accuracy:0.5228,  val_loss:0.9823,  \n",
      "....................................................................................................\n",
      "Epoch: 3900, accuracy:0.5367,  loss:0.9842,  val_accuracy:0.5295,  val_loss:0.9817,  \n",
      "....................................................................................................\n",
      "Epoch: 4000, accuracy:0.5346,  loss:0.9849,  val_accuracy:0.5280,  val_loss:0.9814,  \n",
      "....................................................................................................\n",
      "Epoch: 4100, accuracy:0.5361,  loss:0.9819,  val_accuracy:0.5295,  val_loss:0.9815,  \n",
      "....................................................................................................\n",
      "Epoch: 4200, accuracy:0.5371,  loss:0.9800,  val_accuracy:0.5303,  val_loss:0.9811,  \n",
      "....................................................................................................\n",
      "Epoch: 4300, accuracy:0.5365,  loss:0.9825,  val_accuracy:0.5280,  val_loss:0.9808,  \n",
      "....................................................................................................\n",
      "Epoch: 4400, accuracy:0.5359,  loss:0.9845,  val_accuracy:0.5266,  val_loss:0.9805,  \n",
      "....................................................................................................\n",
      "Epoch: 4500, accuracy:0.5372,  loss:0.9823,  val_accuracy:0.5280,  val_loss:0.9806,  \n",
      "...........................................................................................Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_77 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 4)                 56        \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 253\n",
      "Trainable params: 253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.2767,  loss:1.1514,  val_accuracy:0.2552,  val_loss:1.1225,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5149,  loss:1.0080,  val_accuracy:0.5317,  val_loss:0.9956,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5191,  loss:1.0036,  val_accuracy:0.5292,  val_loss:0.9923,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5221,  loss:0.9990,  val_accuracy:0.5312,  val_loss:0.9896,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5193,  loss:1.0024,  val_accuracy:0.5302,  val_loss:0.9907,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5207,  loss:0.9981,  val_accuracy:0.5310,  val_loss:0.9883,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5208,  loss:0.9969,  val_accuracy:0.5297,  val_loss:0.9886,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5202,  loss:0.9972,  val_accuracy:0.5317,  val_loss:0.9877,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5228,  loss:0.9997,  val_accuracy:0.5305,  val_loss:0.9867,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5163,  loss:0.9988,  val_accuracy:0.5310,  val_loss:0.9872,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5207,  loss:0.9988,  val_accuracy:0.5325,  val_loss:0.9866,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5237,  loss:0.9977,  val_accuracy:0.5332,  val_loss:0.9868,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5220,  loss:0.9981,  val_accuracy:0.5302,  val_loss:0.9874,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5178,  loss:0.9959,  val_accuracy:0.5317,  val_loss:0.9855,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5241,  loss:0.9970,  val_accuracy:0.5322,  val_loss:0.9858,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5181,  loss:0.9983,  val_accuracy:0.5330,  val_loss:0.9857,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5178,  loss:0.9973,  val_accuracy:0.5312,  val_loss:0.9863,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5209,  loss:0.9983,  val_accuracy:0.5325,  val_loss:0.9856,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5200,  loss:0.9966,  val_accuracy:0.5320,  val_loss:0.9857,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5202,  loss:0.9955,  val_accuracy:0.5342,  val_loss:0.9853,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5213,  loss:0.9961,  val_accuracy:0.5335,  val_loss:0.9852,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5225,  loss:0.9962,  val_accuracy:0.5302,  val_loss:0.9862,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5193,  loss:0.9961,  val_accuracy:0.5322,  val_loss:0.9850,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, accuracy:0.5174,  loss:0.9970,  val_accuracy:0.5315,  val_loss:0.9856,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, accuracy:0.5195,  loss:0.9978,  val_accuracy:0.5312,  val_loss:0.9855,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, accuracy:0.5198,  loss:0.9968,  val_accuracy:0.5292,  val_loss:0.9859,  \n",
      ".....................Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_80 (Dense)             (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 3)                 90        \n",
      "=================================================================\n",
      "Total params: 2,700\n",
      "Trainable params: 2,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.3716,  loss:1.1833,  val_accuracy:0.4884,  val_loss:1.1681,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5176,  loss:1.0170,  val_accuracy:0.5460,  val_loss:0.9929,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5198,  loss:1.0090,  val_accuracy:0.5460,  val_loss:0.9845,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5211,  loss:1.0077,  val_accuracy:0.5557,  val_loss:0.9810,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5219,  loss:1.0014,  val_accuracy:0.5520,  val_loss:0.9771,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5262,  loss:0.9977,  val_accuracy:0.5512,  val_loss:0.9743,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5279,  loss:1.0000,  val_accuracy:0.5542,  val_loss:0.9749,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5324,  loss:0.9966,  val_accuracy:0.5557,  val_loss:0.9728,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5279,  loss:0.9958,  val_accuracy:0.5542,  val_loss:0.9717,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5322,  loss:0.9921,  val_accuracy:0.5557,  val_loss:0.9702,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5247,  loss:0.9949,  val_accuracy:0.5557,  val_loss:0.9727,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5333,  loss:0.9923,  val_accuracy:0.5572,  val_loss:0.9714,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5312,  loss:0.9928,  val_accuracy:0.5580,  val_loss:0.9686,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5290,  loss:0.9937,  val_accuracy:0.5542,  val_loss:0.9718,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5402,  loss:0.9907,  val_accuracy:0.5565,  val_loss:0.9686,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5271,  loss:0.9932,  val_accuracy:0.5587,  val_loss:0.9701,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5324,  loss:0.9874,  val_accuracy:0.5587,  val_loss:0.9673,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5333,  loss:0.9904,  val_accuracy:0.5602,  val_loss:0.9672,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5312,  loss:0.9899,  val_accuracy:0.5602,  val_loss:0.9678,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5305,  loss:0.9872,  val_accuracy:0.5595,  val_loss:0.9686,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5387,  loss:0.9861,  val_accuracy:0.5580,  val_loss:0.9685,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5389,  loss:0.9869,  val_accuracy:0.5647,  val_loss:0.9661,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5374,  loss:0.9857,  val_accuracy:0.5587,  val_loss:0.9675,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, accuracy:0.5337,  loss:0.9910,  val_accuracy:0.5587,  val_loss:0.9691,  \n",
      "................................................................Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_84 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 13)                338       \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 1,212\n",
      "Trainable params: 1,212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.3770,  loss:1.1480,  val_accuracy:0.4714,  val_loss:1.1359,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5036,  loss:1.0313,  val_accuracy:0.5316,  val_loss:1.0041,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5152,  loss:1.0241,  val_accuracy:0.5316,  val_loss:0.9999,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5103,  loss:1.0195,  val_accuracy:0.5353,  val_loss:0.9976,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5075,  loss:1.0169,  val_accuracy:0.5376,  val_loss:0.9958,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5100,  loss:1.0175,  val_accuracy:0.5308,  val_loss:0.9954,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5109,  loss:1.0176,  val_accuracy:0.5353,  val_loss:0.9934,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5134,  loss:1.0182,  val_accuracy:0.5323,  val_loss:0.9928,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5137,  loss:1.0137,  val_accuracy:0.5383,  val_loss:0.9921,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5094,  loss:1.0169,  val_accuracy:0.5331,  val_loss:0.9920,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5141,  loss:1.0126,  val_accuracy:0.5361,  val_loss:0.9914,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5156,  loss:1.0097,  val_accuracy:0.5323,  val_loss:0.9912,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5098,  loss:1.0141,  val_accuracy:0.5338,  val_loss:0.9912,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5094,  loss:1.0120,  val_accuracy:0.5338,  val_loss:0.9909,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5150,  loss:1.0115,  val_accuracy:0.5353,  val_loss:0.9900,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5169,  loss:1.0118,  val_accuracy:0.5323,  val_loss:0.9901,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5092,  loss:1.0138,  val_accuracy:0.5331,  val_loss:0.9889,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5149,  loss:1.0099,  val_accuracy:0.5353,  val_loss:0.9902,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5194,  loss:1.0102,  val_accuracy:0.5338,  val_loss:0.9879,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5132,  loss:1.0089,  val_accuracy:0.5353,  val_loss:0.9880,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5181,  loss:1.0084,  val_accuracy:0.5331,  val_loss:0.9869,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5192,  loss:1.0055,  val_accuracy:0.5383,  val_loss:0.9879,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5181,  loss:1.0064,  val_accuracy:0.5376,  val_loss:0.9878,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, accuracy:0.5211,  loss:1.0065,  val_accuracy:0.5406,  val_loss:0.9877,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, accuracy:0.5145,  loss:1.0082,  val_accuracy:0.5353,  val_loss:0.9868,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, accuracy:0.5203,  loss:1.0079,  val_accuracy:0.5361,  val_loss:0.9860,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, accuracy:0.5211,  loss:1.0045,  val_accuracy:0.5383,  val_loss:0.9860,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, accuracy:0.5196,  loss:1.0053,  val_accuracy:0.5376,  val_loss:0.9840,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, accuracy:0.5181,  loss:1.0057,  val_accuracy:0.5353,  val_loss:0.9839,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, accuracy:0.5214,  loss:1.0044,  val_accuracy:0.5398,  val_loss:0.9832,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 3000, accuracy:0.5231,  loss:1.0048,  val_accuracy:0.5391,  val_loss:0.9831,  \n",
      "....................................................................................................\n",
      "Epoch: 3100, accuracy:0.5194,  loss:1.0035,  val_accuracy:0.5368,  val_loss:0.9831,  \n",
      "....................................................................................................\n",
      "Epoch: 3200, accuracy:0.5162,  loss:1.0064,  val_accuracy:0.5421,  val_loss:0.9846,  \n",
      "....................................................................................................\n",
      "Epoch: 3300, accuracy:0.5207,  loss:1.0042,  val_accuracy:0.5376,  val_loss:0.9835,  \n",
      "....................................................................................................\n",
      "Epoch: 3400, accuracy:0.5218,  loss:1.0056,  val_accuracy:0.5398,  val_loss:0.9818,  \n",
      "....................................................................................................\n",
      "Epoch: 3500, accuracy:0.5203,  loss:1.0040,  val_accuracy:0.5383,  val_loss:0.9811,  \n",
      "....................................................................................................\n",
      "Epoch: 3600, accuracy:0.5214,  loss:1.0025,  val_accuracy:0.5383,  val_loss:0.9811,  \n",
      "....................................................................................................\n",
      "Epoch: 3700, accuracy:0.5237,  loss:1.0007,  val_accuracy:0.5398,  val_loss:0.9801,  \n",
      "....................................................................................................\n",
      "Epoch: 3800, accuracy:0.5263,  loss:1.0017,  val_accuracy:0.5421,  val_loss:0.9814,  \n",
      "....................................................................................................\n",
      "Epoch: 3900, accuracy:0.5205,  loss:1.0083,  val_accuracy:0.5459,  val_loss:0.9827,  \n",
      "....................................................................................................\n",
      "Epoch: 4000, accuracy:0.5233,  loss:1.0048,  val_accuracy:0.5406,  val_loss:0.9805,  \n",
      "....................................................................................................\n",
      "Epoch: 4100, accuracy:0.5205,  loss:1.0003,  val_accuracy:0.5414,  val_loss:0.9799,  \n",
      "....................................................................................................\n",
      "Epoch: 4200, accuracy:0.5250,  loss:1.0018,  val_accuracy:0.5398,  val_loss:0.9793,  \n",
      "....................................................................................................\n",
      "Epoch: 4300, accuracy:0.5246,  loss:1.0018,  val_accuracy:0.5406,  val_loss:0.9808,  \n",
      "....................................................................................................\n",
      "Epoch: 4400, accuracy:0.5207,  loss:1.0024,  val_accuracy:0.5406,  val_loss:0.9792,  \n",
      "....................................................................................................\n",
      "Epoch: 4500, accuracy:0.5156,  loss:1.0060,  val_accuracy:0.5429,  val_loss:0.9799,  \n",
      "....................................................................................................\n",
      "Epoch: 4600, accuracy:0.5213,  loss:1.0004,  val_accuracy:0.5429,  val_loss:0.9785,  \n",
      "............................................................................................Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_88 (Dense)             (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 8)                 272       \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 1,493\n",
      "Trainable params: 1,493\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.2716,  loss:1.1609,  val_accuracy:0.2376,  val_loss:1.1528,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.4947,  loss:1.0313,  val_accuracy:0.5316,  val_loss:1.0117,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5075,  loss:1.0261,  val_accuracy:0.5271,  val_loss:1.0078,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5055,  loss:1.0247,  val_accuracy:0.5293,  val_loss:1.0054,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5060,  loss:1.0251,  val_accuracy:0.5226,  val_loss:1.0050,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5011,  loss:1.0256,  val_accuracy:0.5316,  val_loss:1.0048,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5015,  loss:1.0224,  val_accuracy:0.5286,  val_loss:1.0037,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5051,  loss:1.0235,  val_accuracy:0.5323,  val_loss:1.0037,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5043,  loss:1.0250,  val_accuracy:0.5308,  val_loss:1.0028,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5117,  loss:1.0189,  val_accuracy:0.5293,  val_loss:1.0020,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5083,  loss:1.0194,  val_accuracy:0.5241,  val_loss:1.0023,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5113,  loss:1.0178,  val_accuracy:0.5241,  val_loss:1.0017,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5098,  loss:1.0178,  val_accuracy:0.5241,  val_loss:1.0015,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5071,  loss:1.0189,  val_accuracy:0.5316,  val_loss:1.0010,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5040,  loss:1.0190,  val_accuracy:0.5278,  val_loss:1.0014,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5085,  loss:1.0181,  val_accuracy:0.5308,  val_loss:1.0007,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5068,  loss:1.0175,  val_accuracy:0.5331,  val_loss:1.0005,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5068,  loss:1.0203,  val_accuracy:0.5323,  val_loss:1.0011,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5034,  loss:1.0226,  val_accuracy:0.5323,  val_loss:1.0004,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5062,  loss:1.0173,  val_accuracy:0.5308,  val_loss:0.9997,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5060,  loss:1.0193,  val_accuracy:0.5323,  val_loss:0.9994,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5062,  loss:1.0216,  val_accuracy:0.5316,  val_loss:0.9991,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5122,  loss:1.0157,  val_accuracy:0.5331,  val_loss:0.9990,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, accuracy:0.5040,  loss:1.0205,  val_accuracy:0.5323,  val_loss:0.9993,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, accuracy:0.5083,  loss:1.0176,  val_accuracy:0.5323,  val_loss:0.9989,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, accuracy:0.5141,  loss:1.0149,  val_accuracy:0.5278,  val_loss:0.9985,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, accuracy:0.5064,  loss:1.0172,  val_accuracy:0.5331,  val_loss:0.9983,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, accuracy:0.5019,  loss:1.0169,  val_accuracy:0.5293,  val_loss:0.9981,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, accuracy:0.5060,  loss:1.0169,  val_accuracy:0.5323,  val_loss:0.9980,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, accuracy:0.5124,  loss:1.0165,  val_accuracy:0.5323,  val_loss:0.9979,  \n",
      "....................................................................................................\n",
      "Epoch: 3000, accuracy:0.5070,  loss:1.0180,  val_accuracy:0.5301,  val_loss:0.9979,  \n",
      "....................................................................................................\n",
      "Epoch: 3100, accuracy:0.5023,  loss:1.0186,  val_accuracy:0.5301,  val_loss:0.9976,  \n",
      "....................................................................................................\n",
      "Epoch: 3200, accuracy:0.5017,  loss:1.0155,  val_accuracy:0.5323,  val_loss:0.9974,  \n",
      "....................................................................................................\n",
      "Epoch: 3300, accuracy:0.5109,  loss:1.0160,  val_accuracy:0.5308,  val_loss:0.9975,  \n",
      "....................................................................................................\n",
      "Epoch: 3400, accuracy:0.5081,  loss:1.0179,  val_accuracy:0.5331,  val_loss:0.9971,  \n",
      "....................................................................................................\n",
      "Epoch: 3500, accuracy:0.5075,  loss:1.0145,  val_accuracy:0.5323,  val_loss:0.9968,  \n",
      "....................................................................................................\n",
      "Epoch: 3600, accuracy:0.5047,  loss:1.0167,  val_accuracy:0.5301,  val_loss:0.9968,  \n",
      "....................................................................................................\n",
      "Epoch: 3700, accuracy:0.5113,  loss:1.0140,  val_accuracy:0.5308,  val_loss:0.9963,  \n",
      "....................................................................................................\n",
      "Epoch: 3800, accuracy:0.5139,  loss:1.0156,  val_accuracy:0.5331,  val_loss:0.9960,  \n",
      ".................................................................................Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_92 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 770\n",
      "Trainable params: 770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.3475,  loss:1.1490,  val_accuracy:0.4627,  val_loss:1.1408,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5217,  loss:1.0068,  val_accuracy:0.5327,  val_loss:0.9916,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5224,  loss:1.0008,  val_accuracy:0.5246,  val_loss:0.9924,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5256,  loss:1.0013,  val_accuracy:0.5327,  val_loss:0.9878,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5248,  loss:0.9973,  val_accuracy:0.5332,  val_loss:0.9866,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5275,  loss:0.9996,  val_accuracy:0.5322,  val_loss:0.9863,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5279,  loss:0.9972,  val_accuracy:0.5317,  val_loss:0.9860,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5262,  loss:0.9985,  val_accuracy:0.5310,  val_loss:0.9859,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5277,  loss:0.9971,  val_accuracy:0.5320,  val_loss:0.9853,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5262,  loss:0.9936,  val_accuracy:0.5310,  val_loss:0.9849,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5259,  loss:0.9958,  val_accuracy:0.5310,  val_loss:0.9850,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5255,  loss:0.9971,  val_accuracy:0.5305,  val_loss:0.9846,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5261,  loss:0.9952,  val_accuracy:0.5322,  val_loss:0.9847,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5261,  loss:0.9961,  val_accuracy:0.5277,  val_loss:0.9868,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5269,  loss:0.9965,  val_accuracy:0.5315,  val_loss:0.9842,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5277,  loss:0.9961,  val_accuracy:0.5327,  val_loss:0.9842,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5262,  loss:0.9937,  val_accuracy:0.5297,  val_loss:0.9841,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5266,  loss:0.9975,  val_accuracy:0.5307,  val_loss:0.9843,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5293,  loss:0.9944,  val_accuracy:0.5320,  val_loss:0.9834,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5262,  loss:0.9933,  val_accuracy:0.5315,  val_loss:0.9836,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5267,  loss:0.9951,  val_accuracy:0.5320,  val_loss:0.9835,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5270,  loss:0.9922,  val_accuracy:0.5315,  val_loss:0.9836,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5251,  loss:0.9968,  val_accuracy:0.5310,  val_loss:0.9838,  \n",
      "...................................................................................Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_97 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 13)                338       \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 1,394\n",
      "Trainable params: 1,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.2703,  loss:1.1705,  val_accuracy:0.2451,  val_loss:1.1614,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5041,  loss:1.0326,  val_accuracy:0.5338,  val_loss:1.0089,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5081,  loss:1.0273,  val_accuracy:0.5323,  val_loss:1.0034,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5051,  loss:1.0258,  val_accuracy:0.5346,  val_loss:1.0017,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5096,  loss:1.0227,  val_accuracy:0.5323,  val_loss:0.9998,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5090,  loss:1.0223,  val_accuracy:0.5331,  val_loss:0.9997,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5130,  loss:1.0215,  val_accuracy:0.5353,  val_loss:0.9983,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5098,  loss:1.0193,  val_accuracy:0.5316,  val_loss:0.9986,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5154,  loss:1.0178,  val_accuracy:0.5338,  val_loss:0.9977,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5083,  loss:1.0180,  val_accuracy:0.5368,  val_loss:0.9966,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5117,  loss:1.0177,  val_accuracy:0.5361,  val_loss:0.9981,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5117,  loss:1.0165,  val_accuracy:0.5346,  val_loss:0.9964,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5102,  loss:1.0174,  val_accuracy:0.5361,  val_loss:0.9963,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5150,  loss:1.0195,  val_accuracy:0.5376,  val_loss:0.9972,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5173,  loss:1.0171,  val_accuracy:0.5361,  val_loss:0.9952,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5117,  loss:1.0162,  val_accuracy:0.5361,  val_loss:0.9940,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5162,  loss:1.0157,  val_accuracy:0.5353,  val_loss:0.9945,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5167,  loss:1.0127,  val_accuracy:0.5368,  val_loss:0.9928,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5179,  loss:1.0119,  val_accuracy:0.5421,  val_loss:0.9937,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5124,  loss:1.0147,  val_accuracy:0.5376,  val_loss:0.9939,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5188,  loss:1.0116,  val_accuracy:0.5368,  val_loss:0.9927,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5126,  loss:1.0156,  val_accuracy:0.5368,  val_loss:0.9937,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5143,  loss:1.0163,  val_accuracy:0.5353,  val_loss:0.9914,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, accuracy:0.5188,  loss:1.0129,  val_accuracy:0.5406,  val_loss:0.9931,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, accuracy:0.5235,  loss:1.0101,  val_accuracy:0.5391,  val_loss:0.9906,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, accuracy:0.5111,  loss:1.0139,  val_accuracy:0.5406,  val_loss:0.9926,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, accuracy:0.5188,  loss:1.0108,  val_accuracy:0.5391,  val_loss:0.9901,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, accuracy:0.5179,  loss:1.0092,  val_accuracy:0.5398,  val_loss:0.9897,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, accuracy:0.5213,  loss:1.0125,  val_accuracy:0.5376,  val_loss:0.9898,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, accuracy:0.5150,  loss:1.0112,  val_accuracy:0.5391,  val_loss:0.9891,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 3000, accuracy:0.5205,  loss:1.0073,  val_accuracy:0.5414,  val_loss:0.9890,  \n",
      "....................................................................................................\n",
      "Epoch: 3100, accuracy:0.5220,  loss:1.0106,  val_accuracy:0.5398,  val_loss:0.9892,  \n",
      "....................................................................................................\n",
      "Epoch: 3200, accuracy:0.5169,  loss:1.0102,  val_accuracy:0.5429,  val_loss:0.9876,  \n",
      "....................................................................................................\n",
      "Epoch: 3300, accuracy:0.5196,  loss:1.0124,  val_accuracy:0.5406,  val_loss:0.9877,  \n",
      "....................................................................................................\n",
      "Epoch: 3400, accuracy:0.5192,  loss:1.0076,  val_accuracy:0.5368,  val_loss:0.9867,  \n",
      "....................................................................................................\n",
      "Epoch: 3500, accuracy:0.5239,  loss:1.0094,  val_accuracy:0.5398,  val_loss:0.9870,  \n",
      "....................................................................................................\n",
      "Epoch: 3600, accuracy:0.5124,  loss:1.0055,  val_accuracy:0.5451,  val_loss:0.9859,  \n",
      "....................................................................................................\n",
      "Epoch: 3700, accuracy:0.5184,  loss:1.0115,  val_accuracy:0.5429,  val_loss:0.9886,  \n",
      "...........................................................Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_102 (Dense)            (None, 21)                462       \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 21)                0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 5)                 110       \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 650\n",
      "Trainable params: 650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.4489,  loss:1.1322,  val_accuracy:0.4488,  val_loss:1.1310,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.4858,  loss:1.0399,  val_accuracy:0.4652,  val_loss:1.0314,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.4929,  loss:1.0295,  val_accuracy:0.5108,  val_loss:1.0212,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.4974,  loss:1.0253,  val_accuracy:0.5093,  val_loss:1.0170,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5049,  loss:1.0217,  val_accuracy:0.5131,  val_loss:1.0127,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5065,  loss:1.0193,  val_accuracy:0.5183,  val_loss:1.0092,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5082,  loss:1.0161,  val_accuracy:0.5168,  val_loss:1.0082,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5099,  loss:1.0149,  val_accuracy:0.5123,  val_loss:1.0060,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5107,  loss:1.0144,  val_accuracy:0.5168,  val_loss:1.0066,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5116,  loss:1.0128,  val_accuracy:0.5161,  val_loss:1.0046,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5159,  loss:1.0097,  val_accuracy:0.5183,  val_loss:1.0030,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5206,  loss:1.0113,  val_accuracy:0.5168,  val_loss:1.0032,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5051,  loss:1.0160,  val_accuracy:0.5206,  val_loss:1.0030,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5114,  loss:1.0129,  val_accuracy:0.5161,  val_loss:1.0016,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5144,  loss:1.0083,  val_accuracy:0.5213,  val_loss:1.0020,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5122,  loss:1.0126,  val_accuracy:0.5251,  val_loss:0.9999,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5107,  loss:1.0103,  val_accuracy:0.5183,  val_loss:0.9994,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5189,  loss:1.0113,  val_accuracy:0.5198,  val_loss:0.9997,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5176,  loss:1.0091,  val_accuracy:0.5251,  val_loss:0.9985,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5122,  loss:1.0089,  val_accuracy:0.5251,  val_loss:0.9987,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5189,  loss:1.0105,  val_accuracy:0.5228,  val_loss:0.9986,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5189,  loss:1.0083,  val_accuracy:0.5228,  val_loss:0.9976,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5182,  loss:1.0049,  val_accuracy:0.5236,  val_loss:0.9971,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, accuracy:0.5133,  loss:1.0104,  val_accuracy:0.5243,  val_loss:0.9968,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, accuracy:0.5193,  loss:1.0094,  val_accuracy:0.5243,  val_loss:0.9968,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, accuracy:0.5161,  loss:1.0101,  val_accuracy:0.5206,  val_loss:0.9969,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, accuracy:0.5152,  loss:1.0107,  val_accuracy:0.5213,  val_loss:0.9962,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, accuracy:0.5254,  loss:1.0052,  val_accuracy:0.5273,  val_loss:0.9964,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 2800, accuracy:0.5247,  loss:1.0072,  val_accuracy:0.5198,  val_loss:0.9967,  \n",
      "..............................................................................Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_107 (Dense)            (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 7)                 210       \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 3)                 24        \n",
      "=================================================================\n",
      "Total params: 1,216\n",
      "Trainable params: 1,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.3003,  loss:1.1875,  val_accuracy:0.2752,  val_loss:1.1659,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.4994,  loss:1.0422,  val_accuracy:0.5228,  val_loss:1.0139,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5006,  loss:1.0298,  val_accuracy:0.5393,  val_loss:0.9999,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5073,  loss:1.0251,  val_accuracy:0.5378,  val_loss:0.9953,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5122,  loss:1.0187,  val_accuracy:0.5527,  val_loss:0.9906,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5150,  loss:1.0170,  val_accuracy:0.5527,  val_loss:0.9857,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5112,  loss:1.0182,  val_accuracy:0.5535,  val_loss:0.9860,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5167,  loss:1.0154,  val_accuracy:0.5527,  val_loss:0.9870,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5157,  loss:1.0141,  val_accuracy:0.5512,  val_loss:0.9811,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5195,  loss:1.0180,  val_accuracy:0.5527,  val_loss:0.9828,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5266,  loss:1.0096,  val_accuracy:0.5512,  val_loss:0.9810,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5157,  loss:1.0130,  val_accuracy:0.5527,  val_loss:0.9822,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5183,  loss:1.0119,  val_accuracy:0.5467,  val_loss:0.9841,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5230,  loss:1.0082,  val_accuracy:0.5527,  val_loss:0.9792,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5249,  loss:1.0084,  val_accuracy:0.5565,  val_loss:0.9788,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5260,  loss:1.0071,  val_accuracy:0.5497,  val_loss:0.9807,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5193,  loss:1.0072,  val_accuracy:0.5527,  val_loss:0.9790,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5210,  loss:1.0114,  val_accuracy:0.5505,  val_loss:0.9788,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5262,  loss:1.0071,  val_accuracy:0.5632,  val_loss:0.9753,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5234,  loss:1.0081,  val_accuracy:0.5587,  val_loss:0.9753,  \n",
      "......Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_112 (Dense)            (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 25)                850       \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 19)                494       \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 19)                0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 12)                240       \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 2,805\n",
      "Trainable params: 2,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.3104,  loss:1.2130,  val_accuracy:0.4150,  val_loss:1.1994,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5085,  loss:1.0391,  val_accuracy:0.5308,  val_loss:1.0203,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5064,  loss:1.0309,  val_accuracy:0.5256,  val_loss:1.0141,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5137,  loss:1.0268,  val_accuracy:0.5316,  val_loss:1.0087,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5182,  loss:1.0212,  val_accuracy:0.5316,  val_loss:1.0065,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5150,  loss:1.0277,  val_accuracy:0.5338,  val_loss:1.0062,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5130,  loss:1.0269,  val_accuracy:0.5331,  val_loss:1.0047,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5207,  loss:1.0216,  val_accuracy:0.5331,  val_loss:1.0037,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5139,  loss:1.0247,  val_accuracy:0.5286,  val_loss:1.0034,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5154,  loss:1.0250,  val_accuracy:0.5323,  val_loss:1.0023,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5194,  loss:1.0255,  val_accuracy:0.5308,  val_loss:1.0011,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5207,  loss:1.0249,  val_accuracy:0.5308,  val_loss:1.0009,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5120,  loss:1.0235,  val_accuracy:0.5316,  val_loss:1.0006,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5150,  loss:1.0209,  val_accuracy:0.5368,  val_loss:0.9998,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5211,  loss:1.0206,  val_accuracy:0.5338,  val_loss:0.9989,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5231,  loss:1.0144,  val_accuracy:0.5361,  val_loss:0.9991,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5218,  loss:1.0195,  val_accuracy:0.5376,  val_loss:0.9988,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5169,  loss:1.0197,  val_accuracy:0.5383,  val_loss:0.9989,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, accuracy:0.5237,  loss:1.0166,  val_accuracy:0.5376,  val_loss:0.9971,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, accuracy:0.5158,  loss:1.0170,  val_accuracy:0.5368,  val_loss:0.9989,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, accuracy:0.5190,  loss:1.0167,  val_accuracy:0.5414,  val_loss:0.9975,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, accuracy:0.5245,  loss:1.0172,  val_accuracy:0.5316,  val_loss:0.9970,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, accuracy:0.5248,  loss:1.0158,  val_accuracy:0.5406,  val_loss:0.9988,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, accuracy:0.5258,  loss:1.0147,  val_accuracy:0.5368,  val_loss:0.9957,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, accuracy:0.5167,  loss:1.0173,  val_accuracy:0.5391,  val_loss:0.9968,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, accuracy:0.5231,  loss:1.0176,  val_accuracy:0.5338,  val_loss:0.9964,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, accuracy:0.5267,  loss:1.0180,  val_accuracy:0.5421,  val_loss:0.9952,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, accuracy:0.5260,  loss:1.0131,  val_accuracy:0.5368,  val_loss:0.9974,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, accuracy:0.5213,  loss:1.0186,  val_accuracy:0.5391,  val_loss:0.9972,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, accuracy:0.5250,  loss:1.0127,  val_accuracy:0.5353,  val_loss:0.9951,  \n",
      "....................................................................................................\n",
      "Epoch: 3000, accuracy:0.5235,  loss:1.0154,  val_accuracy:0.5353,  val_loss:0.9991,  \n",
      "....................................................................................................\n",
      "Epoch: 3100, accuracy:0.5141,  loss:1.0183,  val_accuracy:0.5376,  val_loss:0.9947,  \n",
      "....................................................................................................\n",
      "Epoch: 3200, accuracy:0.5246,  loss:1.0161,  val_accuracy:0.5353,  val_loss:0.9957,  \n",
      "....................................................................................................\n",
      "Epoch: 3300, accuracy:0.5201,  loss:1.0116,  val_accuracy:0.5398,  val_loss:0.9944,  \n",
      "....................................................................................................\n",
      "Epoch: 3400, accuracy:0.5248,  loss:1.0153,  val_accuracy:0.5338,  val_loss:0.9942,  \n",
      "....................................................................................................\n",
      "Epoch: 3500, accuracy:0.5248,  loss:1.0115,  val_accuracy:0.5383,  val_loss:0.9948,  \n",
      "....................................................................................................\n",
      "Epoch: 3600, accuracy:0.5292,  loss:1.0102,  val_accuracy:0.5414,  val_loss:0.9945,  \n",
      "..........................................Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_118 (Dense)            (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 952\n",
      "Trainable params: 952\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.3814,  loss:1.1566,  val_accuracy:0.4627,  val_loss:1.1454,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5240,  loss:1.0087,  val_accuracy:0.5322,  val_loss:0.9970,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5231,  loss:1.0079,  val_accuracy:0.5322,  val_loss:0.9939,  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5185,  loss:1.0047,  val_accuracy:0.5302,  val_loss:0.9935,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5189,  loss:1.0077,  val_accuracy:0.5302,  val_loss:0.9926,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5229,  loss:1.0050,  val_accuracy:0.5310,  val_loss:0.9916,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5217,  loss:1.0031,  val_accuracy:0.5302,  val_loss:0.9921,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5236,  loss:1.0024,  val_accuracy:0.5292,  val_loss:0.9918,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5231,  loss:1.0040,  val_accuracy:0.5315,  val_loss:0.9909,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5219,  loss:1.0046,  val_accuracy:0.5327,  val_loss:0.9907,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5221,  loss:1.0046,  val_accuracy:0.5299,  val_loss:0.9906,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5229,  loss:1.0060,  val_accuracy:0.5330,  val_loss:0.9901,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5208,  loss:1.0055,  val_accuracy:0.5310,  val_loss:0.9902,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5218,  loss:1.0030,  val_accuracy:0.5335,  val_loss:0.9899,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5215,  loss:1.0036,  val_accuracy:0.5340,  val_loss:0.9900,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5215,  loss:1.0024,  val_accuracy:0.5337,  val_loss:0.9897,  \n",
      "...................................................................................................Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_124 (Dense)            (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dropout_98 (Dropout)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dropout_100 (Dropout)        (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 3)                 90        \n",
      "=================================================================\n",
      "Total params: 4,440\n",
      "Trainable params: 4,440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.3123,  loss:1.2426,  val_accuracy:0.4869,  val_loss:1.2287,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5163,  loss:1.0215,  val_accuracy:0.5430,  val_loss:0.9966,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5258,  loss:1.0117,  val_accuracy:0.5497,  val_loss:0.9868,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5247,  loss:1.0086,  val_accuracy:0.5475,  val_loss:0.9843,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5245,  loss:1.0073,  val_accuracy:0.5438,  val_loss:0.9835,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5286,  loss:1.0040,  val_accuracy:0.5490,  val_loss:0.9805,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5307,  loss:1.0024,  val_accuracy:0.5438,  val_loss:0.9800,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5208,  loss:1.0060,  val_accuracy:0.5572,  val_loss:0.9749,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5283,  loss:1.0024,  val_accuracy:0.5475,  val_loss:0.9783,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5318,  loss:0.9997,  val_accuracy:0.5647,  val_loss:0.9719,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5327,  loss:0.9987,  val_accuracy:0.5497,  val_loss:0.9742,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5284,  loss:0.9996,  val_accuracy:0.5527,  val_loss:0.9743,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.5337,  loss:0.9970,  val_accuracy:0.5490,  val_loss:0.9775,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.5384,  loss:0.9945,  val_accuracy:0.5520,  val_loss:0.9760,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.5348,  loss:0.9959,  val_accuracy:0.5490,  val_loss:0.9762,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.5335,  loss:0.9961,  val_accuracy:0.5557,  val_loss:0.9729,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.5356,  loss:0.9916,  val_accuracy:0.5520,  val_loss:0.9728,  \n",
      "..Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_130 (Dense)            (None, 21)                462       \n",
      "_________________________________________________________________\n",
      "dropout_101 (Dropout)        (None, 21)                0         \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 5)                 110       \n",
      "_________________________________________________________________\n",
      "dropout_102 (Dropout)        (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dropout_103 (Dropout)        (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dropout_104 (Dropout)        (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dropout_105 (Dropout)        (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 680\n",
      "Trainable params: 680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, accuracy:0.4207,  loss:1.1373,  val_accuracy:0.4488,  val_loss:1.1341,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.4639,  loss:1.0470,  val_accuracy:0.4488,  val_loss:1.0393,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.4639,  loss:1.0384,  val_accuracy:0.4488,  val_loss:1.0298,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.4639,  loss:1.0343,  val_accuracy:0.4488,  val_loss:1.0249,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.4639,  loss:1.0298,  val_accuracy:0.4488,  val_loss:1.0212,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.4639,  loss:1.0304,  val_accuracy:0.4488,  val_loss:1.0198,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.4639,  loss:1.0301,  val_accuracy:0.4488,  val_loss:1.0200,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.4639,  loss:1.0206,  val_accuracy:0.4488,  val_loss:1.0185,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.4639,  loss:1.0340,  val_accuracy:0.4488,  val_loss:1.0190,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.4639,  loss:1.0271,  val_accuracy:0.4488,  val_loss:1.0162,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.4639,  loss:1.0271,  val_accuracy:0.4488,  val_loss:1.0168,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.4639,  loss:1.0326,  val_accuracy:0.4488,  val_loss:1.0167,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, accuracy:0.4639,  loss:1.0231,  val_accuracy:0.4488,  val_loss:1.0155,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, accuracy:0.4639,  loss:1.0287,  val_accuracy:0.4488,  val_loss:1.0154,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, accuracy:0.4639,  loss:1.0244,  val_accuracy:0.4488,  val_loss:1.0156,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, accuracy:0.4639,  loss:1.0287,  val_accuracy:0.4488,  val_loss:1.0152,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, accuracy:0.4639,  loss:1.0250,  val_accuracy:0.4488,  val_loss:1.0147,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, accuracy:0.5041,  loss:1.0283,  val_accuracy:0.5206,  val_loss:1.0153,  \n",
      "........."
     ]
    }
   ],
   "source": [
    "##### Model04:\n",
    "\n",
    "l2_drop_model04_H1_H = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X04.shape[1],)), # 25 feature\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(25, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "l2_drop_model05_H1_H = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(33, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "l2_drop_model02_H1_M = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(12, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "##### Model01:\n",
    "\n",
    "l2_drop_model01_H1_L = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(4, activation='relu',kernel_regularizer=regularizers.l2(0.001)), \n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "### 2 Hidden Layers:\n",
    "#### High Amount of Neurons (H):\n",
    "\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "l2_drop_model03_H2_H = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(29, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(29, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "l2_drop_model04_H2_M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "l2_drop_model05_H2_L = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(8, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(8, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "### 3 Hidden Layers:\n",
    "#### High Amount of Neurons (H):\n",
    "##### Model01:\n",
    "\n",
    "l2_drop_model01_H3_H = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "l2_drop_model04_H3_M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "l2_drop_model02_H3_L = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(5, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(5, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(5, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "l2_drop_model03_H3_L = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(7, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(7, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(7, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "#### Funnel Architecture:\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "l2_drop_model05_H3_F = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(25, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(19, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(12, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(6, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "### 4 Hidden Layers:\n",
    "#### High Amount of Neurons (H):\n",
    "##### Model01:\n",
    "\n",
    "l2_drop_model01_H4_H = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(13, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "l2_drop_model03_H4_H = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(29, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(29, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(29, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(29, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "l2_drop_model02_H4_L = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',kernel_regularizer=regularizers.l2(0.001),input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(5, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(5, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(5, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(5, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# H1_H\n",
    "size_histories['l2_drop_model04_H1_H'] = compile_and_fit(l2_drop_model04_H1_H, 'l2_drop_model04_H1_H', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['l2_drop_model05_H1_H'] = compile_and_fit(l2_drop_model05_H1_H, 'l2_drop_model05_H1_H', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H1_Ml2_\n",
    "size_histories['l2_drop_model02_H1_M'] = compile_and_fit(l2_drop_model02_H1_M, 'l2_drop_model02_H1_M', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H1_Ll2_\n",
    "size_histories['l2_drop_model01_H1_L'] = compile_and_fit(l2_drop_model01_H1_L, 'l2_drop_model01_H1_L', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H2_H\n",
    "size_histories['l2_drop_model03_H2_H'] = compile_and_fit(l2_drop_model03_H2_H, 'l2_drop_model03_H2_H', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H2_M\n",
    "size_histories['l2_drop_model04_H2_M'] = compile_and_fit(l2_drop_model04_H2_M, 'l2_drop_model04_H2_M', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H2_L\n",
    "size_histories['l2_drop_model05_H2_L'] = compile_and_fit(l2_drop_model05_H2_L, 'l2_drop_model05_H2_L', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3_H\n",
    "size_histories['l2_drop_model01_H3_H'] = compile_and_fit(l2_drop_model01_H3_H, 'l2_drop_model01_H3_H', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3_M\n",
    "size_histories['l2_drop_model04_H3_M'] = compile_and_fit(l2_drop_model04_H3_M, 'l2_drop_model04_H3_M', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3_L\n",
    "size_histories['l2_drop_model02_H3_L'] = compile_and_fit(l2_drop_model02_H3_L, 'l2_drop_model02_H3_L', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['l2_drop_model03_H3_L'] = compile_and_fit(l2_drop_model03_H3_L, 'l2_drop_model03_H3_L', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3_F\n",
    "size_histories['l2_drop_model05_H3_F'] = compile_and_fit(l2_drop_model05_H3_F, 'l2_drop_model05_H3_F', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H4_H\n",
    "size_histories['l2_drop_model01_H4_H'] = compile_and_fit(l2_drop_model01_H4_H, 'l2_drop_model01_H4_H', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['l2_drop_model03_H4_H'] = compile_and_fit(l2_drop_model03_H4_H, 'l2_drop_model03_H4_H', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H4_L\n",
    "size_histories['l2_drop_model02_H4_L'] = compile_and_fit(l2_drop_model02_H4_L, 'l2_drop_model02_H4_L', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "1DwuhGCJH2yL",
    "outputId": "13ba4f8a-0516-4937-d37a-8b0130fc5a56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2_drop_model04_H1_H\n",
      "Test Score: 0.9925440107073102\n",
      "Test Accuracy: 0.54571426\n",
      "#####\n",
      "l2_drop_model05_H1_H\n",
      "Test Score: 1.0030996016093663\n",
      "Test Accuracy: 0.5\n",
      "#####\n",
      "l2_drop_model02_H1_M\n",
      "Test Score: 0.9829188747839495\n",
      "Test Accuracy: 0.5426136\n",
      "#####\n",
      "l2_drop_model01_H1_L\n",
      "Test Score: 0.9763588614747529\n",
      "Test Accuracy: 0.54702497\n",
      "#####\n",
      "l2_drop_model03_H2_H\n",
      "Test Score: 0.9698443629524924\n",
      "Test Accuracy: 0.53125\n",
      "#####\n",
      "l2_drop_model04_H2_M\n",
      "Test Score: 0.9935530274254936\n",
      "Test Accuracy: 0.5371429\n",
      "#####\n",
      "l2_drop_model05_H2_L\n",
      "Test Score: 1.014468056815011\n",
      "Test Accuracy: 0.50285715\n",
      "#####\n",
      "l2_drop_model02_H3_H\n",
      "Test Score: 0.9712221226628134\n",
      "Test Accuracy: 0.54798466\n",
      "#####\n",
      "l2_drop_model04_H3_M\n",
      "Test Score: 0.9995487311908177\n",
      "Test Accuracy: 0.5342857\n",
      "#####\n",
      "l2_model02_H3_L\n",
      "Test Score: 0.9982757839289579\n",
      "Test Accuracy: 0.54545456\n",
      "#####\n",
      "l2_drop_model03_H3_L\n",
      "Test Score: 0.9791314927014437\n",
      "Test Accuracy: 0.53977275\n",
      "#####\n",
      "l2_drop_model05_H3_F\n",
      "Test Score: 1.0078801485470363\n",
      "Test Accuracy: 0.50285715\n",
      "#####\n",
      "l2_drop_model02_H4_H\n",
      "Test Score: 0.980391783357353\n",
      "Test Accuracy: 0.54894435\n",
      "#####\n",
      "l2_drop_model03_H4_H\n",
      "Test Score: 0.977168083190918\n",
      "Test Accuracy: 0.53409094\n",
      "#####\n",
      "l2_drop_model02_H4_L\n",
      "Test Score: 1.019774079322815\n",
      "Test Accuracy: 0.45170453\n",
      "#####\n"
     ]
    }
   ],
   "source": [
    "# H1_H\n",
    "score = load_model('../model/l2_drop_model04_H1_H.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"l2_drop_model04_H1_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/l2_drop_model05_H1_H.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"l2_drop_model05_H1_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H1_M\n",
    "\n",
    "score = load_model('../model/l2_drop_model02_H1_M.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"l2_drop_model02_H1_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "\n",
    "# H1_L\n",
    "score = load_model('../model/l2_drop_model01_H1_L.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"l2_drop_model01_H1_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "\n",
    "# H2_H\n",
    "\n",
    "\n",
    "score = load_model('../model/l2_drop_model03_H2_H.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"l2_drop_model03_H2_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "\n",
    "# H2_M\n",
    "\n",
    "\n",
    "score = load_model('../model/l2_drop_model04_H2_M.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"l2_drop_model04_H2_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H2_L\n",
    "\n",
    "score = load_model('../model/l2_drop_model05_H2_L.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"l2_drop_model05_H2_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H3_H\n",
    "score = load_model('../model/l2_drop_model01_H3_H.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"l2_drop_model02_H3_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "\n",
    "# H3_M\n",
    "\n",
    "score = load_model('../model/l2_drop_model04_H3_M.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"l2_drop_model04_H3_M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H3_L\n",
    "\n",
    "score = load_model('../model/l2_drop_model02_H3_L.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"l2_model02_H3_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/l2_drop_model03_H3_L.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"l2_drop_model03_H3_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H3_F\n",
    "score = load_model('../model/l2_drop_model05_H3_F.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"l2_drop_model05_H3_F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H4_H\n",
    "score = load_model('../model/l2_drop_model01_H4_H.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"l2_drop_model02_H4_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "\n",
    "score = load_model('../model/l2_drop_model03_H4_H.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"l2_drop_model03_H4_H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H4_L\n",
    "\n",
    "score = load_model('../model/l2_drop_model02_H4_L.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"l2_drop_model02_H4_L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "colab-nn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
