%!TEX root = ../../main.tex

\chapter{Evaluation}
In this phase of the CRISP-DM, we have carried out the process evaluation of the the models and the features which we have previously generated.\newline

\section{Prediction of the final result}
In this part, the evaluation criteria for the models and in the same way for the features which are used, have based on the test-accuracy. We have reached the highest accuracy jet, have been 56.25\% with the Sliding Window Option 1, which means with the highest amount of features. The more features, the less training samples are there for the training, so it could be better to train with more samples and less features. But because of the reason that every models are in the same range, which means there is no model which has a much smaller accuracy, it is not possible to tell the one with the highest accuracy as the best model or has the best feature selection in every case. Better accuracy might be reached using another model with different data or a higher or smaller amount of features rather than the one which reached the highest accuracy in the actual case. The first ranked model has used Keras Sequantial Neural Network, as shown in \autoref{table:coparison_of_classifiers}:

\begin{table}[H]
\centering
\begin{tabular}{|p{2.5cm}|p{2.5cm}|p{2.5cm}|p{2.5cm}|p{2.5cm}|}
\hline

\textbf{Rank} & \textbf{Model} & \textbf{Sliding Window Option} & \textbf{Parameters} & \textbf{Test-Accuracy} \\ \hline
\textbf{1} & Keras Sequential Neural Network & 3 & Hidden layers: 2 (21, 21 neurons) & 0.5625 \\ \hline
\textbf{2} & Multi-layer Perceptron & 1 & Hidden layers: 2 (52, 32 neurons) & 0.5345 \\ \hline
\textbf{3} & Decision Tree & 1 & Depth = 4 & 0.5295 \\ \hline

\end{tabular}
\caption{Comparison of classifiers}
\label{table:coparison_of_classifiers}
\end{table}

As the reader can see in the table \autoref{table:coparison_of_classifiers}, too. It is not even possible to tell, that the more features, the better the outcome will be. For example with the Multi-layer Perceptron one might get a worse accuracy with more features. But for the actual situation use of the first ranked model for predicting the outcome for football games is recommended, but in the future a different model with other features could be better.

\section{Predicting the final goals}
In this part, we have described the evaluation criteria which we used in order to compare the models. First, a own quality criteria was created to ensure that there is a possibility to compare regression results and classification results. Second, test-accuracy was used.
\subsection{Quality Criteria}
The self made quality criteria is divided into two parts: Rounding the predicted values and calculating the score.

\subsubsection{Round the predicted values}

The main idea of creating a rounding function is to assign the predicted values of the model to the nearest real class.
For example, if one predicts 0.54, it will be rounded to 0.6 because it is between 0.33 and 0.67.
0.60 is the encoded value to score 4 goals, as shown in the decoded value column.
The following table shows the intervals of all possible values that can be predicted and the associated decoded value.

\begin{table}[H]
    \centering
    \resizebox{12cm}{!}{%
    \begin{tabular}{|l|l|l|}
    \hline
    
    \textbf{Predicted value Range} & \textbf{Round predicted value} & \textbf{Decoded value} \\ \hline
    \textbf{ [-1, -0.67[} & -1 & 0 \\ \hline
    \textbf{ ]-0.67, -0.33]} & -0.60 & 1  \\ \hline
    \textbf{ ]-0.33, 0]} & -0.20 & 2 \\ \hline
    \textbf{ ]0, 0.33]} & 0.20 & 3 \\ \hline
    \textbf{ ]0.33, 0.67]} & 0.60 & 4 \\ \hline
    \textbf{ ]0.67, 1]} & 1 & 5 \\ \hline
    \end{tabular}
    }
    \caption{Round and Decode predicted values}
    \label{table:qualitycriteriaround}
    \end{table}
The decoding function is used both in the predicted values and in the original values before comparing them and calculating the scores. This function is defined to facilitate the comparison process.

\subsubsection{Calculate the scores}

We have calculated, at first the absolute value between the original value 
and that predicted between the goals scored by the home team and the away team to calculate the scores.
Then, this calculated value which is between 0 and 5 to a value between 0 and 1 has been encoded in range of 0 to 5. 
0 goal corresponds to a score equal to 1 and 5 goals corresponds to a score equal to 0.
The following table shows all the possible values.


\begin{table}[H]
    \centering
    \resizebox{8cm}{!}{%
    \begin{tabular}{|l|l|}
    \hline
    
    \textbf{Abs (yoriginal - ypred)} & \textbf{Degree difference}  \\ \hline
    \textbf{0} & 1 \\ \hline
    \textbf{1} & 0.8  \\ \hline
    \textbf{2} & 0.6 \\ \hline
    \textbf{3} & 0.4 \\ \hline
    \textbf{4} & 0.2 \\ \hline
    \textbf{5} & 0 \\ \hline
    \end{tabular}
    }
    \caption{Calculate the degree difference}
    \label{table:degreedifferencecalculate}
\end{table}

After calculating the difference in degree for goals scored for home and away teams, we have calculated the score which is the average of the two columns. The final result calculated would be be the average of all the rows in the table which is between 0 and 1.

\subsection{Comparing the regressors}
In this section, we have highlighted the different regressor models created for two different datasets with different features and then these models are compared to find the best model to make predictions on the new data or test data, three different models using tried trial and error to set parameters and hiddenlayers units are created.\newline 
In classification tasks, it is easy to calculate sensitivity or specificity of classifier because output is always binary {correct classification, incorrect classification}. So it is possible to count good/bad answers and based on the confusion matrix calculate some measurements. But in regression tasks, the output is a number. So it is not possible to just say is it correct or incorrect but instead it is necessary to measure "how far from true solution is it" by either calculating coefficient of determination Rsquare or by focusing on minimizing the mean squared error also known as loss. That is why in the regression models, the loss for validation as well as for training is calculated.
\subsubsection{Performance of Machine Learning regressors}
Multioutput regressor(Gradient Bossting Regressor)\newline
The final training accuracy Final is 20.59\%, training accuracy home team goals is 17.10\% and training accuracy away team goals: 24.08\% \newline
The final test accuracy for gradient booster is 18.89\% , test accuracy for home team goals is 12.93\% and test accuracy for away team goals is 24.86\%. Also, the coefficient of determination R square value of the prediction is calculated to be 0.1612.\newline
Multioutput regressor(Support Vector Regressor)\newline
The final training accuracy Final is 16.22\%, training accuracy home team goals is 13\% and training accuracy away team goals: 19.43\% \newline
The final test accuracy for gradient booster is 16.26\% , test accuracy for home team goals is 10.51\% and test accuracy for away team goals is 22.02\%. Also, the coefficient of determination R square value of the prediction is calculated to be 0.0882 \newline
Decision Tree regressor\newline
The final training accuracy Final is 23.18\%, training accuracy home team goals is 32.53\% and training accuracy away team goals: 13.83\% \newline
The final test accuracy for gradient booster is 22.37\% , test accuracy for home team goals is 30.82\% and test accuracy for away team goals is 13.83\%. Also, the coefficient of determination R square of the prediction is calculated to be 0.0898\newline 
Random Forest Regressor\newline
The final training accuracy Final is 45.47\%, training accuracy home team goals is 43.53\% and training accuracy away team goals: 47.42\% \newline
The final test accuracy for gradient booster is 16.12\% , test accuracy for home team goals is 14.06\% and test accuracy for away team goals is 18.18\%. Also, the coefficient of determination R square of the prediction is calculated to be 0.0845 \newline 
Multi-layer perceptron regressor(using Adam Optimizer)\newline
The final training accuracy Final is 18.53\%, training accuracy home team goals is 14.02\% and training accuracy away team goals: 23.04\% \newline
The final test accuracy for gradient booster is 18.82\% , test accuracy for home team goals is 11.36\% and test accuracy for away team goals is 26.28\%. Also, the coefficient of determination R square of the prediction is calculated to be 0.1538 \newline
Multi-layer perceptron regressor(using Stochastic Gradient optimizer)\newline
The final training accuracy Final is 15.01\%, training accuracy home team goals is 0.14\% and training accuracy away team goals: 29.88\% \newline
The final test accuracy for gradient booster is 15.20\% , test accuracy for home team goals is 0.14\% and test accuracy for away team goals is 30.26\%. Also, the coefficient of determination R square of the prediction is calculated to be negative 0.0015 \newline 
The r square value of the model must be in between 0 and 1 and as close to 1 is the better.\newline
As observed, none of the regressor model using machine learning algorithms has provided us the satisfactory accuracy to use it in backend of our website. Hence, we have decided to use deep learning with tensorflow and keras to perform regression.\newline
\subsubsection{Performance of Deep Learning regressors}
We have created three different artificial neural networks using sequential model of scikit. For all the three models, input units have been taken equal to features that is 21 units and as the models are predicting two outputs- Home Team Goals and Away Team Goals, the output layers are having 2 units or neurons. For the dataset sliding02, we have 3 hidden layers from which first hidden layer has 30 units which makes the neural network densely connected with 20 units in the second hidden layer and 10 in the third hidden layer. We have trained the model and while training the model, the validation accuracy of 68 percent and Training accuracy of 70 percent is noted. For second model, we have used three hidden layers with 21 units in first hidden layer making the artificial neural network as fullyconnected, 10 units in second hidden layer and 5 in third hidden layer which resulted in validation accuracy of 66 percent and training accuracy of 72 percent. 
And we have created third model in which we have used 4 hidden layers with 21 units in first hidden layer layer, 14 units in second hidden layer, 12 units in third hidden layer and 10 units in last hidden layer which results in validation accuracy of 56 percent and training accuracy of 69 percent.\newline
Similarly, similar experiments have been made with dataset sliding03 as well. For all the models the evaluation of the quality for each team and for both training dataset and test dataset using the quality criteria defined in the above section is done. The evaluated qualities for all three models for dataset sliding02 and sliding03 are displayed in the respective tables \autoref{table:qualitymodelregression1} and \autoref{table:qualitymodelregression2} where QM is abbreviation of Quality Model, HG is abbreviation of Home goals and AG is abbreviation of Away goals\newline

\begin{table}
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline

\textbf{Dataset
Sliding02
Models
} & \textbf{QM-HG-Train} & \textbf{QM-AG-Train} & \textbf{FinalQM- Train} & \textbf{QM-HG-Test} & \textbf{ QM-AG-Test } & \textbf{ FinalQM- Test} \\ \hline
\textbf{ Model1 } & 0.83 & 0.84 & 0.83 & 0.81 & 0.83 & 0.82 \\ \hline
\textbf{ Model2 } & 0.82 & 0.84 & 0.83 & 0.81 & 0.84 & 0.83 \\ \hline
\textbf{ Model3 } & 0.82 & 0.84 & 0.83 & 0.81 & 0.84 & 0.83 \\ \hline
\end{tabular}
}
\caption{ Quality Model for models with different hidden units for dataset sliding02}
\label{table:qualitymodelregression1}
\end{table}



\begin{table}
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline

\textbf{Dataset
Sliding03
Models
} & \textbf{QM-HG-Train} & \textbf{QM-AG-Train} & \textbf{FinalQM- Train} & \textbf{QM-HG-Test} & \textbf{ QM-AG-Test } & \textbf{ FinalQM- Test} \\ \hline
\textbf{ Model1 } & 0.83 & 0.84 & 0.84 & 0.81 & 0.83 & 0.82 \\ \hline
\textbf{ Model2 } & 0.80 & 0.83 & 0.82 & 0.80 & 0.84 & 0.82 \\ \hline
\textbf{ Model3 } & 0.83 & 0.84 & 0.83 & 0.81 & 0.84 & 0.82 \\ \hline
\end{tabular}
}
\caption{ Quality Model for models with different hidden units for dataset sliding03}
\label{table:qualitymodelregression2}
\end{table}

We hav eobserved that the first model from dataset sliding02 proves to be the best model during the tests as the  validation and training accuracy of this model is better than the other models with a percentage of 68 percent and 72 percent respectively, ideally the validation accuracy must be slightly better than the training accuracy to prevent overfitting of the model. Because if the training loss is higher than validation loss then there are chances of overfitting and if the training loss is very less than validation loss then there are chances of underfitting. But still the validation accuracy is quite lower than the training accuracy.\newline
Also, one goal is to minimize the mse that is mean squared error in order to get predictions on test data as close to actual data, this model provides the minimum training mse of 0.19 and validation mse of 0.21. So it can be considered as the best model.\newline
Using quality criteria defined, we have calculated a final quality of performance for model 1 for Training data is 83 percent and for test data it is 82 percent. One important point is, that the quality evaluation for all the models are showing almost similar values to each other. This is not an ideal solution, so there are lot of scope of improvement in the project.\newline

\subsection{Comparing Regression with Multi Class Classification}
We have observed that the Multi Class Classification has still many possibilities to improve, so in this point we have only compared the actual model with the best regression model. For this we have used the self made Quality Criteria, but as it is described in the part `Quality Criteria', the used quality criteria has some flaws and can be considered for further improvements in the future. Because of this, we have also used the test accuracy for the comparison. For the Multi Class Classification approach, the model has achieved a test accuracy of 30.54\% for the away team and 37.64\% for the home team, which makes an average of 34.09\%. The regression model has achieved a test accuracy of 46.68\%. The self made quality criteria also used which have reached the average of  80.38\% (77.30\% for the home team and 83.47\% for the away team) with the Multi Class Classification and an average of 82\%(82\% for the home team and 83\% for the away team) with the regression approach. We have decided to use the reression model for the home page over classification model because of the better results achieved with the regression model. However by making suitable improvements in the regression and the Multi Class Classification, this can be changed.